<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Functional Programming in Lean</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="custom.css">
        <link rel="stylesheet" href="pygments.css">
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="title.html">Functional Programming in Lean</a></li><li class="chapter-item expanded affix "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><a href="acknowledgments.html">Acknowledgments</a></li><li class="chapter-item expanded "><a href="getting-to-know.html"><strong aria-hidden="true">1.</strong> Getting to Know Lean</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="getting-to-know/evaluating.html"><strong aria-hidden="true">1.1.</strong> Evaluating Expressions</a></li><li class="chapter-item expanded "><a href="getting-to-know/types.html"><strong aria-hidden="true">1.2.</strong> Types</a></li><li class="chapter-item expanded "><a href="getting-to-know/functions-and-definitions.html"><strong aria-hidden="true">1.3.</strong> Functions and Definitions</a></li><li class="chapter-item expanded "><a href="getting-to-know/structures.html"><strong aria-hidden="true">1.4.</strong> Structures</a></li><li class="chapter-item expanded "><a href="getting-to-know/datatypes-and-patterns.html"><strong aria-hidden="true">1.5.</strong> Datatypes, Patterns and Recursion</a></li><li class="chapter-item expanded "><a href="getting-to-know/polymorphism.html"><strong aria-hidden="true">1.6.</strong> Polymorphism</a></li><li class="chapter-item expanded "><a href="getting-to-know/conveniences.html"><strong aria-hidden="true">1.7.</strong> Additional Conveniences</a></li><li class="chapter-item expanded "><a href="getting-to-know/summary.html"><strong aria-hidden="true">1.8.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="hello-world.html"><strong aria-hidden="true">2.</strong> Hello, World!</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="hello-world/running-a-program.html"><strong aria-hidden="true">2.1.</strong> Running a Program</a></li><li class="chapter-item expanded "><a href="hello-world/step-by-step.html"><strong aria-hidden="true">2.2.</strong> Step By Step</a></li><li class="chapter-item expanded "><a href="hello-world/starting-a-project.html"><strong aria-hidden="true">2.3.</strong> Starting a Project</a></li><li class="chapter-item expanded "><a href="hello-world/cat.html"><strong aria-hidden="true">2.4.</strong> Worked Example: cat</a></li><li class="chapter-item expanded "><a href="hello-world/conveniences.html"><strong aria-hidden="true">2.5.</strong> Additional Conveniences</a></li><li class="chapter-item expanded "><a href="hello-world/summary.html"><strong aria-hidden="true">2.6.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="props-proofs-indexing.html"><strong aria-hidden="true">3.</strong> Interlude: Propositions, Proofs, and Indexing</a></li><li class="chapter-item expanded "><a href="type-classes.html"><strong aria-hidden="true">4.</strong> Overloading and Type Classes</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="type-classes/pos.html"><strong aria-hidden="true">4.1.</strong> Positive Numbers</a></li><li class="chapter-item expanded "><a href="type-classes/polymorphism.html"><strong aria-hidden="true">4.2.</strong> Type Classes and Polymorphism</a></li><li class="chapter-item expanded "><a href="type-classes/out-params.html"><strong aria-hidden="true">4.3.</strong> Controlling Instance Search</a></li><li class="chapter-item expanded "><a href="type-classes/indexing.html"><strong aria-hidden="true">4.4.</strong> Arrays and Indexing</a></li><li class="chapter-item expanded "><a href="type-classes/standard-classes.html"><strong aria-hidden="true">4.5.</strong> Standard Classes</a></li><li class="chapter-item expanded "><a href="type-classes/coercion.html"><strong aria-hidden="true">4.6.</strong> Coercions</a></li><li class="chapter-item expanded "><a href="type-classes/conveniences.html"><strong aria-hidden="true">4.7.</strong> Additional Conveniences</a></li><li class="chapter-item expanded "><a href="type-classes/summary.html"><strong aria-hidden="true">4.8.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="monads.html"><strong aria-hidden="true">5.</strong> Monads</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="monads/class.html"><strong aria-hidden="true">5.1.</strong> The Monad Type Class</a></li><li class="chapter-item expanded "><a href="monads/arithmetic.html"><strong aria-hidden="true">5.2.</strong> Example: Arithmetic in Monads</a></li><li class="chapter-item expanded "><a href="monads/do.html"><strong aria-hidden="true">5.3.</strong> do-Notation for Monads</a></li><li class="chapter-item expanded "><a href="monads/io.html"><strong aria-hidden="true">5.4.</strong> The IO Monad</a></li><li class="chapter-item expanded "><a href="monads/conveniences.html"><strong aria-hidden="true">5.5.</strong> Additional Conveniences</a></li><li class="chapter-item expanded "><a href="monads/summary.html"><strong aria-hidden="true">5.6.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="functor-applicative-monad.html"><strong aria-hidden="true">6.</strong> Functors, Applicative Functors, and Monads</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="functor-applicative-monad/inheritance.html"><strong aria-hidden="true">6.1.</strong> Structures and Inheritance</a></li><li class="chapter-item expanded "><a href="functor-applicative-monad/applicative.html"><strong aria-hidden="true">6.2.</strong> Applicative Functors</a></li><li class="chapter-item expanded "><a href="functor-applicative-monad/applicative-contract.html"><strong aria-hidden="true">6.3.</strong> The Applicative Contract</a></li><li class="chapter-item expanded "><a href="functor-applicative-monad/alternative.html"><strong aria-hidden="true">6.4.</strong> Alternatives</a></li><li class="chapter-item expanded "><a href="functor-applicative-monad/universes.html"><strong aria-hidden="true">6.5.</strong> Universes</a></li><li class="chapter-item expanded "><a href="functor-applicative-monad/complete.html"><strong aria-hidden="true">6.6.</strong> The Complete Definitions</a></li><li class="chapter-item expanded "><a href="functor-applicative-monad/summary.html"><strong aria-hidden="true">6.7.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="monad-transformers.html"><strong aria-hidden="true">7.</strong> Monad Transformers</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="monad-transformers/reader-io.html"><strong aria-hidden="true">7.1.</strong> Combining IO and Reader</a></li><li class="chapter-item expanded "><a href="monad-transformers/transformers.html"><strong aria-hidden="true">7.2.</strong> A Monad Construction Kit</a></li><li class="chapter-item expanded "><a href="monad-transformers/order.html"><strong aria-hidden="true">7.3.</strong> Ordering Monad Transformers</a></li><li class="chapter-item expanded "><a href="monad-transformers/do.html"><strong aria-hidden="true">7.4.</strong> More do Features</a></li><li class="chapter-item expanded "><a href="monad-transformers/conveniences.html"><strong aria-hidden="true">7.5.</strong> Additional Conveniences</a></li><li class="chapter-item expanded "><a href="monad-transformers/summary.html"><strong aria-hidden="true">7.6.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="dependent-types.html"><strong aria-hidden="true">8.</strong> Programming with Dependent Types</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="dependent-types/indexed-families.html"><strong aria-hidden="true">8.1.</strong> Indexed Families</a></li><li class="chapter-item expanded "><a href="dependent-types/universe-pattern.html"><strong aria-hidden="true">8.2.</strong> The Universe Design Pattern</a></li><li class="chapter-item expanded "><a href="dependent-types/typed-queries.html"><strong aria-hidden="true">8.3.</strong> Worked Example: Typed Queries</a></li><li class="chapter-item expanded "><a href="dependent-types/indices-parameters-universes.html"><strong aria-hidden="true">8.4.</strong> Indices, Parameters, and Universe Levels</a></li><li class="chapter-item expanded "><a href="dependent-types/pitfalls.html"><strong aria-hidden="true">8.5.</strong> Pitfalls of Programming with Dependent Types</a></li><li class="chapter-item expanded "><a href="dependent-types/summary.html"><strong aria-hidden="true">8.6.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="tactics-induction-proofs.html"><strong aria-hidden="true">9.</strong> Interlude: Tactics, Induction, and Proofs</a></li><li class="chapter-item expanded "><a href="programs-proofs.html"><strong aria-hidden="true">10.</strong> Programming, Proving, and Performance</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="programs-proofs/tail-recursion.html"><strong aria-hidden="true">10.1.</strong> Tail Recursion</a></li><li class="chapter-item expanded "><a href="programs-proofs/tail-recursion-proofs.html"><strong aria-hidden="true">10.2.</strong> Proving Equivalence</a></li><li class="chapter-item expanded "><a href="programs-proofs/arrays-termination.html"><strong aria-hidden="true">10.3.</strong> Arrays and Termination</a></li><li class="chapter-item expanded "><a href="programs-proofs/inequalities.html"><strong aria-hidden="true">10.4.</strong> More Inequalities</a></li><li class="chapter-item expanded "><a href="programs-proofs/fin.html"><strong aria-hidden="true">10.5.</strong> Safe Array Indices</a></li><li class="chapter-item expanded "><a href="programs-proofs/insertion-sort.html"><strong aria-hidden="true">10.6.</strong> Insertion Sort and Array Mutation</a></li><li class="chapter-item expanded "><a href="programs-proofs/special-types.html"><strong aria-hidden="true">10.7.</strong> Special Types</a></li><li class="chapter-item expanded "><a href="programs-proofs/summary.html"><strong aria-hidden="true">10.8.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="next-steps.html">Next Steps</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Functional Programming in Lean</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="functional-programming-in-lean"><a class="header" href="#functional-programming-in-lean">Functional Programming in Lean</a></h1>
<p><em>by David Thrane Christiansen</em></p>
<p><em>Copyright Microsoft Corporation 2023</em></p>
<p>This is an in-progress book on using Lean 4 as a programming language.
The most recent release is found at <a href="https://leanprover.github.io/functional_programming_in_lean/">https://leanprover.github.io/functional_programming_in_lean/</a>, and it will be updated monthly.
This version of the text is written for Lean 4 release <code>nightly-2023-05-22</code>.</p>
<h2 id="release-history"><a class="header" href="#release-history">Release history</a></h2>
<h3 id="may-2023"><a class="header" href="#may-2023">May, 2023</a></h3>
<p>The book is now complete! Compared to the April pre-release, many small details have been improved and minor mistakes have been fixed.</p>
<h3 id="april-2023"><a class="header" href="#april-2023">April, 2023</a></h3>
<p>This release adds an interlude on writing proofs with tactics as well as a final chapter that combines discussion of performance and cost models with proofs of termination and program equivalence.
This is the last release prior to the final release.</p>
<h3 id="march-2023"><a class="header" href="#march-2023">March, 2023</a></h3>
<p>This release adds a chapter on programming with dependent types and indexed families.</p>
<h3 id="january-2023"><a class="header" href="#january-2023">January, 2023</a></h3>
<p>This release adds a chapter on monad transformers that includes a description of the imperative features that are available in <code>do</code>-notation.</p>
<h3 id="december-2022"><a class="header" href="#december-2022">December, 2022</a></h3>
<p>This release adds a chapter on applicative functors that additionally describes structures and type classes in more detail.
This is accompanied with improvements to the description of monads.
The December 2022 release was delayed until January 2023 due to winter holidays.</p>
<h3 id="november-2022"><a class="header" href="#november-2022">November, 2022</a></h3>
<p>This release adds a chapter on programming with monads. Additionally, the example of using JSON in the coercions section has been updated to include the complete code.</p>
<h3 id="october-2022"><a class="header" href="#october-2022">October, 2022</a></h3>
<p>This release completes the chapter on type classes. In addition, a short interlude introducing propositions, proofs, and tactics has been added just before the chapter on type classes, because a small amount of familiarity with the concepts helps to understand some of the standard library type classes.</p>
<h3 id="september-2022"><a class="header" href="#september-2022">September, 2022</a></h3>
<p>This release adds the first half of a chapter on type classes, which are Lean's mechanism for overloading operators and an important means of organizing code and structuring libraries. Additionally, the second chapter has been updated to account for changes in Lean's stream API.</p>
<h3 id="august-2022"><a class="header" href="#august-2022">August, 2022</a></h3>
<p>This third public release adds a second chapter, which describes compiling and running programs along with Lean's model for side effects.</p>
<h3 id="july-2022"><a class="header" href="#july-2022">July, 2022</a></h3>
<p>The second public release completes the first chapter.</p>
<h3 id="june-2022"><a class="header" href="#june-2022">June, 2022</a></h3>
<p>This was the first public release, consisting of an introduction and part of the first chapter.</p>
<h2 id="about-the-author"><a class="header" href="#about-the-author">About the Author</a></h2>
<p>David Thrane Christiansen has been using functional languages for twenty years, and dependent types for ten.
Together with Daniel P. Friedman, he wrote <a href="https://thelittletyper.com/"><em>The Little Typer</em></a>, an introduction to the key ideas of dependent type theory.
He has a Ph.D. from the IT University of Copenhagen.
During his studies, he was a major contributor to the first version of the Idris language.
Since leaving academia, he has worked at Galois in Portland, Oregon and Deon Digital in Copenhagen, Denmark.
At the time of writing, he is the Executive Director of the Haskell Foundation.</p>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><p>Lean is an interactive theorem prover developed at Microsoft Research, based on dependent type theory.
Dependent type theory unites the worlds of programs and proofs; thus, Lean is also a programming language.
Lean takes its dual nature seriously, and it is designed to be suitable for use as a general-purpose programming language—Lean is even implemented in itself.
This book is about writing programs in Lean.</p>
<p>When viewed as a programming language, Lean is a strict pure functional language with dependent types.
A large part of learning to program with Lean consists of learning how each of these attributes affects the way programs are written, and how to think like a functional programmer.
<em>Strictness</em> means that function calls in Lean work similarly to the way they do in most languages: the arguments are fully computed before the function's body begins running.
<em>Purity</em> means that Lean programs cannot have side effects such as modifying locations in memory, sending emails, or deleting files without the program's type saying so.
Lean is a <em>functional</em> language in the sense that functions are first-class values like any other and that the execution model is inspired by the evaluation of mathematical expressions.
<em>Dependent types</em>, which are the most unusual feature of Lean, make types into a first-class part of the language, allowing types to contain programs and programs to compute types.</p>
<p>This book is intended for programmers who want to learn Lean, but who have not necessarily used a functional programming language before.
Familiarity with functional languages such as Haskell, OCaml, or F# is not required.
On the other hand, this book does assume knowledge of concepts like loops, functions, and data structures that are common to most programming languages.
While this book is intended to be a good first book on functional programming, it is not a good first book on programming in general.</p>
<p>Mathematicians who are using Lean as a proof assistant will likely need to write custom proof automation tools at some point.
This book is also for them.
As these tools become more sophisticated, they begin to resemble programs in functional languages, but most working mathematicians are trained in languages like Python and Mathematica.
This book can help bridge the gap, empowering more mathematicians to write maintainable and understandable proof automation tools.</p>
<p>This book is intended to be read linearly, from the beginning to the end.
Concepts are introduced one at a time, and later sections assume familiarity with earlier sections.
Sometimes, later chapters will go into depth on a topic that was only briefly addressed earlier on.
Some sections of the book contain exercises.
These are worth doing, in order to cement your understanding of the section.
It is also useful to explore Lean as you read the book, finding creative new ways to use what you have learned.</p>
<h1 id="getting-lean"><a class="header" href="#getting-lean">Getting Lean</a></h1>
<p>Before writing and running programs written in Lean, you'll need to set up Lean on your own computer.
The Lean tooling consists of the following:</p>
<ul>
<li><code>elan</code> manages the Lean compiler toolchains, similarly to <code>rustup</code> or <code>ghcup</code>.</li>
<li><code>lake</code> builds Lean packages and their dependencies, similarly to <code>cargo</code>, <code>make</code>, or Gradle.</li>
<li><code>lean</code> type checks and compiles individual Lean files as well as providing information to programmer tools about files that are currently being written.
Normally, <code>lean</code> is invoked by other tools rather than directly by users.</li>
<li>Plugins for editors, such as Visual Studio Code or Emacs, that communicate with <code>lean</code> and present its information conveniently.</li>
</ul>
<p>Please refer to the <a href="https://leanprover.github.io/lean4/doc/quickstart.html">Lean manual</a> for up-to-date instructions for installing Lean.</p>
<h1 id="typographical-conventions"><a class="header" href="#typographical-conventions">Typographical Conventions</a></h1>
<p>Code examples that are provided to Lean as <em>input</em> are formatted like this:</p>
<pre><code class="language-lean">def add1 (n : Nat) : Nat := n + 1

#eval add1 7
</code></pre>
<p>The last line above (beginning with <code>#eval</code>) is a command that instructs Lean to calculate an answer.
Lean's replies are formatted like this:</p>
<pre><code class="language-output info">8
</code></pre>
<p>Error messages returned by Lean are formatted like this:</p>
<pre><code class="language-output error">application type mismatch
  add1 &quot;seven&quot;
argument
  &quot;seven&quot;
has type
  String : Type
but is expected to have type
  Nat : Type
</code></pre>
<p>Warnings are formatted like this:</p>
<pre><code class="language-output warning">declaration uses 'sorry'
</code></pre>
<h1 id="unicode"><a class="header" href="#unicode">Unicode</a></h1>
<p>Idiomatic Lean code makes use of a variety of Unicode characters that are not part of ASCII.
For instance, Greek letters like <code>α</code> and <code>β</code> and the arrow <code>→</code> both occur in the first chapter of this book.
This allows Lean code to more closely resemble ordinary mathematical notation.</p>
<p>With the default Lean settings, both Visual Studio Code and Emacs allow these characters to be typed with a backslash (<code>\</code>) followed by a name.
For example, to enter <code>α</code>, type <code>\alpha</code>.
To find out how to type a character in Visual Studio Code, point the mouse at it and look at the tooltip.
In Emacs, use <code>C-c C-k</code> with point on the character in question.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="acknowledgments"><a class="header" href="#acknowledgments">Acknowledgments</a></h1>
<p>This free online book was made possible by the generous support of Microsoft Research, who paid for it to be written and given away.
During the process of writing, they made the expertise of the Lean development team available to both answer my questions and make Lean easier to use.
In particular, Leonardo de Moura initiated the project and helped me get started, Chris Lovett set up the CI and deployment automation and provided great feedback as a test reader, Gabriel Ebner provided technical reviews, Sarah Smith kept the administrative side working well, and Vanessa Rodriguez helped me diagnose a tricky interaction between the source-code highlighting library and certain versions of Safari on iOS.</p>
<p>Writing this book has taken up many hours outside of normal working hours.
My wife Ellie Thrane Christiansen has taken on a larger than usual share of running the family, and this book could not exist if she had not done so.
An extra day of work each week has not been easy for my family—thank you for your patience and support while I was writing.</p>
<p>The online community surrounding Lean provided enthusiastic support for the project, both technical and emotional.
In particular, Sebastian Ullrich provided key help when I was learning Lean's metaprogramming system in order to write the supporting code that allowed the text of error messages to be both checked in CI and easily included in the book itself.
Within hours of posting a new revision, excited readers would be finding mistakes, providing suggestions, and showering me with kindness.
In particular, I'd like to thank Arien Malec, Asta Halkjær From, Bulhwi Cha, Daniel Fabian, Evgenia Karunus, eyelash, Floris van Doorn, František Silváši, Henrik Böving, Ian Young, Jeremy Salwen, Jireh Loreaux, Kevin Buzzard, Mac Malone, Malcolm Langfield, Mario Carneiro, Newell Jensen, Patrick Massot, Paul Chisholm, Tomas Puverle, Yaël Dillies, and Zhiyuan Bao for their many suggestions, both stylistic and technical.</p>
<div style="break-before: page; page-break-before: always;"></div><p>According to tradition, a programming language should be introduced by
compiling and running a program that displays <code>&quot;Hello, world!&quot;</code> on the
console. This simple program ensures that the language tooling is
installed correctly and that the programmer is able to run the
compiled code.</p>
<p>Since the 1970s, however, programming has changed. Today, compilers
are typically integrated into text editors, and the programming
environment offers feedback as the program is written. Lean is no
exception: it implements an extended version of the Language Server
Protocol that allows it to communicate with a text editor and provide
feedback as the user types.</p>
<p>Languages as varied as Python, Haskell, and JavaScript offer a read-eval-print-loop (REPL), also known as an interactive toplevel or a browser console, in which expressions or statements can be entered.
The language then computes and displays the result of the user's input.
Lean, on the other hand, integrates these features into the interaction with the editor, providing commands that cause the text editor to display feedback integrated into the program text itself.
This chapter provides a short introduction to interacting with Lean in an editor, while <a href="">Hello, World!</a> describes how to use Lean traditionally from the command line in batch mode.</p>
<p>It is best if you read this book with Lean open in your editor,
following along and typing in each example. Please play with the
examples, and see what happens!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="evaluating-expressions"><a class="header" href="#evaluating-expressions">Evaluating Expressions</a></h1>
<p>The most important thing to understand as a programmer learning Lean
is how evaluation works. Evaluation is the process of finding the
value of an expression, just as one does in arithmetic. For instance,
the value of 15 - 6 is 9 and the value of 2 × (3 + 1) is 8.
To find the value of the latter expression, 3 + 1 is first replaced by 4, yielding 2 × 4, which itself can be reduced to 8.
Sometimes, mathematical expressions contain variables: the value of <em>x</em> + 1 cannot be computed until we know what the value of <em>x</em> is.
In Lean, programs are first and foremost expressions, and the primary way to think about computation is as evaluating expressions to find their values.</p>
<p>Most programming languages are <em>imperative</em>, where a program consists
of a series of statements that should be carried out in order to find
the program's result. Programs have access to mutable memory, so the
value referred to by a variable can change over time. In addition to mutable state, programs may have other side
effects, such as deleting files, making outgoing network connections,
throwing or catching exceptions, and reading data from a
database. &quot;Side effects&quot; is essentially a catch-all term for
describing things that may happen in a program that don't follow the
model of evaluating mathematical expressions.</p>
<p>In Lean, however, programs work the same way as mathematical
expressions. Once given a value, variables cannot be reassigned. Evaluating an expression cannot have side effects. If two
expressions have the same value, then replacing one with the other
will not cause the program to compute a different result. This does
not mean that Lean cannot be used to write <code>Hello, world!</code> to the
console, but performing I/O is not a core part of the experience of
using Lean in the same way. Thus, this chapter focuses on how to
evaluate expressions interactively with Lean, while the next chapter
describes how to write, compile, and run the <code>Hello, world!</code> program.</p>
<p>To ask Lean to evaluate an expression, write <code>#eval</code> before it in your
editor, which will then report the result back. Typically, the result
is found by putting the cursor or mouse pointer over <code>#eval</code>. For
instance,</p>
<pre><code class="language-lean">#eval 1 + 2
</code></pre>
<p>yields the value <code>3</code>.</p>
<p>Lean obeys the ordinary rules of precedence and associativity for
arithmetic operators. That is,</p>
<pre><code class="language-lean">#eval 1 + 2 * 5
</code></pre>
<p>yields the value <code>11</code> rather than
<code>15</code>.</p>
<p>While both ordinary mathematical notation and the majority of
programming languages use parentheses (e.g. <code>f(x)</code>) to apply a function to its
arguments, Lean simply writes the function next to its
arguments (e.g. <code>f x</code>). Function application is one of the most common operations,
so it pays to keep it concise. Rather than writing</p>
<pre><code class="language-lean">#eval String.append(&quot;Hello, &quot;, &quot;Lean!&quot;)
</code></pre>
<p>to compute <code>&quot;Hello, Lean!&quot;</code>,
one would instead write</p>
<pre><code class="language-Lean">#eval String.append &quot;Hello, &quot; &quot;Lean!&quot;
</code></pre>
<p>where the function's two arguments are simply written next to
it with spaces.</p>
<p>Just as the order-of-operations rules for arithmetic demand
parentheses in the expression <code>(1 + 2) * 5</code>, parentheses are also
necessary when a function's argument is to be computed via another
function call. For instance, parentheses are required in</p>
<pre><code class="language-Lean">#eval String.append &quot;great &quot; (String.append &quot;oak &quot; &quot;tree&quot;)
</code></pre>
<p>because otherwise the second <code>String.append</code> would be interpreted as
an argument to the first, rather than as a function being passed
<code>&quot;oak &quot;</code> and <code>&quot;tree&quot;</code> as arguments. The value of the inner <code>String.append</code>
call must be found first, after which it can be appended to <code>&quot;great &quot;</code>,
yielding the final value <code>&quot;great oak tree&quot;</code>.</p>
<p>Imperative languages often have two kinds of conditional: a
conditional <em>statement</em> that determines which instructions to carry
out based on a Boolean value, and a conditional <em>expression</em> that
determines which of two expressions to evaluate based on a Boolean
value. For instance, in C and C++, the conditional statement is
written using <code>if</code> and <code>else</code>, while the conditional expression is
written with a ternary operator <code>?</code> and <code>:</code>. In Python, the
conditional statement begins with <code>if</code>, while the conditional
expression puts <code>if</code> in the middle.
Because Lean is an expression-oriented functional language, there are no conditional statements, only conditional expressions.
They are written using <code>if</code>, <code>then</code>, and <code>else</code>. For
instance,</p>
<pre><code class="language-Lean">String.append &quot;it is &quot; (if 1 &gt; 2 then &quot;yes&quot; else &quot;no&quot;)
</code></pre>
<p>evaluates to</p>
<pre><code class="language-Lean">String.append &quot;it is &quot; (if false then &quot;yes&quot; else &quot;no&quot;)
</code></pre>
<p>which evaluates to</p>
<pre><code class="language-lean">String.append &quot;it is &quot; &quot;no&quot;
</code></pre>
<p>which finally evaluates to <code>&quot;it is no&quot;</code>.</p>
<p>For the sake of brevity, a series of evaluation steps like this will sometimes be written with arrows between them:</p>
<pre><code class="language-lean">String.append &quot;it is &quot; (if 1 &gt; 2 then &quot;yes&quot; else &quot;no&quot;)
===&gt;
String.append &quot;it is &quot; (if false then &quot;yes&quot; else &quot;no&quot;)
===&gt;
String.append &quot;it is &quot; &quot;no&quot;
===&gt;
&quot;it is no&quot;
</code></pre>
<h2 id="messages-you-may-meet"><a class="header" href="#messages-you-may-meet">Messages You May Meet</a></h2>
<p>Asking Lean to evaluate a function application that is missing an argument will lead to an error message.
In particular, the example</p>
<pre><code class="language-lean">#eval String.append &quot;it is &quot;
</code></pre>
<p>yields a quite long error message:</p>
<pre><code class="language-output error">expression
  String.append &quot;it is &quot;
has type
  String → String
but instance
  Lean.MetaEval (String → String)
failed to be synthesized, this instance instructs Lean on how to display the resulting value, recall that any type implementing the `Repr` class also implements the `Lean.MetaEval` class
</code></pre>
<p>This message occurs because Lean functions that are applied to only some of their arguments return new functions that are waiting for the rest of the arguments.
Lean cannot display functions to users, and thus returns an error when asked to do so.</p>
<h2 id="exercises"><a class="header" href="#exercises">Exercises</a></h2>
<p>What are the values of the following expressions? Work them out by hand,
then enter them into Lean to check your work.</p>
<ul>
<li><code>42 + 19</code></li>
<li><code>String.append &quot;A&quot; (String.append &quot;B&quot; &quot;C&quot;)</code></li>
<li><code>String.append (String.append &quot;A&quot; &quot;B&quot;) &quot;C&quot;</code></li>
<li><code>if 3 == 3 then 5 else 7</code></li>
<li><code>if 3 == 4 then &quot;equal&quot; else &quot;not equal&quot;</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="types"><a class="header" href="#types">Types</a></h1>
<p>Types classify programs based on the values that they can
compute. Types serve a number of roles in a program:</p>
<ol>
<li>
<p>They allow the compiler to make decisions about the in-memory
representation of a value.</p>
</li>
<li>
<p>They help programmers to communicate their intent to others,
serving as a lightweight specification for the inputs and outputs
of a function that the compiler can ensure the program adheres to.</p>
</li>
<li>
<p>They prevent various potential mistakes, such as adding a number
to a string, and thus reduce the number of tests that are
necessary for a program.</p>
</li>
<li>
<p>They help the Lean compiler automate the production of auxiliary code that can save boilerplate.</p>
</li>
</ol>
<p>Lean's type system is unusually expressive.
Types can encode strong specifications like &quot;this sorting function returns a permutation of its input&quot; and flexible specifications like &quot;this function has different return types, depending on the value of its argument&quot;.
The type system can even be used as a full-blown logic for proving mathematical theorems.
This cutting-edge expressive power doesn't obviate the need for simpler types, however, and understanding these simpler types is a prerequisite for using the more advanced features.</p>
<p>Every program in Lean must have a type. In particular, every
expression must have a type before it can be evaluated. In the
examples so far, Lean has been able to discover a type on its own, but
it is sometimes necessary to provide one. This is done using the colon
operator:</p>
<pre><code class="language-lean">#eval (1 + 2 : Nat)
</code></pre>
<p>Here, <code>Nat</code> is the type of <em>natural numbers</em>, which are arbitrary-precision unsigned integers.
In Lean, <code>Nat</code> is the default type for non-negative integer literals.
This default type is not always the best choice.
In C, unsigned integers underflow to the largest representable numbers when subtraction would otherwise yield a result less than zero.
<code>Nat</code>, however, can represent arbitrarily-large unsigned numbers, so there is no largest number to underflow to.
Thus, subtraction on <code>Nat</code> returns <code>0</code> when the answer would have otherwise been negative.
For instance,</p>
<pre><code class="language-lean">#eval 1 - 2
</code></pre>
<p>evaluates to <code>0</code> rather
than <code>-1</code>. To use a type that can represent the negative integers,
provide it directly:</p>
<pre><code class="language-lean">#eval (1 - 2 : Int)
</code></pre>
<p>With this type, the result is <code>-1</code>, as expected.</p>
<p>To check the type of an expression without evaluating it, use <code>#check</code>
instead of <code>#eval</code>. For instance:</p>
<pre><code class="language-lean">#check (1 - 2 : Int)
</code></pre>
<p>reports <code>1 - 2 : Int</code> without actually performing the subtraction.</p>
<p>When a program can't be given a type, an error is returned from both
<code>#check</code> and <code>#eval</code>. For instance:</p>
<pre><code class="language-lean">#check String.append &quot;hello&quot; [&quot; &quot;, &quot;world&quot;]
</code></pre>
<p>outputs</p>
<pre><code class="language-output error">application type mismatch
  String.append &quot;hello&quot; [&quot; &quot;, &quot;world&quot;]
argument
  [&quot; &quot;, &quot;world&quot;]
has type
  List String : Type
but is expected to have type
  String : Type
</code></pre>
<p>because the second argument to <code>String.append</code> is expected to be a
string, but a list of strings was provided instead.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="functions-and-definitions"><a class="header" href="#functions-and-definitions">Functions and Definitions</a></h1>
<p>In Lean, definitions are introduced using the <code>def</code> keyword. For instance, to define the name <code>hello</code> to refer to the string <code>&quot;Hello&quot;</code>, write:</p>
<pre><code class="language-lean">def hello := &quot;Hello&quot;
</code></pre>
<p>In Lean, new names are defined using the colon-equal operator<code>:=</code>
rather than <code>=</code>. This is because <code>=</code> is used to describe equalities
between existing expressions, and using two different operators helps
prevent confusion.</p>
<p>In the definition of <code>hello</code>, the expression <code>&quot;Hello&quot;</code> is simple enough that Lean is able to determine the definition's type automatically.
However, most definitions are not so simple, so it will usually be necessary to add a type.
This is done using a colon after the name being defined.</p>
<pre><code class="language-lean">def lean : String := &quot;Lean&quot;
</code></pre>
<p>Now that the names have been defined, they can be used, so</p>
<pre><code class="language-Lean">#eval String.append hello (String.append &quot; &quot; lean)
</code></pre>
<p>outputs</p>
<pre><code class="language-Lean info">&quot;Hello Lean&quot;
</code></pre>
<p>In Lean, defined names may only be used after their definitions.</p>
<p>In many languages, definitions of functions use a different syntax than definitions of other values.
For instance, Python function definitions begin with the <code>def</code> keyword, while other definitions are defined with an equals sign.
In Lean, functions are defined using the same <code>def</code> keyword as other values.
Nonetheless, definitions such as <code>hello</code> introduce names that refer <em>directly</em> to their values, rather than to zero-argument functions that return equivalent results each time they are called.</p>
<h2 id="defining-functions"><a class="header" href="#defining-functions">Defining Functions</a></h2>
<p>There are a variety of ways to define functions in Lean. The simplest is to place the function's arguments before the definition's type, separated by spaces. For instance, a function that adds one to its argument can be written:</p>
<pre><code class="language-lean">def add1 (n : Nat) : Nat := n + 1
</code></pre>
<p>Testing this function with <code>#eval</code> gives <code>8</code>, as expected:</p>
<pre><code class="language-lean">#eval add1 7
</code></pre>
<p>Just as functions are applied to multiple arguments by writing spaces between each argument, functions that accept multiple arguments are defined with spaces between the arguments' names and types. The function <code>maximum</code>, whose result is equal to the greatest of its two arguments, takes two <code>Nat</code> arguments <code>n</code> and <code>k</code> and returns a <code>Nat</code>.</p>
<pre><code class="language-lean">def maximum (n : Nat) (k : Nat) : Nat :=
  if n &lt; k then
    k
  else n
</code></pre>
<p>When a defined function like <code>maximum</code> has been provided with its arguments, the result is determined by first replacing the argument names with the provided values in the body, and then evaluating the resulting body. For example:</p>
<pre><code class="language-lean">maximum (5 + 8) (2 * 7)
===&gt;
maximum 13 14
===&gt;
if 13 &lt; 14 then 14 else 13
===&gt;
14
</code></pre>
<p>Expressions that evaluate to natural numbers, integers, and strings have types that say this (<code>Nat</code>, <code>Int</code>, and <code>String</code>, respectively).
This is also true of functions.
A function that accepts a <code>Nat</code> and returns a <code>Bool</code> has type <code>Nat → Bool</code>, and a function that accepts two <code>Nat</code>s and returns a <code>Nat</code> has type <code>Nat → Nat → Nat</code>.</p>
<p>As a special case, Lean returns a function's signature when its name is used directly with <code>#check</code>.
Entering <code>#check add1</code> yields <code>add1 (n : Nat) : Nat</code>.
However, Lean can be &quot;tricked&quot; into showing the function's type by writing the function's name in parentheses, which causes the function to be treated as an ordinary expression, so <code>#check (add1)</code> yields <code>add1 : Nat → Nat</code> and <code>#check (maximum)</code> yields <code>maximum : Nat → Nat → Nat</code>.
This arrow can also be written with an ASCII alternative arrow <code>-&gt;</code>, so the preceding function types can be written <code>Nat -&gt; Nat</code> and <code>Nat -&gt; Nat -&gt; Nat</code>, respectively.</p>
<p>Behind the scenes, all functions actually expect precisely one argument.
Functions like <code>maximum</code> that seem to take more than one argument are in fact functions that take one argument and then return a new function.
This new function takes the next argument, and the process continues until no more arguments are expected.
This can be seen by providing one argument to a multiple-argument function: <code>#check maximum 3</code> yields <code>maximum 3 : Nat → Nat</code> and <code>#check String.append &quot;Hello &quot;</code> yields <code>String.append &quot;Hello &quot; : String → String</code>.
Using a function that returns a function to implement multiple-argument functions is called <em>currying</em> after the mathematician Haskell Curry.
Function arrows associate to the right, which means that <code>Nat → Nat → Nat</code> should be parenthesized <code>Nat → (Nat → Nat)</code>.</p>
<h3 id="exercises-1"><a class="header" href="#exercises-1">Exercises</a></h3>
<ul>
<li>Define the function <code>joinStringsWith</code> with type <code>String -&gt; String -&gt; String -&gt; String</code> that creates a new string by placing its first argument between its second and third arguments. <code>joinStringsWith &quot;, &quot; &quot;one&quot; &quot;and another&quot;</code> should evaluate to <code>&quot;one, and another&quot;</code>.</li>
<li>What is the type of <code>joinStringsWith &quot;: &quot;</code>? Check your answer with Lean.</li>
<li>Define a function <code>volume</code> with type <code>Nat → Nat → Nat → Nat</code> that computes the volume of a rectangular prism with the given height, width, and depth.</li>
</ul>
<h2 id="defining-types"><a class="header" href="#defining-types">Defining Types</a></h2>
<p>Most typed programming languages have some means of defining aliases for types, such as C's <code>typedef</code>.
In Lean, however, types are a first-class part of the language - they are expressions like any other.
This means that definitions can refer to types just as well as they can refer to other values.</p>
<p>For instance, if <code>String</code> is too much to type, a shorter abbreviation <code>Str</code> can be defined:</p>
<pre><code class="language-lean">def Str : Type := String
</code></pre>
<p>It is then possible to use <code>Str</code> as a definition's type instead of <code>String</code>:</p>
<pre><code class="language-lean">def aStr : Str := &quot;This is a string.&quot;
</code></pre>
<p>The reason this works is that types follow the same rules as the rest of Lean.
Types are expressions, and in an expression, a defined name can be replaced with its definition.
Because <code>Str</code> has been defined to mean <code>String</code>, the definition of <code>aStr</code> makes sense.</p>
<h3 id="messages-you-may-meet-1"><a class="header" href="#messages-you-may-meet-1">Messages You May Meet</a></h3>
<p>Experimenting with using definitions for types is made more complicated by the way that Lean supports overloaded integer literals.
If <code>Nat</code> is too short, a longer name <code>NaturalNumber</code> can be defined:</p>
<pre><code class="language-lean">def NaturalNumber : Type := Nat
</code></pre>
<p>However, using <code>NaturalNumber</code> as a definition's type instead of <code>Nat</code> does not have the expected effect.
In particular, the definition:</p>
<pre><code class="language-lean">def thirtyEight : NaturalNumber := 38
</code></pre>
<p>results in the following error:</p>
<pre><code class="language-output error">failed to synthesize instance
  OfNat NaturalNumber 38
</code></pre>
<p>This error occurs because Lean allows number literals to be <em>overloaded</em>.
When it makes sense to do so, natural number literals can be used for new types, just as if those types were built in to the system.
This is part of Lean's mission of making it convenient to represent mathematics, and different branches of mathematics use number notation for very different purposes.
The specific feature that allows this overloading does not replace all defined names with their definitions before looking for overloading, which is what leads to the error message above.</p>
<p>One way to work around this limitation is by providing the type <code>Nat</code> on the right-hand side of the definition, causing <code>Nat</code>'s overloading rules to be used for <code>38</code>:</p>
<pre><code class="language-lean">def thirtyEight : NaturalNumber := (38 : Nat)
</code></pre>
<p>The definition is still type-correct because <code>NaturalNumber</code> is the same type as <code>Nat</code>—by definition!</p>
<p>Another solution is to define an overloading for <code>NaturalNumber</code> that works equivalently to the one for <code>Nat</code>.
This requires more advanced features of Lean, however.</p>
<p>Finally, defining the new name for <code>Nat</code> using <code>abbrev</code> instead of <code>def</code> allows overloading resolution to replace the defined name with its definition.
Definitions written using <code>abbrev</code> are always unfolded.
For instance,</p>
<pre><code class="language-lean">abbrev N : Type := Nat
</code></pre>
<p>and</p>
<pre><code class="language-lean">def thirtyNine : N := 39
</code></pre>
<p>are accepted without issue.</p>
<p>Behind the scenes, some definitions are internally marked as being unfoldable during overload resolution, while others are not.
Definitions that are to be unfolded are called <em>reducible</em>.
Control over reducibility is essential to allow Lean to scale: fully unfolding all definitions can result in very large types that are slow for a machine to process and difficult for users to understand.
Definitions produced with <code>abbrev</code> are marked as reducible.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="structures"><a class="header" href="#structures">Structures</a></h1>
<p>The first step in writing a program is usually to identify the problem domain's concepts, and then find suitable representations for them in code.
Sometimes, a domain concept is a collection of other, simpler, concepts.
In that case, it can be convenient to group these simpler components together into a single &quot;package&quot;, which can then be given a meaningful name.
In Lean, this is done using <em>structures</em>, which are analogous to <code>struct</code>s in C or Rust and <code>record</code>s in C#.</p>
<p>Defining a structure introduces a completely new type to Lean that can't be reduced to any other type.
This is useful because multiple structures might represent different concepts that nonetheless contain the same data.
For instance, a point might be represented using either Cartesian or polar coordinates, each being a pair of floating-point numbers.
Defining separate structures prevents API clients from confusing one for another.</p>
<p>Lean's floating-point number type is called <code>Float</code>, and floating-point numbers are written in the usual notation.</p>
<pre><code class="language-lean">#check 1.2
</code></pre>
<pre><code class="language-output info">1.2 : Float
</code></pre>
<pre><code class="language-lean">#check -454.2123215
</code></pre>
<pre><code class="language-output info">-454.2123215 : Float
</code></pre>
<pre><code class="language-lean">#check 0.0
</code></pre>
<pre><code class="language-output info">0.0 : Float
</code></pre>
<p>When floating point numbers are written with the decimal point, Lean will infer the type <code>Float</code>. If they are written without it, then a type annotation may be necessary.</p>
<pre><code class="language-lean">#check 0
</code></pre>
<pre><code class="language-output info">0 : Nat
</code></pre>
<pre><code class="language-lean">#check (0 : Float)
</code></pre>
<pre><code class="language-output info">0 : Float
</code></pre>
<p>A Cartesian point is a structure with two <code>Float</code> fields, called <code>x</code> and <code>y</code>.
This is declared using the <code>structure</code> keyword.</p>
<pre><code class="language-lean">structure Point where
  x : Float
  y : Float
deriving Repr
</code></pre>
<p>After this declaration, <code>Point</code> is a new structure type.
The final line, which says <code>deriving Repr</code>, asks Lean to generate code to display values of type <code>Point</code>.
This code is used by <code>#eval</code> to render the result of evaluation for consumption by programmers, analogous to the <code>repr</code> function in Python.
It is also possible to override the compiler's generated display code.</p>
<p>The typical way to create a value of a structure type is to provide values for all of its fields inside of curly braces.
The origin of a Cartesian plane is where <code>x</code> and <code>y</code> are both zero:</p>
<pre><code class="language-lean">def origin : Point := { x := 0.0, y := 0.0 }
</code></pre>
<p>If the <code>deriving Repr</code> line in <code>Point</code>'s definition were omitted, then attempting <code>#eval origin</code> would yield an error similar to that which occurs when omitting a function's argument:</p>
<pre><code class="language-output error">expression
  origin
has type
  Point
but instance
  Lean.MetaEval Point
failed to be synthesized, this instance instructs Lean on how to display the resulting value, recall that any type implementing the `Repr` class also implements the `Lean.MetaEval` class
</code></pre>
<p>That message is saying that the evaluation machinery doesn't know how to communicate the result of evaluation back to the user.</p>
<p>Happily, with <code>deriving Repr</code>, the result of <code>#eval origin</code> looks very much like the definition of <code>origin</code>.</p>
<pre><code class="language-output info">{ x := 0.000000, y := 0.000000 }
</code></pre>
<p>Because structures exist to &quot;bundle up&quot; a collection of data, naming it and treating it as a single unit, it is also important to be able to extract the individual fields of a structure.
This is done using dot notation, as in C, Python, or Rust.</p>
<pre><code class="language-lean">#eval origin.x
</code></pre>
<pre><code class="language-output info">0.000000
</code></pre>
<pre><code class="language-lean">#eval origin.y
</code></pre>
<pre><code class="language-output info">0.000000
</code></pre>
<p>This can be used to define functions that take structures as arguments.
For instance, addition of points is performed by adding the underlying coordinate values.
It should be the case that <code>#eval addPoints { x := 1.5, y := 32 } { x := -8, y := 0.2 }</code> yields</p>
<pre><code class="language-output info">{ x := -6.500000, y := 32.200000 }
</code></pre>
<p>The function itself takes two <code>Points</code> as arguments, called <code>p1</code> and <code>p2</code>.
The resulting point is based on the <code>x</code> and <code>y</code> fields of both <code>p1</code> and <code>p2</code>:</p>
<pre><code class="language-lean">def addPoints (p1 : Point) (p2 : Point) : Point :=
  { x := p1.x + p2.x, y := p1.y + p2.y }
</code></pre>
<p>Similarly, the distance between two points, which is the square root of the sum of the squares of the differences in their <code>x</code> and <code>y</code> components, can be written:</p>
<pre><code class="language-lean">def distance (p1 : Point) (p2 : Point) : Float :=
  Float.sqrt (((p2.x - p1.x) ^ 2.0) + ((p2.y - p1.y) ^ 2.0))
</code></pre>
<p>For example, the distance between (1, 2) and (5, -1) is 5:</p>
<pre><code class="language-lean">#eval distance { x := 1.0, y := 2.0 } { x := 5.0, y := -1.0 }
</code></pre>
<pre><code class="language-output info">5.000000
</code></pre>
<p>Multiple structures may have fields with the same names.
For instance, a three-dimensional point datatype may share the fields <code>x</code> and <code>y</code>, and be instantiated with the same field names:</p>
<pre><code class="language-lean">structure Point3D where
  x : Float
  y : Float
  z : Float
deriving Repr

def origin3D : Point3D := { x := 0.0, y := 0.0, z := 0.0 }
</code></pre>
<p>This means that the structure's expected type must be known in order to use the curly-brace syntax.
If the type is not known, Lean will not be able to instantiate the structure.
For instance,</p>
<pre><code class="language-lean">#check { x := 0.0, y := 0.0 }
</code></pre>
<p>leads to the error</p>
<pre><code class="language-output error">invalid {...} notation, expected type is not known
</code></pre>
<p>As usual, the situation can be remedied by providing a type annotation.</p>
<pre><code class="language-lean">#check ({ x := 0.0, y := 0.0 } : Point)
</code></pre>
<pre><code class="language-output info">{ x := 0.0, y := 0.0 } : Point
</code></pre>
<p>To make programs more concise, Lean also allows the structure type annotation inside the curly braces.</p>
<pre><code class="language-lean">#check { x := 0.0, y := 0.0 : Point}
</code></pre>
<pre><code class="language-output info">{ x := 0.0, y := 0.0 } : Point
</code></pre>
<h2 id="updating-structures"><a class="header" href="#updating-structures">Updating Structures</a></h2>
<p>Imagine a function <code>zeroX</code> that replaces the <code>x</code> field of a <code>Point</code> with <code>0.0</code>.
In most programming language communities, this sentence would mean that the memory location pointed to by <code>x</code> was to be overwritten with a new value.
However, Lean does not have mutable state.
In functional programming communities, what is almost always meant by this kind of statement is that a fresh <code>Point</code> is allocated with the <code>x</code> field pointing to the new value, and all other fields pointing to the original values from the input.
One way to write <code>zeroX</code> is to follow this description literally, filling out the new value for <code>x</code> and manually transferring <code>y</code>:</p>
<pre><code class="language-lean">def zeroX (p : Point) : Point :=
  { x := 0, y := p.y }
</code></pre>
<p>This style of programming has drawbacks, however.
First off, if a new field is added to a structure, then every site that updates any field at all must be updated, causing maintenance difficulties.
Secondly, if the structure contains multiple fields with the same type, then there is a real risk of copy-paste coding leading to field contents being duplicated or switched.
Finally, the program becomes long and bureaucratic.</p>
<p>Lean provides a convenient syntax for replacing some fields in a structure while leaving the others alone.
This is done by using the <code>with</code> keyword in a structure initialization.
The source of unchanged fields occurs before the <code>with</code>, and the new fields occur after.
For instance, <code>zeroX</code> can be written with only the new <code>x</code> value:</p>
<pre><code class="language-lean">def zeroX (p : Point) : Point :=
  { p with x := 0 }
</code></pre>
<p>Remember that this structure update syntax does not modify existing values—it creates new values that share some fields with old values.
For instance, given the point <code>fourAndThree</code>:</p>
<pre><code class="language-lean">def fourAndThree : Point :=
  { x := 4.3, y := 3.4 }
</code></pre>
<p>evaluating it, then evaluating an update of it using <code>zeroX</code>, then evaluating it again yields the original value:</p>
<pre><code class="language-lean">#eval fourAndThree
</code></pre>
<pre><code class="language-output info">{ x := 4.300000, y := 3.400000 }
</code></pre>
<pre><code class="language-lean">#eval zeroX fourAndThree
</code></pre>
<pre><code class="language-output info">{ x := 0.000000, y := 3.400000 }
</code></pre>
<pre><code class="language-lean">#eval fourAndThree
</code></pre>
<pre><code class="language-output info">{ x := 4.300000, y := 3.400000 }
</code></pre>
<p>One consequence of the fact that structure updates do not modify the original structure is that it becomes easier to reason about cases where the new value is computed from the old one.
All references to the old structure continue to refer to the same field values in all of the new values provided.</p>
<h2 id="behind-the-scenes"><a class="header" href="#behind-the-scenes">Behind the Scenes</a></h2>
<p>Every structure has a <em>constructor</em>.
Here, the term &quot;constructor&quot; may be a source of confusion.
Unlike constructors in languages such as Java or Python, constructors in Lean are not arbitrary code to be run when a datatype is initialized.
Instead, constructors simply gather the data to be stored in the newly-allocated data structure.
It is not possible to provide a custom constructor that pre-processes data or rejects invalid arguments.
This is really a case of the word &quot;constructor&quot; having different, but related, meanings in the two contexts.</p>
<p>By default, the constructor for a structure named <code>S</code> is named <code>S.mk</code>.
Here, <code>S</code> is a namespace qualifier, and <code>mk</code> is the name of the constructor itself.
Instead of using curly-brace initialization syntax, the constructor can also be applied directly.</p>
<pre><code class="language-lean">#check Point.mk 1.5 2.8
</code></pre>
<p>However, this is not generally considered to be good Lean style, and Lean even returns its feedback using the standard structure initializer syntax.</p>
<pre><code class="language-output info">{ x := 1.5, y := 2.8 } : Point
</code></pre>
<p>Constructors have function types, which means they can be used anywhere that a function is expected.
For instance, <code>Point.mk</code> is a function that accepts two <code>Float</code>s (respectively <code>x</code> and <code>y</code>) and returns a new <code>Point</code>.</p>
<pre><code class="language-lean">#check (Point.mk)
</code></pre>
<pre><code class="language-output info">Point.mk : Float → Float → Point
</code></pre>
<p>To override a structure's constructor name, write it with two colons at the beginning.
For instance, to use <code>Point.point</code> instead of <code>Point.mk</code>, write:</p>
<pre><code class="language-lean">structure Point where
  point ::
  x : Float
  y : Float
deriving Repr
</code></pre>
<p>In addition to the constructor, an accessor function is defined for each field of a structure.
These have the same name as the field, in the structure's namespace.
For <code>Point</code>, accessor functions <code>Point.x</code> and <code>Point.y</code> are generated.</p>
<pre><code class="language-lean">#check (Point.x)
</code></pre>
<pre><code class="language-output info">Point.x : Point → Float
</code></pre>
<pre><code class="language-lean">#check (Point.y)
</code></pre>
<pre><code class="language-output info">Point.y : Point → Float
</code></pre>
<p>In fact, just as the curly-braced structure construction syntax is converted to a call to the structure's constructor behind the scenes, the syntax <code>p1.x</code> in the prior definition of <code>addPoints</code> is converted into a call to the <code>Point.x</code> accessor.
That is, <code>#eval origin.x</code> and <code>#eval Point.x origin</code> both yield</p>
<pre><code class="language-output info">0.000000
</code></pre>
<p>Accessor dot notation is usable with more than just structure fields.
It can also be used for functions that take any number of arguments.
More generally, accessor notation has the form <code>TARGET.f ARG1 ARG2 ...</code>.
If <code>TARGET</code> has type <code>T</code>, the function named <code>T.f</code> is called.
<code>TARGET</code> becomes its leftmost argument of type <code>T</code>, which is often but not always the first one, and <code>ARG1 ARG2 ...</code> are provided in order as the remaining arguments.
For instance, <code>String.append</code> can be invoked from a string with accessor notation, even though <code>String</code> is not a structure with an <code>append</code> field.</p>
<pre><code class="language-lean">#eval &quot;one string&quot;.append &quot; and another&quot;
</code></pre>
<pre><code class="language-output info">&quot;one string and another&quot;
</code></pre>
<p>In that example, <code>TARGET</code> represents <code>&quot;one string&quot;</code> and <code>ARG1</code> represents <code>&quot; and another&quot;</code>.</p>
<p>The function <code>Point.modifyBoth</code> (that is, <code>modifyBoth</code> defined in the <code>Point</code> namespace) applies a function to both fields in a <code>Point</code>:</p>
<pre><code class="language-lean">def Point.modifyBoth (f : Float → Float) (p : Point) : Point :=
  { x:= f p.x, y := f p.y }
</code></pre>
<p>Even though the <code>Point</code> argument comes after the function argument, it can be used with dot notation as well:</p>
<pre><code class="language-lean">#eval fourAndThree.modifyBoth Float.floor
</code></pre>
<pre><code class="language-output info">{ x := 4.000000, y := 3.000000 }
</code></pre>
<p>In this case, <code>TARGET</code> represents <code>fourAndThree</code>, while <code>ARG1</code> is <code>Float.floor</code>.
This is because the target of the accessor notation is used as the first argument in which the type matches, not necessarily the first argument.</p>
<h2 id="exercises-2"><a class="header" href="#exercises-2">Exercises</a></h2>
<ul>
<li>Define a structure named <code>RectangularPrism</code> that contains the height, width, and depth of a rectangular prism, each as a <code>Float</code>.</li>
<li>Define a function named <code>volume : RectangularPrism → Float</code> that computes the volume of a rectangular prism.</li>
<li>Define a structure named <code>Segment</code> that represents a line segment by its endpoints, and define a function <code>length : Segment → Float</code> that computes the length of a line segment. <code>Segment</code> should have at most two fields.</li>
<li>Which names are introduced by the declaration of <code>RectangularPrism</code>?</li>
<li>Which names are introduced by the following declarations of <code>Hamster</code> and <code>Book</code>? What are their types?</li>
</ul>
<pre><code class="language-lean">structure Hamster where
  name : String
  fluffy : Bool
</code></pre>
<pre><code class="language-lean">structure Book where
  makeBook ::
  title : String
  author : String
  price : Float
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="datatypes-and-patterns"><a class="header" href="#datatypes-and-patterns">Datatypes and Patterns</a></h1>
<p>Structures enable multiple independent pieces of data to be combined into a coherent whole that is represented by a brand new type.
Types such as structures that group together a collection of values are called <em>product types</em>.
Many domain concepts, however, can't be naturally represented as structures.
For instance, an application might need to track user permissions, where some users are document owners, some may edit documents, and others may only read them.
A calculator has a number of binary operators, such as addition, subtraction, and multiplication.
Structures do not provide an easy way to encode multiple choices.</p>
<p>Similarly, while a structure is an excellent way to keep track of a fixed set of fields, many applications require data that may contain an arbitrary number of elements.
Most classic data structures, such as trees and lists, have a recursive structure, where the tail of a list is itself a list, or where the left and right branches of a binary tree are themselves binary trees.
In the aforementioned calculator, the structure of expressions themselves is recursive.
The summands in an addition expression may themselves be multiplication expressions, for instance.</p>
<p>Datatypes that allow choices are called <em>sum types</em> and datatypes that can include instances of themselves are called <em>recursive datatypes</em>.
Recursive sum types are called <em>inductive datatypes</em>, because mathematical induction may be used to prove statements about them.
When programming, inductive datatypes are consumed through pattern matching and recursive functions.</p>
<p>Many of the built-in types are actually inductive datatypes in the standard library.
For instance, <code>Bool</code> is an inductive datatype:</p>
<pre><code class="language-lean">inductive Bool where
  | false : Bool
  | true : Bool
</code></pre>
<p>This definition has two main parts.
The first line provides the name of the new type (<code>Bool</code>), while the remaining lines each describe a constructor.
As with constructors of structures, constructors of inductive datatypes are mere inert receivers of and containers for other data, rather than places to insert arbitrary initialization and validation code.
Unlike structures, inductive datatypes may have multiple constructors.
Here, there are two constructors, <code>true</code> and <code>false</code>, and neither takes any arguments.
Just as a structure declaration places its names in a namespace named after the declared type, an inductive datatype places the names of its constructors in a namespace.
In the Lean standard library, <code>true</code> and <code>false</code> are re-exported from this namespace so that they can be written alone, rather than as <code>Bool.true</code> and <code>Bool.false</code>, respectively.</p>
<p>From a data modeling perspective, inductive datatypes are used in many of the same contexts where a sealed abstract class might be used in other languages.
In languages like C# or Java, one might write a similar definition of <code>Bool</code>:</p>
<pre><code class="language-C#">abstract class Bool {}
class True : Bool {}
class False : Bool {}
</code></pre>
<p>However, the specifics of these representations are fairly different. In particular, each non-abstract class creates both a new type and new ways of allocating data. In the object-oriented example, <code>True</code> and <code>False</code> are both types that are more specific than <code>Bool</code>, while the Lean definition introduces only the new type <code>Bool</code>.</p>
<p>The type <code>Nat</code> of non-negative integers is an inductive datatype:</p>
<pre><code class="language-lean">inductive Nat where
  | zero : Nat
  | succ (n : Nat) : Nat
</code></pre>
<p>Here, <code>zero</code> represents 0, while <code>succ</code> represents the successor of some other number.
The <code>Nat</code> mentioned in <code>succ</code>'s declaration is the very type <code>Nat</code> that is in the process of being defined.
<em>Successor</em> means &quot;one greater than&quot;, so the successor of five is six and the successor of 32,185 is 32,186.
Using this definition, <code>4</code> is represented as <code>Nat.succ (Nat.succ (Nat.succ (Nat.succ Nat.zero)))</code>.
This definition is almost like the definition of <code>Bool</code> with slightly different names.
The only real difference is that <code>succ</code> is followed by <code>(n : Nat)</code>, which specifies that the constructor <code>succ</code> takes an argument of type <code>Nat</code> which happens to be named <code>n</code>.
The names <code>zero</code> and <code>succ</code> are in a namespace named after their type, so they must be referred to as <code>Nat.zero</code> and <code>Nat.succ</code>, respectively.</p>
<p>Argument names, such as <code>n</code>, may occur in Lean's error messages and in feedback provided when writing mathematical proofs.
Lean also has an optional syntax for providing arguments by name.
Generally, however, the choice of argument name is less important than the choice of a structure field name, as it does not form as large a part of the API.</p>
<p>In C# or Java, <code>Nat</code> could be defined as follows:</p>
<pre><code class="language-C#">abstract class Nat {}
class Zero : Nat {}
class Succ : Nat {
  public Nat n;
  public Succ(Nat pred) {
	n = pred;
  }
}
</code></pre>
<p>Just as in the <code>Bool</code> example above, this defines more types than the Lean equivalent.
Additionally, this example highlights how Lean datatype constructors are much more like subclasses of an abstract class than they are like constructors in C# or Java, as the constructor shown here contains initialization code to be executed.</p>
<p>Sum types are also similar to using a string tag to encode discriminated unions in TypeScript.
In TypeScript, <code>Nat</code> could be defined as follows:</p>
<pre><code class="language-typescript">interface Zero {
    tag: &quot;zero&quot;;
}

interface Succ {
    tag: &quot;succ&quot;;
    predecessor: Nat;
}

type Nat = Zero | Succ;
</code></pre>
<p>Just like C# and Java, this encoding ends up with more types than in Lean, because <code>Zero</code> and <code>Succ</code> are each a type on their own.
It also illustrates that Lean constructors correspond to objects in JavaScript or TypeScript that include a tag that identifies the contents.</p>
<h2 id="pattern-matching"><a class="header" href="#pattern-matching">Pattern Matching</a></h2>
<p>In many languages, these kinds of data are consumed by first using an instance-of operator to check which subclass has been received and then reading the values of the fields that are available in the given subclass.
The instance-of check determines which code to run, ensuring that the data needed by this code is available, while the fields themselves provide the data.
In Lean, both of these purposes are simultaneously served by <em>pattern matching</em>.</p>
<p>An example of a function that uses pattern matching is <code>isZero</code>, which is a function that returns <code>true</code> when its argument is <code>Nat.zero</code>, or false otherwise.</p>
<pre><code class="language-lean">def isZero (n : Nat) : Bool :=
  match n with
  | Nat.zero =&gt; true
  | Nat.succ k =&gt; false
</code></pre>
<p>The <code>match</code> expression is provided the function's argument <code>n</code> for destructuring.
If <code>n</code> was constructed by <code>Nat.zero</code>, then the first branch of the pattern match is taken, and the result is <code>true</code>.
If <code>n</code> was constructed by <code>Nat.succ</code>, then the second branch is taken, and the result is <code>false</code>.</p>
<p>Step-by-step, evaluation of <code>isZero Nat.zero</code> proceeds as follows:</p>
<pre><code class="language-lean">isZero Nat.zero
===&gt;
match Nat.zero with
| Nat.zero =&gt; true
| Nat.succ k =&gt; false
===&gt;
true
</code></pre>
<p>Evaluation of <code>isZero 5</code> proceeds similarly:</p>
<pre><code class="language-lean">isZero 5
===&gt;
isZero (Nat.succ (Nat.succ (Nat.succ (Nat.succ (Nat.succ Nat.zero)))))
===&gt;
match Nat.succ (Nat.succ (Nat.succ (Nat.succ (Nat.succ Nat.zero)))) with
| Nat.zero =&gt; true
| Nat.succ k =&gt; false
===&gt;
false
</code></pre>
<p>The <code>k</code> in the second branch of the pattern in <code>isZero</code> is not decorative.
It makes the <code>Nat</code> that is the argument to <code>succ</code> visible, with the provided name.
That smaller number can then be used to compute the final result of the expression.</p>
<p>Just as the successor of some number \( n \) is one greater than \( n \) (that is, \( n + 1\)), the predecessor of a number is one less than it.
If <code>pred</code> is a function that finds the predecessor of a <code>Nat</code>, then it should be the case that the following examples find the expected result:</p>
<pre><code class="language-lean">#eval pred 5
</code></pre>
<pre><code class="language-output info">4
</code></pre>
<pre><code class="language-lean">#eval pred 839
</code></pre>
<pre><code class="language-output info">838
</code></pre>
<p>Because <code>Nat</code> cannot represent negative numbers, <code>0</code> is a bit of a conundrum.
Usually, when working with <code>Nat</code>, operators that would ordinarily produce a negative number are redefined to produce <code>0</code> itself:</p>
<pre><code class="language-lean">#eval pred 0
</code></pre>
<pre><code class="language-output info">0
</code></pre>
<p>To find the predecessor of a <code>Nat</code>, the first step is to check which constructor was used to create it.
If it was <code>Nat.zero</code>, then the result is <code>Nat.zero</code>.
If it was <code>Nat.succ</code>, then the name <code>k</code> is used to refer to the <code>Nat</code> underneath it.
And this <code>Nat</code> is the desired predecessor, so the result of the <code>Nat.succ</code> branch is <code>k</code>.</p>
<pre><code class="language-lean">def pred (n : Nat) : Nat :=
  match n with
  | Nat.zero =&gt; Nat.zero
  | Nat.succ k =&gt; k
</code></pre>
<p>Applying this function to <code>5</code> yields the following steps:</p>
<pre><code class="language-lean">pred 5
===&gt;
pred (Nat.succ 4)
===&gt;
match Nat.succ 4 with
| Nat.zero =&gt; Nat.zero
| Nat.succ k =&gt; k
===&gt;
4
</code></pre>
<p>Pattern matching can be used with structures as well as with sum types.
For instance, a function that extracts the third dimension from a <code>Point3D</code> can be written as follows:</p>
<pre><code class="language-lean">def depth (p : Point3D) : Float :=
  match p with
  | { x:= h, y := w, z := d } =&gt; d
</code></pre>
<p>In this case, it would have been much simpler to just use the <code>z</code> accessor, but structure patterns are occasionally the simplest way to write a function.</p>
<h2 id="recursive-functions"><a class="header" href="#recursive-functions">Recursive Functions</a></h2>
<p>Definitions that refer to the name being defined are called <em>recursive definitions</em>.
Inductive datatypes are allowed to be recursive; indeed, <code>Nat</code> is an example of such a datatype because <code>succ</code> demands another <code>Nat</code>.
Recursive datatypes can represent arbitrarily large data, limited only by technical factors like available memory.
Just as it would be impossible to write down one constructor for each natural number in the datatype definition, it is also impossible to write down a pattern match case for each possibility.</p>
<p>Recursive datatypes are nicely complemented by recursive functions.
A simple recursive function over <code>Nat</code> checks whether its argument is even.
In this case, <code>zero</code> is even.
Non-recursive branches of the code like this one are called <em>base cases</em>.
The successor of an odd number is even, and the successor of an even number is odd.
This means that a number built with <code>succ</code> is even if and only if its argument is not even.</p>
<pre><code class="language-lean">def even (n : Nat) : Bool :=
  match n with
  | Nat.zero =&gt; true
  | Nat.succ k =&gt; not (even k)
</code></pre>
<p>This pattern of thought is typical for writing recursive functions on <code>Nat</code>.
First, identify what to do for <code>zero</code>.
Then, determine how to transform a result for an arbitrary <code>Nat</code> into a result for its successor, and apply this transformation to the result of the recursive call.
This pattern is called <em>structural recursion</em>.</p>
<p>Unlike many languages, Lean ensures by default that every recursive function will eventually reach a base case.
From a programming perspective, this rules out accidental infinite loops.
But this feature is especially important when proving theorems, where infinite loops cause major difficulties.
A consequence of this is that Lean will not accept a version of <code>even</code> that attempts to invoke itself recursively on the original number:</p>
<pre><code class="language-lean">def evenLoops (n : Nat) : Bool :=
  match n with
  | Nat.zero =&gt; true
  | Nat.succ k =&gt; not (evenLoops n)
</code></pre>
<p>The important part of the error message is that Lean could not determine that the recursive function always reaches a base case (because it doesn't).</p>
<pre><code class="language-output error">fail to show termination for
  evenLoops
with errors
structural recursion cannot be used

well-founded recursion cannot be used, 'evenLoops' does not take any (non-fixed) arguments
</code></pre>
<p>Even though addition takes two arguments, only one of them needs to be inspected.
To add zero to a number \( n \), just return \( n \).
To add the successor of \( k \) to \( n \), take the successor of the result of adding \( k \) to \( n \).</p>
<pre><code class="language-lean">def plus (n : Nat) (k : Nat) : Nat :=
  match k with
  | Nat.zero =&gt; n
  | Nat.succ k' =&gt; Nat.succ (plus n k')
</code></pre>
<p>In the definition of <code>plus</code>, the name <code>k'</code> is chosen to indicate that it is connected to, but not identical with, the argument <code>k</code>.
For instance, walking through the evaluation of <code>plus 3 2</code> yields the following steps:</p>
<pre><code class="language-lean">plus 3 2
===&gt;
plus 3 (Nat.succ (Nat.succ Nat.zero))
===&gt;
match Nat.succ (Nat.succ Nat.zero) with
| Nat.zero =&gt; 3
| Nat.succ k' =&gt; Nat.succ (plus 3 k')
===&gt;
Nat.succ (plus 3 (Nat.succ Nat.zero))
===&gt;
Nat.succ (match Nat.succ Nat.zero with
| Nat.zero =&gt; 3
| Nat.succ k' =&gt; Nat.succ (plus 3 k'))
===&gt;
Nat.succ (Nat.succ (plus 3 Nat.zero))
===&gt;
Nat.succ (Nat.succ (match Nat.zero with
| Nat.zero =&gt; 3
| Nat.succ k' =&gt; Nat.succ (plus 3 k')))
===&gt;
Nat.succ (Nat.succ 3)
===&gt;
5
</code></pre>
<p>One way to think about addition is that \( n + k \) applies <code>Nat.succ</code> \( k \) times to \( n \).
Similarly, multiplication \( n × k \) adds \( n \) to itself \( k \) times and subtraction \( n - k \) takes \( n \)'s predecessor \( k \) times.</p>
<pre><code class="language-lean">def times (n : Nat) (k : Nat) : Nat :=
  match k with
  | Nat.zero =&gt; Nat.zero
  | Nat.succ k' =&gt; plus n (times n k')

def minus (n : Nat) (k : Nat) : Nat :=
  match k with
  | Nat.zero =&gt; n
  | Nat.succ k' =&gt; pred (minus n k')
</code></pre>
<p>Not every function can be easily written using structural recursion.
The understanding of addition as iterated <code>Nat.succ</code>, multiplication as iterated addition, and subtraction as iterated predecessor suggests an implementation of division as iterated subtraction.
In this case, if the numerator is less than the divisor, the result is zero.
Otherwise, the result is the successor of dividing the numerator minus the divisor by the divisor.</p>
<pre><code class="language-lean">def div (n : Nat) (k : Nat) : Nat :=
  if n &lt; k then
    0
  else Nat.succ (div (n - k) k)
</code></pre>
<p>As long as the second argument is not <code>0</code>, this program terminates, as it always makes progress towards the base case.
However, it is not structurally recursive, because it doesn't follow the pattern of finding a result for zero and transforming a result for a smaller <code>Nat</code> into a result for its successor.
In particular, the recursive invocation of the function is applied to the result of another function call, rather than to an input constructor's argument.
Thus, Lean rejects it with the following message:</p>
<pre><code class="language-output error">fail to show termination for
  div
with errors
argument #1 was not used for structural recursion
  failed to eliminate recursive application
    div (n - k) k

argument #2 was not used for structural recursion
  failed to eliminate recursive application
    div (n - k) k

structural recursion cannot be used

failed to prove termination, use `termination_by` to specify a well-founded relation
</code></pre>
<p>This message means that <code>div</code> requires a manual proof of termination.
This topic is explored in <a href="getting-to-know/../programs-proofs/inequalities.html#division-as-iterated-subtraction">the final chapter</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="polymorphism"><a class="header" href="#polymorphism">Polymorphism</a></h1>
<p>Just as in most languages, types in Lean can take arguments.
For instance, the type <code>List Nat</code> describes lists of natural numbers, <code>List String</code> describes lists of strings, and <code>List (List Point)</code> describes lists of lists of points.
This is very similar to <code>List&lt;Nat&gt;</code>, <code>List&lt;String&gt;</code>, or <code>List&lt;List&lt;Point&gt;&gt;</code> in a language like C# or Java.
Just as Lean uses a space to pass an argument to a function, it uses a space to pass an argument to a type.</p>
<p>In functional programming, the term <em>polymorphism</em> typically refers to datatypes and definitions that take types as arguments.
This is different from the object-oriented programming community, where the term typically refers to subclasses that may override some behavior of their superclass.
In this book, &quot;polymorphism&quot; always refers to the first sense of the word.
These type arguments can be used in the datatype or definition, which allows the same datatype or definition to be used with any type that results from replacing the arguments' names with some other types.</p>
<p>The <code>Point</code> structure requires that both the <code>x</code> and <code>y</code> fields are <code>Float</code>s.
There is, however, nothing about points that require a specific representation for each coordinate.
A polymorphic version of <code>Point</code>, called <code>PPoint</code>, can take a type as an argument, and then use that type for both fields:</p>
<pre><code class="language-lean">structure PPoint (α : Type) where
  x : α
  y : α
deriving Repr
</code></pre>
<p>Just as a function definition's arguments are written immediately after the name being defined, a structure's arguments are written immediately after the structure's name.
It is customary to use Greek letters to name type arguments in Lean when no more specific name suggests itself.
<code>Type</code> is a type that describes other types, so <code>Nat</code>, <code>List String</code>, and <code>PPoint Int</code> all have type <code>Type</code>.</p>
<p>Just like <code>List</code>, <code>PPoint</code> can be used by providing a specific type as its argument:</p>
<pre><code class="language-lean">def natOrigin : PPoint Nat :=
  { x := Nat.zero, y := Nat.zero }
</code></pre>
<p>In this example, both fields are expected to be <code>Nat</code>s.
Just as a function is called by replacing its argument variables with its argument values, providing <code>PPoint</code> with the type <code>Nat</code> as an argument yields a structure in which the fields <code>x</code> and <code>y</code> have the type <code>Nat</code>, because the argument name <code>α</code> has been replaced by the argument type <code>Nat</code>.
Types are ordinary expressions in Lean, so passing arguments to polymorphic types (like <code>PPoint</code>) doesn't require any special syntax.</p>
<p>Definitions may also take types as arguments, which makes them polymorphic.
The function <code>replaceX</code> replaces the <code>x</code> field of a <code>PPoint</code> with a new value.
In order to allow <code>replaceX</code> to work with <em>any</em> polymorphic point, it must be polymorphic itself.
This is achieved by having its first argument be the type of the point's fields, with later arguments referring back to the first argument's name.</p>
<pre><code class="language-lean">def replaceX (α : Type) (point : PPoint α) (newX : α) : PPoint α :=
  { point with x := newX }
</code></pre>
<p>In other words, when the types of the arguments <code>point</code> and <code>newX</code> mention <code>α</code>, they are referring to <em>whichever type was provided as the first argument</em>.
This is similar to the way that function argument names refer to the values that were provided when they occur in the function's body.</p>
<p>This can be seen by asking Lean to check the type of <code>replaceX</code>, and then asking it to check the type of <code>replaceX Nat</code>.</p>
<pre><code class="language-lean">#check (replaceX)
</code></pre>
<pre><code class="language-output info">replaceX : (α : Type) → PPoint α → α → PPoint α
</code></pre>
<p>This function type includes the <em>name</em> of the first argument, and later arguments in the type refer back to this name.
Just as the value of a function application is found by replacing the argument name with the provided argument value in the function's body, the type of a function application is found by replacing the argument's name with the provided value in the function's return type.
Providing the first argument, <code>Nat</code>, causes all occurrences of <code>α</code> in the remainder of the type to be replaced with <code>Nat</code>:</p>
<pre><code class="language-lean">#check replaceX Nat
</code></pre>
<pre><code class="language-output info">replaceX Nat : PPoint Nat → Nat → PPoint Nat
</code></pre>
<p>Because the remaining arguments are not explicitly named, no further substitution occurs as more arguments are provided:</p>
<pre><code class="language-lean">#check replaceX Nat natOrigin
</code></pre>
<pre><code class="language-output info">replaceX Nat natOrigin : Nat → PPoint Nat
</code></pre>
<pre><code class="language-lean">#check replaceX Nat natOrigin 5
</code></pre>
<pre><code class="language-output info">replaceX Nat natOrigin 5 : PPoint Nat
</code></pre>
<p>The fact that the type of the whole function application expression was determined by passing a type as an argument has no bearing on the ability to evaluate it.</p>
<pre><code class="language-lean">#eval replaceX Nat natOrigin 5
</code></pre>
<pre><code class="language-output info">{ x := 5, y := 0 }
</code></pre>
<p>Polymorphic functions work by taking a named type argument and having later types refer to the argument's name.
However, there's nothing special about type arguments that allows them to be named.
Given a datatype that represents positive or negative signs:</p>
<pre><code class="language-lean">inductive Sign where
  | pos
  | neg
</code></pre>
<p>it is possible to write a function whose argument is a sign.
If the argument is positive, the function returns a <code>Nat</code>, while if it's negative, it returns an <code>Int</code>:</p>
<pre><code class="language-lean">def posOrNegThree (s : Sign) : match s with | Sign.pos =&gt; Nat | Sign.neg =&gt; Int :=
  match s with
  | Sign.pos =&gt; (3 : Nat)
  | Sign.neg =&gt; (-3 : Int)
</code></pre>
<p>Because types are first class and can be computed using the ordinary rules of the Lean language, they can be computed by pattern-matching against a datatype.
When Lean is checking this function, it uses the fact that the <code>match</code>-expression in the function's body corresponds to the <code>match</code>-expression in the type to make <code>Nat</code> be the expected type for the <code>pos</code> case and to make <code>Int</code> be the expected type for the <code>neg</code> case.</p>
<p>Applying <code>posOrNegThree</code> to <code>Sign.pos</code> results in the argument name <code>s</code> in both the body of the function and its return type being replaced by <code>Sign.pos</code>.
Evaluation can occur both in the expression and its type:</p>
<pre><code class="language-lean">(posOrNegThree Sign.pos : match Sign.pos with | Sign.pos =&gt; Nat | Sign.neg =&gt; Int)
===&gt;
((match Sign.pos with
  | Sign.pos =&gt; (3 : Nat)
  | Sign.neg =&gt; (-3 : Int)) :
 match Sign.pos with | Sign.pos =&gt; Nat | Sign.neg =&gt; Int)
===&gt;
((3 : Nat) : Nat)
===&gt;
3
</code></pre>
<h2 id="linked-lists"><a class="header" href="#linked-lists">Linked Lists</a></h2>
<p>Lean's standard library includes a canonical linked list datatype, called <code>List</code>, and special syntax that makes it more convenient to use.
Lists are written in square brackets.
For instance, a list that contains the prime numbers less than 10 can be written:</p>
<pre><code class="language-lean">def primesUnder10 : List Nat := [2, 3, 5, 7]
</code></pre>
<p>Behind the scenes, <code>List</code> is an inductive datatype, defined like this:</p>
<pre><code class="language-lean">inductive List (α : Type) where
  | nil : List α
  | cons : α → List α → List α
</code></pre>
<p>The actual definition in the standard library is slightly different, because it uses features that have not yet been presented, but it is substantially similar.
This definition says that <code>List</code> takes a single type as its argument, just as <code>PPoint</code> did.
This type is the type of the entries stored in the list.
According to the constructors, a <code>List α</code> can be built with either <code>nil</code> or <code>cons</code>.
The constructor <code>nil</code> represents empty lists and the constructor <code>cons</code> is used for non-empty lists.
The first argument to <code>cons</code> is the head of the list, and the second argument is its tail.
A list that contains \( n \) entries contains \( n \) <code>cons</code> constructors, the last of which has <code>nil</code> as its tail.</p>
<p>The <code>primesUnder10</code> example can be written more explicitly by using <code>List</code>'s constructors directly:</p>
<pre><code class="language-lean">def explicitPrimesUnder10 : List Nat :=
  List.cons 2 (List.cons 3 (List.cons 5 (List.cons 7 List.nil)))
</code></pre>
<p>These two definitions are completely equivalent, but <code>primesUnder10</code> is much easier to read than <code>explicitPrimesUnder10</code>.</p>
<p>Functions that consume <code>List</code>s can be defined in much the same way as functions that consume <code>Nat</code>s.
Indeed, one way to think of a linked list is as a <code>Nat</code> that has an extra data field dangling off each <code>succ</code> constructor.
From this point of view, computing the length of a list is the process of replacing each <code>cons</code> with a <code>succ</code> and the final <code>nil</code> with a <code>zero</code>.
Just as <code>replaceX</code> took the type of the fields of the point as an argument, <code>length</code> takes the type of the list's entries.
For example, if the list contains strings, then the first argument is <code>String</code>: <code>length String [&quot;Sourdough&quot;, &quot;bread&quot;]</code>.
It should compute like this:</p>
<pre><code>length String [&quot;Sourdough&quot;, &quot;bread&quot;]
===&gt;
length String (List.cons &quot;Sourdough&quot; (List.cons &quot;bread&quot; List.nil))
===&gt;
Nat.succ (length String (List.cons &quot;bread&quot; List.nil))
===&gt;
Nat.succ (Nat.succ (length String List.nil))
===&gt;
Nat.succ (Nat.succ Nat.zero)
===&gt;
2
</code></pre>
<p>The definition of <code>length</code> is both polymorphic (because it takes the list entry type as an argument) and recursive (because it refers to itself).
Generally, functions follow the shape of the data: recursive datatypes lead to recursive functions, and polymorphic datatypes lead to polymorphic functions.</p>
<pre><code class="language-lean">def length (α : Type) (xs : List α) : Nat :=
  match xs with
  | List.nil =&gt; Nat.zero
  | List.cons y ys =&gt; Nat.succ (length α ys)
</code></pre>
<p>Names such as <code>xs</code> and <code>ys</code> are conventionally used to stand for lists of unknown values.
The <code>s</code> in the name indicates that they are plural, so they are pronounced &quot;exes&quot; and &quot;whys&quot; rather than &quot;x s&quot; and &quot;y s&quot;.</p>
<p>To make it easier to read functions on lists, the bracket notation <code>[]</code> can be used to pattern-match against <code>nil</code>, and an infix <code>::</code> can be used in place of <code>cons</code>:</p>
<pre><code class="language-lean">def length (α : Type) (xs : List α) : Nat :=
  match xs with
  | [] =&gt; 0
  | y :: ys =&gt; Nat.succ (length α ys)
</code></pre>
<h2 id="implicit-arguments"><a class="header" href="#implicit-arguments">Implicit Arguments</a></h2>
<p>Both <code>replaceX</code> and <code>length</code> are somewhat bureaucratic to use, because the type argument is typically uniquely determined by the later values.
Indeed, in most languages, the compiler is perfectly capable of determining type arguments on its own, and only occasionally needs help from users.
This is also the case in Lean.
Arguments can be declared <em>implicit</em> by wrapping them in curly braces instead of parentheses when defining a function.
For instance, a version of <code>replaceX</code> with an implicit type argument looks like this:</p>
<pre><code class="language-lean">def replaceX {α : Type} (point : PPoint α) (newX : α) : PPoint α :=
  { point with x := newX }
</code></pre>
<p>It can be used with <code>natOrigin</code> without providing <code>Nat</code> explicitly, because Lean can <em>infer</em> the value of <code>α</code> from the later arguments:</p>
<pre><code class="language-lean">#eval replaceX natOrigin 5
</code></pre>
<pre><code class="language-output info">{ x := 5, y := 0 }
</code></pre>
<p>Similarly, <code>length</code> can be redefined to take the entry type implicitly:</p>
<pre><code class="language-lean">def length {α : Type} (xs : List α) : Nat :=
  match xs with
  | [] =&gt; 0
  | y :: ys =&gt; Nat.succ (length ys)
</code></pre>
<p>This <code>length</code> function can be applied directly to <code>primesUnder10</code>:</p>
<pre><code class="language-lean">#eval length primesUnder10
</code></pre>
<pre><code class="language-output info">4
</code></pre>
<p>In the standard library, Lean calls this function <code>List.length</code>, which means that the dot syntax that is used for structure field access can also be used to find the length of a list:</p>
<pre><code class="language-lean">#eval primesUnder10.length
</code></pre>
<pre><code class="language-output info">4
</code></pre>
<p>Just as C# and Java require type arguments to be provided explicitly from time to time, Lean is not always capable of finding implicit arguments.
In these cases, they can be provided using their names.
For instance, a version of <code>List.length</code> that only works for lists of integers can be specified by setting <code>α</code> to <code>Int</code>:</p>
<pre><code class="language-lean">#check List.length (α := Int)
</code></pre>
<pre><code class="language-output info">List.length : List Int → Nat
</code></pre>
<h2 id="more-built-in-datatypes"><a class="header" href="#more-built-in-datatypes">More Built-In Datatypes</a></h2>
<p>In addition to lists, Lean's standard library contains a number of other structures and inductive datatypes that can be used in a variety of contexts.</p>
<h3 id="option"><a class="header" href="#option"><code>Option</code></a></h3>
<p>Not every list has a first entry—some lists are empty.
Many operations on collections may fail to find what they are looking for.
For instance, a function that finds the first entry in a list may not find any such entry.
It must therefore have a way to signal that there was no first entry.</p>
<p>Many languages have a <code>null</code> value that represents the absence of a value.
Instead of equipping existing types with a special <code>null</code> value, Lean provides a datatype called <code>Option</code> that equips some other type with an indicator for missing values.
For instance, a nullable <code>Int</code> is represented by <code>Option Int</code>, and a nullable list of strings is represented by the type <code>Option (List String)</code>.
Introducing a new type to represent nullability means that the type system ensures that checks for <code>null</code> cannot be forgotten, because an <code>Option Int</code> can't be used in a context where an <code>Int</code> is expected.</p>
<p><code>Option</code> has two constructors, called <code>some</code> and <code>none</code>, that respectively represent the non-null and null versions of the underlying type.
The non-null constructor, <code>some</code>, contains the underlying value, while <code>none</code> takes no arguments:</p>
<pre><code class="language-lean">inductive Option (α : Type) : Type where
  | none : Option α
  | some (val : α) : Option α
</code></pre>
<p>The <code>Option</code> type is very similar to nullable types in languages like C# and Kotlin, but it is not identical.
In these languages, if a type (say, <code>Boolean</code>) always refers to actual values of the type (<code>true</code> and <code>false</code>), the type <code>Boolean?</code> or <code>Nullable&lt;Boolean&gt;</code> additionally admits the <code>null</code> value.
Tracking this in the type system is very useful: the type checker and other tooling can help programmers remember to check for null, and APIs that explicitly describe nullability through type signatures are more informative than ones that don't.
However, these nullable types differ from Lean's <code>Option</code> in one very important way, which is that they don't allow multiple layers of optionality.
<code>Option (Option Int)</code> can be constructed with <code>none</code>, <code>some none</code>, or <code>some (some 360)</code>.
C#, on the other hand, forbids multiple layers of nullability by only allowing <code>?</code> to be added to non-nullable types, while Kotlin treats <code>T??</code> as being equivalent to <code>T?</code>.
This subtle difference is rarely relevant in practice, but it can matter from time to time.</p>
<p>To find the first entry in a list, if it exists, use <code>List.head?</code>.
The question mark is part of the name, and is not related to the use of question marks to indicate nullable types in C# or Kotlin.
In the definition of <code>List.head?</code>, an underscore is used to represent the tail of the list.
In patterns, underscores match anything at all, but do not introduce variables to refer to the matched data.
Using underscores instead of names is a way to clearly communicate to readers that part of the input is ignored.</p>
<pre><code class="language-lean">def List.head? {α : Type} (xs : List α) : Option α :=
  match xs with
  | [] =&gt; none
  | y :: _ =&gt; some y
</code></pre>
<p>A Lean naming convention is to define operations that might fail in groups using the suffixes <code>?</code> for a version that returns an <code>Option</code>, <code>!</code> for a version that crashes when provided with invalid input, and <code>D</code> for a version that returns a default value when the operation would otherwise fail.
For instance, <code>head</code> requires the caller to provide mathematical evidence that the list is not empty, <code>head?</code> returns an <code>Option</code>, <code>head!</code> crashes the program when passed an empty list, and <code>headD</code> takes a default value to return in case the list is empty.
The question mark and exclamation mark are part of the name, not special syntax, as Lean's naming rules are more liberal than many languages.</p>
<p>Because <code>head?</code> is defined in the <code>List</code> namespace, it can be used with accessor notation:</p>
<pre><code class="language-lean">#eval primesUnder10.head?
</code></pre>
<pre><code class="language-output info">some 2
</code></pre>
<p>However, attempting to test it on the empty list leads to two errors:</p>
<pre><code class="language-lean">#eval [].head?
</code></pre>
<pre><code class="language-output error">don't know how to synthesize implicit argument
  @List.nil ?m.20368
context:
⊢ Type ?u.20365

don't know how to synthesize implicit argument
  @_root_.List.head? ?m.20368 []
context:
⊢ Type ?u.20365
</code></pre>
<p>This is because Lean was unable to fully determine the expression's type.
In particular, it could neither find the implicit type argument to <code>List.head?</code>, nor could it find the implicit type argument to <code>List.nil</code>.
In Lean's output, <code>?m.XYZ</code> represents a part of a program that could not be inferred.
These unknown parts are called <em>metavariables</em>, and they occur in some error messages.
In order to evaluate an expression, Lean needs to be able to find its type, and the type was unavailable because the empty list does not have any entries from which the type can be found.
Explicitly providing a type allows Lean to proceed:</p>
<pre><code class="language-lean">#eval [].head? (α := Int)
</code></pre>
<pre><code class="language-output info">none
</code></pre>
<p>The type can also be provided with a type annotation:</p>
<pre><code class="language-lean">#eval ([] : List Int).head?
</code></pre>
<pre><code class="language-output info">none
</code></pre>
<p>The error messages provide a useful clue.
Both messages use the <em>same</em> metavariable to describe the missing implicit argument, which means that Lean has determined that the two missing pieces will share a solution, even though it was unable to determine the actual value of the solution.</p>
<h3 id="prod"><a class="header" href="#prod"><code>Prod</code></a></h3>
<p>The <code>Prod</code> structure, short for &quot;Product&quot;, is a generic way of joining two values together.
For instance, a <code>Prod Nat String</code> contains a <code>Nat</code> and a <code>String</code>.
In other words, <code>PPoint Nat</code> could be replaced by <code>Prod Nat Nat</code>.
<code>Prod</code> is very much like C#'s tuples, the <code>Pair</code> and <code>Triple</code> types in Kotlin, and <code>tuple</code> in C++.
Many applications are best served by defining their own structures, even for simple cases like <code>Point</code>, because using domain terminology can make it easier to read the code.
Additionally, defining structure types helps catch more errors by assigning different types to different domain concepts, preventing them from being mixed up.</p>
<p>On the other hand, there are some cases where it is not worth the overhead of defining a new type.
Additionally, some libraries are sufficiently generic that there is no more specific concept than &quot;pair&quot;.
Finally, the standard library contains a variety of convenience functions that make it easier to work with the built-in pair type.</p>
<p>The standard pair structure is called <code>Prod</code>.</p>
<pre><code class="language-lean">structure Prod (α : Type) (β : Type) : Type where
  fst : α
  snd : β
</code></pre>
<p>Lists are used so frequently that there is special syntax to make them more readable.
For the same reason, both the product type and its constructor have special syntax.
The type <code>Prod α β</code> is typically written <code>α × β</code>, mirroring the usual notation for a Cartesian product of sets.
Similarly, the usual mathematical notation for pairs is available for <code>Prod</code>.
In other words, instead of writing:</p>
<pre><code class="language-lean">def fives : String × Int := { fst := &quot;five&quot;, snd := 5 }
</code></pre>
<p>it suffices to write:</p>
<pre><code class="language-lean">def fives : String × Int := (&quot;five&quot;, 5)
</code></pre>
<p>Both notations are right-associative.
This means that the following definitions are equivalent:</p>
<pre><code class="language-lean">def sevens : String × Int × Nat := (&quot;VII&quot;, 7, 4 + 3)

def sevens : String × (Int × Nat) := (&quot;VII&quot;, (7, 4 + 3))
</code></pre>
<p>In other words, all products of more than two types, and their corresponding constructors, are actually nested products and nested pairs behind the scenes.</p>
<h3 id="sum"><a class="header" href="#sum"><code>Sum</code></a></h3>
<p>The <code>Sum</code> datatype is a generic way of allowing a choice between values of two different types.
For instance, a <code>Sum String Int</code> is either a <code>String</code> or an <code>Int</code>.
Like <code>Prod</code>, <code>Sum</code> should be used either when writing very generic code, for a very small section of code where there is no sensible domain-specific type, or when the standard library contains useful functions.
In most situations, it is more readable and maintainable to use a custom inductive type.</p>
<p>Values of type <code>Sum α β</code> are either the constructor <code>inl</code> applied to a value of type <code>α</code> or the constructor <code>inr</code> applied to a value of type <code>β</code>:</p>
<pre><code class="language-lean">inductive Sum (α : Type) (β : Type) : Type where
  | inl : α → Sum α β
  | inr : β → Sum α β
</code></pre>
<p>These names are abbreviations for &quot;left injection&quot; and &quot;right injection&quot;, respectively.
Just as the Cartesian product notation is used for <code>Prod</code>, a &quot;circled plus&quot; notation is used for <code>Sum</code>, so <code>α ⊕ β</code> is another way to write <code>Sum α β</code>.
There is no special syntax for <code>Sum.inl</code> and <code>Sum.inr</code>.</p>
<p>For instance, if pet names can either be dog names or cat names, then a type for them can be introduced as a sum of strings:</p>
<pre><code class="language-lean">def PetName : Type := String ⊕ String
</code></pre>
<p>In a real program, it would usually be better to define a custom inductive datatype for this purpose with informative constructor names.
Here, <code>Sum.inl</code> is to be used for dog names, and <code>Sum.inr</code> is to be used for cat names.
These constructors can be used to write a list of animal names:</p>
<pre><code class="language-lean">def animals : List PetName :=
  [Sum.inl &quot;Spot&quot;, Sum.inr &quot;Tiger&quot;, Sum.inl &quot;Fifi&quot;, Sum.inl &quot;Rex&quot;, Sum.inr &quot;Floof&quot;]
</code></pre>
<p>Pattern matching can be used to distinguish between the two constructors.
For instance, a function that counts the number of dogs in a list of animal names (that is, the number of <code>Sum.inl</code> constructors) looks like this:</p>
<pre><code class="language-lean">def howManyDogs (pets : List PetName) : Nat :=
  match pets with
  | [] =&gt; 0
  | Sum.inl _ :: morePets =&gt; howManyDogs morePets + 1
  | Sum.inr _ :: morePets =&gt; howManyDogs morePets
</code></pre>
<p>Function calls are evaluated before infix operators, so <code>howManyDogs morePets + 1</code> is the same as <code>(howManyDogs morePets) + 1</code>.
As expected, <code>#eval howManyDogs animals</code> yields <code>3</code>.</p>
<h3 id="unit"><a class="header" href="#unit"><code>Unit</code></a></h3>
<p><code>Unit</code> is a type with just one argumentless constructor, called <code>unit</code>.
In other words, it describes only a single value, which consists of said constructor applied to no arguments whatsoever.
<code>Unit</code> is defined as follows:</p>
<pre><code class="language-lean">inductive Unit : Type where
  | unit : Unit
</code></pre>
<p>On its own, <code>Unit</code> is not particularly useful.
However, in polymorphic code, it can be used as a placeholder for data that is missing.
For instance, the following inductive datatype represents arithmetic expressions:</p>
<pre><code class="language-lean">inductive ArithExpr (ann : Type) : Type where
  | int : ann → Int → ArithExpr ann
  | plus : ann → ArithExpr ann → ArithExpr ann → ArithExpr ann
  | minus : ann → ArithExpr ann → ArithExpr ann → ArithExpr ann
  | times : ann → ArithExpr ann → ArithExpr ann → ArithExpr ann
</code></pre>
<p>The type argument <code>ann</code> stands for annotations, and each constructor is annotated.
Expressions coming from a parser might be annotated with source locations, so a return type of <code>ArithExpr SourcePos</code> ensures that the parser put a <code>SourcePos</code> at each subexpression.
Expressions that don't come from the parser, however, will not have source locations, so their type can be <code>ArithExpr Unit</code>.</p>
<p>Additionally, because all Lean functions have arguments, zero-argument functions in other languages can be represented as functions that take a <code>Unit</code> argument.
In a return position, the <code>Unit</code> type is similar to <code>void</code> in languages derived from C.
In the C family, a function that returns <code>void</code> will return control to its caller, but it will not return any interesting value.
By being an intentionally uninteresting value, <code>Unit</code> allows this to be expressed without requiring a special-purpose <code>void</code> feature in the type system.
Unit's constructor can be written as empty parentheses: <code>() : Unit</code>.</p>
<h3 id="empty"><a class="header" href="#empty"><code>Empty</code></a></h3>
<p>The <code>Empty</code> datatype has no constructors whatsoever.
Thus, it indicates unreachable code, because no series of calls can ever terminate with a value at type <code>Empty</code>.</p>
<p><code>Empty</code> is not used nearly as often as <code>Unit</code>.
However, it is useful in some specialized contexts.
Many polymorphic datatypes do not use all of their type arguments in all of their constructors.
For instance, <code>Sum.inl</code> and <code>Sum.inr</code> each use only one of <code>Sum</code>'s type arguments.
Using <code>Empty</code> as one of the type arguments to <code>Sum</code> can rule out one of the constructors at a particular point in a program.
This can allow generic code to be used in contexts that have additional restrictions.</p>
<h3 id="naming-sums-products-and-units"><a class="header" href="#naming-sums-products-and-units">Naming: Sums, Products, and Units</a></h3>
<p>Generally speaking, types that offer multiple constructors are called <em>sum types</em>, while types whose single constructor takes multiple arguments are called <em>product types</em>.
These terms are related to sums and products used in ordinary arithmetic.
The relationship is easiest to see when the types involved contain a finite number of values.
If <code>α</code> and <code>β</code> are types that contain \( n \) and \( k \) distinct values, respectively, then <code>α ⊕ β</code> contains \( n + k \) distinct values and <code>α × β</code> contains \( n \times k \) distinct values.
For instance, <code>Bool</code> has two values: <code>true</code> and <code>false</code>, and <code>Unit</code> has one value: <code>Unit.unit</code>.
The product <code>Bool × Unit</code> has the two values <code>(true, Unit.unit)</code> and <code>(false, Unit.unit)</code>, and the sum <code>Bool ⊕ Unit</code> has the three values <code>Sum.inl true</code>, <code>Sum.inl false</code>, and <code>Sum.inr unit</code>.
Similarly, \( 2 \times 1 = 2 \), and \( 2 + 1 = 3 \).</p>
<h2 id="messages-you-may-meet-2"><a class="header" href="#messages-you-may-meet-2">Messages You May Meet</a></h2>
<p>Not all definable structures or inductive types can have the type <code>Type</code>.
In particular, if a constructor takes an arbitrary type as an argument, then the inductive type must have a different type.
These errors usually state something about &quot;universe levels&quot;.
For example, for this inductive type:</p>
<pre><code class="language-lean">inductive MyType : Type where
  | ctor : (α : Type) → α → MyType
</code></pre>
<p>Lean gives the following error:</p>
<pre><code class="language-output error">invalid universe level in constructor 'MyType.ctor', parameter 'α' has type
  Type
at universe level
  2
it must be smaller than or equal to the inductive datatype universe level
  1
</code></pre>
<p>A later chapter describes why this is the case, and how to modify definitions to make them work.
For now, try making the type an argument to the inductive type as a whole, rather than to the constructor.</p>
<p>Similarly, if a constructor's argument is a function that takes the datatype being defined as an argument, then the definition is rejected.
For example:</p>
<pre><code class="language-lean">inductive MyType : Type where
  | ctor : (MyType → Int) → MyType
</code></pre>
<p>yields the message:</p>
<pre><code class="language-output error">(kernel) arg #1 of 'MyType.ctor' has a non positive occurrence of the datatypes being declared
</code></pre>
<p>For technical reasons, allowing these datatypes could make it possible to undermine Lean's internal logic, making it unsuitable for use as a theorem prover.</p>
<p>Forgetting an argument to an inductive type can also yield a confusing message.
For example, when the argument <code>α</code> is not passed to <code>MyType</code> in <code>ctor</code>'s type:</p>
<pre><code class="language-lean">inductive MyType (α : Type) : Type where
  | ctor : α → MyType
</code></pre>
<p>Lean replies with the following error:</p>
<pre><code class="language-output error">type expected, got
  (MyType : Type → Type)
</code></pre>
<p>The error message is saying that <code>MyType</code>'s type, which is <code>Type → Type</code>, does not itself describe types.
<code>MyType</code> requires an argument to become an actual honest-to-goodness type.</p>
<p>The same message can appear when type arguments are omitted in other contexts, such as in a type signature for a definition:</p>
<pre><code class="language-lean">inductive MyType (α : Type) : Type where
  | ctor : α → MyType α

def ofFive : MyType := ctor 5
</code></pre>
<h2 id="exercises-3"><a class="header" href="#exercises-3">Exercises</a></h2>
<ul>
<li>Write a function to find the last entry in a list. It should return an <code>Option</code>.</li>
<li>Write a function that finds the first entry in a list that satisfies a given predicate. Start the definition with <code>def List.findFirst? {α : Type} (xs : List α) (predicate : α → Bool) : Option α :=</code></li>
<li>Write a function <code>Prod.swap</code> that swaps the two fields in a pair. Start the definition with <code>def Prod.swap {α β : Type} (pair : α × β) : β × α :=</code></li>
<li>Rewrite the <code>PetName</code> example to use a custom datatype and compare it to the version that uses <code>Sum</code>.</li>
<li>Write a function <code>zip</code> that combines two lists into a list of pairs. The resulting list should be as long as the shortest input list. Start the definition with <code>def zip {α β : Type} (xs : List α) (ys : List β) : List (α × β) :=</code>.</li>
<li>Write a polymorphic function <code>take</code> that returns the first \( n \) entries in a list, where \( n \) is a <code>Nat</code>. If the list contains fewer than <code>n</code> entries, then the resulting list should be the input list. <code>#eval take 3 [&quot;bolete&quot;, &quot;oyster&quot;]</code> should yield <code>[&quot;bolete&quot;, &quot;oyster&quot;]</code>, and <code>#eval take 1 [&quot;bolete&quot;, &quot;oyster&quot;]</code> should yield <code>[&quot;bolete&quot;]</code>.</li>
<li>Using the analogy between types and arithmetic, write a function that distributes products over sums. In other words, it should have type <code>α × (β ⊕ γ) → (α × β) ⊕ (α × γ)</code>.</li>
<li>Using the analogy between types and arithmetic, write a function that turns multiplication by two into a sum. In other words, it should have type <code>Bool × α → α ⊕ α</code>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="additional-conveniences"><a class="header" href="#additional-conveniences">Additional Conveniences</a></h1>
<p>Lean contains a number of convenience features that make programs much more concise.</p>
<h2 id="automatic-implicit-arguments"><a class="header" href="#automatic-implicit-arguments">Automatic Implicit Arguments</a></h2>
<p>When writing polymorphic functions in Lean, it is typically not necessary to list all the implicit arguments.
Instead, they can simply be mentioned.
If Lean can determine their type, then they are automatically inserted as implicit arguments.
In other words, the previous definition of <code>length</code>:</p>
<pre><code class="language-lean">def length {α : Type} (xs : List α) : Nat :=
  match xs with
  | [] =&gt; 0
  | y :: ys =&gt; Nat.succ (length ys)
</code></pre>
<p>can be written without <code>{α : Type}</code>:</p>
<pre><code class="language-lean">def length (xs : List α) : Nat :=
  match xs with
  | [] =&gt; 0
  | y :: ys =&gt; Nat.succ (length ys)
</code></pre>
<p>This can greatly simplify highly polymorphic definitions that take many implicit arguments.</p>
<h2 id="pattern-matching-definitions"><a class="header" href="#pattern-matching-definitions">Pattern-Matching Definitions</a></h2>
<p>When defining functions with <code>def</code>, it is quite common to name an argument and then immediately use it with pattern matching.
For instance, in <code>length</code>, the argument <code>xs</code> is used only in <code>match</code>.
In these situations, the cases of the <code>match</code> expression can be written directly, without naming the argument at all.</p>
<p>The first step is to move the arguments' types to the right of the colon, so the return type is a function type.
For instance, the type of <code>length</code> is <code>List α → Nat</code>.
Then, replace the <code>:=</code> with each case of the pattern match:</p>
<pre><code class="language-lean">def length : List α → Nat
  | [] =&gt; 0
  | y :: ys =&gt; Nat.succ (length ys)
</code></pre>
<p>This syntax can also be used to define functions that take more than one argument.
In this case, their patterns are separated by commas.
For instance, <code>drop</code> takes a number \( n \) and a list, and returns the list after removing the first \( n \) entries.</p>
<pre><code class="language-lean">def drop : Nat → List α → List α
  | Nat.zero, xs =&gt; xs
  | _, [] =&gt; []
  | Nat.succ n, x :: xs =&gt; drop n xs
</code></pre>
<p>Named arguments and patterns can also be used in the same definition.
For instance, a function that takes a default value and an optional value, and returns the default when the optional value is <code>none</code>, can be written:</p>
<pre><code class="language-lean">def fromOption (default : α) : Option α → α
  | none =&gt; default
  | some x =&gt; x
</code></pre>
<p>This function is called <code>Option.getD</code> in the standard library, and can be called with dot notation:</p>
<pre><code class="language-lean">#eval (some &quot;salmonberry&quot;).getD &quot;&quot;
</code></pre>
<pre><code class="language-output info">&quot;salmonberry&quot;
</code></pre>
<pre><code class="language-lean">#eval none.getD &quot;&quot;
</code></pre>
<pre><code class="language-output info">&quot;&quot;
</code></pre>
<h2 id="local-definitions"><a class="header" href="#local-definitions">Local Definitions</a></h2>
<p>It is often useful to name intermediate steps in a computation.
In many cases, intermediate values represent useful concepts all on their own, and naming them explicitly can make the program easier to read.
In other cases, the intermediate value is used more than once.
As in most other languages, writing down the same code twice in Lean causes it to be computed twice, while saving the result in a variable leads to the result of the computation being saved and re-used.</p>
<p>For instance, <code>unzip</code> is a function that transforms a list of pairs into a pair of lists.
When the list of pairs is empty, then the result of <code>unzip</code> is a pair of empty lists.
When the list of pairs has a pair at its head, then the two fields of the pair are added to the result of unzipping the rest of the list.
This definition of <code>unzip</code> follows that description exactly:</p>
<pre><code class="language-lean">def unzip : List (α × β) → List α × List β
  | [] =&gt; ([], [])
  | (x, y) :: xys =&gt;
    (x :: (unzip xys).fst, y :: (unzip xys).snd)
</code></pre>
<p>Unfortunately, there is a problem: this code is slower than it needs to be.
Each entry in the list of pairs leads to two recursive calls, which makes this function take exponential time.
However, both recursive calls will have the same result, so there is no reason to make the recursive call twice.</p>
<p>In Lean, the result of the recursive call can be named, and thus saved, using <code>let</code>.
Local definitions with <code>let</code> resemble top-level definitions with <code>def</code>: it takes a name to be locally defined, arguments if desired, a type signature, and then a body following <code>:=</code>.
After the local definition, the expression in which the local definition is available (called the <em>body</em> of the <code>let</code>-expression) must be on a new line, starting at a column in the file that is less than or equal to that of the <code>let</code> keyword.
For instance, <code>let</code> can be used in <code>unzip</code> like this:</p>
<pre><code class="language-lean">def unzip : List (α × β) → List α × List β
  | [] =&gt; ([], [])
  | (x, y) :: xys =&gt;
    let unzipped : List α × List β := unzip xys
    (x :: unzipped.fst, y :: unzipped.snd)
</code></pre>
<p>To use <code>let</code> on a single line, separate the local definition from the body with a semicolon.</p>
<p>Local definitions with <code>let</code> may also use pattern matching when one pattern is enough to match all cases of a datatype.
In the case of <code>unzip</code>, the result of the recursive call is a pair.
Because pairs have only a single constructor, the name <code>unzipped</code> can be replaced with a pair pattern:</p>
<pre><code class="language-lean">def unzip : List (α × β) → List α × List β
  | [] =&gt; ([], [])
  | (x, y) :: xys =&gt;
    let (xs, ys) : List α × List β := unzip xys
    (x :: xs, y :: ys)
</code></pre>
<p>Judicious use of patterns with <code>let</code> can make code easier to read, compared to writing the accessor calls by hand.</p>
<p>The biggest difference between <code>let</code> and <code>def</code> is that recursive <code>let</code> definitions must be explicitly indicated by writing <code>let rec</code>.
For instance, one way to reverse a list involves a recursive helper function, as in this definition:</p>
<pre><code class="language-lean">def reverse (xs : List α) : List α :=
  let rec helper : List α → List α → List α
    | [], soFar =&gt; soFar
    | y :: ys, soFar =&gt; helper ys (y :: soFar)
  helper xs []
</code></pre>
<p>The helper function walks down the input list, moving one entry at a time over to <code>soFar</code>.
When it reaches the end of the input list, <code>soFar</code> contains a reversed version of the input.</p>
<h2 id="type-inference"><a class="header" href="#type-inference">Type Inference</a></h2>
<p>In many situations, Lean can automatically determine an expression's type.
In these cases, explicit types may be omitted from both top-level definitions (with <code>def</code>) and local definitions (with <code>let</code>).
For instance, the recursive call to <code>unzip</code> does not need an annotation:</p>
<pre><code class="language-lean">def unzip : List (α × β) → List α × List β
  | [] =&gt; ([], [])
  | (x, y) :: xys =&gt;
    let unzipped := unzip xys
    (x :: unzipped.fst, y :: unzipped.snd)
</code></pre>
<p>As a rule of thumb, omitting the types of literal values (like strings and numbers) usually works, although Lean may pick a type for literal numbers that is more specific than the intended type.
Lean can usually determine a type for a function application, because it already knows the argument types and the return type.
Omitting return types for function definitions will often work, but function arguments typically require annotations.
Definitions that are not functions, like <code>unzipped</code> in the example, do not need type annotations if their bodies do not need type annotations, and the body of this definition is a function application.</p>
<p>Omitting the return type for <code>unzip</code> is possible when using an explicit <code>match</code> expression:</p>
<pre><code class="language-lean">def unzip (pairs : List (α × β)) :=
  match pairs with
  | [] =&gt; ([], [])
  | (x, y) :: xys =&gt;
    let unzipped := unzip xys
    (x :: unzipped.fst, y :: unzipped.snd)
</code></pre>
<p>Generally speaking, it is a good idea to err on the side of too many, rather than too few, type annotations.
First off, explicit types communicate assumptions about the code to readers.
Even if Lean can determine the type on its own, it can still be easier to read code without having to repeatedly query Lean for type information.
Secondly, explicit types help localize errors.
The more explicit a program is about its types, the more informative the error messages can be.
This is especially important in a language like Lean that has a very expressive type system.
Thirdly, explicit types make it easier to write the program in the first place.
The type is a specification, and the compiler's feedback can be a helpful tool in writing a program that meets the specification.
Finally, Lean's type inference is a best-effort system.
Because Lean's type system is so expressive, there is no &quot;best&quot; or most general type to find for all expressions.
This means that even if you get a type, there's no guarantee that it's the <em>right</em> type for a given application.
For instance, <code>14</code> can be a <code>Nat</code> or an <code>Int</code>:</p>
<pre><code class="language-lean">#check 14
</code></pre>
<pre><code class="language-output info">14 : Nat
</code></pre>
<pre><code class="language-lean">#check (14 : Int)
</code></pre>
<pre><code class="language-output info">14 : Int
</code></pre>
<p>Missing type annotations can give confusing error messages.
Omitting all types from the definition of <code>unzip</code>:</p>
<pre><code class="language-lean">def unzip pairs :=
  match pairs with
  | [] =&gt; ([], [])
  | (x, y) :: xys =&gt;
    let unzipped := unzip xys
    (x :: unzipped.fst, y :: unzipped.snd)
</code></pre>
<p>leads to a message about the <code>match</code> expression:</p>
<pre><code class="language-output error">invalid match-expression, pattern contains metavariables
  []
</code></pre>
<p>This is because <code>match</code> needs to know the type of the value being inspected, but that type was not available.
A &quot;metavariable&quot; is an unknown part of a program, written <code>?m.XYZ</code> in error messages—they are described in the <a href="getting-to-know/polymorphism.html">section on Polymorphism</a>.
In this program, the type annotation on the argument is required.</p>
<p>Even some very simple programs require type annotations.
For instance, the identity function just returns whatever argument it is passed.
With argument and type annotations, it looks like this:</p>
<pre><code class="language-lean">def id (x : α) : α := x
</code></pre>
<p>Lean is capable of determining the return type on its own:</p>
<pre><code class="language-lean">def id (x : α) := x
</code></pre>
<p>Omitting the argument type, however, causes an error:</p>
<pre><code class="language-lean">def id x := x
</code></pre>
<pre><code class="language-output error">failed to infer binder type
</code></pre>
<p>In general, messages that say something like &quot;failed to infer&quot; or that mention metavariables are often a sign that more type annotations are necessary.
Especially while still learning Lean, it is useful to provide most types explicitly.</p>
<h2 id="simultaneous-matching"><a class="header" href="#simultaneous-matching">Simultaneous Matching</a></h2>
<p>Pattern-matching expressions, just like pattern-matching definitions, can match on multiple values at once.
Both the expressions to be inspected and the patterns that they match against are written with commas between them, similarly to the syntax used for definitions.
Here is a version of <code>drop</code> that uses simultaneous matching:</p>
<pre><code class="language-lean">def drop (n : Nat) (xs : List α) : List α :=
  match n, xs with
  | Nat.zero, ys =&gt; ys
  | _, [] =&gt; []
  | Nat.succ n , y :: ys =&gt; drop n ys
</code></pre>
<h2 id="natural-number-patterns"><a class="header" href="#natural-number-patterns">Natural Number Patterns</a></h2>
<p>In the section on <a href="getting-to-know/datatypes-and-patterns.html">datatypes and patterns</a>, <code>even</code> was defined like this:</p>
<pre><code class="language-lean">def even (n : Nat) : Bool :=
  match n with
  | Nat.zero =&gt; true
  | Nat.succ k =&gt; not (even k)
</code></pre>
<p>Just as there is special syntax to make list patterns more readable than using <code>List.cons</code> and <code>List.nil</code> directly, natural numbers can be matched using literal numbers and <code>+</code>.
For instance, <code>even</code> can also be defined like this:</p>
<pre><code class="language-lean">def even : Nat → Bool
  | 0 =&gt; true
  | n + 1 =&gt; not (even n)
</code></pre>
<p>In this notation, the arguments to the <code>+</code> pattern serve different roles.
Behind the scenes, the left argument (<code>n</code> above) becomes an argument to some number of <code>Nat.succ</code> patterns, and the right argument (<code>1</code> above) determines how many <code>Nat.succ</code>s to wrap around the pattern.
The explicit patterns in <code>halve</code>, which divides a <code>Nat</code> by two and drops the remainder:</p>
<pre><code class="language-lean">def halve : Nat → Nat
  | Nat.zero =&gt; 0
  | Nat.succ Nat.zero =&gt; 0
  | Nat.succ (Nat.succ n) =&gt; halve n + 1
</code></pre>
<p>can be replaced by numeric literals and <code>+</code>:</p>
<pre><code class="language-lean">def halve : Nat → Nat
  | 0 =&gt; 0
  | 1 =&gt; 0
  | n + 2 =&gt; halve n + 1
</code></pre>
<p>Behind the scenes, both definitions are completely equivalent.
Remember: <code>halve n + 1</code> is equivalent to <code>(halve n) + 1</code>, not <code>halve (n + 1)</code>.</p>
<p>When using this syntax, the second argument to <code>+</code> should always be a literal <code>Nat</code>.
Even though addition is commutative, flipping the arguments in a pattern can result in errors like the following:</p>
<pre><code class="language-lean">def halve : Nat → Nat
  | 0 =&gt; 0
  | 1 =&gt; 0
  | 2 + n =&gt; halve n + 1
</code></pre>
<pre><code class="language-output error">invalid patterns, `n` is an explicit pattern variable, but it only occurs in positions that are inaccessible to pattern matching
  .(Nat.add 2 n)
</code></pre>
<p>This restriction enables Lean to transform all uses of the <code>+</code> notation in a pattern into uses of the underlying <code>Nat.succ</code>, keeping the language simpler behind the scenes.</p>
<h2 id="anonymous-functions"><a class="header" href="#anonymous-functions">Anonymous Functions</a></h2>
<p>Functions in Lean need not be defined at the top level.
As expressions, functions are produced with the <code>fun</code> syntax.
Function expressions begin with the keyword <code>fun</code>, followed by one or more arguments, which are separated from the return expression using <code>=&gt;</code>.
For instance, a function that adds one to a number can be written:</p>
<pre><code class="language-lean">#check fun x =&gt; x + 1
</code></pre>
<pre><code class="language-output info">fun x =&gt; x + 1 : Nat → Nat
</code></pre>
<p>Type annotations are written the same way as on <code>def</code>, using parentheses and colons:</p>
<pre><code class="language-lean">#check fun (x : Int) =&gt; x + 1
</code></pre>
<pre><code class="language-output info">fun x =&gt; x + 1 : Int → Int
</code></pre>
<p>Similarly, implicit arguments may be written with curly braces:</p>
<pre><code class="language-lean">#check fun {α : Type} (x : α) =&gt; x
</code></pre>
<pre><code class="language-output info">fun {α} x =&gt; x : {α : Type} → α → α
</code></pre>
<p>This style of anonymous function expression is often referred to as a <em>lambda expression</em>, because the typical notation used in mathematical descriptions of programming languages uses the Greek letter λ (lambda) where Lean has the keyword <code>fun</code>.
Even though Lean does permit <code>λ</code> to be used instead of <code>fun</code>, it is most common to write <code>fun</code>.</p>
<p>Anonymous functions also support the multiple-pattern style used in <code>def</code>.
For instance, a function that returns the predecessor of a natural number if it exists can be written:</p>
<pre><code class="language-lean">#check fun
  | 0 =&gt; none
  | n + 1 =&gt; some n
</code></pre>
<pre><code class="language-output info">fun x =&gt;
  match x with
  | 0 =&gt; none
  | Nat.succ n =&gt; some n : Nat → Option Nat
</code></pre>
<p>Note that Lean's own description of the function has a named argument and a <code>match</code> expression.
Many of Lean's convenient syntactic shorthands are expanded to simpler syntax behind the scenes, and the abstraction sometimes leaks.</p>
<p>Definitions using <code>def</code> that take arguments may be rewritten as function expressions.
For instance, a function that doubles its argument can be written as follows:</p>
<pre><code class="language-lean">def double : Nat → Nat := fun
  | 0 =&gt; 0
  | k + 1 =&gt; double k + 2
</code></pre>
<p>When an anonymous function is very simple, like <code>fun x =&gt; x + 1</code>, the syntax for creating the function can be fairly verbose.
In that particular example, six non-whitespace characters are used to introduce the function, and its body consists of only three non-whitespace characters.
For these simple cases, Lean provides a shorthand.
In an expression surrounded by parentheses, a centered dot character <code>·</code> can stand for an argument, and the expression inside the parentheses becomes the function's body.
That particular function can also be written <code>(· + 1)</code>.</p>
<p>The centered dot always creates a function out of the <em>closest</em> surrounding set of parentheses.
For instance, <code>(· + 5, 3)</code> is a function that returns a pair of numbers, while <code>((· + 5), 3)</code> is a pair of a function and a number.
If multiple dots are used, then they become arguments from left to right:</p>
<pre><code class="language-lean">(· , ·) 1 2
===&gt;
(1, ·) 2
===&gt;
(1, 2)
</code></pre>
<p>Anonymous functions can be applied in precisely the same way as functions defined using <code>def</code> or <code>let</code>.
The command <code>#eval (fun x =&gt; x + x) 5</code> results in:</p>
<pre><code class="language-output info">10
</code></pre>
<p>while <code>#eval (· * 2) 5</code> results in:</p>
<pre><code class="language-output info">10
</code></pre>
<h2 id="namespaces"><a class="header" href="#namespaces">Namespaces</a></h2>
<p>Each name in Lean occurs in a <em>namespace</em>, which is a collection of names.
Names are placed in namespaces using <code>.</code>, so <code>List.map</code> is the name <code>map</code> in the <code>List</code> namespace.
Names in different namespaces do not conflict with each other, even if they are otherwise identical.
This means that <code>List.map</code> and <code>Array.map</code> are different names.
Namespaces may be nested, so <code>Project.Frontend.User.loginTime</code> is the name <code>loginTime</code> in the nested namespace <code>Project.Frontend.User</code>.</p>
<p>Names can be directly defined within a namespace.
For instance, the name <code>double</code> can be defined in the <code>Nat</code> namespace:</p>
<pre><code class="language-lean">def Nat.double (x : Nat) : Nat := x + x
</code></pre>
<p>Because <code>Nat</code> is also the name of a type, dot notation is available to call <code>Nat.double</code> on expressions with type <code>Nat</code>:</p>
<pre><code class="language-lean">#eval (4 : Nat).double
</code></pre>
<pre><code class="language-output info">8
</code></pre>
<p>In addition to defining names directly in a namespace, a sequence of declarations can be placed in a namespace using the <code>namespace</code> and <code>end</code> commands.
For instance, this defines <code>triple</code> and <code>quadruple</code> in the namespace <code>NewNamespace</code>:</p>
<pre><code class="language-lean">namespace NewNamespace
def triple (x : Nat) : Nat := 3 * x
def quadruple (x : Nat) : Nat := 2 * x + 2 * x
end NewNamespace
</code></pre>
<p>To refer to them, prefix their names with <code>NewNamespace.</code>:</p>
<pre><code class="language-lean">#check NewNamespace.triple
</code></pre>
<pre><code class="language-output info">NewNamespace.triple (x : Nat) : Nat
</code></pre>
<pre><code class="language-lean">#check NewNamespace.quadruple
</code></pre>
<pre><code class="language-output info">NewNamespace.quadruple (x : Nat) : Nat
</code></pre>
<p>Namespaces may be <em>opened</em>, which allows the names in them to be used without explicit qualification.
Writing <code>open MyNamespace in</code> before an expression causes the contents of <code>MyNamespace</code> to be available in the expression.
For example, <code>timesTwelve</code> uses both <code>quadruple</code> and <code>triple</code> after opening <code>NewNamespace</code>:</p>
<pre><code class="language-lean">def timesTwelve (x : Nat) :=
  open NewNamespace in
  quadruple (triple x)
</code></pre>
<p>Namespaces can also be opened prior to a command.
This allows all parts of the command to refer to the contents of the namespace, rather than just a single expression.
To do this, place the <code>open ... in</code> prior to the command.</p>
<pre><code class="language-lean">open NewNamespace in
#check quadruple
</code></pre>
<pre><code class="language-output info">NewNamespace.quadruple (x : Nat) : Nat
</code></pre>
<p>Function signatures show the name's full namespace.
Namespaces may additionally be opened for <em>all</em> following commands for the rest of the file.
To do this, simply omit the <code>in</code> from a top-level usage of <code>open</code>.</p>
<h2 id="if-let"><a class="header" href="#if-let">if let</a></h2>
<p>When consuming values that have a sum type, it is often the case that only a single constructor is of interest.
For instance, given this type that represents a subset of Markdown inline elements:</p>
<pre><code class="language-lean">inductive Inline : Type where
  | lineBreak
  | string : String → Inline
  | emph : Inline → Inline
  | strong : Inline → Inline
</code></pre>
<p>a function that recognizes string elements and extracts their contents can be written:</p>
<pre><code class="language-lean">def Inline.string? (inline : Inline) : Option String :=
  match inline with
  | Inline.string s =&gt; some s
  | _ =&gt; none
</code></pre>
<p>An alternative way of writing this function's body uses <code>if</code> together with <code>let</code>:</p>
<pre><code class="language-lean">def Inline.string? (inline : Inline) : Option String :=
  if let Inline.string s := inline then
    some s
  else none
</code></pre>
<p>This is very much like the pattern-matching <code>let</code> syntax.
The difference is that it can be used with sum types, because a fallback is provided in the <code>else</code> case.
In some contexts, using <code>if let</code> instead of <code>match</code> can make code easier to read.</p>
<h2 id="positional-structure-arguments"><a class="header" href="#positional-structure-arguments">Positional Structure Arguments</a></h2>
<p>The <a href="getting-to-know/structures.html">section on structures</a> presents two ways of constructing structures:</p>
<ol>
<li>The constructor can be called directly, as in <code>Point.mk 1 2</code>.</li>
<li>Brace notation can be used, as in <code>{ x := 1, y := 2 }</code>.</li>
</ol>
<p>In some contexts, it can be convenient to pass arguments positionally, rather than by name, but without naming the constructor directly.
For instance, defining a variety of similar structure types can help keep domain concepts separate, but the natural way to read the code may treat each of them as being essentially a tuple.
In these contexts, the arguments can be enclosed in angle brackets <code>⟨</code> and <code>⟩</code>.
A <code>Point</code> can be written <code>⟨1, 2⟩</code>.
Be careful!
Even though they look like the less-than sign <code>&lt;</code> and greater-than sign <code>&gt;</code>, these brackets are different.
They can be input using <code>\&lt;</code> and <code>\&gt;</code>, respectively.</p>
<p>Just as with the brace notation for named constructor arguments, this positional syntax can only be used in a context where Lean can determine the structure's type, either from a type annotation or from other type information in the program.
For instance, <code>#eval ⟨1, 2⟩</code> yields the following error:</p>
<pre><code class="language-output error">invalid constructor ⟨...⟩, expected type must be an inductive type 
  ?m.35347
</code></pre>
<p>The metavariable in the error is because there is no type information available.
Adding an annotation, such as in <code>#eval (⟨1, 2⟩ : Point)</code>, solves the problem:</p>
<pre><code class="language-output info">{ x := 1.000000, y := 2.000000 }
</code></pre>
<h2 id="string-interpolation"><a class="header" href="#string-interpolation">String Interpolation</a></h2>
<p>In Lean, prefixing a string with <code>s!</code> triggers <em>interpolation</em>, where expressions contained in curly braces inside the string are replaced with their values.
This is similar to <code>f</code>-strings in Python and <code>$</code>-prefixed strings in C#.
For instance,</p>
<pre><code class="language-lean">#eval s!&quot;three fives is {NewNamespace.triple 5}&quot;
</code></pre>
<p>yields the output</p>
<pre><code class="language-output info">&quot;three fives is 15&quot;
</code></pre>
<p>Not all expressions can be interpolated into a string.
For instance, attempting to interpolate a function results in an error.</p>
<pre><code class="language-lean">#check s!&quot;three fives is {NewNamespace.triple}&quot;
</code></pre>
<p>yields the output</p>
<pre><code class="language-output info">failed to synthesize instance
  ToString (Nat → Nat)
</code></pre>
<p>This is because there is no standard way to convert functions into strings.
The Lean compiler maintains a table that describes how to convert values of various types into strings, and the message <code>failed to synthesize instance</code> means that the Lean compiler didn't find an entry in this table for the given type.
This uses the same language feature as the <code>deriving Repr</code> syntax that was described in the <a href="getting-to-know/structures.html">section on structures</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary"><a class="header" href="#summary">Summary</a></h1>
<h2 id="evaluating-expressions-1"><a class="header" href="#evaluating-expressions-1">Evaluating Expressions</a></h2>
<p>In Lean, computation occurs when expressions are evaluated.
This follows the usual rules of mathematical expressions: sub-expressions are replaced by their values following the usual order of operations, until the entire expression has become a value.
When evaluating an <code>if</code> or a <code>match</code>, the expressions in the branches are not evaluated until the value of the condition or the match subject has been found.</p>
<p>Once they have been given a value, variables never change.
Similarly to mathematics but unlike most programming languages, Lean variables are simply placeholders for values, rather than addresses to which new values can be written.
Variables' values may come from global definitions with <code>def</code>, local definitions with <code>let</code>, as named arguments to functions, or from pattern matching.</p>
<h2 id="functions"><a class="header" href="#functions">Functions</a></h2>
<p>Functions in Lean are first-class values, meaning that they can be passed as arguments to other functions, saved in variables, and used like any other value.
Every Lean function takes exactly one argument.
To encode a function that takes more than one argument, Lean uses a technique called currying, where providing the first argument returns a function that expects the remaining arguments.
To encode a function that takes no arguments, Lean uses the <code>Unit</code> type, which is the least informative possible argument.</p>
<p>There are three primary ways of creating functions:</p>
<ol>
<li>Anonymous functions are written using <code>fun</code>.
For instance, a function that swaps the fields of a <code>Point</code> can be written <code>fun (point : Point) =&gt; { x := point.y, y := point.x : Point}</code></li>
<li>Very simple anonymous functions are written by placing one or more centered dots <code>·</code> inside of parentheses.
Each centered dot becomes an argument to the function, and the parentheses delimit its body.
For instance, a function that subtracts one from its argument can be written as <code>(· - 1)</code> instead of as <code>fun x =&gt; x - 1</code>.</li>
<li>Functions can be defined using <code>def</code> or <code>let</code> by adding an argument list or by using pattern-matching notation.</li>
</ol>
<h2 id="types-1"><a class="header" href="#types-1">Types</a></h2>
<p>Lean checks that every expression has a type.
Types, such as <code>Int</code>, <code>Point</code>, <code>{α : Type} → Nat → α → List α</code>, and <code>Option (String ⊕ (Nat × String))</code>, describe the values that may eventually be found for an expression.
Like other languages, types in Lean can express lightweight specifications for programs that are checked by the Lean compiler, obviating the need for certain classes of unit test.
Unlike most languages, Lean's types can also express arbitrary mathematics, unifying the worlds of programming and theorem proving.
While using Lean for proving theorems is mostly out of scope for this book, <em><a href="https://leanprover.github.io/theorem_proving_in_lean4/">Theorem Proving in Lean 4</a></em> contains more information on this topic.</p>
<p>Some expressions can be given multiple types.
For instance, <code>3</code> can be an <code>Int</code> or a <code>Nat</code>.
In Lean, this should be understood as two separate expressions, one with type <code>Nat</code> and one with type <code>Int</code>, that happen to be written in the same way, rather than as two different types for the same thing.</p>
<p>Lean is sometimes able to determine types automatically, but types must often be provided by the user.
This is because Lean's type system is so expressive.
Even when Lean can find a type, it may not find the desired type—<code>3</code> could be intended to be used as an <code>Int</code>, but Lean will give it the type <code>Nat</code> if there are no further constraints.
In general, it is a good idea to write most types explicitly, only letting Lean fill out the very obvious types.
This improves Lean's error messages and helps make programmer intent more clear.</p>
<p>Some functions or datatypes take types as arguments.
They are called <em>polymorphic</em>.
Polymorphism allows programs such as one that calculates the length of a list without caring what type the entries in the list have.
Because types are first class in Lean, polymorphism does not require any special syntax, so types are passed just like other arguments.
Giving an argument a name in a function type allows later types to mention that argument, and the type of applying that function to an argument is found by replacing the argument's name with the argument's value.</p>
<h2 id="structures-and-inductive-types"><a class="header" href="#structures-and-inductive-types">Structures and Inductive Types</a></h2>
<p>Brand new datatypes can be introduced to Lean using the <code>structure</code> or <code>inductive</code> features.
These new types are not considered to be equivalent to any other type, even if their definitions are otherwise identical.
Datatypes have <em>constructors</em> that explain the ways in which their values can be constructed, and each constructor takes some number of arguments.
Constructors in Lean are not the same as constructors in object-oriented languages: Lean's constructors are inert holders of data, rather than active code that initializes an allocated object.</p>
<p>Typically, <code>structure</code> is used to introduce a product type (that is, a type with just one constructor that takes any number of arguments), while <code>inductive</code> is used to introduce a sum type (that is, a type with many distinct constructors).
Datatypes defined with <code>structure</code> are provided with one accessor function for each of the constructor's arguments.
Both structures and inductive datatypes may be consumed with pattern matching, which exposes the values stored inside of constructors using a subset of the syntax used to call said constructors.
Pattern matching means that knowing how to create a value implies knowing how to consume it.</p>
<h2 id="recursion"><a class="header" href="#recursion">Recursion</a></h2>
<p>A definition is recursive when the name being defined is used in the definition itself.
Because Lean is an interactive theorem prover in addition to being a programming language, there are certain restrictions placed on recursive definitions.
In Lean's logical side, circular definitions could lead to logical inconsistency.</p>
<p>In order to ensure that recursive definitions do not undermine the logical side of Lean, Lean must be able to prove that all recursive functions terminate, no matter what arguments they are called with.
In practice, this means either that recursive calls are all performed on a structurally-smaller piece of the input, which ensures that there is always progress towards a base case, or that users must provide some other evidence that the function always terminates.
Similarly, recursive inductive types are not allowed to have a constructor that takes a function <em>from</em> the type as an argument, because this would make it possible to encode non-terminating functions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hello-world"><a class="header" href="#hello-world">Hello, World!</a></h1>
<p>While Lean has been designed to have a rich interactive environment in which programmers can get quite a lot of feedback from the language without leaving the confines of their favorite text editor, it is also a language in which real programs can be written.
This means that it also has a batch-mode compiler, a build system, a package manager, and all the other tools that are necessary for writing programs.</p>
<p>While the <a href="./getting-to-know.html">previous chapter</a> presented the basics of functional programming in Lean, this chapter explains how to start a programming project, compile it, and run the result.
Programs that run and interact with their environment (e.g. by reading input from standard input or creating files) are difficult to reconcile with the understanding of computation as the evaluation of mathematical expressions.
In addition to a description of the Lean build tools, this chapter also provides a way to think about functional programs that interact with the world.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="running-a-program"><a class="header" href="#running-a-program">Running a Program</a></h1>
<p>The simplest way to run a Lean program is to use the <code>--run</code> option to the Lean executable.
Create a file called <code>Hello.lean</code> and enter the following contents:</p>
<pre><code class="language-lean">def main : IO Unit := IO.println &quot;Hello, world!&quot;
</code></pre>
<p>Then, from the command line, run:</p>
<pre><code>lean --run Hello.lean
</code></pre>
<p>The program displays <code>Hello, world!</code> and exits.</p>
<h2 id="anatomy-of-a-greeting"><a class="header" href="#anatomy-of-a-greeting">Anatomy of a Greeting</a></h2>
<p>When Lean is invoked with the <code>--run</code> option, it invokes the program's <code>main</code> definition.
In programs that do not take command-line arguments, <code>main</code> should have type <code>IO Unit</code>.
This means that <code>main</code> is not a function, because there are no arrows (<code>→</code>) in its type.
Instead of being a function that has side effects, <code>main</code> consists of a description of effects to be carried out.</p>
<p>As discussed in <a href="hello-world/../getting-to-know/polymorphism.html">the preceding chapter</a>, <code>Unit</code> is the simplest inductive type.
It has a single constructor called <code>unit</code> that takes no arguments.
Languages in the C tradition have a notion of a <code>void</code> function that does not return any value at all.
In Lean, all functions take an argument and return a value, and the lack of interesting arguments or return values can be signaled by using the <code>Unit</code> type instead.
If <code>Bool</code> represents a single bit of information, <code>Unit</code> represents zero bits of information.</p>
<p><code>IO α</code> is the type of a program that, when executed, will either throw an exception or return a value of type <code>α</code>.
During execution, this program may have side effects.
These programs are referred to as <code>IO</code> <em>actions</em>.
Lean distinguishes between <em>evaluation</em> of expressions, which strictly adheres to the mathematical model of substitution of values for variables and reduction of sub-expressions without side effects, and <em>execution</em> of <code>IO</code> actions, which rely on an external system to interact with the world.
<code>IO.println</code> is a function from strings to <code>IO</code> actions that, when executed, write the given string to standard output.
Because this action doesn't read any interesting information from the environment in the process of emitting the string, <code>IO.println</code> has type <code>String → IO Unit</code>.
If it did return something interesting, then that would be indicated by the <code>IO</code> action having a type other than <code>Unit</code>.</p>
<h2 id="functional-programming-vs-effects"><a class="header" href="#functional-programming-vs-effects">Functional Programming vs Effects</a></h2>
<p>Lean's model of computation is based on the evaluation of mathematical expressions, in which variables are given exactly one value that does not change over time.
The result of evaluating an expression does not change, and evaluating the same expression again will always yield the same result.</p>
<p>On the other hand, useful programs must interact with the world.
A program that performs neither input nor output can't ask a user for data, create files on disk, or open network connections.
Lean is written in itself, and the Lean compiler certainly reads files, creates files, and interacts with text editors.
How can a language in which the same expression always yields the same result support programs that read files from disk, when the contents of these files might change over time?</p>
<p>This apparent contradiction can be resolved by thinking a bit differently about side effects.
Imagine a café that sells coffee and sandwiches.
This café has two employees: a cook who fulfills orders, and a worker at the counter who interacts with customers and places order slips.
The cook is a surly person, who really prefers not to have any contact with the world outside, but who is very good at consistently delivering the food and drinks that the café is known for.
In order to do this, however, the cook needs peace and quiet, and can't be disturbed with conversation.
The counter worker is friendly, but completely incompetent in the kitchen.
Customers interact with the counter worker, who delegates all actual cooking to the cook.
If the cook has a question for a customer, such as clarifying an allergy, they send a little note to the counter worker, who interacts with the customer and passes a note back to the cook with the result.</p>
<p>In this analogy, the cook is the Lean language.
When provided with an order, the cook faithfully and consistently delivers what is requested.
The counter worker is the surrounding run-time system that interacts with the world and can accept payments, dispense food, and have conversations with customers.
Working together, the two employees serve all the functions of the restaurant, but their responsibilities are divided, with each performing the tasks that they're best at.
Just as keeping customers away allows the cook to focus on making truly excellent coffee and sandwiches, Lean's lack of side effects allows programs to be used as part of formal mathematical proofs.
It also helps programmers understand the parts of the program in isolation from each other, because there are no hidden state changes that create subtle coupling between components.
The cook's notes represent <code>IO</code> actions that are produced by evaluating Lean expressions, and the counter worker's replies are the values that are passed back from effects.</p>
<p>This model of side effects is quite similar to how the overall aggregate of the Lean language, its compiler, and its run-time system (RTS) work.
Primitives in the run-time system, written in C, implement all the basic effects.
When running a program, the RTS invokes the <code>main</code> action, which returns new <code>IO</code> actions to the RTS for execution.
The RTS executes these actions, delegating to the user's Lean code to carry out computations.
From the internal perspective of Lean, programs are free of side effects, and <code>IO</code> actions are just descriptions of tasks to be carried out.
From the external perspective of the program's user, there is a layer of side effects that create an interface to the program's core logic.</p>
<h2 id="real-world-functional-programming"><a class="header" href="#real-world-functional-programming">Real-World Functional Programming</a></h2>
<p>The other useful way to think about side effects in Lean is by considering <code>IO</code> actions to be functions that take the entire world as an argument and return a value paired with a new world.
In this case, reading a line of text from standard input <em>is</em> a pure function, because a different world is provided as an argument each time.
Writing a line of text to standard output is a pure function, because the world that the function returns is different from the one that it began with.
Programs do need to be careful to never re-use the world, nor to fail to return a new world—this would amount to time travel or the end of the world, after all.
Careful abstraction boundaries can make this style of programming safe.
If every primitive <code>IO</code> action accepts one world and returns a new one, and they can only be combined with tools that preserve this invariant, then the problem cannot occur.</p>
<p>This model cannot be implemented.
After all, the entire universe cannot be turned into a Lean value and placed into memory.
However, it is possible to implement a variation of this model with an abstract token that stands for the world.
When the program is started, it is provided with a world token.
This token is then passed on to the IO primitives, and their returned tokens are similarly passed to the next step.
At the end of the program, the token is returned to the operating system.</p>
<p>This model of side effects is a good description of how <code>IO</code> actions as descriptions of tasks to be carried out by the RTS are represented internally in Lean.
The actual functions that transform the real world are behind an abstraction barrier.
But real programs typically consist of a sequence of effects, rather than just one.
To enable programs to use multiple effects, there is a sub-language of Lean called <code>do</code> notation that allows these primitive <code>IO</code> actions to be safely composed into a larger, useful program.</p>
<h2 id="combining-io-actions"><a class="header" href="#combining-io-actions">Combining <code>IO</code> Actions</a></h2>
<p>Most useful programs accept input in addition to producing output.
Furthermore, they may take decisions based on input, using the input data as part of a computation.
The following program, called <code>HelloName.lean</code>, asks the user for their name and then greets them:</p>
<pre><code class="language-lean">def main : IO Unit := do
  let stdin ← IO.getStdin
  let stdout ← IO.getStdout

  stdout.putStrLn &quot;How would you like to be addressed?&quot;
  let input ← stdin.getLine
  let name := input.dropRightWhile Char.isWhitespace

  stdout.putStrLn s!&quot;Hello, {name}!&quot;
</code></pre>
<p>In this program, the <code>main</code> action consists of a <code>do</code> block.
This block contains a sequence of <em>statements</em>, which can be both local variables (introduced using <code>let</code>) and actions that are to be executed.
Just as SQL can be thought of as a special-purpose language for interacting with databases, the <code>do</code> syntax can be thought of as a special-purpose sub-language within Lean that is dedicated to modeling imperative programs.
<code>IO</code> actions that are built with a <code>do</code> block are executed by executing the statements in order.</p>
<p>This program can be run in the same manner as the prior program:</p>
<pre><code>lean --run HelloName.lean
</code></pre>
<p>If the user responds with <code>David</code>, a session of interaction with the program reads:</p>
<pre><code>How would you like to be addressed?
David
Hello, David!
</code></pre>
<p>The type signature line is just like the one for <code>Hello.lean</code>:</p>
<pre><code class="language-lean">def main : IO Unit := do
</code></pre>
<p>The only difference is that it ends with the keyword <code>do</code>, which initiates a sequence of commands.
Each indented line following the keyword <code>do</code> is part of the same sequence of commands.</p>
<p>The first two lines, which read:</p>
<pre><code class="language-lean">  let stdin ← IO.getStdin
  let stdout ← IO.getStdout
</code></pre>
<p>retrieve the <code>stdin</code> and <code>stdout</code> handles by executing the library actions <code>IO.getStdin</code> and <code>IO.getStdout</code>, respectively.
In a <code>do</code> block, <code>let</code> has a slightly different meaning than in an ordinary expression.
Ordinarily, the local definition in a <code>let</code> can be used in just one expression, which immediately follows the local definition.
In a <code>do</code> block, local bindings introduced by <code>let</code> are available in all statements in the remainder of the <code>do</code> block, rather than just the next one.
Additionally, <code>let</code> typically connects the name being defined to its definition using <code>:=</code>, while some <code>let</code> bindings in <code>do</code> use a left arrow (<code>←</code> or <code>&lt;-</code>) instead.
Using an arrow means that the value of the expression is an <code>IO</code> action that should be executed, with the result of the action saved in the local variable.
In other words, if the expression to the right of the arrow has type <code>IO α</code>, then the variable has type <code>α</code> in the remainder of the <code>do</code> block.
<code>IO.getStdin</code> and <code>IO.getStdout</code> are <code>IO</code> actions in order to allow <code>stdin</code> and <code>stdout</code> to be locally overridden in a program, which can be convenient.
If they were global variables as in C, then there would be no meaningful way to override them, but <code>IO</code> actions can return different values each time they are executed.</p>
<p>The next part of the <code>do</code> block is responsible for asking the user for their name:</p>
<pre><code class="language-lean">  stdout.putStrLn &quot;How would you like to be addressed?&quot;
  let input ← stdin.getLine
  let name := input.dropRightWhile Char.isWhitespace
</code></pre>
<p>The first line writes the question to <code>stdout</code>, the second line requests input from <code>stdin</code>, and the third line removes the trailing newline (plus any other trailing whitespace) from the input line.
The definition of <code>name</code> uses <code>:=</code>, rather than <code>←</code>, because <code>String.dropRightWhile</code> is an ordinary function on strings, rather than an <code>IO</code> action.</p>
<p>Finally, the last line in the program is:</p>
<pre><code>  stdout.putStrLn s!&quot;Hello, {name}!&quot;
</code></pre>
<p>It uses <a href="hello-world/../getting-to-know/conveniences.html#string-interpolation">string interpolation</a> to insert the provided name into a greeting string, writing the result to <code>stdout</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="step-by-step"><a class="header" href="#step-by-step">Step By Step</a></h1>
<p>A <code>do</code> block can be executed one line at a time.
Start with the program from the prior section:</p>
<pre><code class="language-lean">  let stdin ← IO.getStdin
  let stdout ← IO.getStdout
  stdout.putStrLn &quot;How would you like to be addressed?&quot;
  let input ← stdin.getLine
  let name := input.dropRightWhile Char.isWhitespace
  stdout.putStrLn s!&quot;Hello, {name}!&quot;
</code></pre>
<h2 id="standard-io"><a class="header" href="#standard-io">Standard IO</a></h2>
<p>The first line is <code>  let stdin ← IO.getStdin</code>, while the remainder is:</p>
<pre><code class="language-lean">  let stdout ← IO.getStdout
  stdout.putStrLn &quot;How would you like to be addressed?&quot;
  let input ← stdin.getLine
  let name := input.dropRightWhile Char.isWhitespace
  stdout.putStrLn s!&quot;Hello, {name}!&quot;
</code></pre>
<p>To execute a <code>let</code> statement that uses a <code>←</code>, start by evaluating the expression to the right of the arrow (in this case, <code>IO.getStdIn</code>).
Because this expression is just a variable, its value is looked up.
The resulting value is a built-in primitive <code>IO</code> action.
The next step is to execute this <code>IO</code> action, resulting in a value that represents the standard input stream, which has type <code>IO.FS.Stream</code>.
Standard input is then associated with the name to the left of the arrow (here <code>stdin</code>) for the remainder of the <code>do</code> block.</p>
<p>Executing the second line, <code>  let stdout ← IO.getStdout</code>, proceeds similarly.
First, the expression <code>IO.getStdout</code> is evaluated, yielding an <code>IO</code> action that will return the standard output.
Next, this action is executed, actually returning the standard output.
Finally, this value is associated with the name <code>stdout</code> for the remainder of the <code>do</code> block.</p>
<h2 id="asking-a-question"><a class="header" href="#asking-a-question">Asking a Question</a></h2>
<p>Now that <code>stdin</code> and <code>stdout</code> have been found, the remainder of the block consists of a question and an answer:</p>
<pre><code class="language-lean">  stdout.putStrLn &quot;How would you like to be addressed?&quot;
  let input ← stdin.getLine
  let name := input.dropRightWhile Char.isWhitespace
  stdout.putStrLn s!&quot;Hello, {name}!&quot;
</code></pre>
<p>The first statement in the block, <code>  stdout.putStrLn &quot;How would you like to be addressed?&quot;</code>, consists of an expression.
To execute an expression, it is first evaluated.
In this case, <code>IO.FS.Stream.putStrLn</code> has type <code>IO.FS.Stream → String → IO Unit</code>.
This means that it is a function that accepts a stream and a string, returning an <code>IO</code> action.
The expression uses <a href="hello-world/../getting-to-know/structures.html#behind-the-scenes">accessor notation</a> for a function call.
This function is applied to two arguments: the standard output stream and a string.
The value of the expression is an <code>IO</code> action that will write the string and a newline character to the output stream.
Having found this value, the next step is to execute it, which causes the string and newline to actually be written to <code>stdout</code>.
Statements that consist only of expressions do not introduce any new variables.</p>
<p>The next statement in the block is <code>  let input ← stdin.getLine</code>.
<code>IO.FS.Stream.getLine</code> has type <code>IO.FS.Stream → IO String</code>, which means that it is a function from a stream to an <code>IO</code> action that will return a string.
Once again, this is an example of accessor notation.
This <code>IO</code> action is executed, and the program waits until the user has typed a complete line of input.
Assume the user writes &quot;<code>David</code>&quot;.
The resulting line (<code>&quot;David\n&quot;</code>) is associated with <code>input</code>, where the escape sequence <code>\n</code> denotes the newline character.</p>
<pre><code class="language-lean">  let name := input.dropRightWhile Char.isWhitespace
  stdout.putStrLn s!&quot;Hello, {name}!&quot;
</code></pre>
<p>The next line, <code>  let name := input.dropRightWhile Char.isWhitespace</code>, is a <code>let</code> statement.
Unlike the other <code>let</code> statements in this program, it uses <code>:=</code> instead of <code>←</code>.
This means that the expression will be evaluated, but the resulting value need not be an <code>IO</code> action and will not be executed.
In this case, <code>String.dropRightWhile</code> takes a string and a predicate over characters and returns a new string from which all the characters at the end of the string that satisfy the predicate have been removed.
For example,</p>
<pre><code class="language-lean">#eval &quot;Hello!!!&quot;.dropRightWhile (· == '!')
</code></pre>
<p>yields</p>
<pre><code class="language-output info">&quot;Hello&quot;
</code></pre>
<p>and</p>
<pre><code class="language-lean">#eval &quot;Hello...   &quot;.dropRightWhile (fun c =&gt; not (c.isAlphanum))
</code></pre>
<p>yields</p>
<pre><code class="language-output info">&quot;Hello&quot;
</code></pre>
<p>in which all non-alphanumeric characters have been removed from the right side of the string.
In the current line of the program, whitespace characters (including the newline) are removed from the right side of the input string, resulting in <code>&quot;David&quot;</code>, which is associated with <code>name</code> for the remainder of the block.</p>
<h2 id="greeting-the-user"><a class="header" href="#greeting-the-user">Greeting the User</a></h2>
<p>All that remains to be executed in the <code>do</code> block is a single statement:</p>
<pre><code class="language-lean">  stdout.putStrLn s!&quot;Hello, {name}!&quot;
</code></pre>
<p>The string argument to <code>putStrLn</code> is constructed via string interpolation, yielding the string <code>&quot;Hello, David!&quot;</code>.
Because this statement is an expression, it is evaluated to yield an <code>IO</code> action that will print this string with a newline to standard output.
Once the expression has been evaluated, the resulting <code>IO</code> action is executed, resulting in the greeting.</p>
<h2 id="io-actions-as-values"><a class="header" href="#io-actions-as-values"><code>IO</code> Actions as Values</a></h2>
<p>In the above description, it can be difficult to see why the distinction between evaluating expressions and executing <code>IO</code> actions is necessary.
After all, each action is executed immediately after it is produced.
Why not simply carry out the effects during evaluation, as is done in other languages?</p>
<p>The answer is twofold.
First off, separating evaluation from execution means that programs must be explicit about which functions can have side effects.
Because the parts of the program that do not have effects are much more amenable to mathematical reasoning, whether in the heads of programmers or using Lean's facilities for formal proof, this separation can make it easier to avoid bugs.
Secondly, not all <code>IO</code> actions need be executed at the time that they come into existence.
The ability to mention an action without carrying it out allows ordinary functions to be used as control structures.</p>
<p>For instance, the function <code>twice</code> takes an <code>IO</code> action as its argument, returning a new action that will execute the first one twice.</p>
<pre><code class="language-lean">def twice (action : IO Unit) : IO Unit := do
  action
  action
</code></pre>
<p>For instance, executing</p>
<pre><code class="language-lean">twice (IO.println &quot;shy&quot;)
</code></pre>
<p>results in</p>
<pre><code class="language-output info">shy
shy
</code></pre>
<p>being printed.
This can be generalized to a version that runs the underlying action any number of times:</p>
<pre><code class="language-lean">def nTimes (action : IO Unit) : Nat → IO Unit
  | 0 =&gt; pure ()
  | n + 1 =&gt; do
    action
    nTimes action n
</code></pre>
<p>In the base case for <code>Nat.zero</code>, the result is <code>pure ()</code>.
The function <code>pure</code> creates an <code>IO</code> action that has no side effects, but returns <code>pure</code>'s argument, which in this case is the constructor for <code>Unit</code>.
As an action that does nothing and returns nothing interesting, <code>pure ()</code> is at the same time utterly boring and very useful.
In the recursive step, a <code>do</code> block is used to create an action that first executes <code>action</code> and then executes the result of the recursive call.
Executing <code>nTimes (IO.println &quot;Hello&quot;) 3</code> causes the following output:</p>
<pre><code class="language-output info">Hello
Hello
Hello
</code></pre>
<p>In addition to using functions as control structures, the fact that <code>IO</code> actions are first-class values means that they can be saved in data structures for later execution.
For instance, the function <code>countdown</code> takes a <code>Nat</code> and returns a list of unexecuted <code>IO</code> actions, one for each <code>Nat</code>:</p>
<pre><code class="language-lean">def countdown : Nat → List (IO Unit)
  | 0 =&gt; [IO.println &quot;Blast off!&quot;]
  | n + 1 =&gt; IO.println s!&quot;{n + 1}&quot; :: countdown n
</code></pre>
<p>This function has no side effects, and does not print anything.
For example, it can be applied to an argument, and the length of the resulting list of actions can be checked:</p>
<pre><code class="language-lean">def from5 : List (IO Unit) := countdown 5
</code></pre>
<p>This list contains six elements (one for each number, plus a <code>&quot;Blast off!&quot;</code> action for zero):</p>
<pre><code class="language-lean">#eval from5.length
</code></pre>
<pre><code class="language-output info">6
</code></pre>
<p>The function <code>runActions</code> takes a list of actions and constructs a single action that runs them all in order:</p>
<pre><code class="language-lean">def runActions : List (IO Unit) → IO Unit
  | [] =&gt; pure ()
  | act :: actions =&gt; do
    act
    runActions actions
</code></pre>
<p>Its structure is essentially the same as that of <code>nTimes</code>, except instead of having one action that is executed for each <code>Nat.succ</code>, the action under each <code>List.cons</code> is to be executed.
Similarly, <code>runActions</code> does not itself run the actions.
It creates a new action that will run them, and that action must be placed in a position where it will be executed as a part of <code>main</code>:</p>
<pre><code class="language-lean">def main : IO Unit := runActions from5
</code></pre>
<p>Running this program results in the following output:</p>
<pre><code class="language-output info">5
4
3
2
1
Blast off!
</code></pre>
<p>What happens when this program is run?
The first step is to evaluate <code>main</code>. That occurs as follows:</p>
<pre><code class="language-lean">main
===&gt;
runActions from5
===&gt;
runActions (countdown 5)
===&gt;
runActions
  [IO.println &quot;5&quot;,
   IO.println &quot;4&quot;,
   IO.println &quot;3&quot;,
   IO.println &quot;2&quot;,
   IO.println &quot;1&quot;,
   IO.println &quot;Blast off!&quot;]
===&gt;
do IO.println &quot;5&quot;
   IO.println &quot;4&quot;
   IO.println &quot;3&quot;
   IO.println &quot;2&quot;
   IO.println &quot;1&quot;
   IO.println &quot;Blast off!&quot;
   pure ()
</code></pre>
<p>The resulting <code>IO</code> action is a <code>do</code> block.
Each step of the <code>do</code> block is then executed, one at a time, yielding the expected output.
The final step, <code>pure ()</code>, does not have any effects, and it is only present because the definition of <code>runActions</code> needs a base case.</p>
<h2 id="exercise"><a class="header" href="#exercise">Exercise</a></h2>
<p>Step through the execution of the following program on a piece of paper:</p>
<pre><code class="language-lean">def main : IO Unit := do
  let englishGreeting := IO.println &quot;Hello!&quot;
  IO.println &quot;Bonjour!&quot;
  englishGreeting
</code></pre>
<p>While stepping through the program's execution, identify when an expression is being evaluated and when an <code>IO</code> action is being executed.
When executing an <code>IO</code> action results in a side effect, write it down.
After doing this, run the program with Lean and double-check that your predictions about the side effects were correct.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="starting-a-project"><a class="header" href="#starting-a-project">Starting a Project</a></h1>
<p>As a program written in Lean becomes more serious, an ahead-of-time compiler-based workflow that results in an executable becomes more attractive.
Like other languages, Lean has tools for building multiple-file packages and managing dependencies.
The standard Lean build tool is called Lake (short for &quot;Lean Make&quot;), and it is configured in Lean.
Just as Lean contains a special-purpose language for writing programs with effects (the <code>do</code> language), Lake contains a special-purpose language for configuring builds.
These languages are referred to as <em>embedded domain-specific languages</em> (or sometimes <em>domain-specific embedded languages</em>, abbreviated EDSL or DSEL).
They are <em>domain-specific</em> in the sense that they are used for a particular purpose, with concepts from some sub-domain, and they are typically not suitable for general-purpose programming.
They are <em>embedded</em> because they occur inside another language's syntax.
While Lean contains rich facilities for creating EDSLs, they are beyond the scope of this book.</p>
<h2 id="first-steps"><a class="header" href="#first-steps">First steps</a></h2>
<p>To get started with a project that uses Lake, use the command <code>lake new greeting</code> in a directory that does not already contain a file or directory called <code>greeting</code>.
This creates a directory called <code>greeting</code> that contains the following files:</p>
<ul>
<li><code>Main.lean</code> is the file in which the Lean compiler will look for the <code>main</code> action.</li>
<li><code>Greeting.lean</code> is the scaffolding of a support library for the program.</li>
<li><code>lakefile.lean</code> contains the configuration that <code>lake</code> needs to build the application.</li>
<li><code>lean-toolchain</code> contains an identifier for the specific version of Lean that is used for the project.</li>
</ul>
<p>Additionally, <code>lake new</code> initializes the project as a Git repository and configures its <code>.gitignore</code> file to ignore intermediate build products.
Typically, the majority of the application logic will be in a collection of libraries for the program, while <code>Main.lean</code> will contain a small wrapper around these pieces that does things like parsing command lines and executing the central application logic.
To create a project in an already-existing directory, run <code>lake init</code> instead of <code>lake new</code>.</p>
<p>By default, the library file <code>Greeting.lean</code> contains a single definition:</p>
<pre><code class="language-lean">def hello := &quot;world&quot;
</code></pre>
<p>while the executable source <code>Main.lean</code> contains:</p>
<pre><code class="language-lean">import «Greeting»

def main : IO Unit :=
  IO.println s!&quot;Hello, {hello}!&quot;
</code></pre>
<p>The <code>import</code> line makes the contents of <code>Greeting.lean</code> available in <code>Main.lean</code>.
Placing guillemets around a name, as in <code>«Greeting»</code>, allow it to contain spaces or other characters that are normally not allowed in Lean names, and it allows reserved keywords such as <code>if</code> or <code>def</code> to be used as ordinary names by writing <code>«if»</code> or <code>«def»</code>.
This prevents issues when the package name provided to <code>lake new</code> contains such characters.</p>
<p>To build the package, run the command <code>lake build</code>.
After a number of build commands scroll by, the resulting binary has been placed in <code>build/bin</code>.
Running <code>./build/bin/greeting</code> results in <code>Hello, world!</code>.</p>
<h2 id="lakefiles"><a class="header" href="#lakefiles">Lakefiles</a></h2>
<p>A <code>lakefile.lean</code> describes a <em>package</em>, which is a coherent collection of Lean code for distribution, analogous to an <code>npm</code> or <code>nuget</code> package or a Rust crate.
A package may contain any number of libraries or executables.
While the <a href="https://github.com/leanprover/lake#readme">documentation for Lake</a> describes the available options in a lakefile, it makes use of a number of Lean features that have not yet been described here.
The generated <code>lakefile.lean</code> contains the following:</p>
<pre><code class="language-lean">import Lake
open Lake DSL

package «greeting» {
  -- add package configuration options here
}

lean_lib «Greeting» {
  -- add library configuration options here
}

@[default_target]
lean_exe «greeting» {
  root := `Main
}
</code></pre>
<p>This initial Lakefile consists of three items:</p>
<ul>
<li>a <em>package</em> declaration, named <code>greeting</code>,</li>
<li>a <em>library</em> declaration, named <code>Greeting</code>, and</li>
<li>an <em>executable</em>, also named <code>greeting</code>.</li>
</ul>
<p>Each of these names is enclosed in guillemets to allow users more freedom in picking package names.</p>
<p>Each Lakefile will contain exactly one package, but any number of libraries or executables.
Additionally, Lakefiles may contain <em>external libraries</em>, which are libraries not written in Lean to be statically linked with the resulting executable, <em>custom targets</em>, which are build targets that don't fit naturally into the library/executable taxonomy, <em>dependencies</em>, which are declarations of other Lean packages (either locally or from remote Git repositories), and <em>scripts</em>, which are essentially <code>IO</code> actions (similar to <code>main</code>), but that additionally have access to metadata about the package configuration.
The items in the Lakefile allow things like source file locations, module hierarchies, and compiler flags to be configured.
Generally speaking, however, the defaults are reasonable.</p>
<p>Libraries, executables, and custom targets are all called <em>targets</em>.
By default, <code>lake build</code> builds those targets that are annotated with <code>@[default_target]</code>.
This annotation is an <em>attribute</em>, which is metadata that can be associated with a Lean declaration.
Attributes are similar to Java annotations or C# and Rust attributes.
They are used pervasively throughout Lean.
To build a target that is not annotated with <code>@[default_target]</code>, specify the target's name as an argument after <code>lake build</code>.</p>
<h2 id="libraries-and-imports"><a class="header" href="#libraries-and-imports">Libraries and Imports</a></h2>
<p>A Lean library consists of a hierarchically organized collection of source files from which names can be imported, called <em>modules</em>.
By default, a library has a single root file that matches its name.
In this case, the root file for the library <code>Greeting</code> is <code>Greeting.lean</code>.
The first line of <code>Main.lean</code>, which is <code>import Greeting</code>, makes the contents of <code>Greeting.lean</code> available in <code>Main.lean</code>.</p>
<p>Additional module files may be added to the library by creating a directory called <code>Greeting</code> and placing them inside.
These names can be imported by replacing the directory separator with a dot.
For instance, creating the file <code>Greeting/Smile.lean</code> with the contents:</p>
<pre><code class="language-lean">def expression : String := &quot;a big smile&quot;
</code></pre>
<p>means that <code>Main.lean</code> can use the definition as follows:</p>
<pre><code class="language-lean">import Greeting
import Greeting.Smile

def main : IO Unit :=
  IO.println s!&quot;Hello, {hello}, with {expression}!&quot;
</code></pre>
<p>The module name hierarchy is decoupled from the namespace hierarchy.
In Lean, modules are units of code distribution, while namespaces are units of code organization.
That is, names defined in the module <code>Greeting.Smile</code> are not automatically in a corresponding namespace <code>Greeting.Smile</code>.
Modules may place names into any namespace they like, and the code that imports them may <code>open</code> the namespace or not.
<code>import</code> is used to make the contents of a source file available, while <code>open</code> makes names from a namespace available in the current context without prefixes.
In the Lakefile, the line <code>import Lake</code> makes the contents of the <code>Lake</code> module available, while the line <code>open Lake DSL</code> makes the contents of the <code>Lake</code> and <code>Lake.DSL</code> namespaces available without any prefixes.
<code>Lake.DSL</code> is opened because opening <code>Lake</code> makes <code>Lake.DSL</code> available as just <code>DSL</code>, just like all other names in the <code>Lake</code> namespace.
The <code>Lake</code> module places names into both the <code>Lake</code> and <code>Lake.DSL</code> namespaces.</p>
<p>Namespaces may also be opened <em>selectively</em>, making only some of their names available without explicit prefixes.
This is done by writing the desired names in parentheses.
For example, <code>Nat.toFloat</code> converts a natural number to a <code>Float</code>.
It can be made available as <code>toFloat</code> using <code>open Nat (toFloat)</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="worked-example-cat"><a class="header" href="#worked-example-cat">Worked Example: <code>cat</code></a></h1>
<p>The standard Unix utility <code>cat</code> takes a number of command-line options, followed by zero or more input files.
If no files are provided, or if one of them is a dash (<code>-</code>), then it takes the standard input as the corresponding input instead of reading a file.
The contents of the inputs are written, one after the other, to the standard output.
If a specified input file does not exist, this is noted on standard error, but <code>cat</code> continues concatenating the remaining inputs.
A non-zero exit code is returned if any of the input files do not exist.</p>
<p>This section describes a simplified version of <code>cat</code>, called <code>feline</code>.
Unlike commonly-used versions of <code>cat</code>, <code>feline</code> has no command-line options for features such as numbering lines, indicating non-printing characters, or displaying help text.
Furthermore, it cannot read more than once from a standard input that's associated with a terminal device.</p>
<p>To get the most benefit from this section, follow along yourself.
It's OK to copy-paste the code examples, but it's even better to type them in by hand.
This makes it easier to learn the mechanical process of typing in code, recovering from mistakes, and interpreting feedback from the compiler.</p>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting started</a></h2>
<p>The first step in implementing <code>feline</code> is to create a package and decide how to organize the code.
In this case, because the program is so simple, all the code will be placed in <code>Main.lean</code>.
The first step is to run <code>lake new feline</code>.
Edit the Lakefile to remove the library, and delete the generated library code and the reference to it from <code>Main.lean</code>.
Once this has been done, <code>lakefile.lean</code> should contain:</p>
<pre><code class="language-lean">import Lake
open Lake DSL

package «feline» {
  -- add package configuration options here
}

@[default_target]
lean_exe «feline» {
  root := `Main
}
</code></pre>
<p>and <code>Main.lean</code> should contain something like:</p>
<pre><code class="language-lean">def main : IO Unit :=
  IO.println s!&quot;Hello, cats!&quot;
</code></pre>
<p>Alternatively, running <code>lake new feline exe</code> instructs <code>lake</code> to use a template that does not include a library section, making it unnecessary to edit the file.</p>
<p>Ensure that the code can be built by running <code>lake build</code>.</p>
<h2 id="concatenating-streams"><a class="header" href="#concatenating-streams">Concatenating Streams</a></h2>
<p>Now that the basic skeleton of the program has been built, it's time to actually enter the code.
A proper implementation of <code>cat</code> can be used with infinite IO streams, such as <code>/dev/random</code>, which means that it can't read its input into memory before outputting it.
Furthermore, it should not work one character at a time, as this leads to frustratingly slow performance.
Instead, it's better to read contiguous blocks of data all at once, directing the data to the standard output one block at a time.</p>
<p>The first step is to decide how big of a block to read.
For the sake of simplicity, this implementation uses a conservative 20 kilobyte block.
<code>USize</code> is analogous to <code>size_t</code> in C—it's an unsigned integer type that is big enough to represent all valid array sizes.</p>
<pre><code class="language-lean">def bufsize : USize := 20 * 1024
</code></pre>
<h3 id="streams"><a class="header" href="#streams">Streams</a></h3>
<p>The main work of <code>feline</code> is done by <code>dump</code>, which reads input one block at a time, dumping the result to standard output, until the end of the input has been reached:</p>
<pre><code class="language-lean">partial def dump (stream : IO.FS.Stream) : IO Unit := do
  let buf ← stream.read bufsize
  if buf.isEmpty then
    pure ()
  else
    let stdout ← IO.getStdout
    stdout.write buf
    dump stream
</code></pre>
<p>The <code>dump</code> function is declared <code>partial</code>, because it calls itself recursively on input that is not immediately smaller than an argument.
When a function is declared to be partial, Lean does not require a proof that it terminates.
On the other hand, partial functions are also much less amenable to proofs of correctness, because allowing infinite loops in Lean's logic would make it unsound.
However, there is no way to prove that <code>dump</code> terminates, because infinite input (such as from <code>/dev/random</code>) would mean that it does not, in fact, terminate.
In cases like this, there is no alternative to declaring the function <code>partial</code>.</p>
<p>The type <code>IO.FS.Stream</code> represents a POSIX stream.
Behind the scenes, it is represented as a structure that has one field for each POSIX stream operation.
Each operation is represented as an IO action that provides the corresponding operation:</p>
<pre><code class="language-lean">structure Stream where
  flush   : IO Unit
  read    : USize → IO ByteArray
  write   : ByteArray → IO Unit
  getLine : IO String
  putStr  : String → IO Unit
</code></pre>
<p>The Lean compiler contains <code>IO</code> actions (such as <code>IO.getStdout</code>, which is called in <code>dump</code>) to get streams that represent standard input, standard output, and standard error.
These are <code>IO</code> actions rather than ordinary definitions because Lean allows these standard POSIX streams to be replaced in a process, which makes it easier to do things like capturing the output from a program into a string by writing a custom <code>IO.FS.Stream</code>.</p>
<p>The control flow in <code>dump</code> is essentially a <code>while</code> loop.
When <code>dump</code> is called, if the stream has reached the end of the file, <code>pure ()</code> terminates the function by returning the constructor for <code>Unit</code>.
If the stream has not yet reached the end of the file, one block is read, and its contents are written to <code>stdout</code>, after which <code>dump</code> calls itself directly.
The recursive calls continue until <code>stream.read</code> returns an empty byte array, which indicates that the end of the file has been reached.</p>
<p>When an <code>if</code> expression occurs as a statement in a <code>do</code>, as in <code>dump</code>, each branch of the <code>if</code> is implicitly provided with a <code>do</code>.
In other words, the sequence of steps following the <code>else</code> are treated as a sequence of <code>IO</code> actions to be executed, just as if they had a <code>do</code> at the beginning.
Names introduced with <code>let</code> in the branches of the <code>if</code> are visible only in their own branches, and are not in scope outside of the <code>if</code>.</p>
<p>There is no danger of running out of stack space while calling <code>dump</code> because the recursive call happens as the very last step in the function, and its result is returned directly rather than being manipulated or computed with.
This kind of recursion is called <em>tail recursion</em>, and it is described in more detail <a href="hello-world/../programs-proofs/tail-recursion.html">later in this book</a>.
Because the compiled code does not need to retain any state, the Lean compiler can compile the recursive call to a jump.</p>
<p>If <code>feline</code> only redirected standard input to standard output, then <code>dump</code> would be sufficient.
However, it also needs to be able to open files that are provided as command-line arguments and emit their contents.
When its argument is the name of a file that exists, <code>fileStream</code> returns a stream that reads the file's contents.
When the argument is not a file, <code>fileStream</code> emits an error and returns <code>none</code>.</p>
<pre><code class="language-lean">def fileStream (filename : System.FilePath) : IO (Option IO.FS.Stream) := do
  let fileExists ← filename.pathExists
  if not fileExists then
    let stderr ← IO.getStderr
    stderr.putStrLn s!&quot;File not found: {filename}&quot;
    pure none
  else
    let handle ← IO.FS.Handle.mk filename IO.FS.Mode.read
    pure (some (IO.FS.Stream.ofHandle handle))
</code></pre>
<p>Opening a file as a stream takes two steps.
First, a file handle is created by opening the file in read mode.
A Lean file handle tracks an underlying file descriptor.
When there are no references to the file handle value, a finalizer closes the file descriptor.
Second, the file handle is given the same interface as a POSIX stream using <code>IO.FS.Stream.ofHandle</code>, which fills each field of the <code>Stream</code> structure with the corresponding <code>IO</code> action that works on file handles.</p>
<h3 id="handling-input"><a class="header" href="#handling-input">Handling Input</a></h3>
<p>The main loop of <code>feline</code> is another tail-recursive function, called <code>process</code>.
In order to return a non-zero exit code if any of the inputs could not be read, <code>process</code> takes an argument <code>exitCode</code> that represents the current exit code for the whole program.
Additionally, it takes a list of input files to be processed.</p>
<pre><code class="language-lean">def process (exitCode : UInt32) (args : List String) : IO UInt32 := do
  match args with
  | [] =&gt; pure exitCode
  | &quot;-&quot; :: args =&gt;
    let stdin ← IO.getStdin
    dump stdin
    process exitCode args
  | filename :: args =&gt;
    let stream ← fileStream ⟨filename⟩
    match stream with
    | none =&gt;
      process 1 args
    | some stream =&gt;
      dump stream
      process exitCode args
</code></pre>
<p>Just as with <code>if</code>, each branch of a <code>match</code> that is used as a statement in a <code>do</code> is implicitly provided with its own <code>do</code>.</p>
<p>There are three possibilities.
One is that no more files remain to be processed, in which case <code>process</code> returns the error code unchanged.
Another is that the specified filename is <code>&quot;-&quot;</code>, in which case <code>process</code> dumps the contents of the standard input and then processes the remaining filenames.
The final possibility is that an actual filename was specified.
In this case, <code>fileStream</code> is used to attempt to open the file as a POSIX stream.
Its argument is encased in <code>⟨ ... ⟩</code> because a <code>FilePath</code> is a single-field structure that contains a string.
If the file could not be opened, it is skipped, and the recursive call to <code>process</code> sets the exit code to <code>1</code>.
If it could, then it is dumped, and the recursive call to <code>process</code> leaves the exit code unchanged.</p>
<p><code>process</code> does not need to be marked <code>partial</code> because it is structurally recursive.
Each recursive call is provided with the tail of the input list, and all Lean lists are finite.
Thus, <code>process</code> does not introduce any non-termination.</p>
<h3 id="main"><a class="header" href="#main">Main</a></h3>
<p>The final step is to write the <code>main</code> action.
Unlike prior examples, <code>main</code> in <code>feline</code> is a function.
In Lean, <code>main</code> can have one of three types:</p>
<ul>
<li><code>main : IO Unit</code> corresponds to programs that cannot read their command-line arguments and always indicate success with an exit code of <code>0</code>,</li>
<li><code>main : IO UInt32</code> corresponds to <code>int main(void)</code> in C, for programs without arguments that return exit codes, and</li>
<li><code>main : List String → IO UInt32</code> corresponds to <code>int main(int argc, char **argv)</code> in C, for programs that take arguments and signal success or failure.</li>
</ul>
<p>If no arguments were provided, <code>feline</code> should read from standard input as if it were called with a single <code>&quot;-&quot;</code> argument.
Otherwise, the arguments should be processed one after the other.</p>
<pre><code class="language-lean">def main (args : List String) : IO UInt32 :=
  match args with
  | [] =&gt; process 0 [&quot;-&quot;]
  | _ =&gt;  process 0 args
</code></pre>
<h2 id="meow"><a class="header" href="#meow">Meow!</a></h2>
<p>To check whether <code>feline</code> works, the first step is to build it with <code>lake build</code>.
First off, when called without arguments, it should emit what it receives from standard input.
Check that</p>
<pre><code>echo &quot;It works!&quot; | ./build/bin/feline
</code></pre>
<p>emits <code>It works!</code>.</p>
<p>Secondly, when called with files as arguments, it should print them.
If the file <code>test1.txt</code> contains</p>
<pre><code>It's time to find a warm spot
</code></pre>
<p>and <code>test2.txt</code> contains</p>
<pre><code>and curl up!
</code></pre>
<p>then the command</p>
<pre><code>./build/bin/feline test1.txt test2.txt
</code></pre>
<p>should emit</p>
<pre><code>It's time to find a warm spot
and curl up!
</code></pre>
<p>Finally, the <code>-</code> argument should be handled appropriately.</p>
<pre><code>echo &quot;and purr&quot; | ./build/bin/feline test1.txt - test2.txt
</code></pre>
<p>should yield</p>
<pre><code>It's time to find a warm spot
and purr
and curl up!
</code></pre>
<h2 id="exercise-1"><a class="header" href="#exercise-1">Exercise</a></h2>
<p>Extend <code>feline</code> with support for usage information.
The extended version should accept a command-line argument <code>--help</code> that causes documentation about the available command-line options to be written to standard output.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="additional-conveniences-1"><a class="header" href="#additional-conveniences-1">Additional Conveniences</a></h1>
<h2 id="nested-actions"><a class="header" href="#nested-actions">Nested Actions</a></h2>
<p>Many of the functions in <code>feline</code> exhibit a repetitive pattern in which an <code>IO</code> action's result is given a name, and then used immediately and only once.
For instance, in <code>dump</code>:</p>
<pre><code class="language-lean">partial def dump (stream : IO.FS.Stream) : IO Unit := do
  let buf ← stream.read bufsize
  if buf.isEmpty then
    pure ()
  else
    let stdout ← IO.getStdout
    stdout.write buf
    dump stream
</code></pre>
<p>the pattern occurs for <code>stdout</code>:</p>
<pre><code class="language-lean">    let stdout ← IO.getStdout
    stdout.write buf
</code></pre>
<p>Similarly, <code>fileStream</code> contains the following snippet:</p>
<pre><code class="language-lean">  let fileExists ← filename.pathExists
  if not fileExists then
</code></pre>
<p>When Lean is compiling a <code>do</code> block, expressions that consist of a left arrow immediately under parentheses are lifted to the nearest enclosing <code>do</code>, and their results are bound to a unique name.
This unique name replaces the origin of the expression.
This means that <code>dump</code> can also be written as follows:</p>
<pre><code class="language-lean">partial def dump (stream : IO.FS.Stream) : IO Unit := do
  let buf ← stream.read bufsize
  if buf.isEmpty then
    pure ()
  else
    (← IO.getStdout).write buf
    dump stream
</code></pre>
<p>This version of <code>dump</code> avoids introducing names that are used only once, which can greatly simplify a program.
<code>IO</code> actions that Lean lifts from a nested expression context are called <em>nested actions</em>.</p>
<p><code>fileStream</code> can be simplified using the same technique:</p>
<pre><code class="language-lean">def fileStream (filename : System.FilePath) : IO (Option IO.FS.Stream) := do
  if not (← filename.pathExists) then
    (← IO.getStderr).putStrLn s!&quot;File not found: {filename}&quot;
    pure none
  else
    let handle ← IO.FS.Handle.mk filename IO.FS.Mode.read
    pure (some (IO.FS.Stream.ofHandle handle))
</code></pre>
<p>In this case, the local name of <code>handle</code> could also have been eliminated using nested actions, but the resulting expression would have been long and complicated.
Even though it's often good style to use nested actions, it can still sometimes be helpful to name intermediate results.</p>
<p>It is important to remember, however, that nested actions are only a shorter notation for <code>IO</code> actions that occur in a surrounding <code>do</code> block.
The side effects that are involved in executing them still occur in the same order, and execution of side effects is not interspersed with the evaluation of expressions.
For an example of where this might be confusing, consider the following helper definitions that return data after announcing to the world that they have been executed:</p>
<pre><code class="language-lean">def getNumA : IO Nat := do
  (← IO.getStdout).putStrLn &quot;A&quot;
  pure 5

def getNumB : IO Nat := do
  (← IO.getStdout).putStrLn &quot;B&quot;
  pure 7
</code></pre>
<p>These definitions are intended to stand in for more complicated <code>IO</code> code that might validate user input, read a database, or open a file.</p>
<p>A program that prints <code>0</code> when number A is five, or number <code>B</code> otherwise, can be written as follows:</p>
<pre><code class="language-lean">def test : IO Unit := do
  let a : Nat := if (← getNumA) == 5 then 0 else (← getNumB)
  (← IO.getStdout).putStrLn s!&quot;The answer is {a}&quot;
</code></pre>
<p>However, this program probably has more side effects (such as prompting for user input or reading a database) than was intended.
The definition of <code>getNumA</code> makes it clear that it will always return <code>5</code>, and thus the program should not read number B.
However, running the program results in the following output:</p>
<pre><code class="language-output info">A
B
The answer is 0
</code></pre>
<p><code>getNumB</code> was executed because <code>test</code> is equivalent to this definition:</p>
<pre><code class="language-lean">def test : IO Unit := do
  let x ← getNumA
  let y ← getNumB
  let a : Nat := if x == 5 then 0 else y
  (← IO.getStdout).putStrLn s!&quot;The answer is {a}&quot;
</code></pre>
<p>This is due to the rule that nested actions are lifted to the <em>closest enclosing</em> <code>do</code> block.
The branches of the <code>if</code> were not implicitly wrapped in <code>do</code> blocks because the <code>if</code> is not itself a statement in the <code>do</code> block—the statement is the <code>let</code> that defines <code>a</code>.
Indeed, they could not be wrapped this way, because the type of the conditional expression is <code>Nat</code>, not <code>IO Nat</code>.</p>
<h2 id="flexible-layouts-for-do"><a class="header" href="#flexible-layouts-for-do">Flexible Layouts for <code>do</code></a></h2>
<p>In Lean, <code>do</code> expressions are whitespace-sensitive.
Each <code>IO</code> action or local binding in the <code>do</code> is expected to start on its own line, and they should all have the same indentation.
Almost all uses of <code>do</code> should be written this way.
In some rare contexts, however, manual control over whitespace and indentation may be necessary, or it may be convenient to have multiple small actions on a single line.
In these cases, newlines can be replaced with a semicolon and indentation can be replaced with curly braces.</p>
<p>For instance, all of the following programs are equivalent:</p>
<pre><code class="language-lean">-- This version uses only whitespace-sensitive layout
def main : IO Unit := do
  let stdin ← IO.getStdin
  let stdout ← IO.getStdout

  stdout.putStrLn &quot;How would you like to be addressed?&quot;
  let name := (← stdin.getLine).trim
  stdout.putStrLn s!&quot;Hello, {name}!&quot;

-- This version is as explicit as possible
def main : IO Unit := do {
  let stdin ← IO.getStdin;
  let stdout ← IO.getStdout;

  stdout.putStrLn &quot;How would you like to be addressed?&quot;;
  let name := (← stdin.getLine).trim;
  stdout.putStrLn s!&quot;Hello, {name}!&quot;
}

-- This version uses a semicolon to put two actions on the same line
def main : IO Unit := do
  let stdin ← IO.getStdin; let stdout ← IO.getStdout

  stdout.putStrLn &quot;How would you like to be addressed?&quot;
  let name := (← stdin.getLine).trim
  stdout.putStrLn s!&quot;Hello, {name}!&quot;
</code></pre>
<p>Idiomatic Lean code uses curly braces with <code>do</code> very rarely.</p>
<h2 id="running-io-actions-with-eval"><a class="header" href="#running-io-actions-with-eval">Running <code>IO</code> Actions With <code>#eval</code></a></h2>
<p>Lean's <code>#eval</code> command can be used to execute <code>IO</code> actions, rather than just evaluating them.
Normally, adding a <code>#eval</code> command to a Lean file causes Lean to evaluate the provided expression, convert the resulting value to a string, and provide that string as a tooltip and in the info window.
Rather than failing because <code>IO</code> actions can't be converted to strings, <code>#eval</code> executes them, carrying out their side effects.
If the result of execution is the <code>Unit</code> value <code>()</code>, then no result string is shown, but if it is a type that can be converted to a string, then Lean displays the resulting value.</p>
<p>This means that, given the prior definitions of <code>countdown</code> and <code>runActions</code>,</p>
<pre><code class="language-lean">#eval runActions (countdown 3)
</code></pre>
<p>displays</p>
<pre><code class="language-output info">3
2
1
Blast off!
</code></pre>
<p>This is the output produced by running the <code>IO</code> action, rather than some opaque representation of the action itself.
In other words, for <code>IO</code> actions, <code>#eval</code> both <em>evaluates</em> the provided expression and <em>executes</em> the resulting action value.</p>
<p>Quickly testing <code>IO</code> actions with <code>#eval</code> can be much more convenient that compiling and running whole programs.
However, there are some limitations.
For instance, reading from standard input simply returns empty input.
Additionally, the <code>IO</code> action is re-executed whenever Lean needs to update the diagnostic information that it provides to users, and this can happen at unpredictable times.
An action that reads and writes files, for instance, may do so at inconvenient times.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-1"><a class="header" href="#summary-1">Summary</a></h1>
<h2 id="evaluation-vs-execution"><a class="header" href="#evaluation-vs-execution">Evaluation vs Execution</a></h2>
<p>Side effects are aspects of program execution that go beyond the evaluation of mathematical expressions, such as reading files, throwing exceptions, or triggering industrial machinery.
While most languages allow side effects to occur during evaluation, Lean does not.
Instead, Lean has a type called <code>IO</code> that represents <em>descriptions</em> of programs that use side effects.
These descriptions are then executed by the language's run-time system, which invokes the Lean expression evaluator to carry out specific computations.
Values of type <code>IO α</code> are called <em><code>IO</code> actions</em>.
The simplest is <code>pure</code>, which returns its argument and has no actual side effects.</p>
<p><code>IO</code> actions can also be understood as functions that take the whole world as an argument and return a new world in which the side effect has occurred.
Behind the scenes, the <code>IO</code> library ensures that the world is never duplicated, created, or destroyed.
While this model of side effects cannot actually be implemented, as the whole universe is too big to fit in memory, the real world can be represented by a token that is passed around through the program.</p>
<p>An <code>IO</code> action <code>main</code> is executed when the program starts.
<code>main</code> can have one of three types:</p>
<ul>
<li><code>main : IO Unit</code> is used for simple programs that cannot read their command-line arguments and always return exit code <code>0</code>,</li>
<li><code>main : IO UInt32</code> is used for programs without arguments that may signal success or failure, and</li>
<li><code>main : List String → IO UInt32</code> is used for programs that take command-line arguments and signal success or failure.</li>
</ul>
<h2 id="do-notation"><a class="header" href="#do-notation"><code>do</code> Notation</a></h2>
<p>The Lean standard library provides a number of basic <code>IO</code> actions that represent effects such as reading from and writing to files and interacting with standard input and standard output.
These base <code>IO</code> actions are composed into larger <code>IO</code> actions using <code>do</code> notation, which is a built-in domain-specific language for writing descriptions of programs with side effects.
A <code>do</code> expression contains a sequence of <em>statements</em>, which may be:</p>
<ul>
<li>expressions that represent <code>IO</code> actions,</li>
<li>ordinary local definitions with <code>let</code> and <code>:=</code>, where the defined name refers to the value of the provided expression, or</li>
<li>local definitions with <code>let</code> and <code>←</code>, where the defined name refers to the result of executing the value of the provided expression.</li>
</ul>
<p><code>IO</code> actions that are written with <code>do</code> are executed one statement at a time.</p>
<p>Furthermore, <code>if</code> and <code>match</code> expressions that occur immediately under a <code>do</code> are implicitly considered to have their own <code>do</code> in each branch.
Inside of a <code>do</code> expression, <em>nested actions</em> are expressions with a left arrow immediately under parentheses.
The Lean compiler implicitly lifts them to the nearest enclosing <code>do</code>, which may be implicitly part of a branch of a <code>match</code> or <code>if</code> expression, and gives them a unique name.
This unique name then replaces the origin site of the nested action.</p>
<h2 id="compiling-and-running-programs"><a class="header" href="#compiling-and-running-programs">Compiling and Running Programs</a></h2>
<p>A Lean program that consists of a single file with a <code>main</code> definition can be run using <code>lean --run FILE</code>.
While this can be a nice way to get started with a simple program, most programs will eventually graduate to a multiple-file project that should be compiled before running.</p>
<p>Lean projects are organized into <em>packages</em>, which are collections of libraries and executables together with information about dependencies and a build configuration.
Packages are described using Lake, a Lean build tool.
Use <code>lake new</code> to create a Lake package in a new directory, or <code>lake init</code> to create one in the current directory.
Lake package configuration is another domain-specific language.
Use <code>lake build</code> to build a project.</p>
<h2 id="partiality"><a class="header" href="#partiality">Partiality</a></h2>
<p>One consequence of following the mathematical model of expression evaluation is that every expression must have a value.
This rules out both incomplete pattern matches that fail to cover all constructors of a datatype and programs that can fall into an infinite loop.
Lean ensures that all <code>match</code> expressions cover all cases, and that all recursive functions are either structurally recursive or have an explicit proof of termination.</p>
<p>However, some real programs require the possibility of looping infinitely, because they handle potentially-infinite data, such as POSIX streams.
Lean provides an escape hatch: functions whose definition is marked <code>partial</code> are not required to terminate.
This comes at a cost.
Because types are a first-class part of the Lean language, functions can return types.
Partial functions, however, are not evaluated during type checking, because an infinite loop in a function could cause the type checker to enter an infinite loop.
Furthermore, mathematical proofs are unable to inspect the definitions of partial functions, which means that programs that use them are much less amenable to formal proof.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="interlude-propositions-proofs-and-indexing"><a class="header" href="#interlude-propositions-proofs-and-indexing">Interlude: Propositions, Proofs, and Indexing</a></h1>
<p>Like many languages, Lean uses square brackets for indexing into arrays and lists.
For instance, if <code>woodlandCritters</code> is defined as follows:</p>
<pre><code class="language-lean">def woodlandCritters : List String :=
  [&quot;hedgehog&quot;, &quot;deer&quot;, &quot;snail&quot;]
</code></pre>
<p>then the individual components can be extracted:</p>
<pre><code class="language-lean">def hedgehog := woodlandCritters[0]
def deer := woodlandCritters[1]
def snail := woodlandCritters[2]
</code></pre>
<p>However, attempting to extract the fourth element results in a compile-time error, rather than a run-time error:</p>
<pre><code class="language-lean">def oops := woodlandCritters[3]
</code></pre>
<pre><code class="language-output error">failed to prove index is valid, possible solutions:
  - Use `have`-expressions to prove the index is valid
  - Use `a[i]!` notation instead, runtime check is perfomed, and 'Panic' error message is produced if index is not valid
  - Use `a[i]?` notation instead, result is an `Option` type
  - Use `a[i]'h` notation instead, where `h` is a proof that index is valid
⊢ 3 &lt; List.length woodlandCritters
</code></pre>
<p>This error message is saying Lean tried to automatically mathematically prove that <code>3 &lt; List.length woodlandCritters</code>, which would mean that the lookup was safe, but that it could not do so.
Out-of-bounds errors are a common class of bugs, and Lean uses its dual nature as a programming language and a theorem prover to rule out as many as possible.</p>
<p>Understanding how this works requires an understanding of three key ideas: propositions, proofs, and tactics.</p>
<h2 id="propositions-and-proofs"><a class="header" href="#propositions-and-proofs">Propositions and Proofs</a></h2>
<p>A <em>proposition</em> is a statement that can be true or false.
All of the following are propositions:</p>
<ul>
<li>1 + 1 = 2</li>
<li>Addition is commutative</li>
<li>There are infinitely many prime numbers</li>
<li>1 + 1 = 15</li>
<li>Paris is the capital of France</li>
<li>Buenos Aires is the capital of South Korea</li>
<li>All birds can fly</li>
</ul>
<p>On the other hand, nonsense statements are not propositions.
None of the following are propositions:</p>
<ul>
<li>1 + green = ice cream</li>
<li>All capital cities are prime numbers</li>
<li>At least one gorg is a fleep</li>
</ul>
<p>Propositions come in two varieties: those that are purely mathematical, relying only on our definitions of concepts, and those that are facts about the world.
Theorem provers like Lean are concerned with the former category, and have nothing to say about the flight capabilities of penguins or the legal status of cities.</p>
<p>A <em>proof</em> is a convincing argument that a proposition is true.
For mathematical propositions, these arguments make use of the definitions of the concepts that are involved as well as the rules of logical argumentation.
Most proofs are written for people to understand, and leave out many tedious details.
Computer-aided theorem provers like Lean are designed to allow mathematicians to write proofs while omitting many details, and it is the software's responsibility to fill in the missing explicit steps.
This decreases the likelihood of oversights or mistakes.</p>
<p>In Lean, a program's type describes the ways it can be interacted with.
For instance, a program of type <code>Nat → List String</code> is a function that takes a <code>Nat</code> argument and produces a list of strings.
In other words, each type specifies what counts as a program with that type.</p>
<p>In Lean, propositions are in fact types.
They specify what counts as evidence that the statement is true.
The proposition is proved by providing this evidence.
On the other hand, if the proposition is false, then it will be impossible to construct this evidence.</p>
<p>For example, the proposition &quot;1 + 1 = 2&quot; can be written directly in Lean.
The evidence for this proposition is the constructor <code>rfl</code>, which is short for <em>reflexivity</em>:</p>
<pre><code class="language-lean">def onePlusOneIsTwo : 1 + 1 = 2 := rfl
</code></pre>
<p>On the other hand, <code>rfl</code> does not prove the false proposition &quot;1 + 1 = 15&quot;:</p>
<pre><code class="language-lean">def onePlusOneIsFifteen : 1 + 1 = 15 := rfl
</code></pre>
<pre><code class="language-output error">type mismatch
  rfl
has type
  1 + 1 = 1 + 1 : Prop
but is expected to have type
  1 + 1 = 15 : Prop
</code></pre>
<p>This error message indicates that <code>rfl</code> can prove that two expressions are equal when both sides of the equality statement are already the same number.
Because <code>1 + 1</code> evaluates directly to <code>2</code>, they are considered to be the same, which allows <code>onePlusOneIsTwo</code> to be accepted.
Just as <code>Type</code> describes types such as <code>Nat</code>, <code>String</code>, and <code>List (Nat × String × (Int → Float))</code> that represent data structures and functions, <code>Prop</code> describes propositions.</p>
<p>When a proposition has been proven, it is called a <em>theorem</em>.
In Lean, it is conventional to declare theorems with the <code>theorem</code> keyword instead of <code>def</code>.
This helps readers see which declarations are intended to be read as mathematical proofs, and which are definitions.
Generally speaking, with a proof, what matters is that there is evidence that a proposition is true, but it's not particularly important <em>which</em> evidence was provided.
With definitions, on the other hand, it matters very much which particular value is selected—after all, a definition of addition that always returns <code>0</code> is clearly wrong.</p>
<p>The prior example could be rewritten as follows:</p>
<pre><code class="language-lean">def OnePlusOneIsTwo : Prop := 1 + 1 = 2

theorem onePlusOneIsTwo : OnePlusOneIsTwo := rfl
</code></pre>
<h2 id="tactics"><a class="header" href="#tactics">Tactics</a></h2>
<p>Proofs are normally written using <em>tactics</em>, rather than by providing evidence directly.
Tactics are small programs that construct evidence for a proposition.
These programs run in a <em>proof state</em> that tracks the statement that is to be proved (called the <em>goal</em>) along with the assumptions that are available to prove it.
Running a tactic on a goal results in a new proof state that contains new goals.
The proof is complete when all goals have been proven.</p>
<p>To write a proof with tactics, begin the definition with <code>by</code>.
Writing <code>by</code> puts Lean into tactic mode until the end of the next indented block.
While in tactic mode, Lean provides ongoing feedback about the current proof state.
Written with tactics, <code>onePlusOneIsTwo</code> is still quite short:</p>
<pre><code class="language-leantac">theorem onePlusOneIsTwo : 1 + 1 = 2 := by
  simp
</code></pre>
<p>The <code>simp</code> tactic, short for &quot;simplify&quot;, is the workhorse of Lean proofs.
It rewrites the goal to as simple a form as possible, taking care of parts of the proof that are small enough.
In particular, it proves simple equality statements.
Behind the scenes, a detailed formal proof is constructed, but using <code>simp</code> hides this complexity.</p>
<p>Tactics are useful for a number of reasons:</p>
<ol>
<li>Many proofs are complicated and tedious when written out down to the smallest detail, and tactics can automate these uninteresting parts.</li>
<li>Proofs written with tactics are easier to maintain over time, because flexible automation can paper over small changes to definitions.</li>
<li>Because a single tactic can prove many different theorems, Lean can use tactics behind the scenes to free users from writing proofs by hand. For instance, an array lookup requires a proof that the index is in bounds, and a tactic can typically construct that proof without the user needing to worry about it.</li>
</ol>
<p>Behind the scenes, indexing notation uses a tactic to prove that the user's lookup operation is safe.
This tactic is <code>simp</code>, configured to take certain arithmetic identities into account.</p>
<h2 id="connectives"><a class="header" href="#connectives">Connectives</a></h2>
<p>The basic building blocks of logic, such as &quot;and&quot;, &quot;or&quot;, &quot;true&quot;, &quot;false&quot;, and &quot;not&quot;, are called <em>logical connectives</em>.
Each connective defines what counts as evidence of its truth.
For example, to prove a statement &quot;<em>A</em> and <em>B</em>&quot;, one must prove both <em>A</em> and <em>B</em>.
This means that evidence for &quot;<em>A</em> and <em>B</em>&quot; is a pair that contains both evidence for <em>A</em> and evidence for <em>B</em>.
Similarly, evidence for &quot;<em>A</em> or <em>B</em>&quot; consists of either evidence for <em>A</em> or evidence for <em>B</em>.</p>
<p>In particular, most of these connectives are defined like datatypes, and they have constructors.
If <code>A</code> and <code>B</code> are propositions, then &quot;<code>A</code> and <code>B</code>&quot; (written <code>A ∧ B</code>) is a proposition.
Evidence for <code>A ∧ B</code> consists of the constructor <code>And.intro</code>, which has the type <code>A → B → A ∧ B</code>.
Replacing <code>A</code> and <code>B</code> with concrete propositions, it is possible to prove <code>1 + 1 = 2 ∧ &quot;Str&quot;.append &quot;ing&quot; = &quot;String&quot;</code> with <code>And.intro rfl rfl</code>.
Of course, <code>simp</code> is also powerful enough to find this proof:</p>
<pre><code class="language-leantac">theorem addAndAppend : 1 + 1 = 2 ∧ &quot;Str&quot;.append &quot;ing&quot; = &quot;String&quot; := by simp
</code></pre>
<p>Similarly, &quot;<code>A</code> or <code>B</code>&quot; (written <code>A ∨ B</code>) has two constructors, because a proof of &quot;<code>A</code> or <code>B</code>&quot; requires only that one of the two underlying propositions be true.
There are two constructors: <code>Or.inl</code>, with type <code>A → A ∨ B</code>, and <code>Or.inr</code>, with type <code>B → A ∨ B</code>.</p>
<p>Implication (if <em>A</em> then <em>B</em>) is represented using functions.
In particular, a function that transforms evidence for <em>A</em> into evidence for <em>B</em> is itself evidence that <em>A</em> implies <em>B</em>.
This is different from the usual description of implication, in which <code>A → B</code> is shorthand for <code>¬A ∨ B</code>, but the two formulations are equivalent.</p>
<p>Because evidence for an &quot;and&quot; is a constructor, it can be used with pattern matching.
For instance, a proof that <em>A</em> and <em>B</em> implies <em>A</em> or <em>B</em> is a function that pulls the evidence of <em>A</em> (or of <em>B</em>) out of the evidence for <em>A</em> and <em>B</em>, and then uses this evidence to produce evidence of <em>A</em> or <em>B</em>:</p>
<pre><code class="language-lean">theorem andImpliesOr : A ∧ B → A ∨ B :=
  fun andEvidence =&gt;
    match andEvidence with
    | And.intro a b =&gt; Or.inl a
</code></pre>
<table><thead><tr><th>Connective</th><th>Lean Syntax</th><th>Evidence</th></tr></thead><tbody>
<tr><td>True</td><td><code>True</code></td><td><code>True.intro : True</code></td></tr>
<tr><td>False</td><td><code>False</code></td><td>No evidence</td></tr>
<tr><td><em>A</em> and <em>B</em></td><td><code>A ∧ B</code></td><td><code>And.intro : A → B → A ∧ B</code></td></tr>
<tr><td><em>A</em> or <em>B</em></td><td><code>A ∨ B</code></td><td>Either <code>Or.inl : A → A ∨ B</code> or <code>Or.inr : B → A ∨ B</code></td></tr>
<tr><td><em>A</em> implies <em>B</em></td><td><code>A → B</code></td><td>A function that transforms evidence of <em>A</em> into evidence of <em>B</em></td></tr>
<tr><td>not <em>A</em></td><td><code>¬A</code></td><td>A function that would transform evidence of <em>A</em> into evidence of <code>False</code></td></tr>
</tbody></table>
<p>The <code>simp</code> tactic can prove theorems that use these connectives.
For example:</p>
<pre><code class="language-leantac">theorem onePlusOneAndLessThan : 1 + 1 = 2 ∨ 3 &lt; 5 := by simp
theorem notTwoEqualFive : ¬(1 + 1 = 5) := by simp
theorem trueIsTrue : True := True.intro
theorem trueOrFalse : True ∨ False := by simp
theorem falseImpliesTrue : False → True := by simp
</code></pre>
<h2 id="evidence-as-arguments"><a class="header" href="#evidence-as-arguments">Evidence as Arguments</a></h2>
<p>While <code>simp</code> does a great job proving propositions that involve equalities and inequalities of specific numbers, it is not very good at proving statements that involve variables.
For instance, <code>simp</code> can prove that <code>4 &lt; 15</code>, but it can't easily tell that because <code>x &lt; 4</code>, it's also true that <code>x &lt; 15</code>.
Because index notation uses <code>simp</code> behind the scenes to prove that array access is safe, it can require a bit of hand-holding.</p>
<p>One of the easiest ways to make indexing notation work well is to have the function that performs a lookup into a data structure take the required evidence of safety as an argument.
For instance, a function that returns the third entry in a list is not generally safe because lists might contain zero, one, or two entries:</p>
<pre><code class="language-lean">def third (xs : List α) : α := xs[2]
</code></pre>
<pre><code class="language-output error">failed to prove index is valid, possible solutions:
  - Use `have`-expressions to prove the index is valid
  - Use `a[i]!` notation instead, runtime check is perfomed, and 'Panic' error message is produced if index is not valid
  - Use `a[i]?` notation instead, result is an `Option` type
  - Use `a[i]'h` notation instead, where `h` is a proof that index is valid
α : Type ?u.3900
xs : List α
⊢ 2 &lt; List.length xs
</code></pre>
<p>However, the obligation to show that the list has at least three entries can be imposed on the caller by adding an argument that consists of evidence that the indexing operation is safe:</p>
<pre><code class="language-lean">def third (xs : List α) (ok : xs.length &gt; 2) : α := xs[2]
</code></pre>
<p>In this example, <code>xs.length &gt; 2</code> is not a program that checks <em>whether</em> <code>xs</code> has more than 2 entries.
It is a proposition that could be true or false, and the argument <code>ok</code> must be evidence that it is true.</p>
<p>When the function is called on a concrete list, its length is known.
In these cases, <code>by simp</code> can construct the evidence automatically:</p>
<pre><code class="language-leantac">#eval third woodlandCritters (by simp)
</code></pre>
<pre><code class="language-output info">&quot;snail&quot;
</code></pre>
<h2 id="indexing-without-evidence"><a class="header" href="#indexing-without-evidence">Indexing Without Evidence</a></h2>
<p>In cases where it's not practical to prove that an indexing operation is in bounds, there are other alternatives.
Adding a question mark results in an <code>Option</code>, where the result is <code>some</code> if the index is in bounds, and <code>none</code> otherwise.
For example:</p>
<pre><code class="language-lean">def thirdOption (xs : List α) : Option α := xs[2]?

#eval thirdOption woodlandCritters
</code></pre>
<pre><code class="language-output info">some &quot;snail&quot;
</code></pre>
<pre><code class="language-lean">#eval thirdOption [&quot;only&quot;, &quot;two&quot;]
</code></pre>
<pre><code class="language-output info">none
</code></pre>
<p>There is also a version that crashes the program when the index is out of bounds, rather than returning an <code>Option</code>:</p>
<pre><code class="language-lean">#eval woodlandCritters[1]!
</code></pre>
<pre><code class="language-output info">&quot;deer&quot;
</code></pre>
<p>Be careful!
Because code that is run with <code>#eval</code> runs in the context of the Lean compiler, selecting the wrong index can crash your IDE.</p>
<h2 id="messages-you-may-meet-3"><a class="header" href="#messages-you-may-meet-3">Messages You May Meet</a></h2>
<p>In addition to the error that occurs when Lean is unable to find compile-time evidence that an indexing operation is safe, polymorphic functions that use unsafe indexing may produce the following message:</p>
<pre><code class="language-lean">def unsafeThird (xs : List α) : α := xs[2]!
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  Inhabited α
</code></pre>
<p>This is due to a technical restriction that is part of keeping Lean usable as both a logic for proving theorems and a programming language.
In particular, only programs whose types contain at least one value are allowed to crash.
This is because a proposition in Lean is a kind of type that classifies evidence of its truth.
False propositions have no such evidence.
If a program with an empty type could crash, then that crashing program could be used as a kind of fake evidence for a false proposition.</p>
<p>Internally, Lean contains a table of types that are known to have at least one value.
This error is saying that some arbitrary type <code>α</code> is not necessarily in that table.
The next chapter describes how to add to this table, and how to successfully write functions like <code>unsafeThird</code>.</p>
<p>Adding whitespace between a list and the brackets used for lookup can cause another message:</p>
<pre><code class="language-lean">#eval woodlandCritters [1]
</code></pre>
<pre><code class="language-output error">function expected at
  woodlandCritters
term has type
  List String
</code></pre>
<p>Adding a space causes Lean to treat the expression as a function application, and the index as a list that contains a single number.
This error message results from having Lean attempt to treat <code>woodlandCritters</code> as a function.</p>
<h2 id="exercises-4"><a class="header" href="#exercises-4">Exercises</a></h2>
<ul>
<li>Prove the following theorems using <code>rfl</code>: <code>2 + 3 = 5</code>, <code>15 - 8 = 7</code>, <code>&quot;Hello, &quot;.append &quot;world&quot; = &quot;Hello, world&quot;</code>. What happens if <code>rfl</code> is used to prove <code>5 &lt; 18</code>? Why?</li>
<li>Prove the following theorems using <code>by simp</code>: <code>2 + 3 = 5</code>, <code>15 - 8 = 7</code>, <code>&quot;Hello, &quot;.append &quot;world&quot; = &quot;Hello, world&quot;</code>, <code>5 &lt; 18</code>.</li>
<li>Write a function that looks up the fifth entry in a list. Pass the evidence that this lookup is safe as an argument to the function.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overloading-and-type-classes"><a class="header" href="#overloading-and-type-classes">Overloading and Type Classes</a></h1>
<p>In many languages, the built-in datatypes get special treatment.
For example, in C and Java, <code>+</code> can be used to add <code>float</code>s and <code>int</code>s, but not arbitrary-precision numbers from a third-party library.
Similarly, numeric literals can be used directly for the built-in types, but not for user-defined number types.
Other languages provide an <em>overloading</em> mechanism for operators, where the same operator can be given a meaning for a new type.
In these languages, such as C++ and C#, a wide variety of built-in operators can be overloaded, and the compiler uses the type checker to select a particular implementation.</p>
<p>In addition to numeric literals and operators, many languages allow overloading of functions or methods.
In C++, Java, C# and Kotlin, multiple implementations of a method are allowed, with differing numbers and types of arguments.
The compiler uses the number of arguments and their types to determine which overload was intended.</p>
<p>Function and operator overloading has a key limitation: polymorphic functions can't restrict their type arguments to types for which a given overload exists.
That is, there is no way to write a function that works for any type that has addition defined.
Instead, this function must itself be overloaded for each type that has addition, resulting in many boilerplate definitions instead of a single polymorphic definition.
Another consequence of this restriction is that some operators (such as equality in Java) end up being defined for <em>every</em> combination of arguments, even when it is not necessarily sensible to do so.
If programmers are not very careful, this can lead to programs that crash at runtime or silently compute an incorrect result.</p>
<p>Lean implements overloading using a mechanism called <em>type classes</em>, pioneered in Haskell, that allows overloading of operators, functions, and literals in a manner that works well with polymorphism.
A type class describes a collection of overloadable operations.
To overload these operations for a new type, an <em>instance</em> is created that contains an implementation of each operation for the new type.
For example, a type class named <code>Add</code> describes types that allow addition, and an instance of <code>Add</code> for <code>Nat</code> provides an implementation of addition for <code>Nat</code>.</p>
<p>The terms <em>class</em> and <em>instance</em> can be confusing for those who are used to object-oriented languages, because they are not closely related to classes and instances in object-oriented languages.
However, they do share common roots: in everyday language, the term &quot;class&quot; refers to a group that shares some common attributes.
While classes in object-oriented programming certainly describe groups of objects with common attributes, the term additionally refers to a specific mechanism in a programming language for describing such a group.
Type classes are also a means of describing types that share common attributes (namely, implementations of certain operations), but they don't really have anything else in common with classes as found in object-oriented programming.</p>
<p>A Lean type class is much more analogous to a Java or C# <em>interface</em>.
Both type classes and interfaces describe a conceptually related set of operations that are implemented for a type or collection of types.
Similarly, an instance of a type class is akin to the code in a Java or C# class that is prescribed by the implemented interfaces, rather than an instance of a Java or C# class.
Unlike Java or C#'s interfaces, types can be given instances for type classes that the author of the type does not have access to.
In this way, they are very similar to Rust traits.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="positive-numbers"><a class="header" href="#positive-numbers">Positive Numbers</a></h1>
<p>In some applications, only positive numbers make sense.
For example, compilers and interpreters typically use one-indexed line and column numbers for source positions, and a datatype that represents only non-empty lists will never report a length of zero.
Rather than relying on natural numbers, and littering the code with assertions that the number is not zero, it can be useful to design a datatype that represents only positive numbers.</p>
<p>One way to represent positive numbers is very similar to <code>Nat</code>, except with <code>one</code> as the base case instead of <code>zero</code>:</p>
<pre><code class="language-lean">inductive Pos : Type where
  | one : Pos
  | succ : Pos → Pos
</code></pre>
<p>This datatype represents exactly the intended set of values, but it is not very convenient to use.
For example, numeric literals are rejected:</p>
<pre><code class="language-lean">def seven : Pos := 7
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  OfNat Pos 7
</code></pre>
<p>Instead, the constructors must be used directly:</p>
<pre><code class="language-lean">def seven : Pos :=
  Pos.succ (Pos.succ (Pos.succ (Pos.succ (Pos.succ (Pos.succ Pos.one)))))
</code></pre>
<p>Similarly, addition and multiplication are not easy to use:</p>
<pre><code class="language-lean">def fourteen : Pos := seven + seven
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  HAdd Pos Pos ?m.291
</code></pre>
<pre><code class="language-lean">def fortyNine : Pos := seven * seven
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  HMul Pos Pos ?m.291
</code></pre>
<p>Each of these error messages begins with <code>failed to synthesize instance</code>.
This indicates that the error is due to an overloaded operation that has not been implemented, and it describes the type class that must be implemented.</p>
<h2 id="classes-and-instances"><a class="header" href="#classes-and-instances">Classes and Instances</a></h2>
<p>A type class consists of a name, some parameters, and a collection of <em>methods</em>.
The parameters describe the types for which overloadable operations are being defined, and the methods are the names and type signatures of the overloadable operations.
Once again, there is a terminology clash with object-oriented languages.
In object-oriented programming, a method is essentially a function that is connected to a particular object in memory, with special access to the object's private state.
Objects are interacted with via their methods.
In Lean, the term &quot;method&quot; refers to an operation that has been declared to be overloadable, with no special connection to objects or values or private fields.</p>
<p>One way to overload addition is to define a type class named <code>Plus</code>, with an addition method named <code>plus</code>.
Once an instance of <code>Plus</code> for <code>Nat</code> has been defined, it becomes possible to add two <code>Nat</code>s using <code>Plus.plus</code>:</p>
<pre><code class="language-lean">#eval Plus.plus 5 3
</code></pre>
<pre><code class="language-output info">8
</code></pre>
<p>Adding more instances allows <code>Plus.plus</code> to take more types of arguments.</p>
<p>In the following type class declaration, <code>Plus</code> is the name of the class, <code>α : Type</code> is the only argument, and <code>plus : α → α → α</code> is the only method:</p>
<pre><code class="language-lean">class Plus (α : Type) where
  plus : α → α → α
</code></pre>
<p>This declaration says that there is a type class <code>Plus</code> that overloads operations with respect to a type <code>α</code>.
In particular, there is one overloaded operation called <code>plus</code> that takes two <code>α</code>s and returns an <code>α</code>.</p>
<p>Type classes are first class, just as types are first class.
In particular, a type class is another kind of type.
The type of <code>Plus</code> is <code>Type → Type</code>, because it takes a type as an argument (<code>α</code>) and results in a new type that describes the overloading of <code>Plus</code>'s operation for <code>α</code>.</p>
<p>To overload <code>plus</code> for a particular type, write an instance:</p>
<pre><code class="language-lean">instance : Plus Nat where
  plus := Nat.add
</code></pre>
<p>The colon after <code>instance</code> indicates that <code>Plus Nat</code> is indeed a type.
Each method of class <code>Plus</code> should be assigned a value using <code>:=</code>.
In this case, there is only one method: <code>plus</code>.</p>
<p>By default, type class methods are defined in a namespace with the same name as the type class.
It can be convenient to <code>open</code> the namespace so that users don't need to type the name of the class first.
Parentheses in an <code>open</code> command indicate that only the indicated names from the namespace are to be made accessible:</p>
<pre><code class="language-lean">open Plus (plus)

#eval plus 5 3
</code></pre>
<pre><code class="language-output info">8
</code></pre>
<p>Defining an addition function for <code>Pos</code> and an instance of <code>Plus Pos</code> allows <code>plus</code> to be used to add both <code>Pos</code> and <code>Nat</code> values:</p>
<pre><code class="language-lean">def Pos.plus : Pos → Pos → Pos
  | Pos.one, k =&gt; Pos.succ k
  | Pos.succ n, k =&gt; Pos.succ (n.plus k)

instance : Plus Pos where
  plus := Pos.plus

def fourteen : Pos := plus seven seven
</code></pre>
<p>Because there is not yet an instance of <code>Plus Float</code>, attempting to add two floating-point numbers with <code>plus</code> fails with a familiar message:</p>
<pre><code class="language-lean">#eval plus 5.2 917.25861
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  Plus Float
</code></pre>
<p>These errors mean that Lean was unable to find an instance for a given type class.</p>
<h2 id="overloaded-addition"><a class="header" href="#overloaded-addition">Overloaded Addition</a></h2>
<p>Lean's built-in addition operator is syntactic sugar for a type class called <code>HAdd</code>, which flexibly allows the arguments to addition to have different types.
<code>HAdd</code> is short for <em>heterogeneous addition</em>.
For example, an <code>HAdd</code> instance can be written to allow a <code>Nat</code> to be added to a <code>Float</code>, resulting in a new <code>Float</code>.
When a programmer writes <code>x + y</code>, it is interpreted as meaning <code>HAdd.hAdd x y</code>.</p>
<p>While an understanding of the full generality of <code>HAdd</code> relies on features that are discussed in <a href="type-classes/out-params.html">another section in this chapter</a>, there is a simpler type class called <code>Add</code> that does not allow the types of the arguments to be mixed.
The Lean libraries are set up so that an instance of <code>Add</code> will be found when searching for an instance of <code>HAdd</code> in which both arguments have the same type.</p>
<p>Defining an instance of <code>Add Pos</code> allows <code>Pos</code> values to use ordinary addition syntax:</p>
<pre><code class="language-lean">instance : Add Pos where
  add := Pos.plus

def fourteen : Pos := seven + seven
</code></pre>
<h2 id="conversion-to-strings"><a class="header" href="#conversion-to-strings">Conversion to Strings</a></h2>
<p>Another useful built-in class is called <code>ToString</code>.
Instances of <code>ToString</code> provide a standard way of converting values from a given type into strings.
For example, a <code>ToString</code> instance is used when a value occurs in an interpolated string, and it determines how the <code>IO.println</code> function used at the <a href="type-classes/../hello-world/running-a-program.html#running-a-program">beginning of the description of <code>IO</code></a> will display a value.</p>
<p>For example, one way to convert a <code>Pos</code> into a <code>String</code> is to reveal its inner structure.
The function <code>posToString</code> takes a <code>Bool</code> that determines whether to parenthesize uses of <code>Pos.succ</code>, which should be <code>true</code> in the initial call to the function and <code>false</code> in all recursive calls.</p>
<pre><code class="language-lean">def posToString (atTop : Bool) (p : Pos) : String :=
  let paren s := if atTop then s else &quot;(&quot; ++ s ++ &quot;)&quot;
  match p with
  | Pos.one =&gt; &quot;Pos.one&quot;
  | Pos.succ n =&gt; paren s!&quot;Pos.succ {posToString false n}&quot;
</code></pre>
<p>Using this function for a <code>ToString</code> instance:</p>
<pre><code class="language-lean">instance : ToString Pos where
  toString := posToString true
</code></pre>
<p>results in informative, yet overwhelming, output:</p>
<pre><code class="language-lean">#eval s!&quot;There are {seven}&quot;
</code></pre>
<pre><code class="language-output info">&quot;There are Pos.succ (Pos.succ (Pos.succ (Pos.succ (Pos.succ (Pos.succ Pos.one)))))&quot;
</code></pre>
<p>On the other hand, every positive number has a corresponding <code>Nat</code>.
Converting it to a <code>Nat</code> and then using the <code>ToString Nat</code> instance (that is, the overloading of <code>toString</code> for <code>Nat</code>) is a quick way to generate much shorter output:</p>
<pre><code class="language-lean">def Pos.toNat : Pos → Nat
  | Pos.one =&gt; 1
  | Pos.succ n =&gt; n.toNat + 1

instance : ToString Pos where
  toString x := toString (x.toNat)

#eval s!&quot;There are {seven}&quot;
</code></pre>
<pre><code class="language-output info">&quot;There are 7&quot;
</code></pre>
<p>When more than one instance is defined, the most recent takes precedence.
Additionally, if a type has a <code>ToString</code> instance, then it can be used to display the result of <code>#eval</code> even if the type in question was not defined with <code>deriving Repr</code>, so <code>#eval seven</code> outputs <code>7</code>.</p>
<h2 id="overloaded-multiplication"><a class="header" href="#overloaded-multiplication">Overloaded Multiplication</a></h2>
<p>For multiplication, there is a type class called <code>HMul</code> that allows mixed argument types, just like <code>HAdd</code>.
Just as <code>x + y</code> is interpreted as <code>HAdd.hAdd x y</code>, <code>x * y</code> is interpreted as <code>HMul.hMul x y</code>.
For the common case of multiplication of two arguments with the same type, a <code>Mul</code> instance suffices.</p>
<p>An instance of <code>Mul</code> allows ordinary multiplication syntax to be used with <code>Pos</code>:</p>
<pre><code class="language-lean">def Pos.mul : Pos → Pos → Pos
  | Pos.one, k =&gt; k
  | Pos.succ n, k =&gt; n.mul k + k

instance : Mul Pos where
  mul := Pos.mul
</code></pre>
<p>With this instance, multiplication works as expected:</p>
<pre><code class="language-lean">#eval [seven * Pos.one,
       seven * seven,
       Pos.succ Pos.one * seven]
</code></pre>
<pre><code class="language-output info">[7, 49, 14]
</code></pre>
<h2 id="literal-numbers"><a class="header" href="#literal-numbers">Literal Numbers</a></h2>
<p>It is quite inconvenient to write out a sequence of constructors for positive numbers.
One way to work around the problem would be to provide a function to convert a <code>Nat</code> into a <code>Pos</code>.
However, this approach has downsides.
First off, because <code>Pos</code> cannot represent <code>0</code>, the resulting function would either convert a <code>Nat</code> to a bigger number, or it would return <code>Option Nat</code>.
Neither is particularly convenient for users.
Secondly, the need to call the function explicitly would make programs that use positive numbers much less convenient to write than programs that use <code>Nat</code>.
Having a trade-off between precise types and convenient APIs means that the precise types become less useful.</p>
<p>In Lean, natural number literals are interpreted using a type class called <code>OfNat</code>:</p>
<pre><code class="language-lean">class OfNat (α : Type) (_ : Nat) where
  ofNat : α
</code></pre>
<p>This type class takes two arguments: <code>α</code> is the type for which a natural number is overloaded, and the unnamed <code>Nat</code> argument is the actual literal number that was encountered in the program.
The method <code>ofNat</code> is then used as the value of the numeric literal.
Because the class contains the <code>Nat</code> argument, it becomes possible to define only instances for those values where the number makes sense.</p>
<p><code>OfNat</code> demonstrates that the arguments to type classes do not need to be types.
Because types in Lean are first-class participants in the language that can be passed as arguments to functions and given definitions with <code>def</code> and <code>abbrev</code>, there is no barrier that prevents non-type arguments in positions where a less-flexible language could not permit them.
This flexibility allows overloaded operations to be provided for particular values as well as particular types.</p>
<p>For example, a sum type that represents natural numbers less than four can be defined as follows:</p>
<pre><code class="language-lean">inductive LT4 where
  | zero
  | one
  | two
  | three
deriving Repr
</code></pre>
<p>While it would not make sense to allow <em>any</em> literal number to be used for this type, numbers less than four clearly make sense:</p>
<pre><code class="language-lean">instance : OfNat LT4 0 where
  ofNat := LT4.zero

instance : OfNat LT4 1 where
  ofNat := LT4.one

instance : OfNat LT4 2 where
  ofNat := LT4.two

instance : OfNat LT4 3 where
  ofNat := LT4.three
</code></pre>
<p>With these instances, the following examples work:</p>
<pre><code class="language-lean">#eval (3 : LT4)
</code></pre>
<pre><code class="language-output info">LT4.three
</code></pre>
<pre><code class="language-lean">#eval (0 : LT4)
</code></pre>
<pre><code class="language-output info">LT4.zero
</code></pre>
<p>On the other hand, out-of-bounds literals are still not allowed:</p>
<pre><code class="language-lean">#eval (4 : LT4)
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
OfNat LT4 4
</code></pre>
<p>For <code>Pos</code>, the <code>OfNat</code> instance should work for <em>any</em> <code>Nat</code> other than <code>Nat.zero</code>.
Another way to phrase this is to say that for all natural numbers <code>n</code>, the instance should work for <code>n + 1</code>.
Just as names like <code>α</code> automatically become implicit arguments to functions that Lean fills out on its own, instances can take automatic implicit arguments.
In this instance, the argument <code>n</code> stands for any <code>Nat</code>, and the instance is defined for a <code>Nat</code> that's one greater:</p>
<pre><code class="language-lean">instance : OfNat Pos (n + 1) where
  ofNat :=
    let rec natPlusOne : Nat → Pos
      | 0 =&gt; Pos.one
      | k + 1 =&gt; Pos.succ (natPlusOne k)
    natPlusOne n
</code></pre>
<p>Because <code>n</code> stands for a <code>Nat</code> that's one less than what the user wrote, the helper function <code>natPlusOne</code> returns a <code>Pos</code> that's one greater than its argument.
This makes it possible to use natural number literals for positive numbers, but not for zero:</p>
<pre><code class="language-lean">def eight : Pos := 8

def zero : Pos := 0
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  OfNat Pos 0
</code></pre>
<h2 id="exercises-5"><a class="header" href="#exercises-5">Exercises</a></h2>
<h3 id="another-representation"><a class="header" href="#another-representation">Another Representation</a></h3>
<p>An alternative way to represent a positive number is as the successor of some <code>Nat</code>.
Replace the definition of <code>Pos</code> with a structure whose constructor is named <code>succ</code> that contains a <code>Nat</code>:</p>
<pre><code class="language-lean">structure Pos where
  succ ::
  pred : Nat
</code></pre>
<p>Define instances of <code>Add</code>, <code>Mul</code>, <code>ToString</code>, and <code>OfNat</code> that allow this version of <code>Pos</code> to be used conveniently.</p>
<h3 id="even-numbers"><a class="header" href="#even-numbers">Even Numbers</a></h3>
<p>Define a datatype that represents only even numbers. Define instances of <code>Add</code>, <code>Mul</code>, and <code>ToString</code> that allow it to be used conveniently.
<code>OfNat</code> requires a feature that is introduced in <a href="type-classes/polymorphism.html">the next section</a>.</p>
<h3 id="http-requests"><a class="header" href="#http-requests">HTTP Requests</a></h3>
<p>An HTTP request begins with an identification of a HTTP method, such as <code>GET</code> or <code>POST</code>, along with a URI and an HTTP version.
Define an inductive type that represents an interesting subset of the HTTP methods, and a structure that represents HTTP responses.
Responses should have a <code>ToString</code> instance that makes it possible to debug them.
Use a type class to associate different <code>IO</code> actions with each HTTP method, and write a test harness as an <code>IO</code> action that calls each method and prints the result.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="type-classes-and-polymorphism"><a class="header" href="#type-classes-and-polymorphism">Type Classes and Polymorphism</a></h1>
<p>It can be useful to write functions that work for <em>any</em> overloading of a given function.
For instance, <code>IO.println</code> works for any type that has an instance of <code>ToString</code>.
This is indicated using square brackets around the required instance: the type of <code>IO.println</code> is <code>{α : Type} → [ToString α] → α → IO Unit</code>.
This type says that <code>IO.println</code> accepts an argument of type <code>α</code>, which Lean should determine automatically, and that there must be a <code>ToString</code> instance available for <code>α</code>.
It returns an <code>IO</code> action.</p>
<h2 id="checking-polymorphic-functions-types"><a class="header" href="#checking-polymorphic-functions-types">Checking Polymorphic Functions' Types</a></h2>
<p>Checking the type of a function that takes implicit arguments or uses type classes requires the use of some additional syntax.
Simply writing</p>
<pre><code class="language-lean">#check (IO.println)
</code></pre>
<p>yields a type with metavariables:</p>
<pre><code class="language-output info">IO.println : ?m.3659 → IO Unit
</code></pre>
<p>This is because Lean does its best to discover implicit arguments, and the presence of metavariables indicates that it did not yet discover enough type information to do so.
To understand the signature of a function, this feature can be suppressed with an at-sign (<code>@</code>) before the function's name:</p>
<pre><code class="language-lean">#check @IO.println
</code></pre>
<pre><code class="language-output info">@IO.println : {α : Type u_1} → [inst : ToString α] → α → IO Unit
</code></pre>
<p>In this output, the instance itself has been given the name <code>inst</code>.
Additionally, there is a <code>u_1</code> after <code>Type</code>, which uses a feature of Lean that has not yet been introduced.
For now, ignore these parameters to <code>Type</code>.</p>
<h2 id="defining-polymorphic-functions-with-instance-implicits"><a class="header" href="#defining-polymorphic-functions-with-instance-implicits">Defining Polymorphic Functions with Instance Implicits</a></h2>
<p>A function that sums all entries in a list needs two instances: <code>Add</code> allows the entries to be added, and an <code>OfNat</code> instance for <code>0</code> provides a sensible value to return for the empty list:</p>
<pre><code class="language-lean">def List.sum [Add α] [OfNat α 0] : List α → α
  | [] =&gt; 0
  | x :: xs =&gt; x + xs.sum
</code></pre>
<p>This function can be used for a list of <code>Nat</code>s:</p>
<pre><code class="language-lean">def fourNats : List Nat := [1, 2, 3, 4]

#eval fourNats.sum
</code></pre>
<pre><code class="language-output info">10
</code></pre>
<p>but not for a list of <code>Pos</code> numbers:</p>
<pre><code class="language-lean">def fourPos : List Pos := [1, 2, 3, 4]

#eval fourPos.sum
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  OfNat Pos 0
</code></pre>
<p>Specifications of required instances in square brackets are called <em>instance implicits</em>.
Behind the scenes, every type class defines a structure that has a field for each overloaded operation.
Instances are values of that structure type, with each field containing an implementation.
At a call site, Lean is responsible for finding an instance value to pass for each instance implicit argument.
The most important difference between ordinary implicit arguments and instance implicits is the strategy that Lean uses to find an argument value.
In the case of ordinary implicit arguments, Lean uses a technique called <em>unification</em> to find a single unique argument value that would allow the program to pass the type checker.
This process relies only on the specific types involved in the function's definition and the call site.
For instance implicits, Lean instead consults a built-in table of instance values.</p>
<p>Just as the <code>OfNat</code> instance for <code>Pos</code> took a natural number <code>n</code> as an automatic implicit argument, instances may also take instance implicit arguments themselves.
The <a href="type-classes/../getting-to-know/polymorphism.html">section on polymorphism</a> presented a polymorphic point type:</p>
<pre><code class="language-lean">structure PPoint (α : Type) where
  x : α
  y : α
deriving Repr
</code></pre>
<p>Addition of points should add the underlying <code>x</code> and <code>y</code> fields.
Thus, an <code>Add</code> instance for <code>PPoint</code> requires an <code>Add</code> instance for whatever type these fields have.
In other words, the <code>Add</code> instance for <code>PPoint</code> requires a further <code>Add</code> instance for <code>α</code>:</p>
<pre><code class="language-lean">instance [Add α] : Add (PPoint α) where
  add p1 p2 := { x := p1.x + p2.x, y := p1.y + p2.y }
</code></pre>
<p>When Lean encounters an addition of two points, it searches for and finds this instance.
It then performs a further search for the <code>Add α</code> instance.</p>
<p>The instance values that are constructed in this way are values of the type class's structure type.
A successful recursive instance search results in a structure value that has a reference to another structure value.
An instance of <code>Add (PPoint Nat)</code> contains a reference to the instance of <code>Add Nat</code> that was found.</p>
<p>This recursive search process means that type classes offer significantly more power than plain overloaded functions.
A library of polymorphic instances is a set of code building blocks that the compiler will assemble on its own, given nothing but the desired type.
Polymorphic functions that take instance arguments are latent requests to the type class mechanism to assemble helper functions behind the scenes.
The API's clients are freed from the burden of plumbing together all of the necessary parts by hand.</p>
<h2 id="methods-and-implicit-arguments"><a class="header" href="#methods-and-implicit-arguments">Methods and Implicit Arguments</a></h2>
<p>The type of <code>@OfNat.ofNat</code> may be surprising.
It is <code>{α : Type} → (n : Nat) → [OfNat α n] → α</code>, in which the <code>Nat</code> argument <code>n</code> occurs as an explicit function argument.
In the declaration of the method, however, <code>ofNat</code> simply has type <code>α</code>.
This seeming discrepancy is because declaring a type class really results in the following:</p>
<ul>
<li>A structure type to contain the implementation of each overloaded operation</li>
<li>A namespace with the same name as the class</li>
<li>For each method, a function in the class's namespace that retrieves its implementation from an instance</li>
</ul>
<p>This is analogous to the way that declaring a new structure also declares accessor functions.
The primary difference is that a structure's accessors take the structure value as an explicit argument, while the type class methods take the instance value as an instance implicit to be found automatically by Lean.</p>
<p>In order for Lean to find an instance, its arguments must be available.
This means that each argument to the type class must be an argument to the method that occurs before the instance.
It is most convenient when these arguments are implicit, because Lean does the work of discovering their values.
For example, <code>@Add.add</code> has the type <code>{α : Type} → [Add α] → α → α → α</code>.
In this case, the type argument <code>α</code> can be implicit because the arguments to <code>Add.add</code> provide information about which type the user intended.
This type can then be used to search for the <code>Add</code> instance.</p>
<p>In the case of <code>ofNat</code>, however, the particular <code>Nat</code> literal to be decoded does not appear as part of any other argument.
This means that Lean would have no information to use when attempting to figure out the implicit argument <code>n</code>.
The result would be a very inconvenient API.
Thus, in these cases, Lean uses an explicit argument for the class's method.</p>
<h2 id="exercises-6"><a class="header" href="#exercises-6">Exercises</a></h2>
<h3 id="even-number-literals"><a class="header" href="#even-number-literals">Even Number Literals</a></h3>
<p>Write an instance of <code>OfNat</code> for the even number datatype from the <a href="type-classes/pos.html#even-numbers">previous section's exercises</a> that uses recursive instance search.
For the base instance, it is necessary to write <code>OfNat Even Nat.zero</code> instead of <code>OfNat Even 0</code>.</p>
<h3 id="recursive-instance-search-depth"><a class="header" href="#recursive-instance-search-depth">Recursive Instance Search Depth</a></h3>
<p>There is a limit to how many times the Lean compiler will attempt a recursive instance search.
This places a limit on the size of even number literals defined in the previous exercise.
Experimentally determine what the limit is.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="controlling-instance-search"><a class="header" href="#controlling-instance-search">Controlling Instance Search</a></h1>
<p>An instance of the <code>Add</code> class is sufficient to allow two expressions with type <code>Pos</code> to be conveniently added, producing another <code>Pos</code>.
However, in many cases, it can be useful to be more flexible and allow <em>heterogeneous</em> operator overloading, where the arguments may have different types.
For example, adding a <code>Nat</code> to a <code>Pos</code> or a <code>Pos</code> to a <code>Nat</code> will always yield a <code>Pos</code>:</p>
<pre><code class="language-lean">def addNatPos : Nat → Pos → Pos
  | 0, p =&gt; p
  | n + 1, p =&gt; Pos.succ (addNatPos n p)

def addPosNat : Pos → Nat → Pos
  | p, 0 =&gt; p
  | p, n + 1 =&gt; Pos.succ (addPosNat p n)
</code></pre>
<p>These functions allow natural numbers to be added to positive numbers, but they cannot be used with the <code>Add</code> type class, which expects both arguments to <code>add</code> to have the same type.</p>
<h2 id="heterogeneous-overloadings"><a class="header" href="#heterogeneous-overloadings">Heterogeneous Overloadings</a></h2>
<p>As mentioned in the section on <a href="type-classes/pos.html#overloaded-addition">overloaded addition</a>, Lean provides a type class called <code>HAdd</code> for overloading addition heterogeneously.
The <code>HAdd</code> class takes three type parameters: the two argument types and the return type.
Instances of <code>HAdd Nat Pos Pos</code> and <code>HAdd Pos Nat Pos</code> allow ordinary addition notation to be used to mix the types:</p>
<pre><code class="language-lean">instance : HAdd Nat Pos Pos where
  hAdd := addNatPos

instance : HAdd Pos Nat Pos where
  hAdd := addPosNat
</code></pre>
<p>Given the above two instances, the following examples work:</p>
<pre><code class="language-lean">#eval (3 : Pos) + (5 : Nat)
</code></pre>
<pre><code class="language-output info">8
</code></pre>
<pre><code class="language-lean">#eval (3 : Nat) + (5 : Pos)
</code></pre>
<pre><code class="language-output info">8
</code></pre>
<p>The definition of the <code>HAdd</code> type class is very much like the following definition of <code>HPlus</code> with the corresponding instances:</p>
<pre><code class="language-lean">class HPlus (α : Type) (β : Type) (γ : Type) where
  hPlus : α → β → γ

instance : HPlus Nat Pos Pos where
  hPlus := addNatPos

instance : HPlus Pos Nat Pos where
  hPlus := addPosNat
</code></pre>
<p>However, instances of <code>HPlus</code> are significantly less useful than instances of <code>HAdd</code>.
When attempting to use these instances with <code>#eval</code>, an error occurs:</p>
<pre><code class="language-lean">#eval HPlus.hPlus (3 : Pos) (5 : Nat)
</code></pre>
<pre><code class="language-output error">typeclass instance problem is stuck, it is often due to metavariables
  HPlus Pos Nat ?m.7602
</code></pre>
<p>This happens because there is a metavariable in the type, and Lean has no way to solve it.</p>
<p>As discussed in <a href="type-classes/../getting-to-know/polymorphism.html">the initial description of polymorphism</a>, metavariables represent unknown parts of a program that could not be inferred.
When an expression is written following <code>#eval</code>, Lean attempts to determine its type automatically.
In this case, it could not.
Because the third type parameter for <code>HPlus</code> was unknown, Lean couldn't carry out type class instance search, but instance search is the only way that Lean could determine the expression's type.
That is, the <code>HPlus Pos Nat Pos</code> instance can only apply if the expression should have type <code>Pos</code>, but there's nothing in the program other than the instance itself to indicate that it should have this type.</p>
<p>One solution to the problem is to ensure that all three types are available by adding a type annotation to the whole expression:</p>
<pre><code class="language-lean">#eval (HPlus.hPlus (3 : Pos) (5 : Nat) : Pos)
</code></pre>
<pre><code class="language-output info">8
</code></pre>
<p>However, this solution is not very convenient for users of the positive number library.</p>
<h2 id="output-parameters"><a class="header" href="#output-parameters">Output Parameters</a></h2>
<p>This problem can also be solved by declaring <code>γ</code> to be an <em>output parameter</em>.
Most type class parameters are inputs to the search algorithm: they are used to select an instance.
For example, in an <code>OfNat</code> instance, both the type and the natural number are used to select a particular interpretation of a natural number literal.
However, in some cases, it can be convenient to start the search process even when some of the type parameters are not yet known, and use the instances that are discovered in the search to determine values for metavariables.
The parameters that aren't needed to start instance search are outputs of the process, which is declared with the <code>outParam</code> modifier:</p>
<pre><code class="language-lean">class HPlus (α : Type) (β : Type) (γ : outParam Type) where
  hPlus : α → β → γ
</code></pre>
<p>With this output parameter, type class instance search is able to select an instance without knowing <code>γ</code> in advance.
For instance:</p>
<pre><code class="language-lean">#eval HPlus.hPlus (3 : Pos) (5 : Nat)
</code></pre>
<pre><code class="language-output info">8
</code></pre>
<p>It might be helpful to think of output parameters as defining a kind of function.
Any given instance of a type class that has one or more output parameters provides Lean with instructions for determining the outputs from the inputs.
The process of searching for an instance, possibly recursively, ends up being more powerful than mere overloading.
Output parameters can determine other types in the program, and instance search can assemble a collection of underlying instances into a program that has this type.</p>
<h2 id="default-instances"><a class="header" href="#default-instances">Default Instances</a></h2>
<p>Deciding whether a parameter is an input or an output controls the circumstances under which Lean will initiate type class search.
In particular, type class search does not occur until all inputs are known.
However, in some cases, output parameters are not enough, and instance search should also occur when some inputs are unknown.
This is a bit like default values for optional function arguments in Python or Kotlin, except default <em>types</em> are being selected.</p>
<p><em>Default instances</em> are instances that are available for instance search <em>even when not all their inputs are known</em>.
When one of these instances can be used, it will be used.
This can cause programs to successfully type check, rather than failing with errors related to unknown types and metavariables.
On the other hand, default instances can make instance selection less predictable.
In particular, if an undesired default instance is selected, then an expression may have a different type than expected, which can cause confusing type errors to occur elsewhere in the program.
Be selective about where default instances are used!</p>
<p>One example of where default instances can be useful is an instance of <code>HPlus</code> that can be derived from an <code>Add</code> instance.
In other words, ordinary addition is a special case of heterogeneous addition in which all three types happen to be the same.
This can be implemented using the following instance:</p>
<pre><code class="language-lean">instance [Add α] : HPlus α α α where
  hPlus := Add.add
</code></pre>
<p>With this instance, <code>hPlus</code> can be used for any addable type, like <code>Nat</code>:</p>
<pre><code class="language-lean">#eval HPlus.hPlus (3 : Nat) (5 : Nat)
</code></pre>
<pre><code class="language-output info">8
</code></pre>
<p>However, this instance will only be used in situations where the types of both arguments are known.
For example,</p>
<pre><code class="language-lean">#check HPlus.hPlus (5 : Nat) (3 : Nat)
</code></pre>
<p>yields the type</p>
<pre><code class="language-output info">HPlus.hPlus 5 3 : Nat
</code></pre>
<p>as expected, but</p>
<pre><code class="language-lean">#check HPlus.hPlus (5 : Nat)
</code></pre>
<p>yields a type that contains two metavariables, one for the remaining argument and one for the return type:</p>
<pre><code class="language-output info">HPlus.hPlus 5 : ?m.7783 → ?m.7785
</code></pre>
<p>In the vast majority of cases, when someone supplies one argument to addition, the other argument will have the same type.
To make this instance into a default instance, apply the <code>default_instance</code> attribute:</p>
<pre><code class="language-lean">@[default_instance]
instance [Add α] : HPlus α α α where
  hPlus := Add.add
</code></pre>
<p>With this default instance, the example has a more useful type:</p>
<pre><code class="language-lean">#check HPlus.hPlus (5 : Nat)
</code></pre>
<p>yields</p>
<pre><code class="language-output info">HPlus.hPlus 5 : Nat → Nat
</code></pre>
<p>Each operator that exists in overloadable heterogeneous and homogeneous versions follows the pattern of a default instance that allows the homogeneous version to be used in contexts where the heterogeneous is expected.
The infix operator is replaced with a call to the heterogeneous version, and the homogeneous default instance is selected when possible.</p>
<p>Similarly, simply writing <code>5</code> gives a <code>Nat</code> rather than a type with a metavariable that is waiting for more information in order to select an <code>OfNat</code> instance.
This is because the <code>OfNat</code> instance for <code>Nat</code> is a default instance.</p>
<p>Default instances can also be assigned <em>priorities</em> that affect which will be chosen in situations where more than one might apply.
For more information on default instance priorities, please consult the Lean manual.</p>
<h2 id="exercises-7"><a class="header" href="#exercises-7">Exercises</a></h2>
<p>Define an instance of <code>HMul (PPoint α) α (PPoint α)</code> that multiplies both projections by the scalar.
It should work for any type <code>α</code> for which there is a <code>Mul α</code> instance.
For example,</p>
<pre><code class="language-lean">#eval {x := 2.5, y := 3.7 : PPoint Float} * 2.0
</code></pre>
<p>should yield</p>
<pre><code class="language-output info">{ x := 5.000000, y := 7.400000 }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="arrays-and-indexing"><a class="header" href="#arrays-and-indexing">Arrays and Indexing</a></h1>
<p>The <a href="type-classes/../props-proofs-indexing.html">Interlude</a> describes how to use indexing notation in order to look up entries in a list by their position.
This syntax is also governed by a type class, and it can be used for a variety of different types.</p>
<h2 id="arrays"><a class="header" href="#arrays">Arrays</a></h2>
<p>For instance, Lean arrays are much more efficient than linked lists for most purposes.
In Lean, the type <code>Array α</code> is a dynamically-sized array holding values of type <code>α</code>, much like a Java <code>ArrayList</code>, a C++ <code>std::vector</code>, or a Rust <code>Vec</code>.
Unlike <code>List</code>, which has a pointer indirection on each use of the <code>cons</code> constructor, arrays occupy a contiguous region of memory, which is much better for processor caches.
Also, looking up a value in an array takes constant time, while lookup in a linked list takes time proportional to the index being accessed.</p>
<p>In pure functional languages like Lean, it is not possible to mutate a given position in a data structure.
Instead, a copy is made that has the desired modifications.
When using an array, the Lean compiler and runtime contain an optimization that can allow modifications to be implemented as mutations behind the scenes when there is only a single unique reference to an array.</p>
<p>Arrays are written similarly to lists, but with a leading <code>#</code>:</p>
<pre><code class="language-lean">def northernTrees : Array String :=
  #[&quot;sloe&quot;, &quot;birch&quot;, &quot;elm&quot;, &quot;oak&quot;]
</code></pre>
<p>The number of values in an array can be found using <code>Array.size</code>.
For instance, <code>northernTrees.size</code> evaluates to <code>4</code>.
For indices that are smaller than an array's size, indexing notation can be used to find the corresponding value, just as with lists.
That is, <code>northernTrees[2]</code> evaluates to <code>&quot;elm&quot;</code>.
Similarly, the compiler requires a proof that an index is in bounds, and attempting to look up a value outside the bounds of the array results in a compile-time error, just as with lists.
For instance, <code>northernTrees[8]</code> results in:</p>
<pre><code class="language-output error">failed to prove index is valid, possible solutions:
  - Use `have`-expressions to prove the index is valid
  - Use `a[i]!` notation instead, runtime check is perfomed, and 'Panic' error message is produced if index is not valid
  - Use `a[i]?` notation instead, result is an `Option` type
  - Use `a[i]'h` notation instead, where `h` is a proof that index is valid
⊢ 8 &lt; Array.size northernTrees
</code></pre>
<h2 id="non-empty-lists"><a class="header" href="#non-empty-lists">Non-Empty Lists</a></h2>
<p>A datatype that represents non-empty lists can be defined as a structure with a field for the head of the list and a field for the tail, which is an ordinary, potentially empty list:</p>
<pre><code class="language-lean">structure NonEmptyList (α : Type) : Type where
  head : α
  tail : List α
</code></pre>
<p>For example, the non-empty list <code>idahoSpiders</code> (which contains some spider species native to the US state of Idaho) consists of <code>&quot;Banded Garden Spider&quot;</code> followed by four other spiders, for a total of five spiders:</p>
<pre><code class="language-lean">def idahoSpiders : NonEmptyList String := {
  head := &quot;Banded Garden Spider&quot;,
  tail := [
    &quot;Long-legged Sac Spider&quot;,
    &quot;Wolf Spider&quot;,
    &quot;Hobo Spider&quot;,
    &quot;Cat-faced Spider&quot;
  ]
}
</code></pre>
<p>Looking up the value at a specific index in this list with a recursive function should consider three possibilities:</p>
<ol>
<li>The index is <code>0</code>, in which case the head of the list should be returned.</li>
<li>The index is <code>n + 1</code> and the tail is empty, in which case the index is out of bounds.</li>
<li>The index is <code>n + 1</code> and the tail is non-empty, in which case the function can be called recursively on the tail and <code>n</code>.</li>
</ol>
<p>For example, a lookup function that returns an <code>Option</code> can be written as follows:</p>
<pre><code class="language-lean">def NonEmptyList.get? : NonEmptyList α → Nat → Option α
  | xs, 0 =&gt; some xs.head
  | {head := _, tail := []}, _ + 1 =&gt; none
  | {head := _, tail := h :: t}, n + 1 =&gt; get? {head := h, tail := t} n
</code></pre>
<p>Each case in the pattern match corresponds to one of the possibilities above.
The recursive call to <code>get?</code> does not require a <code>NonEmptyList</code> namespace qualifier because the body of the definition is implicitly in the definition's namespace.
Another way to write this function uses <code>get?</code> for lists when the index is greater than zero:</p>
<pre><code class="language-lean">def NonEmptyList.get? : NonEmptyList α → Nat → Option α
  | xs, 0 =&gt; some xs.head
  | xs, n + 1 =&gt; xs.tail.get? n
</code></pre>
<p>If the list contains one entry, then only <code>0</code> is a valid index.
If it contains two entries, then both <code>0</code> and <code>1</code> are valid indices.
If it contains three entries, then <code>0</code>, <code>1</code>, and <code>2</code> are valid indices.
In other words, the valid indices into a non-empty list are natural numbers that are strictly less than the length of the list, which are less than or equal to the length of the tail.</p>
<p>The definition of what it means for an index to be in bounds should be written as an <code>abbrev</code> because the tactics used to find evidence that indices are acceptable are able to solve inequalities of numbers, but they don't know anything about the name <code>NonEmptyList.inBounds</code>:</p>
<pre><code class="language-lean">abbrev NonEmptyList.inBounds (xs : NonEmptyList α) (i : Nat) : Prop :=
  i ≤ xs.tail.length
</code></pre>
<p>This function returns a proposition that might be true or false.
For instance, <code>2</code> is in bounds for <code>idahoSpiders</code>, while <code>5</code> is not:</p>
<pre><code class="language-leantac">theorem atLeastThreeSpiders : idahoSpiders.inBounds 2 := by simp

theorem notSixSpiders : ¬idahoSpiders.inBounds 5 := by simp
</code></pre>
<p>The logical negation operator has a very low precedence, which means that <code>¬idahoSpiders.inBounds 5</code> is equivalent to <code>¬(idahoSpiders.inBounds 5)</code>.</p>
<p>This fact can be used to write a lookup function that requires evidence that the index is valid, and thus need not return <code>Option</code>, by delegating to the version for lists that checks the evidence at compile time:</p>
<pre><code class="language-lean">def NonEmptyList.get (xs : NonEmptyList α) (i : Nat) (ok : xs.inBounds i) : α :=
  match i with
  | 0 =&gt; xs.head
  | n + 1 =&gt; xs.tail[n]
</code></pre>
<p>It is, of course, possible to write this function to use the evidence directly, rather than delegating to a standard library function that happens to be able to use the same evidence.
This requires techniques for working with proofs and propositions that are described later in this book.</p>
<h2 id="overloading-indexing"><a class="header" href="#overloading-indexing">Overloading Indexing</a></h2>
<p>Indexing notation for a collection type can be overloaded by defining an instance of the <code>GetElem</code> type class.
For the sake of flexiblity, <code>GetElem</code> has four parameters:</p>
<ul>
<li>The type of the collection</li>
<li>The type of the index</li>
<li>The type of elements that are extracted from the collection</li>
<li>A function that determines what counts as evidence that the index is in bounds</li>
</ul>
<p>The element type and the evidence function are both output parameters.
<code>GetElem</code> has a single method, <code>getElem</code>, which takes a collection value, an index value, and evidence that the index is in bounds as arguments, and returns an element:</p>
<pre><code class="language-lean">class GetElem (coll : Type) (idx : Type) (item : outParam Type) (inBounds : outParam (coll → idx → Prop)) where
  getElem : (c : coll) → (i : idx) → inBounds c i → item
</code></pre>
<p>In the case of <code>NonEmptyList α</code>, these parameters are:</p>
<ul>
<li>The collection is <code>NonEmptyList α</code></li>
<li>Indices have type <code>Nat</code></li>
<li>The type of elements is <code>α</code></li>
<li>An index is in bounds if it is less than or equal to the length of the tail</li>
</ul>
<p>In fact, the <code>GetElem</code> instance can delegate directly to <code>NonEmptyList.get</code>:</p>
<pre><code class="language-lean">instance : GetElem (NonEmptyList α) Nat α NonEmptyList.inBounds where
  getElem := NonEmptyList.get
</code></pre>
<p>With this instance, <code>NonEmptyList</code> becomes just as convenient to use as <code>List</code>.
Evaluating <code>idahoSpiders[0]</code> yields <code>&quot;Banded Garden Spider&quot;</code>, while <code>idahoSpiders[9]</code> leads to the compile-time error:</p>
<pre><code class="language-output error">failed to prove index is valid, possible solutions:
  - Use `have`-expressions to prove the index is valid
  - Use `a[i]!` notation instead, runtime check is perfomed, and 'Panic' error message is produced if index is not valid
  - Use `a[i]?` notation instead, result is an `Option` type
  - Use `a[i]'h` notation instead, where `h` is a proof that index is valid
⊢ NonEmptyList.inBounds idahoSpiders 9
</code></pre>
<p>Because both the collection type and the index type are input parameters to the <code>GetElem</code> type class, new types can be used to index into existing collections.
The positive number type <code>Pos</code> is a perfectly reasonable index into a <code>List</code>, with the caveat that it cannot point at the first entry.
The follow instance of <code>GetElem</code> allows <code>Pos</code> to be used just as conveniently as <code>Nat</code> to find a list entry:</p>
<pre><code class="language-lean">instance : GetElem (List α) Pos α (fun list n =&gt; list.length &gt; n.toNat) where
  getElem (xs : List α) (i : Pos) ok := xs[i.toNat]
</code></pre>
<p>Indexing can also make sense for non-numeric indices.
For example, <code>Bool</code> can be used to select between the fields in a point, with <code>false</code> corresponding to <code>x</code> and <code>true</code> corresponding to <code>y</code>:</p>
<pre><code class="language-lean">instance : GetElem (PPoint α) Bool α (fun _ _ =&gt; True) where
  getElem (p : PPoint α) (i : Bool) _ :=
    if not i then p.x else p.y
</code></pre>
<p>In this case, both Booleans are valid indices.
Because every possible <code>Bool</code> is in bounds, the evidence is simply the true proposition <code>True</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="standard-classes"><a class="header" href="#standard-classes">Standard Classes</a></h1>
<p>This section presents a variety of operators and functions that can be overloaded using type classes in Lean.
Each operator or function corresponds to a method of a type class.
Unlike C++, infix operators in Lean are defined as abbreviations for named functions; this means that overloading them for new types is not done using the operator itself, but rather using the underlying name (such as <code>HAdd.hAdd</code>).</p>
<h2 id="arithmetic"><a class="header" href="#arithmetic">Arithmetic</a></h2>
<p>Most arithmetic operators are available in a heterogeneous form, where the arguments may have different type and an output parameter decides the type of the resulting expression.
For each heterogeneous operator, there is a corresponding homogeneous version that can found by removing the letter <code>h</code>, so that <code>HAdd.hAdd</code> becomes <code>Add.add</code>.
The following arithmetic operators are overloaded:</p>
<table><thead><tr><th>Expression</th><th>Desugaring</th><th>Class Name</th></tr></thead><tbody>
<tr><td><code>x + y</code></td><td><code>HAdd.hAdd x y</code></td><td><code>HAdd</code></td></tr>
<tr><td><code>x - y</code></td><td><code>HSub.hSub x y</code></td><td><code>HSub</code></td></tr>
<tr><td><code>x * y</code></td><td><code>HMul.hMul x y</code></td><td><code>HMul</code></td></tr>
<tr><td><code>x / y</code></td><td><code>HDiv.hDiv x y</code></td><td><code>HDiv</code></td></tr>
<tr><td><code>x % y</code></td><td><code>HMod.hMod x y</code></td><td><code>HMod</code></td></tr>
<tr><td><code>x ^ y</code></td><td><code>HPow.hPow x y</code></td><td><code>HPow</code></td></tr>
<tr><td><code>(- x)</code></td><td><code>Neg.neg x</code></td><td><code>Neg</code></td></tr>
</tbody></table>
<h2 id="bitwise-operators"><a class="header" href="#bitwise-operators">Bitwise Operators</a></h2>
<p>Lean contains a number of standard bitwise operators that are overloaded using type classes.
There are instances for fixed-width types such as <code>UInt8</code>, <code>UInt16</code>, <code>UInt32</code>, <code>UInt64</code>, and <code>USize</code>.
The latter is the size of words on the current platform, typically 32 or 64 bits.
The following bitwise operators are overloaded:</p>
<table><thead><tr><th>Expression</th><th>Desugaring</th><th>Class Name</th></tr></thead><tbody>
<tr><td><code>x &amp;&amp;&amp; y</code></td><td><code>HAnd.hAnd x y</code></td><td><code>HAnd</code></td></tr>
<tr><td><code class="hljs">x ||| y </code></td><td><code>HOr.hOr x y</code></td><td><code>HOr</code></td></tr>
<tr><td><code>x ^^^ y</code></td><td><code>HXor.hXor x y</code></td><td><code>HXor</code></td></tr>
<tr><td><code>~~~ x</code></td><td><code>Complement.complement x</code></td><td><code>Complement</code></td></tr>
<tr><td><code>x &gt;&gt;&gt; y</code></td><td><code>HShiftRight.hShiftRight x y</code></td><td><code>HShiftRight</code></td></tr>
<tr><td><code>x &lt;&lt;&lt; y</code></td><td><code>HShiftLeft.hShiftLeft x y</code></td><td><code>HShiftLeft</code></td></tr>
</tbody></table>
<p>Because the names <code>And</code> and <code>Or</code> are already taken as the names of logical connectives, the homogeneous versions of <code>HAnd</code> and <code>HOr</code> are called <code>AndOp</code> and <code>OrOp</code> rather than <code>And</code> and <code>Or</code>.</p>
<h2 id="equality-and-ordering"><a class="header" href="#equality-and-ordering">Equality and Ordering</a></h2>
<p>Testing equality of two values typically uses the <code>BEq</code> class, which is short for &quot;Boolean equality&quot;.
Due to Lean's use as a theorem prover, there are really two kinds of equality operators in Lean:</p>
<ul>
<li><em>Boolean equality</em> is the same kind of equality that is found in other programming languages. It is a function that takes two values and returns a <code>Bool</code>. Boolean equality is written with two equals signs, just as in Python and C#. Because Lean is a pure functional language, there's no separate notions of reference vs value equality—pointers cannot be observed directly.</li>
<li><em>Propositional equality</em> is the mathematical statement that two things are equal. Propositional equality is not a function; rather, it is a mathematical statement that admits proof. It is written with a single equals sign. A statement of propositional equality is like a type that classifies evidence of this equality.</li>
</ul>
<p>Both notions of equality are important, and used for different purposes.
Boolean equality is useful in programs, when a decision needs to be made about whether two values are equal.
For example, <code>&quot;Octopus&quot; ==  &quot;Cuttlefish&quot;</code> evaluates to <code>false</code>, and <code>&quot;Octopodes&quot; ==  &quot;Octo&quot;.append &quot;podes&quot;</code> evaluates to <code>true</code>.
Some values, such as functions, cannot be checked for equality.
For example, <code>(fun (x : Nat) =&gt; 1 + x) == (Nat.succ ·)</code> yields the error:</p>
<pre><code class="language-output error">failed to synthesize instance
  BEq (Nat → Nat)
</code></pre>
<p>As this message indicates, <code>==</code> is overloaded using a type class.
The expression <code>x == y</code> is actually shorthand for <code>BEq.beq x y</code>.</p>
<p>Propositional equality is a mathematical statement rather than an invocation of a program.
Because propositions are like types that describe evidence for some statement, propositional equality has more in common with types like <code>String</code> and <code>Nat → List Int</code> than it does with Boolean equality.
This means that it can't automatically be checked.
However, the equality of any two expressions can be stated in Lean, so long as they have the same type.
The statement <code>(fun (x : Nat) =&gt; 1 + x) = (Nat.succ ·)</code> is a perfectly reasonable statement.
From the perspective of mathematics, two functions are equal if they map equal inputs to equal outputs, so this statement is even true, though it requires a two-line proof to convince Lean of this fact.</p>
<p>Generally speaking, when using Lean as a programming language, it's easiest to stick to Boolean functions rather than propositions.
However, as the names <code>true</code> and <code>false</code> for <code>Bool</code>'s constructors suggest, this difference is sometimes blurred.
Some propositions are <em>decidable</em>, which means that they can be checked just like a Boolean function.
The function that checks whether the proposition is true or false is called a <em>decision procedure</em>, and it returns <em>evidence</em> of the truth or falsity of the proposition.
Some examples of decidable propositions include equality and inequality of natural numbers, equality of strings, and &quot;ands&quot; and &quot;ors&quot; of propositions that are themselves decidable.</p>
<p>In Lean, <code>if</code> works with decidable propositions.
For example, <code>2 &lt; 4</code> is a proposition:</p>
<pre><code class="language-lean">#check 2 &lt; 4
</code></pre>
<pre><code class="language-output info">2 &lt; 4 : Prop
</code></pre>
<p>Nonetheless, it is perfectly acceptable to write it as the condition in an <code>if</code>.
For example, <code>if 2 &lt; 4 then 1 else 2</code> has type <code>Nat</code> and evaluates to <code>1</code>.</p>
<p>Not all propositions are decidable.
If they were, then computers would be able to prove any true proposition just by running the decision procedure, and mathematicians would be out of a job.
More specifically, decidable propositions have an instance of the <code>Decidable</code> type class which has a method that is the decision procedure.
Trying to use a proposition that isn't decidable as if it were a <code>Bool</code> results in a failure to find the <code>Decidable</code> instance.
For example, <code>if (fun (x : Nat) =&gt; 1 + x) = (Nat.succ ·) then &quot;yes&quot; else &quot;no&quot;</code> results in:</p>
<pre><code class="language-output error">failed to synthesize instance
  Decidable ((fun x =&gt; 1 + x) = fun x =&gt; Nat.succ x)
</code></pre>
<p>The following propositions, that are usually decidable, are overloaded with type classes:</p>
<table><thead><tr><th>Expression</th><th>Desugaring</th><th>Class Name</th></tr></thead><tbody>
<tr><td><code>x &lt; y</code></td><td><code>LT.lt x y</code></td><td><code>LT</code></td></tr>
<tr><td><code>x ≤ y</code></td><td><code>LE.le x y</code></td><td><code>LE</code></td></tr>
<tr><td><code>x &gt; y</code></td><td><code>LT.lt y x</code></td><td><code>LT</code></td></tr>
<tr><td><code>x ≥ y</code></td><td><code>LE.le y x</code></td><td><code>LE</code></td></tr>
</tbody></table>
<p>Because defining new propositions hasn't yet been demonstrated, it may be difficult to define new instances of <code>LT</code> and <code>LE</code>.</p>
<p>Additionally, comparing values using <code>&lt;</code>, <code>==</code>, and <code>&gt;</code> can be inefficient.
Checking first whether one value is less than another, and then whether they are equal, can require two traversals over large data structures.
To solve this problem, Java and C# have standard <code>compareTo</code> and <code>CompareTo</code> methods (respectively) that can be overridden by a class in order to implement all three operations at the same time.
These methods return a negative integer if the receiver is less than the argument, zero if they are equal, and a positive integer if the receiver is greater than the argument.
Rather than overload the meaning of integers, Lean has a built-in inductive type that describes these three possibilities:</p>
<pre><code class="language-lean">inductive Ordering where
| lt
| eq
| gt
</code></pre>
<p>The <code>Ord</code> type class can be overloaded to produce these comparisons.
For <code>Pos</code>, an implementation can be:</p>
<pre><code class="language-lean">def Pos.comp : Pos → Pos → Ordering
  | Pos.one, Pos.one =&gt; Ordering.eq
  | Pos.one, Pos.succ _ =&gt; Ordering.lt
  | Pos.succ _, Pos.one =&gt; Ordering.gt
  | Pos.succ n, Pos.succ k =&gt; comp n k

instance : Ord Pos where
  compare := Pos.comp
</code></pre>
<p>In situations where <code>compareTo</code> would be the right approach in Java, use <code>Ord.compare</code> in Lean.</p>
<h2 id="hashing"><a class="header" href="#hashing">Hashing</a></h2>
<p>Java and C# have <code>hashCode</code> and <code>GetHashCode</code> methods, respectively, that compute a hash of a value for use in data structures such as hash tables.
The Lean equivalent is a type class called <code>Hashable</code>:</p>
<pre><code class="language-lean">class Hashable (α : Type) where
  hash : α → UInt64
</code></pre>
<p>If two values are considered equal according to a <code>BEq</code> instance for their type, then they should have the same hashes.
In other words, if <code>x == y</code> then <code>hash x == hash y</code>.
If <code>x ≠ y</code>, then <code>hash x</code> won't necessarily differ from <code>hash y</code> (after all, there are infinitely more <code>Nat</code> values than there are <code>UInt64</code> values), but data structures built on hashing will have better performance if unequal values are likely to have unequal hashes.
This is the same expectation as in Java and C#.</p>
<p>The standard library contains a function <code>mixHash</code> with type <code>UInt64 → UInt64 → UInt64</code> that can be used to combine hashes for different fields for a constructor.
A reasonable hash function for an inductive datatype can be written by assigning a unique number to each constructor, and then mixing that number with the hashes of each field.
For example, a <code>Hashable</code> instance for <code>Pos</code> can be written:</p>
<pre><code class="language-lean">def hashPos : Pos → UInt64
  | Pos.one =&gt; 0
  | Pos.succ n =&gt; mixHash 1 (hashPos n)

instance : Hashable Pos where
  hash := hashPos
</code></pre>
<p><code>Hashable</code> instances for polymorphic types can use recursive instance search.
Hashing a <code>NonEmptyList α</code> is only possible when <code>α</code> can be hashed:</p>
<pre><code class="language-lean">instance [Hashable α] : Hashable (NonEmptyList α) where
  hash xs := mixHash (hash xs.head) (hash xs.tail)
</code></pre>
<p>Binary trees use both recursion and recursive instance search in the implementations of <code>BEq</code> and <code>Hashable</code>:</p>
<pre><code class="language-lean">inductive BinTree (α : Type) where
  | leaf : BinTree α
  | branch : BinTree α → α → BinTree α → BinTree α

def eqBinTree [BEq α] : BinTree α → BinTree α → Bool
  | BinTree.leaf, BinTree.leaf =&gt;
    true
  | BinTree.branch l x r, BinTree.branch l2 x2 r2 =&gt;
    x == x2 &amp;&amp; eqBinTree l l2 &amp;&amp; eqBinTree r r2
  | _, _ =&gt;
    false

instance [BEq α] : BEq (BinTree α) where
  beq := eqBinTree

def hashBinTree [Hashable α] : BinTree α → UInt64
  | BinTree.leaf =&gt;
    0
  | BinTree.branch left x right =&gt;
    mixHash 1 (mixHash (hashBinTree left) (mixHash (hash x) (hashBinTree right)))

instance [Hashable α] : Hashable (BinTree α) where
  hash := hashBinTree
</code></pre>
<h2 id="deriving-standard-classes"><a class="header" href="#deriving-standard-classes">Deriving Standard Classes</a></h2>
<p>Instance of classes like <code>BEq</code> and <code>Hashable</code> are often quite tedious to implement by hand.
Lean includes a feature called <em>instance deriving</em> that allows the compiler to automatically construct well-behaved instances of many type classes.
In fact, the <code>deriving Repr</code> phrase in the definition of <code>Point</code> in the <a href="type-classes/../getting-to-know/structures.html">section on structures</a> is an example of instance deriving.</p>
<p>Instances can be derived in two ways.
The first can be used when defining a structure or inductive type.
In this case, add <code>deriving</code> to the end of the type declaration followed by the names of the classes for which instances should be derived.
For a type that is already defined, a standalone <code>deriving</code> command can be used.
Write <code>deriving instance C1, C2, ... for T</code> to derive instances of <code>C1, C2, ...</code> for the type <code>T</code> after the fact.</p>
<p><code>BEq</code> and <code>Hashable</code> instances can be derived for <code>Pos</code> and <code>NonEmptyList</code> using a very small amount of code:</p>
<pre><code class="language-lean">deriving instance BEq, Hashable for Pos
deriving instance BEq, Hashable, Repr for NonEmptyList
</code></pre>
<p>Instances can be derived for at least the following classes:</p>
<ul>
<li><code>Inhabited</code></li>
<li><code>BEq</code></li>
<li><code>Repr</code></li>
<li><code>Hashable</code></li>
<li><code>Ord</code></li>
</ul>
<p>In some cases, however, the derived <code>Ord</code> instance may not produce precisely the ordering desired in an application.
When this is the case, it's fine to write an <code>Ord</code> instance by hand.
The collection of classes for which instances can be derived can be extended by advanced users of Lean.</p>
<p>Aside from the clear advantages in programmer productivity and code readability, deriving instances also makes code easier to maintain, because the instances are updated as the definitions of types evolve.
Changesets involving updates to datatypes are easier to read without line after line of formulaic modifications to equality tests and hash computation.</p>
<h2 id="appending"><a class="header" href="#appending">Appending</a></h2>
<p>Many datatypes have some sort of append operator.
In Lean, appending two values is overloaded with the type class <code>HAppend</code>, which is a heterogeneous operation like that used for arithmetic operations:</p>
<pre><code class="language-lean">class HAppend (α : Type) (β : Type) (γ : outParam Type) where
  hAppend : α → β → γ
</code></pre>
<p>The syntax <code>xs ++ ys</code> desugars to <code>HAppend.hAppend xs ys</code>.
For homogeneous cases, it's enough to implement an instance of <code>Append</code>, which follows the usual pattern:</p>
<pre><code class="language-lean">instance : Append (NonEmptyList α) where
  append xs ys :=
    { head := xs.head, tail := xs.tail ++ ys.head :: ys.tail }
</code></pre>
<p>After defining the above instance,</p>
<pre><code class="language-lean">#eval idahoSpiders ++ idahoSpiders
</code></pre>
<p>has the following output:</p>
<pre><code class="language-output info">{ head := &quot;Banded Garden Spider&quot;,
tail := [&quot;Long-legged Sac Spider&quot;,
         &quot;Wolf Spider&quot;,
         &quot;Hobo Spider&quot;,
         &quot;Cat-faced Spider&quot;,
         &quot;Banded Garden Spider&quot;,
         &quot;Long-legged Sac Spider&quot;,
         &quot;Wolf Spider&quot;,
         &quot;Hobo Spider&quot;,
         &quot;Cat-faced Spider&quot;] }
</code></pre>
<p>Similarly, a definition of <code>HAppend</code> allows non-empty lists to be appended to ordinary lists:</p>
<pre><code class="language-lean">instance : HAppend (NonEmptyList α) (List α) (NonEmptyList α) where
  hAppend xs ys :=
    { head := xs.head, tail := xs.tail ++ ys }
</code></pre>
<p>With this instance available,</p>
<pre><code class="language-lean">#eval idahoSpiders ++ [&quot;Trapdoor Spider&quot;]
</code></pre>
<p>results in</p>
<pre><code class="language-output info">{ head := &quot;Banded Garden Spider&quot;,
  tail := [&quot;Long-legged Sac Spider&quot;, &quot;Wolf Spider&quot;, &quot;Hobo Spider&quot;, &quot;Cat-faced Spider&quot;, &quot;Trapdoor Spider&quot;] }
</code></pre>
<h2 id="functors"><a class="header" href="#functors">Functors</a></h2>
<p>A polymorphic type is a <em>functor</em> if it has an overload for a function named <code>map</code> that transforms every element contained in it by a function.
While most languages use this terminology, C#'s equivalent to <code>map</code> is called <code>System.Linq.Enumerable.Select</code>.
For example, mapping a function over a list constructs a new list in which each entry from the starting list has been replaced by the result of the function on that entry.
Mapping a function <code>f</code> over an <code>Option</code> leaves <code>none</code> untouched, and replaces <code>some x</code> with <code>some (f x)</code>.</p>
<p>Here are some examples of functors and how their <code>Functor</code> instances overload <code>map</code>:</p>
<ul>
<li><code>Functor.map (· + 5) [1, 2, 3]</code> evaluates to <code>[6, 7, 8]</code></li>
<li><code>Functor.map toString (some (List.cons 5 List.nil))</code> evaluates to <code>some &quot;[5]&quot;</code></li>
<li><code>Functor.map List.reverse [[1, 2, 3], [4, 5, 6]]</code> evaluates to <code>[[3, 2, 1], [6, 5, 4]]</code></li>
</ul>
<p>Because <code>Functor.map</code> is a bit of a long name for this common operation, Lean also provides an infix operator for mapping a function, namely <code>&lt;$&gt;</code>.
The prior examples can be rewritten as follows:</p>
<ul>
<li><code>(· + 5) &lt;$&gt; [1, 2, 3]</code> evaluates to <code>[6, 7, 8]</code></li>
<li><code>toString &lt;$&gt; (some (List.cons 5 List.nil))</code> evaluates to <code>some &quot;[5]&quot;</code></li>
<li><code>List.reverse &lt;$&gt; [[1, 2, 3], [4, 5, 6]]</code> evaluates to <code>[[3, 2, 1], [6, 5, 4]]</code></li>
</ul>
<p>An instance of <code>Functor</code> for <code>NonEmptyList</code> requires specifying the <code>map</code> function.</p>
<pre><code class="language-lean">instance : Functor NonEmptyList where
  map f xs := { head := f xs.head, tail := f &lt;$&gt; xs.tail }
</code></pre>
<p>Here, <code>map</code> uses the <code>Functor</code> instance for <code>List</code> to map the function over the tail.
This instance is defined for <code>NonEmptyList</code> rather than for <code>NonEmptyList α</code> because the argument type <code>α</code> plays no role in resolving the type class.
A <code>NonEmptyList</code> can have a function mapped over it <em>no matter what the type of entries is</em>.
If <code>α</code> were a parameter to the class, then it would be possible to make versions of <code>Functor</code> that only worked for <code>NonEmptyList Nat</code>, but part of being a functor is that <code>map</code> works for any entry type.</p>
<p>Here is an instance of <code>Functor</code> for <code>PPoint</code>:</p>
<pre><code class="language-lean">instance : Functor PPoint where
  map f p := { x := f p.x, y := f p.y }
</code></pre>
<p>In this case, <code>f</code> has been applied to both <code>x</code> and <code>y</code>.</p>
<p>Even when the type contained in a functor is itself a functor, mapping a function only goes down one layer.
That is, when using <code>map</code> on a <code>NonEmptyList (PPoint Nat)</code>, the function being mapped should take <code>PPoint Nat</code> as its argument rather than <code>Nat</code>.</p>
<p>The definition of the <code>Functor</code> class uses one more language feature that has not yet been discussed: default method definitions.
Normally, a class will specify some minimal set of overloadable operations that make sense together, and then use polymorphic functions with instance implicit arguments that build on the overloaded operations to provide a larger library of features.
For example, the function <code>concat</code> can concatenate any non-empty list whose entries are appendable:</p>
<pre><code class="language-lean">def concat [Append α] (xs : NonEmptyList α) : α :=
  let rec catList (start : α) : List α → α
    | [] =&gt; start
    | (z :: zs) =&gt; catList (start ++ z) zs
  catList xs.head xs.tail
</code></pre>
<p>However, for some classes, there are operations that can be more efficiently implemented with knowledge of the internals of a datatype.</p>
<p>In these cases, a default method definition can be provided.
A default method definition provides a default implementation of a method in terms of the other methods.
However, instance implementors may choose to override this default with something more efficient.
Default method definitions contain <code>:=</code> in a <code>class</code> definition.</p>
<p>In the case of <code>Functor</code>, some types have a more efficient way of implementing <code>map</code> when the function being mapped ignores its argument.
Functions that ignore their arguments are called <em>constant functions</em> because they always return the same value.
Here is the definition of <code>Functor</code>, in which <code>mapConst</code> has a default implementation:</p>
<pre><code class="language-lean">class Functor (f : Type → Type) where
  map : {α β : Type} → (α → β) → f α → f β

  mapConst {α β : Type} (x : α) (coll : f β) : f α :=
    map (fun _ =&gt; x) coll
</code></pre>
<p>Just as a <code>Hashable</code> instance that doesn't respect <code>BEq</code> is buggy, a <code>Functor</code> instance that moves around the data as it maps the function is also buggy.
For example, a buggy <code>Functor</code> instance for <code>List</code> might throw away its argument and always return the empty list, or it might reverse the list.
A bad instance for <code>PPoint</code> might place <code>f x</code> in both the <code>x</code> and the <code>y</code> fields.
Specifically, <code>Functor</code> instances should follow two rules:</p>
<ol>
<li>Mapping the identity function should result in the original argument.</li>
<li>Mapping two composed functions should have the same effect as composing their mapping.</li>
</ol>
<p>More formally, the first rule says that <code>id &lt;$&gt; x</code> equals <code>x</code>.
The second rule says that <code>map (fun y =&gt; f (g y)) x</code> equals <code>map f (map g x)</code>.
The composition <code>fun y =&gt; f (g y)</code> can also be written <code>f ∘ g</code>.
These rules prevent implementations of <code>map</code> that move the data around or delete some of it.</p>
<h2 id="messages-you-may-meet-4"><a class="header" href="#messages-you-may-meet-4">Messages You May Meet</a></h2>
<p>Lean is not able to derive instances for all classes.
For example, the code</p>
<pre><code class="language-lean">deriving instance ToString for NonEmptyList
</code></pre>
<p>results in the following error:</p>
<pre><code class="language-output error">default handlers have not been implemented yet, class: 'ToString' types: [NonEmptyList]
</code></pre>
<p>Invoking <code>deriving instance</code> causes Lean to consult an internal table of code generators for type class instances.
If the code generator is found, then it is invoked on the provided type to create the instance.
This message, however, means that no code generator was found for <code>ToString</code>.</p>
<h2 id="exercises-8"><a class="header" href="#exercises-8">Exercises</a></h2>
<ul>
<li>Write an instance of <code>HAppend (List α) (NonEmptyList α) (NonEmptyList α)</code> and test it.</li>
<li>Implement a <code>Functor</code> instance for the binary tree datatype.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="coercions"><a class="header" href="#coercions">Coercions</a></h1>
<p>In mathematics, it is common to use the same symbol to stand for different aspects of some object in different contexts.
For example, if a ring is referred to in a context where a set is expected, then it is understood that the ring's underlying set is what's intended.
In programming languages, it is common to have rules to automatically translate values of one type into values of another type.
For instance, Java allows a <code>byte</code> to be automatically promoted to an <code>int</code>, and Kotlin allows a non-nullable type to be used in a context that expects a nullable version of the type.</p>
<p>In Lean, both purposes are served by a mechanism called <em>coercions</em>.
When Lean encounters an expression of one type in a context that expects a different type, it will attempt to coerce the expression before reporting a type error.
Unlike Java, C, and Kotlin, the coercions are extensible by defining instances of type classes.</p>
<h2 id="positive-numbers-1"><a class="header" href="#positive-numbers-1">Positive Numbers</a></h2>
<p>For example, every positive number corresponds to a natural number.
The function <code>Pos.toNat</code> that was defined earlier converts a <code>Pos</code> to the corresponding <code>Nat</code>:</p>
<pre><code class="language-lean">def Pos.toNat : Pos → Nat
  | Pos.one =&gt; 1
  | Pos.succ n =&gt; n.toNat + 1
</code></pre>
<p>The function <code>List.drop</code>, with type <code>{α : Type} → Nat → List α → List α</code>, removes a prefix of a list.
Applying <code>List.drop</code> to a <code>Pos</code>, however, leads to a type error:</p>
<pre><code class="language-lean">[1, 2, 3, 4].drop (2 : Pos)
</code></pre>
<pre><code class="language-output error">application type mismatch
  List.drop 2
argument
  2
has type
  Pos : Type
but is expected to have type
  Nat : Type
</code></pre>
<p>Because the author of <code>List.drop</code> did not make it a method of a type class, it can't be overridden by defining a new instance.</p>
<p>The type class <code>Coe</code> describes overloaded ways of coercing from one type to another:</p>
<pre><code class="language-lean">class Coe (α : Type) (β : Type) where
  coe : α → β
</code></pre>
<p>An instance of <code>Coe Pos Nat</code> is enough to allow the prior code to work:</p>
<pre><code class="language-lean">instance : Coe Pos Nat where
  coe x := x.toNat

#eval [1, 2, 3, 4].drop (2 : Pos)
</code></pre>
<pre><code class="language-output info">[3, 4]
</code></pre>
<p>Using <code>#check</code> shows the result of the instance search that was used behind the scenes:</p>
<pre><code class="language-lean">#check [1, 2, 3, 4].drop (2 : Pos)
</code></pre>
<pre><code class="language-output info">List.drop (Pos.toNat 2) [1, 2, 3, 4] : List Nat
</code></pre>
<h2 id="chaining-coercions"><a class="header" href="#chaining-coercions">Chaining Coercions</a></h2>
<p>When searching for coercions, Lean will attempt to assemble a coercion out of a chain of smaller coercions.
For example, there is already a coercion from <code>Nat</code> to <code>Int</code>.
Because of that instance, combined with the <code>Coe Pos Nat</code> instance, the following code is accepted:</p>
<pre><code class="language-lean">def oneInt : Int := Pos.one
</code></pre>
<p>This definition uses two coercions: from <code>Pos</code> to <code>Nat</code>, and then from <code>Nat</code> to <code>Int</code>.</p>
<p>The Lean compiler does not get stuck in the presence of circular coercions.
For example, even if two types <code>A</code> and <code>B</code> can be coerced to one another, their mutual coercions can be used to find a path:</p>
<pre><code class="language-lean">inductive A where
  | a

inductive B where
  | b

instance : Coe A B where
  coe _ := B.b

instance : Coe B A where
  coe _ := A.a

instance : Coe Unit A where
  coe _ := A.a

def coercedToB : B := ()
</code></pre>
<p>Remember: the double parentheses <code>()</code> is short for the constructor <code>Unit.unit</code>.
After deriving a <code>Repr B</code> instance,</p>
<pre><code class="language-lean">#eval coercedToB
</code></pre>
<p>results in:</p>
<pre><code class="language-output info">B.b
</code></pre>
<p>The <code>Option</code> type can be used similarly to nullable types in C# and Kotlin: the <code>none</code> constructor represents the absence of a value.
The Lean standard library defines a coercion from any type <code>α</code> to <code>Option α</code> that wraps the value in <code>some</code>.
This allows option types to be used in a manner even more similar to nullable types, because <code>some</code> can be omitted.
For instance, the function <code>List.getLast?</code> that finds the last entry in a list can be written without a <code>some</code> around the return value <code>x</code>:</p>
<pre><code class="language-lean">def List.last? : List α → Option α
  | [] =&gt; none
  | [x] =&gt; x
  | _ :: x :: xs =&gt; last? (x :: xs)
</code></pre>
<p>Instance search finds the coercion, and inserts a call to <code>coe</code>, which wraps the argument in <code>some</code>.
These coercions can be chained, so that nested uses of <code>Option</code> don't require nested <code>some</code> constructors:</p>
<pre><code class="language-lean">def perhapsPerhapsPerhaps : Option (Option (Option String)) :=
  &quot;Please don't tell me&quot;
</code></pre>
<p>Coercions are only activated automatically when Lean encounters a mismatch between an inferred type and a type that is imposed from the rest of the program.
In cases with other errors, coercions are not activated.
For example, if the error is that an instance is missing, coercions will not be used:</p>
<pre><code class="language-lean">def perhapsPerhapsPerhapsNat : Option (Option (Option Nat)) :=
  392
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  OfNat (Option (Option (Option Nat))) 392
</code></pre>
<p>This can be worked around by manually indicating the desired type to be used for <code>OfNat</code>:</p>
<pre><code class="language-lean">def perhapsPerhapsPerhapsNat : Option (Option (Option Nat)) :=
  (392 : Nat)
</code></pre>
<p>Additionally, coercions can be manually inserted using an up arrow:</p>
<pre><code class="language-lean">def perhapsPerhapsPerhapsNat : Option (Option (Option Nat)) :=
  ↑(392 : Nat)
</code></pre>
<p>In some cases, this can be used to ensure that Lean finds the right instances.
It can also make the programmer's intentions more clear.</p>
<h2 id="non-empty-lists-and-dependent-coercions"><a class="header" href="#non-empty-lists-and-dependent-coercions">Non-Empty Lists and Dependent Coercions</a></h2>
<p>An instance of <code>Coe α β</code> makes sense when the type <code>β</code> has a value that can represent each value from the type <code>α</code>.
Coercing from <code>Nat</code> to <code>Int</code> makes sense, because the type <code>Int</code> contains all the natural numbers.
Similarly, a coercion from non-empty lists to ordinary lists makes sense because the <code>List</code> type can represent every non-empty list:</p>
<pre><code class="language-lean">instance : Coe (NonEmptyList α) (List α) where
  coe
    | { head := x, tail := xs } =&gt; x :: xs
</code></pre>
<p>This allows non-empty lists to be used with the entire <code>List</code> API.</p>
<p>On the other hand, it is impossible to write an instance of <code>Coe (List α) (NonEmptyList α)</code>, because there's no non-empty list that can represent the empty list.
This limitation can be worked around by using another version of coercions, which are called <em>dependent coercions</em>.
Dependent coercions can be used when the ability to coerce from one type to another depends on which particular value is being coerced.
Just as the <code>OfNat</code> type class takes the particular <code>Nat</code> being overloaded as a parameter, dependent coercion takes the value being coerced as a parameter:</p>
<pre><code class="language-lean">class CoeDep (α : Type) (x : α) (β : Type) where
  coe : β
</code></pre>
<p>This is a chance to select only certain values, either by imposing further type class constraints on the value or by writing certain constructors directly.
For example, any <code>List</code> that is not actually empty can be coerced to a <code>NonEmptyList</code>:</p>
<pre><code class="language-lean">instance : CoeDep (List α) (x :: xs) (NonEmptyList α) where
  coe := { head := x, tail := xs }
</code></pre>
<h2 id="coercing-to-types"><a class="header" href="#coercing-to-types">Coercing to Types</a></h2>
<p>In mathematics, it is common to have a concept that consists of a set equipped with additional structure.
For example, a monoid is some set <em>S</em>, an element <em>s</em> of <em>S</em>, and an associative binary operator on <em>S</em>, such that <em>s</em> is neutral on the left and right of the operator.
<em>S</em> is referred to as the &quot;carrier set&quot; of the monoid.
The natural numbers with zero and addition form a monoid, because addition is associative and adding zero to any number is the identity.
Similarly, the natural numbers with one and multiplication also form a monoid.
Monoids are also widely used in functional programming: lists, the empty list, and the append operator form a monoid, as do strings, the empty string, and string append:</p>
<pre><code class="language-lean">structure Monoid where
  Carrier : Type
  neutral : Carrier
  op : Carrier → Carrier → Carrier

def natMulMonoid : Monoid :=
  { Carrier := Nat, neutral := 1, op := (· * ·) }

def natAddMonoid : Monoid :=
  { Carrier := Nat, neutral := 0, op := (· + ·) }

def stringMonoid : Monoid :=
  { Carrier := String, neutral := &quot;&quot;, op := String.append }

def listMonoid (α : Type) : Monoid :=
  { Carrier := List α, neutral := [], op := List.append }
</code></pre>
<p>Given a monoid, it is possible to write the <code>foldMap</code> function that, in a single pass, transforms the entries in a list into a monoid's carrier set and then combines them using the monoid's operator.
Because monoids have a neutral element, there is a natural result to return when the list is empty, and because the operator is associative, clients of the function don't have to care whether the recursive function combines elements from left to right or from right to left.</p>
<pre><code class="language-lean">def foldMap (M : Monoid) (f : α → M.Carrier) (xs : List α) : M.Carrier :=
  let rec go (soFar : M.Carrier) : List α → M.Carrier
    | [] =&gt; soFar
    | y :: ys =&gt; go (M.op soFar (f y)) ys
  go M.neutral xs
</code></pre>
<p>Even though a monoid consists of three separate pieces of information, it is common to just refer to the monoid's name in order to refer to its set.
Instead of saying &quot;Let A be a monoid and let <em>x</em> and <em>y</em> be elements of its carrier set&quot;, it is common to say &quot;Let <em>A</em> be a monoid and let <em>x</em> and <em>y</em> be elements of <em>A</em>&quot;.
This practice can be encoded in Lean by defining a new kind of coercion, from the monoid to its carrier set.</p>
<p>The <code>CoeSort</code> class is just like the <code>Coe</code> class, with the exception that the target of the coercion must be a <em>sort</em>, namely <code>Type</code> or <code>Prop</code>.
The term <em>sort</em> in Lean refers to these types that classify other types—<code>Type</code> classifies types that themselves classify data, and <code>Prop</code> classifies propositions that themselves classify evidence of their truth.
Just as <code>Coe</code> is checked when a type mismatch occurs, <code>CoeSort</code> is used when something other than a sort is provided in a context where a sort would be expected.</p>
<p>The coercion from a monoid into its carrier set extracts the carrier:</p>
<pre><code class="language-lean">instance : CoeSort Monoid Type where
  coe m := m.Carrier
</code></pre>
<p>With this coercion, the type signatures become less bureaucratic:</p>
<pre><code class="language-lean">def foldMap (M : Monoid) (f : α → M) (xs : List α) : M :=
  let rec go (soFar : M) : List α → M
    | [] =&gt; soFar
    | y :: ys =&gt; go (M.op soFar (f y)) ys
  go M.neutral xs
</code></pre>
<p>Another useful example of <code>CoeSort</code> is used to bridge the gap between <code>Bool</code> and <code>Prop</code>.
As discussed in <a href="type-classes/standard-classes.html#equality-and-ordering">the section on ordering and equality</a>, Lean's <code>if</code> expression expects the condition to be a decidable proposition rather than a <code>Bool</code>.
Programs typically need to be able to branch based on Boolean values, however.
Rather than have two kinds of <code>if</code> expression, the Lean standard library defines a coercion from <code>Bool</code> to the proposition that the <code>Bool</code> in question is equal to <code>true</code>:</p>
<pre><code class="language-lean">instance : CoeSort Bool Prop where
  coe b := b = true
</code></pre>
<p>In this case, the sort in question is <code>Prop</code> rather than <code>Type</code>.</p>
<h2 id="coercing-to-functions"><a class="header" href="#coercing-to-functions">Coercing to Functions</a></h2>
<p>Many datatypes that occur regularly in programming consist of a function along with some extra information about it.
For example, a function might be accompanied by a name to show in logs or by some configuration data.
Additionally, putting a type in a field of a structure, similarly to the <code>Monoid</code> example, can make sense in contexts where there is more than one way to implement an operation and more manual control is needed than type classes would allow.
For example, the specific details of values emitted by a JSON serializer may be important because another application expects a particular format.
Sometimes, the function itself may be derivable from just the configuration data.</p>
<p>A type class called <code>CoeFun</code> can transform values from non-function types to function types.
<code>CoeFun</code> has two parameters: the first is the type whose values should be transformed into functions, and the second is an output parameter that determines exactly which function type is being targeted.</p>
<pre><code class="language-lean">class CoeFun (α : Type) (makeFunctionType : outParam (α → Type)) where
  coe : (x : α) → makeFunctionType x
</code></pre>
<p>The second parameter is itself a function that computes a type.
In Lean, types are first-class and can be passed to functions or returned from them, just like anything else.</p>
<p>For example, a function that adds a constant amount to its argument can be represented as a wrapper around the amount to add, rather than by defining an actual function:</p>
<pre><code class="language-lean">structure Adder where
  howMuch : Nat
</code></pre>
<p>A function that adds five to its argument has a <code>5</code> in the <code>howMuch</code> field:</p>
<pre><code class="language-lean">def add5 : Adder := ⟨5⟩
</code></pre>
<p>This <code>Adder</code> type is not a function, and applying it to an argument results in an error:</p>
<pre><code class="language-lean">#eval add5 3
</code></pre>
<pre><code class="language-output error">function expected at
  add5
term has type
  Adder
</code></pre>
<p>Defining a <code>CoeFun</code> instance causes Lean to transform the adder into a function with type <code>Nat → Nat</code>:</p>
<pre><code class="language-lean">instance : CoeFun Adder (fun _ =&gt; Nat → Nat) where
  coe a := (· + a.howMuch)

#eval add5 3
</code></pre>
<pre><code class="language-output info">8
</code></pre>
<p>Because all <code>Adder</code>s should be transformed into <code>Nat → Nat</code> functions, the argument to <code>CoeFun</code>'s second parameter was ignored.</p>
<p>When the value itself is needed to determine the right function type, then <code>CoeFun</code>'s second parameter is no longer ignored.
For example, given the following representation of JSON values:</p>
<pre><code class="language-lean">inductive JSON where
  | true : JSON
  | false : JSON
  | null : JSON
  | string : String → JSON
  | number : Float → JSON
  | object : List (String × JSON) → JSON
  | array : List JSON → JSON
deriving Repr
</code></pre>
<p>a JSON serializer is a structure that tracks the type it knows how to serialize along with the serialization code itself:</p>
<pre><code class="language-lean">structure Serializer where
  Contents : Type
  serialize : Contents → JSON
</code></pre>
<p>A serializer for strings need only wrap the provided string in the <code>JSON.string</code> constructor:</p>
<pre><code class="language-lean">def Str : Serializer :=
  { Contents := String,
    serialize := JSON.string
  }
</code></pre>
<p>Viewing JSON serializers as functions that serialize their argument requires extracting the inner type of serializable data:</p>
<pre><code class="language-lean">instance : CoeFun Serializer (fun s =&gt; s.Contents → JSON) where
  coe s := s.serialize
</code></pre>
<p>Given this instance, a serializer can be applied directly to an argument:</p>
<pre><code class="language-lean">def buildResponse (title : String) (R : Serializer) (record : R.Contents) : JSON :=
  JSON.object [
    (&quot;title&quot;, JSON.string title),
    (&quot;status&quot;, JSON.number 200),
    (&quot;record&quot;, R record)
  ]
</code></pre>
<p>The serializer can be passed directly to <code>buildResponse</code>:</p>
<pre><code class="language-lean">#eval buildResponse &quot;Functional Programming in Lean&quot; Str &quot;Programming is fun!&quot;
</code></pre>
<pre><code class="language-output info">JSON.object
  [(&quot;title&quot;, JSON.string &quot;Functional Programming in Lean&quot;),
   (&quot;status&quot;, JSON.number 200.000000),
   (&quot;record&quot;, JSON.string &quot;Programming is fun!&quot;)]
</code></pre>
<h3 id="aside-json-as-a-string"><a class="header" href="#aside-json-as-a-string">Aside: JSON as a String</a></h3>
<p>It can be a bit difficult to understand JSON when encoded as Lean objects.
To help make sure that the serialized response was what was expected, it can be convenient to write a simple converter from <code>JSON</code> to <code>String</code>.
The first step is to simplify the display of numbers.
<code>JSON</code> doesn't distinguish between integers and floating point numbers, and the type <code>Float</code> is used to represent both.
In Lean, <code>Float.toString</code> includes a number of trailing zeros:</p>
<pre><code class="language-lean">#eval (5 : Float).toString
</code></pre>
<pre><code class="language-output info">&quot;5.000000&quot;
</code></pre>
<p>The solution is to write a little function that cleans up the presentation by dropping all trailing zeros, followed by a trailing decimal point:</p>
<pre><code class="language-lean">def dropDecimals (numString : String) : String :=
  if numString.contains '.' then
    let noTrailingZeros := numString.dropRightWhile (· == '0')
    noTrailingZeros.dropRightWhile (· == '.')
  else numString
</code></pre>
<p>With this definition, <code>#eval dropDecimals (5 : Float).toString</code> yields <code>&quot;5&quot;</code>, and <code>#eval dropDecimals (5.2 : Float).toString</code> yields <code>&quot;5.2&quot;</code>.</p>
<p>The next step is to define a helper function to append a list of strings with a separator in between them:</p>
<pre><code class="language-lean">def String.separate (sep : String) (strings : List String) : String :=
  match strings with
  | [] =&gt; &quot;&quot;
  | x :: xs =&gt; String.join (x :: xs.map (sep ++ ·))
</code></pre>
<p>This function is useful to account for comma-separated elements in JSON arrays and objects.
<code>#eval &quot;, &quot;.separate [&quot;1&quot;, &quot;2&quot;]</code> yields <code>&quot;1, 2&quot;</code>, <code>#eval &quot;, &quot;.separate [&quot;1&quot;]</code> yields <code>&quot;1&quot;</code>, and <code>#eval &quot;, &quot;.separate []</code> yields <code>&quot;&quot;</code>.</p>
<p>Finally, a string escaping procedure is needed for JSON strings, so that the Lean string containing <code>&quot;Hello!&quot;</code> can be output as <code>&quot;\&quot;Hello!\&quot;&quot;</code>.
Happily, Lean contains a function for escaping JSON strings already, called <code>Lean.Json.escape</code>.</p>
<p>The function that emits a string from a <code>JSON</code> value is declared <code>partial</code> because Lean cannot see that it terminates.
This is because recursive calls to <code>asString</code> occur in functions that are being applied by <code>List.map</code>, and this pattern of recursion is complicated enough that Lean cannot see that the recursive calls are actually being performed on smaller values.
In an application that just needs to produce JSON strings and doesn't need to mathematically reason about the process, having the function be <code>partial</code> is not likely to cause problems.</p>
<pre><code class="language-lean">partial def JSON.asString (val : JSON) : String :=
  match val with
  | true =&gt; &quot;true&quot;
  | false =&gt; &quot;false&quot;
  | null =&gt; &quot;null&quot;
  | string s =&gt; &quot;\&quot;&quot; ++ Lean.Json.escape s ++ &quot;\&quot;&quot;
  | number n =&gt; dropDecimals n.toString
  | object members =&gt;
    let memberToString mem :=
      &quot;\&quot;&quot; ++ Lean.Json.escape mem.fst ++ &quot;\&quot;: &quot; ++ asString mem.snd
    &quot;{&quot; ++ &quot;, &quot;.separate (members.map memberToString) ++ &quot;}&quot;
  | array elements =&gt;
    &quot;[&quot; ++ &quot;, &quot;.separate (elements.map asString) ++ &quot;]&quot;
</code></pre>
<p>With this definition, the output of serialization is easier to read:</p>
<pre><code class="language-lean">#eval (buildResponse &quot;Functional Programming in Lean&quot; Str &quot;Programming is fun!&quot;).asString
</code></pre>
<pre><code class="language-output info">&quot;{\\&quot;title\\&quot;: \\&quot;Functional Programming in Lean\\&quot;, \\&quot;status\\&quot;: 200, \\&quot;record\\&quot;: \\&quot;Programming is fun!\\&quot;}&quot;
</code></pre>
<h2 id="messages-you-may-meet-5"><a class="header" href="#messages-you-may-meet-5">Messages You May Meet</a></h2>
<p>Natural number literals are overloaded with the <code>OfNat</code> type class.
Because coercions fire in cases where types don't match, rather than in cases of missing instances, a missing <code>OfNat</code> instance for a type does not cause a coercion from <code>Nat</code> to be applied:</p>
<pre><code class="language-lean">def perhapsPerhapsPerhapsNat : Option (Option (Option Nat)) :=
  392
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  OfNat (Option (Option (Option Nat))) 392
</code></pre>
<h2 id="design-considerations"><a class="header" href="#design-considerations">Design Considerations</a></h2>
<p>Coercions are a powerful tool that should be used responsibly.
On the one hand, they can allow an API to naturally follow the everyday rules of the domain being modeled.
This can be the difference between a bureaucratic mess of manual conversion functions and a clear program.
As Abelson and Sussman wrote in the preface to <em>Structure and Interpretation of Computer Programs</em> (MIT Press, 1996),</p>
<blockquote>
<p>Programs must be written for people to read, and only incidentally for machines to execute.</p>
</blockquote>
<p>Coercions, used wisely, are a valuable means of achieving readable code that can serve as the basis for communication with domain experts.
APIs that rely heavily on coercions have a number of important limitations, however.
Think carefully about these limitations before using coercions in your own libraries.</p>
<p>First off, coercions are only applied in contexts where enough type information is available for Lean to know all of the types involved, because there are no output parameters in the coercion type classes. This means that a return type annotation on a function can be the difference between a type error and a successfully applied coercion.
For example, the coercion from non-empty lists to lists makes the following program work:</p>
<pre><code class="language-lean">def lastSpider : Option String :=
  List.getLast? idahoSpiders
</code></pre>
<p>On the other hand, if the type annotation is omitted, then the result type is unknown, so Lean is unable to find the coercion:</p>
<pre><code class="language-lean">def lastSpider :=
  List.getLast? idahoSpiders
</code></pre>
<pre><code class="language-output error">application type mismatch
  List.getLast? idahoSpiders
argument
  idahoSpiders
has type
  NonEmptyList String : Type
but is expected to have type
  List ?m.34580 : Type
</code></pre>
<p>More generally, when a coercion is not applied for some reason, the user receives the original type error, which can make it difficult to debug chains of coercions.</p>
<p>Finally, coercions are not applied in the context of field accessor notation.
This means that there is still an important difference between expressions that need to be coerced and those that don't, and this difference is visible to users of your API.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="additional-conveniences-2"><a class="header" href="#additional-conveniences-2">Additional Conveniences</a></h1>
<h2 id="constructor-syntax-for-instances"><a class="header" href="#constructor-syntax-for-instances">Constructor Syntax for Instances</a></h2>
<p>Behind the scenes, type classes are structure types and instances are values of these types.
The only differences are that Lean stores additional information about type classes, such as which parameters are output parameters, and that instances are registered for searching.
While values that have structure types are typically defined using either <code>⟨...⟩</code> syntax or with braces and fields, and instances are typically defined using <code>where</code>, both syntaxes work for both kinds of definition.</p>
<p>For example, a forestry application might represent trees as follows:</p>
<pre><code class="language-lean">structure Tree : Type where
  latinName : String
  commonNames : List String

def oak : Tree :=
  ⟨&quot;Quercus robur&quot;, [&quot;common oak&quot;, &quot;European oak&quot;]⟩

def birch : Tree :=
  { latinName := &quot;Betula pendula&quot;,
    commonNames := [&quot;silver birch&quot;, &quot;warty birch&quot;]
  }

def sloe : Tree where
  latinName := &quot;Prunus spinosa&quot;
  commonNames := [&quot;sloe&quot;, &quot;blackthorn&quot;]
</code></pre>
<p>All three syntaxes are equivalent.</p>
<p>Similarly, type class instances can be defined using all three syntaxes:</p>
<pre><code class="language-lean">class Display (α : Type) where
  displayName : α → String

instance : Display Tree :=
  ⟨Tree.latinName⟩

instance : Display Tree :=
  { displayName := Tree.latinName }

instance : Display Tree where
  displayName t := t.latinName
</code></pre>
<p>Generally speaking, the <code>where</code> syntax should be used for instances, and the curly-brace syntax should be used for structures.
The <code>⟨...⟩</code> syntax can be useful when emphasizing that a structure type is very much like a tuple in which the fields happen to be named, but the names are not important at the moment.
However, there are situations where it can make sense to use other alternatives.
In particular, a library might provide a function that constructs an instance value.
Placing a call to this function after <code>:=</code> in an instance declaration is the easiest way to use such a function.</p>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<p>When experimenting with Lean code, definitions can be more convenient to use than <code>#eval</code> or <code>#check</code> commands.
First off, definitions don't produce any output, which can help keep the reader's focus on the most interesting output.
Secondly, it's easiest to write most Lean programs by starting with a type signature, allowing Lean to provide more assistance and better error messages while writing the program itself.
On the other hand, <code>#eval</code> and <code>#check</code> are easiest to use in contexts where Lean is able to determine the type from the provided expression.
Thirdly, <code>#eval</code> cannot be used with expressions whose types don't have <code>ToString</code> or <code>Repr</code> instances, such as functions.
Finally, multi-step <code>do</code> blocks, <code>let</code>-expressions, and other syntactic forms that take multiple lines are particularly difficult to write with a type annotation in <code>#eval</code> or <code>#check</code>, simply because the required parenthesization can be difficult to predict.</p>
<p>To work around these issues, Lean supports the explicit indication of examples in a source file.
An example is like a definition without a name.
For instance, a non-empty list of birds commonly found in Copenhagen's green spaces can be written:</p>
<pre><code class="language-lean">example : NonEmptyList String :=
  { head := &quot;Sparrow&quot;,
    tail := [&quot;Duck&quot;, &quot;Swan&quot;, &quot;Magpie&quot;, &quot;Eurasian coot&quot;, &quot;Crow&quot;]
  }
</code></pre>
<p>Examples may define functions by accepting arguments:</p>
<pre><code class="language-lean">example (n : Nat) (k : Nat) : Bool :=
  n + k == k + n
</code></pre>
<p>While this creates a function behind the scenes, this function has no name and cannot be called.
Nonetheless, this is useful for demonstrating how a library can be used with arbitrary or unknown values of some given type.
In source files, <code>example</code> declarations are best paired with comments that explain how the example illustrates the concepts of the library.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-2"><a class="header" href="#summary-2">Summary</a></h1>
<h2 id="type-classes-and-overloading"><a class="header" href="#type-classes-and-overloading">Type Classes and Overloading</a></h2>
<p>Type classes are Lean's mechanism for overloading functions and operators.
A polymorphic function can be used with multiple types, but it behaves in the same manner no matter which type it is used with.
For example, a polymorphic function that appends two lists can be used no matter the type of the entries in the list, but it is unable to have different behavior depending on which particular type is found.
An operation that is overloaded with type classes, on the other hand, can also be used with multiple types.
However, each type requires its own implementation of the overloaded operation.
This means that the behavior can vary based on which type is provided.</p>
<p>A <em>type class</em> has a name, parameters, and a body that consists of a number of names with types.
The name is a way to refer to the overloaded operations, the parameters determine which aspects of the definitions can be overloaded, and the body provides the names and type signatures of the overloadable operations.
Each overloadable operation is called a <em>method</em> of the type class.
Type classes may provide default implementations of some methods in terms of the others, freeing implementors from defining each overload by hand when it is not needed.</p>
<p>An <em>instance</em> of a type class provides implementations of the methods for given parameters.
Instances may be polymorphic, in which case they can work for a variety of parameters, and they may optionally provide more specific implementations of default methods in cases where a more efficient version exists for some particular type.</p>
<p>Type class parameters are either <em>input parameters</em> (the default), or <em>output parameters</em> (indicated by an <code>outParam</code> modifier).
Lean will not begin searching for an instance until all input parameters are no longer metavariables, while output parameters may be solved while searching for instances.
Parameters to a type class need not be types—they may also be ordinary values.
The <code>OfNat</code> type class, used to overload natural number literals, takes the overloaded <code>Nat</code> itself as a parameter, which allows instances to restrict the allowed numbers.</p>
<p>Instances may be marked with a <code>@[default_instance]</code> attribute.
When an instance is a default instance, then it will be chosen as a fallback when Lean would otherwise fail to find an instance due to the presence of metavariables in the type.</p>
<h2 id="type-classes-for-common-syntax"><a class="header" href="#type-classes-for-common-syntax">Type Classes for Common Syntax</a></h2>
<p>Most infix operators in Lean are overridden with a type class.
For instance, the addition operator corresponds to a type class called <code>Add</code>.
Most of these operators have a corresponding heterogeneous version, in which the two arguments need not have the same type.
These heterogenous operators are overloaded using a version of the class whose name starts with <code>H</code>, such as <code>HAdd</code>.</p>
<p>Indexing syntax is overloaded using a type class called <code>GetElem</code>, which involves proofs.
<code>GetElem</code> has two output parameters, which are the type of elements to be extracted from the collection and a function that can be used to determine what counts as evidence that the index value is in bounds for the collection.
This evidence is described by a proposition, and Lean attempts to prove this proposition when array indexing is used.
When Lean is unable to check that list or array access operations are in bounds at compile time, the check can be deferred to run time by appending a <code>?</code> to the indexing operation.</p>
<h2 id="functors-1"><a class="header" href="#functors-1">Functors</a></h2>
<p>A functor is a polymorphic type that supports a mapping operation.
This mapping operation transforms all elements &quot;in place&quot;, changing no other structure.
For instance, lists are functors and the mapping operation may neither drop, duplicate, nor mix up entries in the list.</p>
<p>While functors are defined by having <code>map</code>, the <code>Functor</code> type class in Lean contains an additional default method that is responsible for mapping the constant function over a value, replacing all values whose type are given by polymorphic type variable with the same new value.
For some functors, this can be done more efficiently than traversing the entire structure.</p>
<h2 id="deriving-instances"><a class="header" href="#deriving-instances">Deriving Instances</a></h2>
<p>Many type classes have very standard implementations.
For instance, the Boolean equality class <code>BEq</code> is usually implemented by first checking whether both arguments are built with the same constructor, and then checking whether all their arguments are equal.
Instances for these classes can be created <em>automatically</em>.</p>
<p>When defining an inductive type or a structure, a <code>deriving</code> clause at the end of the declaration will cause instances to be created automatically.
Additionally, the <code>deriving instance ... for ...</code> command can be used outside of the definition of a datatype to cause an instance to be generated.
Because each class for which instances can be derived requires special handling, not all classes are derivable.</p>
<h2 id="coercions-1"><a class="header" href="#coercions-1">Coercions</a></h2>
<p>Coercions allow Lean to recover from what would normally be a compile-time error by inserting a call to a function that transforms data from one type to another.
For example, the coercion from any type <code>α</code> to the type <code>Option α</code> allows values to be written directly, rather than with the <code>some</code> constructor, making <code>Option</code> work more like nullable types from object-oriented languages.</p>
<p>There are multiple kinds of coercion.
They can recover from different kinds of errors, and they are represented by their own type classes.
The <code>Coe</code> class is used to recover from type errors.
When Lean has an expression of type <code>α</code> in a context that expects something with type <code>β</code>, Lean first attempts to string together a chain of coercions that can transform <code>α</code>s into <code>β</code>s, and only displays the error when this cannot be done.
The <code>CoeDep</code> class takes the specific value being coerced as an extra parameter, allowing either further type class search to be done on the value or allowing constructors to be used in the instance to limit the scope of the conversion.
The <code>CoeFun</code> class intercepts what would otherwise be a &quot;not a function&quot; error when compiling a function application, and allows the value in the function position to be transformed into an actual function if possible.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="monads"><a class="header" href="#monads">Monads</a></h1>
<p>In C# and Kotlin, the <code>?.</code> operator is a way to look up a property or call a method on a potentially-null value.
If the reciever is <code>null</code>, the whole expression is null.
Otherwise, the underlying non-<code>null</code> value receives the call.
Uses of <code>?.</code> can be chained, in which case the first <code>null</code> result terminates the chain of lookups.
Chaining null-checks like this is much more convenient than writing and maintaining deeply nested <code>if</code>s.</p>
<p>Similarly, exceptions are significantly more convenient than manually checking and propagating error codes.
At the same time, logging is easiest to accomplish by having a dedicated logging framework, rather than having each function return both its log results and its return value.
Chained null checks and exceptions typically require language designers to anticipate this use case, while logging frameworks typically make use of side effects to decouple code that logs from the accumulation of the logs.</p>
<p>All these features and more can be implemented in library code as instances of a common API called <code>Monad</code>.
Lean provides dedicated syntax that makes this API convenient to use, but can also get in the way of understanding what is going on behind the scenes.
This chapter begins with the nitty-gritty presentation of manually nesting null checks, and builds from there to the convenient, general API.
Please suspend your disbelief in the meantime.</p>
<h2 id="checking-for-none-dont-repeat-yourself"><a class="header" href="#checking-for-none-dont-repeat-yourself">Checking for <code>none</code>: Don't Repeat Yourself</a></h2>
<p>In Lean, pattern matching can be used to chain checks for null.
Getting the first entry from a list can just use the optional indexing notation:</p>
<pre><code class="language-lean">def first (xs : List α) : Option α :=
  xs[0]?
</code></pre>
<p>The result must be an <code>Option</code> because empty lists have no first entry.
Extracting the first and third entries requires a check that each is not <code>none</code>:</p>
<pre><code class="language-lean">def firstThird (xs : List α) : Option (α × α) :=
  match xs[0]? with
  | none =&gt; none
  | some first =&gt;
    match xs[2]? with
    | none =&gt; none
    | some third =&gt;
      some (first, third)
</code></pre>
<p>Similarly, extracting the first, third, and fifth entries requires more checks that the values are not <code>none</code>:</p>
<pre><code class="language-lean">def firstThirdFifth (xs : List α) : Option (α × α × α) :=
  match xs[0]? with
  | none =&gt; none
  | some first =&gt;
    match xs[2]? with
    | none =&gt; none
    | some third =&gt;
      match xs[4]? with
      | none =&gt; none
      | some fifth =&gt;
        some (first, third, fifth)
</code></pre>
<p>And adding the seventh entry to this sequence begins to become quite unmanageable:</p>
<pre><code class="language-lean">def firstThirdFifthSeventh (xs : List α) : Option (α × α × α × α) :=
  match xs[0]? with
  | none =&gt; none
  | some first =&gt;
    match xs[2]? with
    | none =&gt; none
    | some third =&gt;
      match xs[4]? with
      | none =&gt; none
      | some fifth =&gt;
        match xs[6]? with
        | none =&gt; none
        | some seventh =&gt;
          some (first, third, fifth, seventh)
</code></pre>
<p>The fundamental problem with this code is that it addresses two concerns: extracting the numbers and checking that all of them are present, but the second concern is addressed by copying and pasting the code that handles the <code>none</code> case.
It is often good style to lift a repetitive segment into a helper function:</p>
<pre><code class="language-lean">def andThen (opt : Option α) (next : α → Option β) : Option β :=
  match opt with
  | none =&gt; none
  | some x =&gt; next x
</code></pre>
<p>This helper, which is used similarly to <code>?.</code> in C# and Kotlin, takes care of propagating <code>none</code> values.
It takes two arguments: an optional value and a function to apply when the value is not <code>none</code>.
If the first argument is <code>none</code>, then the helper returns <code>none</code>.
If the first argument is not <code>none</code>, then the function is applied to the contents of the <code>some</code> constructor.</p>
<p>Now, <code>firstThird</code> can be rewritten to use <code>andThen</code> instead of pattern matching:</p>
<pre><code class="language-lean">def firstThird (xs : List α) : Option (α × α) :=
  andThen xs[0]? fun first =&gt;
  andThen xs[2]? fun third =&gt;
  some (first, third)
</code></pre>
<p>In Lean, functions don't need to be enclosed in parentheses when passed as arguments.
The following equivalent definition uses more parentheses and indents the bodies of functions:</p>
<pre><code class="language-lean">def firstThird (xs : List α) : Option (α × α) :=
  andThen xs[0]? (fun first =&gt;
    andThen xs[2]? (fun third =&gt;
      some (first, third)))
</code></pre>
<p>The <code>andThen</code> helper provides a sort of &quot;pipeline&quot; through which values flow, and the version with the somewhat unusual indentation is more suggestive of this fact.
Improving the syntax used to write <code>andThen</code> can make these computations even easier to understand.</p>
<h3 id="infix-operators"><a class="header" href="#infix-operators">Infix Operators</a></h3>
<p>In Lean, infix operators can be declared using the <code>infix</code>, <code>infixl</code>, and <code>infixr</code> commands, which create (respectively) non-associative, left-associative, and right-associative operators.
When used multiple times in a row, a <em>left associative</em> operator stacks up the opening parentheses on the left side of the expression.
The addition operator <code>+</code> is left associative, so <code>w + x + y + z</code> is equivalent to <code>(((w + x) + y) + z)</code>.
The exponentiation operator <code>^</code> is right associative, so <code>w ^ x ^ y ^ z</code> is equivalent to <code>(w ^ (x ^ (y ^ z)))</code>.
Comparison operators such as <code>&lt;</code> are non-associative, so <code>x &lt; y &lt; z</code> is a syntax error and requires manual parentheses.</p>
<p>The following declaration makes <code>andThen</code> into an infix operator:</p>
<pre><code class="language-lean">infixl:55 &quot; ~~&gt; &quot; =&gt; andThen
</code></pre>
<p>The number following the colon declares the <em>precedence</em> of the new infix operator.
In ordinary mathematical notation, <code>x + y * z</code> is equivalent to <code>x + (y * z)</code> even though both <code>+</code> and <code>*</code> are left associative.
In Lean, <code>+</code> has precedence 65 and <code>*</code> has precedence 70.
Higher-precedence operators are applied before lower-precedence operators.
According to the declaration of <code>~~&gt;</code>, both <code>+</code> and <code>*</code> have higher precedence, and thus apply first.
Typically, figuring out the most convenient precedences for a group of operators requires some experimentation and a large collection of examples.</p>
<p>Following the new infix operator is a double arrow <code>=&gt;</code>, which specifies the named function to be used for the infix operator.
Lean's standard library uses this feature to define <code>+</code> and <code>*</code> as infix operators that point at <code>HAdd.hAdd</code> and <code>HMul.hMul</code>, respectively, allowing type classes to be used to overload the infix operators.
Here, however, <code>andThen</code> is just an ordinary function.</p>
<p>Having defined an infix operator for <code>andThen</code>, <code>firstThird</code> can be rewritten in a way that brings the &quot;pipeline&quot; feeling of <code>none</code>-checks front and center:</p>
<pre><code class="language-lean">def firstThirdInfix (xs : List α) : Option (α × α) :=
  xs[0]? ~~&gt; fun first =&gt;
  xs[2]? ~~&gt; fun third =&gt;
  some (first, third)
</code></pre>
<p>This style is much more concise when writing larger functions:</p>
<pre><code class="language-lean">def firstThirdFifthSeventh (xs : List α) : Option (α × α × α × α) :=
  xs[0]? ~~&gt; fun first =&gt;
  xs[2]? ~~&gt; fun third =&gt;
  xs[4]? ~~&gt; fun fifth =&gt;
  xs[6]? ~~&gt; fun seventh =&gt;
  some (first, third, fifth, seventh)
</code></pre>
<h2 id="propagating-error-messages"><a class="header" href="#propagating-error-messages">Propagating Error Messages</a></h2>
<p>Pure functional languages such as Lean have no built-in exception mechanism for error handling, because throwing or catching an exception is outside of the step-by-step evaluation model for expressions.
However, functional programs certainly need to handle errors.
In the case of <code>firstThirdFifthSeventh</code>, it is likely relevant for a user to know just how long the list was and where the lookup failed.</p>
<p>This is typically accomplished by defining a datatype that can be either an error or a result, and translating functions with exceptions into functions that return this datatype:</p>
<pre><code class="language-lean">inductive Except (ε : Type) (α : Type) where
  | error : ε → Except ε α
  | ok : α → Except ε α
deriving BEq, Hashable, Repr
</code></pre>
<p>The type variable <code>ε</code> stands for the type of errors that can be produced by the function.
Callers are expected to handle both errors and successes, which makes the type variable <code>ε</code> play a role that is a bit like that of a list of checked exceptions in Java.</p>
<p>Similarly to <code>Option</code>, <code>Except</code> can be used to indicate a failure to find an entry in a list.
In this case, the error type is a <code>String</code>:</p>
<pre><code class="language-lean">def get (xs : List α) (i : Nat) : Except String α :=
  match xs[i]? with
  | none =&gt; Except.error s!&quot;Index {i} not found (maximum is {xs.length - 1})&quot;
  | some x =&gt; Except.ok x
</code></pre>
<p>Looking up an in-bounds value yields an <code>Except.ok</code>:</p>
<pre><code class="language-lean">def ediblePlants : List String :=
  [&quot;ramsons&quot;, &quot;sea plantain&quot;, &quot;sea buckthorn&quot;, &quot;garden nasturtium&quot;]

#eval get ediblePlants 2
</code></pre>
<pre><code class="language-output info">Except.ok &quot;sea buckthorn&quot;
</code></pre>
<p>Looking up an out-of-bounds value yields an <code>Except.failure</code>:</p>
<pre><code class="language-lean">#eval get ediblePlants 4
</code></pre>
<pre><code class="language-output info">Except.error &quot;Index 4 not found (maximum is 3)&quot;
</code></pre>
<p>A single list lookup can conveniently return a value or an error:</p>
<pre><code class="language-lean">def first (xs : List α) : Except String α :=
  get xs 0
</code></pre>
<p>However, performing two list lookups requires handling potential failures:</p>
<pre><code class="language-lean">def firstThird (xs : List α) : Except String (α × α) :=
  match get xs 0 with
  | Except.error msg =&gt; Except.error msg
  | Except.ok first =&gt;
    match get xs 2 with
    | Except.error msg =&gt; Except.error msg
    | Except.ok third =&gt;
      Except.ok (first, third)
</code></pre>
<p>Adding another list lookup to the function requires still more error handling:</p>
<pre><code class="language-lean">def firstThirdFifth (xs : List α) : Except String (α × α × α) :=
  match get xs 0 with
  | Except.error msg =&gt; Except.error msg
  | Except.ok first =&gt;
    match get xs 2 with
    | Except.error msg =&gt; Except.error msg
    | Except.ok third =&gt;
      match get xs 4 with
      | Except.error msg =&gt; Except.error msg
      | Except.ok fifth =&gt;
        Except.ok (first, third, fifth)
</code></pre>
<p>And one more list lookup begins to become quite unmanageable:</p>
<pre><code class="language-lean">def firstThirdFifthSeventh (xs : List α) : Except String (α × α × α × α) :=
  match get xs 0 with
  | Except.error msg =&gt; Except.error msg
  | Except.ok first =&gt;
    match get xs 2 with
    | Except.error msg =&gt; Except.error msg
    | Except.ok third =&gt;
      match get xs 4 with
      | Except.error msg =&gt; Except.error msg
      | Except.ok fifth =&gt;
        match get xs 6 with
        | Except.error msg =&gt; Except.error msg
        | Except.ok seventh =&gt;
          Except.ok (first, third, fifth, seventh)
</code></pre>
<p>Once again, a common pattern can be factored out into a helper.
Each step through the function checks for an error, and only proceeds with the rest of the computation if the result was a success.
A new version of <code>andThen</code> can be defined for <code>Except</code>:</p>
<pre><code class="language-lean">def andThen (attempt : Except e α) (next : α → Except e β) : Except e β :=
  match attempt with
  | Except.error msg =&gt; Except.error msg
  | Except.ok x =&gt; next x
</code></pre>
<p>Just as with <code>Option</code>, this version of <code>andThen</code> allows a more concise definition of <code>firstThird</code>:</p>
<pre><code class="language-lean">def firstThird' (xs : List α) : Except String (α × α) :=
  andThen (get xs 0) fun first  =&gt;
  andThen (get xs 2) fun third =&gt;
  Except.ok (first, third)
</code></pre>
<p>In both the <code>Option</code> and <code>Except</code> case, there are two repeating patterns: there is the checking of intermediate results at each step, which has been factored out into <code>andThen</code>, and there is the final successful result, which is <code>some</code> or <code>Except.ok</code>, respectively.
For the sake of convenience, success can be factored out into a helper called <code>ok</code>:</p>
<pre><code class="language-lean">def ok (x : α) : Except ε α := Except.ok x
</code></pre>
<p>Similarly, failure can be factored out into a helper called <code>fail</code>:</p>
<pre><code class="language-lean">def fail (err : ε) : Except ε α := Except.error err
</code></pre>
<p>Using <code>ok</code> and <code>fail</code> makes <code>get</code> a little more readable:</p>
<pre><code class="language-lean">def get (xs : List α) (i : Nat) : Except String α :=
  match xs[i]? with
  | none =&gt; fail s!&quot;Index {i} not found (maximum is {xs.length - 1})&quot;
  | some x =&gt; ok x
</code></pre>
<p>After adding the infix declaration for <code>andThen</code>, <code>firstThird</code> can be just as concise as the version that returns an <code>Option</code>:</p>
<pre><code class="language-lean">infixl:55 &quot; ~~&gt; &quot; =&gt; andThen

def firstThird (xs : List α) : Except String (α × α) :=
  get xs 0 ~~&gt; fun first =&gt;
  get xs 2 ~~&gt; fun third =&gt;
  ok (first, third)
</code></pre>
<p>The technique scales similarly to larger functions:</p>
<pre><code class="language-lean">def firstThirdFifthSeventh (xs : List α) : Except String (α × α × α × α) :=
  get xs 0 ~~&gt; fun first =&gt;
  get xs 2 ~~&gt; fun third =&gt;
  get xs 4 ~~&gt; fun fifth =&gt;
  get xs 6 ~~&gt; fun seventh =&gt;
  ok (first, third, fifth, seventh)
</code></pre>
<h2 id="logging"><a class="header" href="#logging">Logging</a></h2>
<p>A number is even if dividing it by 2 leaves no remainder:</p>
<pre><code class="language-lean">def isEven (i : Int) : Bool :=
  i % 2 == 0
</code></pre>
<p>The function <code>sumAndFindEvens</code> computes the sum of a list while remembering the even numbers encountered along the way:</p>
<pre><code class="language-lean">def sumAndFindEvens : List Int → List Int × Int
  | [] =&gt; ([], 0)
  | i :: is =&gt;
    let (moreEven, sum) := sumAndFindEvens is
    (if isEven i then i :: moreEven else moreEven, sum + i)
</code></pre>
<p>This function is a simplified example of a common pattern.
Many programs need to traverse a data structure once, while both computing a main result and accumulating some kind of tertiary extra result.
One example of this is logging: a program that is an <code>IO</code> action can always log to a file on disk, but because the disk is outside of the mathematical world of Lean functions, it becomes much more difficult to prove things about logs based on <code>IO</code>.
Another example is a function that computes the sum of all the nodes in a tree with an inorder traversal, while simultaneously recording each nodes visited:</p>
<pre><code class="language-lean">def inorderSum : BinTree Int → List Int × Int
  | BinTree.leaf =&gt; ([], 0)
  | BinTree.branch l x r =&gt;
    let (leftVisited, leftSum) := inorderSum l
    let (hereVisited, hereSum) := ([x], x)
    let (rightVisited, rightSum) := inorderSum r
    (leftVisited ++ hereVisited ++ rightVisited, leftSum + hereSum + rightSum)
</code></pre>
<p>Both <code>sumAndFindEvens</code> and <code>inorderSum</code> have a common repetitive structure.
Each step of computation returns a pair that consists of a list of data that have been saved along with the primary result.
The lists are then appended, and the primary result is computed and paired with the appended lists.
The common structure becomes more apparent with a small rewrite of <code>sumAndFindEvens</code> that more cleanly separates the concerns of saving even numbers and computing the sum:</p>
<pre><code class="language-lean">def sumAndFindEvens : List Int → List Int × Int
  | [] =&gt; ([], 0)
  | i :: is =&gt;
    let (moreEven, sum) := sumAndFindEvens is
    let (evenHere, ()) := (if isEven i then [i] else [], ())
    (evenHere ++ moreEven, sum + i)
</code></pre>
<p>For the sake of clarity, a pair that consists of an accumulated result together with a value can be given its own name:</p>
<pre><code class="language-lean">structure WithLog (logged : Type) (α : Type) where
  log : List logged
  val : α
</code></pre>
<p>Similarly, the process of saving a list of accumulated results while passing a value on to the next step of a computation can be factored out into a helper, once again named <code>andThen</code>:</p>
<pre><code class="language-lean">def andThen (result : WithLog α β) (next : β → WithLog α γ) : WithLog α γ :=
  let {log := thisOut, val := thisRes} := result
  let {log := nextOut, val := nextRes} := next thisRes
  {log := thisOut ++ nextOut, val := nextRes}
</code></pre>
<p>In the case of errors, <code>ok</code> represents an operation that always succeeds.
Here, however, it is an operation that simply returns a value without logging anything:</p>
<pre><code class="language-lean">def ok (x : β) : WithLog α β := {log := [], val := x}
</code></pre>
<p>Just as <code>Except</code> provides <code>fail</code> as a possibility, <code>WithLog</code> should allow items to be added to a log.
This has no interesting return value associated with it, so it returns <code>Unit</code>:</p>
<pre><code class="language-lean">def save (data : α) : WithLog α Unit :=
  {log := [data], val := ()}
</code></pre>
<p><code>WithLog</code>, <code>andThen</code>, <code>ok</code>, and <code>save</code> can be used to separate the logging concern from the summing concern in both programs:</p>
<pre><code class="language-lean">def sumAndFindEvens : List Int → WithLog Int Int
  | [] =&gt; ok 0
  | i :: is =&gt;
    andThen (if isEven i then save i else ok ()) fun () =&gt;
    andThen (sumAndFindEvens is) fun sum =&gt;
    ok (i + sum)

def inorderSum : BinTree Int → WithLog Int Int
  | BinTree.leaf =&gt; ok 0
  | BinTree.branch l x r =&gt;
    andThen (inorderSum l) fun leftSum =&gt;
    andThen (save x) fun () =&gt;
    andThen (inorderSum r) fun rightSum =&gt;
    ok (leftSum + x + rightSum)
</code></pre>
<p>And, once again, the infix operator helps put focus on the correct steps:</p>
<pre><code class="language-lean">infixl:55 &quot; ~~&gt; &quot; =&gt; andThen

def sumAndFindEvens : List Int → WithLog Int Int
  | [] =&gt; ok 0
  | i :: is =&gt;
    (if isEven i then save i else ok ()) ~~&gt; fun () =&gt;
    sumAndFindEvens is ~~&gt; fun sum =&gt;
    ok (i + sum)

def inorderSum : BinTree Int → WithLog Int Int
  | BinTree.leaf =&gt; ok 0
  | BinTree.branch l x r =&gt;
    inorderSum l ~~&gt; fun leftSum =&gt;
    save x ~~&gt; fun () =&gt;
    inorderSum r ~~&gt; fun rightSum =&gt;
    ok (leftSum + x + rightSum)
</code></pre>
<h2 id="numbering-tree-nodes"><a class="header" href="#numbering-tree-nodes">Numbering Tree Nodes</a></h2>
<p>An <em>inorder numbering</em> of a tree associates each data point in the tree with the step it would be visited at in an inorder traversal of the tree.
For example, consider <code>aTree</code>:</p>
<pre><code class="language-lean">open BinTree in
def aTree :=
  branch
    (branch
       (branch leaf &quot;a&quot; (branch leaf &quot;b&quot; leaf))
       &quot;c&quot;
       leaf)
    &quot;d&quot;
    (branch leaf &quot;e&quot; leaf)
</code></pre>
<p>Its inorder numbering is:</p>
<pre><code class="language-output info">BinTree.branch
  (BinTree.branch
    (BinTree.branch (BinTree.leaf) (0, &quot;a&quot;) (BinTree.branch (BinTree.leaf) (1, &quot;b&quot;) (BinTree.leaf)))
    (2, &quot;c&quot;)
    (BinTree.leaf))
  (3, &quot;d&quot;)
  (BinTree.branch (BinTree.leaf) (4, &quot;e&quot;) (BinTree.leaf))
</code></pre>
<p>Trees are most naturally processed with recursive functions, but the usual pattern of recursion on trees makes it difficult to compute an inorder numbering.
This is because the highest number assigned anywhere in the left subtree is used to determine the numbering of a node's data value, and then again to determine the starting point for numbering the right subtree.
In an imperative language, this issue can be worked around by using a mutable variable that contains the next number to be assigned.
The following Python program computes an inorder numbering using a mutable variable:</p>
<pre><code class="language-python">class Branch:
    def __init__(self, value, left=None, right=None):
        self.left = left
        self.value = value
        self.right = right
    def __repr__(self):
        return f'Branch({self.value!r}, left={self.left!r}, right={self.right!r})'

def number(tree):
    num = 0
    def helper(t):
        nonlocal num
        if t is None:
            return None
        else:
            new_left = helper(t.left)
            new_value = (num, t.value)
            num += 1
            new_right = helper(t.right)
            return Branch(left=new_left, value=new_value, right=new_right)

    return helper(tree)
</code></pre>
<p>The numbering of the Python equivalent of <code>aTree</code> is:</p>
<pre><code class="language-python">a_tree = Branch(&quot;d&quot;,
                left=Branch(&quot;c&quot;,
                            left=Branch(&quot;a&quot;, left=None, right=Branch(&quot;b&quot;)),
                            right=None),
                right=Branch(&quot;e&quot;))
</code></pre>
<p>and its numbering is:</p>
<pre><code>&gt;&gt;&gt; number(a_tree)
Branch((3, 'd'), left=Branch((2, 'c'), left=Branch((0, 'a'), left=None, right=Branch((1, 'b'), left=None, right=None)), right=None), right=Branch((4, 'e'), left=None, right=None))
</code></pre>
<p>Even though Lean does not have mutable variables, a workaround exists.
From the point of view of the rest of the world, the mutable variable can be thought of as having two relevant aspects: its value when the function is called, and its value when the function returns.
In other words, a function that uses a mutable variable can be seen as a function that takes the mutable variable's starting value as an argument, returning a pair of the variable's final value and the function's result.
This final value can then be passed as an argument to the next step.</p>
<p>Just as the Python example uses an outer function that establishes a mutable variable and an inner helper function that changes the variable, a Lean version of the function uses an outer function that provides the variable's starting value and explicitly returns the function's result along with an inner helper function that threads the variable's value while computing the numbered tree:</p>
<pre><code class="language-lean">def number (t : BinTree α) : BinTree (Nat × α) :=
  let rec helper (n : Nat) : BinTree α → (Nat × BinTree (Nat × α))
    | BinTree.leaf =&gt; (n, BinTree.leaf)
    | BinTree.branch left x right =&gt;
      let (k, numberedLeft) := helper n left
      let (i, numberedRight) := helper (k + 1) right
      (i, BinTree.branch numberedLeft (k, x) numberedRight)
  (helper 0 t).snd
</code></pre>
<p>This code, like the <code>none</code>-propagating <code>Option</code> code, the <code>error</code>-propagating <code>Except</code> code, and the log-accumulating <code>WithLog</code> code, commingles two concerns: propagating the value of the counter, and actually traversing the tree to find the result.
Just as in those cases, an <code>andThen</code> helper can be defined to propagate state from one step of a computation to another.
The first step is to give a name to the pattern of taking an input state as an argument and returning an output state together with a value:</p>
<pre><code class="language-lean">def State (σ : Type) (α : Type) : Type :=
  σ → (σ × α)
</code></pre>
<p>In the case of <code>State</code>, <code>ok</code> is a function that returns the input state unchanged, along with the provided value:</p>
<pre><code class="language-lean">def ok (x : α) : State σ α :=
  fun s =&gt; (s, x)
</code></pre>
<p>When working with a mutable variable, there are two fundamental operations: reading the value and replacing it with a new one.
Reading the current value is accomplished with a function that places the input state unmodified into the output state, and also places it into the value field:</p>
<pre><code class="language-lean">def get : State σ σ :=
  fun s =&gt; (s, s)
</code></pre>
<p>Writing a new value consists of ignoring the input state, and placing the provided new value into the output state:</p>
<pre><code class="language-lean">def set (s : σ) : State σ Unit :=
  fun _ =&gt; (s, ())
</code></pre>
<p>Finally, two computations that use state can be sequenced by finding both the output state and return value of the first function, then passing them both into the next function:</p>
<pre><code class="language-lean">def andThen (first : State σ α) (next : α → State σ β) : State σ β :=
  fun s =&gt;
    let (s', x) := first s
    next x s'

infixl:55 &quot; ~~&gt; &quot; =&gt; andThen
</code></pre>
<p>Using <code>State</code> and its helpers, local mutable state can be simulated:</p>
<pre><code class="language-lean">def number (t : BinTree α) : BinTree (Nat × α) :=
  let rec helper : BinTree α → State Nat (BinTree (Nat × α))
    | BinTree.leaf =&gt; ok BinTree.leaf
    | BinTree.branch left x right =&gt;
      helper left ~~&gt; fun numberedLeft =&gt;
      get ~~&gt; fun n =&gt;
      set (n + 1) ~~&gt; fun () =&gt;
      helper right ~~&gt; fun numberedRight =&gt;
      ok (BinTree.branch numberedLeft (n, x) numberedRight)
  (helper t 0).snd
</code></pre>
<p>Because <code>State</code> simulates only a single local variable, <code>get</code> and <code>set</code> don't need to refer to any particular variable name.</p>
<h2 id="monads-a-functional-design-pattern"><a class="header" href="#monads-a-functional-design-pattern">Monads: A Functional Design Pattern</a></h2>
<p>Each of these examples has consisted of:</p>
<ul>
<li>A polymorphic type, such as <code>Option</code>, <code>Except ε</code>, <code>WithLog logged</code>, or <code>State σ</code></li>
<li>An operator <code>andThen</code> that takes care of some repetitive aspect of sequencing programs that have this type</li>
<li>An operator <code>ok</code> that is (in some sense) the most boring way to use the type</li>
<li>A collection of other operations, such as <code>none</code>, <code>fail</code>, <code>save</code>, and <code>get</code>, that name ways of using the type</li>
</ul>
<p>This style of API is called a <em>monad</em>.
While the idea of monads is derived from a branch of mathematics called category theory, no understanding of category theory is needed in order to use them for programming.
The key idea of monads is that each monad encodes a particular kind of side effect using the tools provided by the pure functional language Lean.
For example, <code>Option</code> represents programs that can fail by returning <code>none</code>, <code>Except</code> represents programs that can throw exceptions, <code>WithLog</code> represents programs that accumulate a log while running, and <code>State</code> represents programs with a single mutable variable.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-monad-type-class"><a class="header" href="#the-monad-type-class">The Monad Type Class</a></h1>
<p>Rather than having to import an operator like <code>ok</code> or <code>andThen</code> for each type that is a monad, the Lean standard library contains a type class that allow them to be overloaded, so that the same operators can be used for <em>any</em> monad.
Monads have two operations, which are the equivalent of <code>ok</code> and <code>andThen</code>:</p>
<pre><code class="language-lean">class Monad (m : Type → Type) where
  pure : α → m α
  bind : m α → (α → m β) → m β
</code></pre>
<p>This definition is slightly simplified.
The actual definition in the Lean library is somewhat more involved, and will be presented later.</p>
<p>The <code>Monad</code> instances for <code>Option</code> and <code>Except</code> can be created by adapting the definitions of their respective <code>andThen</code> operations:</p>
<pre><code class="language-lean">instance : Monad Option where
  pure x := some x
  bind opt next :=
    match opt with
    | none =&gt; none
    | some x =&gt; next x

instance : Monad (Except ε) where
  pure x := Except.ok x
  bind attempt next :=
    match attempt with
    | Except.error e =&gt; Except.error e
    | Except.ok x =&gt; next x
</code></pre>
<p>As an example, <code>firstThirdFifthSeventh</code> was defined separately for <code>Option α</code> and <code>Except String α</code> return types.
Now, it can be defined polymorphically for <em>any</em> monad.
It does, however, require a lookup function as an argument, because different monads might fail to find a result in different ways.
The infix version of <code>bind</code> is <code>&gt;&gt;=</code>, which plays the same role as <code>~~&gt;</code> in the examples.</p>
<pre><code class="language-lean">def firstThirdFifthSeventh [Monad m] (lookup : List α → Nat → m α) (xs : List α) : m (α × α × α × α) :=
  lookup xs 0 &gt;&gt;= fun first =&gt;
  lookup xs 2 &gt;&gt;= fun third =&gt;
  lookup xs 4 &gt;&gt;= fun fifth =&gt;
  lookup xs 6 &gt;&gt;= fun seventh =&gt;
  pure (first, third, fifth, seventh)
</code></pre>
<p>Given example lists of slow mammals and fast birds, this implementation of <code>firstThirdFifthSeventh</code> can be used with <code>Option</code>:</p>
<pre><code class="language-lean">def slowMammals : List String :=
  [&quot;Three-toed sloth&quot;, &quot;Slow loris&quot;]

def fastBirds : List String := [
  &quot;Peregrine falcon&quot;,
  &quot;Saker falcon&quot;,
  &quot;Golden eagle&quot;,
  &quot;Gray-headed albatross&quot;,
  &quot;Spur-winged goose&quot;,
  &quot;Swift&quot;,
  &quot;Anna's hummingbird&quot;
]

#eval firstThirdFifthSeventh (fun xs i =&gt; xs[i]?) slowMammals
</code></pre>
<pre><code class="language-output info">none
</code></pre>
<pre><code class="language-lean">#eval firstThirdFifthSeventh (fun xs i =&gt; xs[i]?) fastBirds
</code></pre>
<pre><code class="language-output info">some (&quot;Peregrine falcon&quot;, &quot;Golden eagle&quot;, &quot;Spur-winged goose&quot;, &quot;Anna's hummingbird&quot;)
</code></pre>
<p>After renaming <code>Except</code>'s lookup function <code>get</code> to something more specific, the very same  implementation of <code>firstThirdFifthSeventh</code> can be used with <code>Except</code> as well:</p>
<pre><code class="language-lean">def getOrExcept (xs : List α) (i : Nat) : Except String α :=
  match xs[i]? with
  | none =&gt; Except.error s!&quot;Index {i} not found (maximum is {xs.length - 1})&quot;
  | some x =&gt; Except.ok x

#eval firstThirdFifthSeventh getOrExcept slowMammals
</code></pre>
<pre><code class="language-output info">Except.error &quot;Index 2 not found (maximum is 1)&quot;
</code></pre>
<pre><code class="language-lean">#eval firstThirdFifthSeventh getOrExcept fastBirds
</code></pre>
<pre><code class="language-output info">Except.ok (&quot;Peregrine falcon&quot;, &quot;Golden eagle&quot;, &quot;Spur-winged goose&quot;, &quot;Anna's hummingbird&quot;)
</code></pre>
<p>The fact that <code>m</code> must have a <code>Monad</code> instance means that the <code>&gt;&gt;=</code> and <code>pure</code> operations are available.</p>
<h2 id="general-monad-operations"><a class="header" href="#general-monad-operations">General Monad Operations</a></h2>
<p>Because many different types are monads, functions that are polymorphic over <em>any</em> monad are very powerful.
For example, the function <code>mapM</code> is a version of <code>map</code> that uses a <code>Monad</code> to sequence and combine the results of applying a function:</p>
<pre><code class="language-lean">def mapM [Monad m] (f : α → m β) : List α → m (List β)
  | [] =&gt; pure []
  | x :: xs =&gt;
    f x &gt;&gt;= fun hd =&gt;
    mapM f xs &gt;&gt;= fun tl =&gt;
    pure (hd :: tl)
</code></pre>
<p>The return type of the function argument <code>f</code> determines which <code>Monad</code> instance will be used.
In other words, <code>mapM</code> can be used for functions that produce logs, for functions that can fail, or for functions that use mutable state.
Because <code>f</code>'s type determines the available effects, they can be tightly controlled by API designers.</p>
<p>As described in <a href="monads/../monads.html#numbering-tree-nodes">this chapter's introduction</a>, <code>State σ α</code> represents programs that make use of a mutable variable of type <code>σ</code> and return a value of type <code>α</code>.
These programs are actually functions from a starting state to a pair of a value and a final state.
The <code>Monad</code> class requires that its parameter expect a single type argument—that is, it should be a <code>Type → Type</code>.
This means that the instance for <code>State</code> should mention the state type <code>σ</code>, which becomes a parameter to the instance:</p>
<pre><code class="language-lean">instance : Monad (State σ) where
  pure x := fun s =&gt; (s, x)
  bind first next :=
    fun s =&gt;
      let (s', x) := first s
      next x s'
</code></pre>
<p>This means that the type of the state cannot change between calls to <code>get</code> and <code>set</code> that are sequenced using <code>bind</code>, which is a reasonable rule for stateful computations.
The operator <code>increment</code> increases a saved state by a given amount, returning the old value:</p>
<pre><code class="language-lean">def increment (howMuch : Int) : State Int Int :=
  get &gt;&gt;= fun i =&gt;
  set (i + howMuch) &gt;&gt;= fun () =&gt;
  pure i
</code></pre>
<p>Using <code>mapM</code> with <code>increment</code> results in a program that computes the sum of the entries in a list.
More specifically, the mutable variable contains the sum so far, while the resulting list contains a running sum.
In other words, <code>mapM increment</code> has type <code>List Int → State Int (List Int)</code>, and expanding the definition of <code>State</code> yields <code>List Int → Int → (Int × List Int)</code>.
It takes an initial sum as an argument, which should be <code>0</code>:</p>
<pre><code class="language-lean">#eval mapM increment [1, 2, 3, 4, 5] 0
</code></pre>
<pre><code class="language-output info">(15, [0, 1, 3, 6, 10])
</code></pre>
<p>A <a href="monads/../monads.html#logging">logging effect</a> can be represented using <code>WithLog</code>.
Just like <code>State</code>, its <code>Monad</code> instance is polymorphic with respect to the type of the logged data:</p>
<pre><code class="language-lean">instance : Monad (WithLog logged) where
  pure x := {log := [], val := x}
  bind result next :=
    let {log := thisOut, val := thisRes} := result
    let {log := nextOut, val := nextRes} := next thisRes
    {log := thisOut ++ nextOut, val := nextRes}
</code></pre>
<p><code>saveIfEven</code> is a function that logs even numbers but returns its argument unchanged:</p>
<pre><code class="language-lean">def saveIfEven (i : Int) : WithLog Int Int :=
  (if isEven i then
    save i
   else pure ()) &gt;&gt;= fun () =&gt;
  pure i
</code></pre>
<p>Using this function with <code>mapM</code> results in a log containing even numbers paired with an unchanged input list:</p>
<pre><code class="language-lean">#eval mapM saveIfEven [1, 2, 3, 4, 5]
</code></pre>
<pre><code class="language-output info">{ log := [2, 4], val := [1, 2, 3, 4, 5] }
</code></pre>
<h2 id="the-identity-monad"><a class="header" href="#the-identity-monad">The Identity Monad</a></h2>
<p>Monads encode programs with effects, such as failure, exceptions, or logging, into explicit representations as data and functions.
Sometimes, however, an API will be written to use a monad for flexibility, but the API's client may not require any encoded effects.
The <em>identity monad</em> is a monad that has no effects, and allows pure code to be used with monadic APIs:</p>
<pre><code class="language-lean">def Id (t : Type) : Type := t

instance : Monad Id where
  pure x := x
  bind x f := f x
</code></pre>
<p>The type of <code>pure</code> should be <code>α → Id α</code>, but <code>Id α</code> reduces to just <code>α</code>.
Similarly, the type of <code>bind</code> should be <code>α → (α → Id β) → Id β</code>.
Because this reduces to <code>α → (α → β) → β</code>, the second argument can be applied to the first to find the result.</p>
<p>With the identity monad, <code>mapM</code> becomes equivalent to <code>map</code>.
To call it this way, however, Lean requires a hint that the intended monad is <code>Id</code>:</p>
<pre><code class="language-lean">#eval mapM (m := Id) (· + 1) [1, 2, 3, 4, 5]
</code></pre>
<pre><code class="language-output info">[2, 3, 4, 5, 6]
</code></pre>
<p>Omitting the hint results in an error:</p>
<pre><code class="language-lean">#eval mapM (· + 1) [1, 2, 3, 4, 5]
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  HAdd Nat Nat (?m.9319 ?m.9321)
</code></pre>
<p>In this error, the application of one metavariable to another indicates that Lean doesn't run the type-level computation backwards.
The return type of the function is expected to be the monad applied to some other type.
Similarly, using <code>mapM</code> with a function whose type doesn't provide any specific hints about which monad is to be used results in an &quot;instance problem stuck&quot; message:</p>
<pre><code class="language-lean">#eval mapM (fun x =&gt; x) [1, 2, 3, 4, 5]
</code></pre>
<pre><code class="language-output error">typeclass instance problem is stuck, it is often due to metavariables
  Monad ?m.9319
</code></pre>
<h2 id="the-monad-contract"><a class="header" href="#the-monad-contract">The Monad Contract</a></h2>
<p>Just as every pair of instances of <code>BEq</code> and <code>Hashable</code> should ensure that any two equal values have the same hash, there is a contract that each instance of <code>Monad</code> should obey.
First, <code>pure</code> should be a left identity of <code>bind</code>.
That is, <code>bind (pure v) f</code> should be the same as <code>f v</code>.
Secondly, <code>pure</code> should be a right identity of <code>bind</code>, so <code>bind v pure</code> is the same as <code>v</code>.
Finally, <code>bind</code> should be associative, so <code>bind (bind v f) g</code> is the same as <code>bind v (fun x =&gt; bind (f x) g)</code>.</p>
<p>This contract specifies the expected properties of programs with effects more generally.
Because <code>pure</code> has no effects, sequencing its effects with <code>bind</code> shouldn't change the result.
The associative property of <code>bind</code> basically says that the sequencing bookkeeping itself doesn't matter, so long as the order in which things are happening is preserved.</p>
<h2 id="exercises-9"><a class="header" href="#exercises-9">Exercises</a></h2>
<h3 id="mapping-on-a-tree"><a class="header" href="#mapping-on-a-tree">Mapping on a Tree</a></h3>
<p>Define a function <code>BinTree.mapM</code>.
By analogy to <code>mapM</code> for lists, this function should apply a monadic function to each data entry in a tree, as a preorder traversal.
The type signature should be:</p>
<pre><code>def BinTree.mapM [Monad m] (f : α → m β) : BinTree α → m (BinTree β)
</code></pre>
<h3 id="the-option-monad-contract"><a class="header" href="#the-option-monad-contract">The Option Monad Contract</a></h3>
<p>First, write a convincing argument that the <code>Monad</code> instance for <code>Option</code> satisfies the monad contract.
Then, consider the following instance:</p>
<pre><code class="language-lean">instance : Monad Option where
  pure x := some x
  bind opt next := none
</code></pre>
<p>Both methods have the correct type.
Why does this instance violate the monad contract?</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="example-arithmetic-in-monads"><a class="header" href="#example-arithmetic-in-monads">Example: Arithmetic in Monads</a></h2>
<p>Monads are a way of encoding programs with side effects into a language that does not have them.
It would be easy to read this as a sort of admission that pure functional programs are missing something important, requiring programmers to jump through hoops just to write a normal program.
However, while using the <code>Monad</code> API does impose a syntactic cost on a program, it brings two important benefits:</p>
<ol>
<li>Programs must be honest about which effects they use in their types. A quick glance at a type signature describes <em>everything</em> that the program can do, rather than just what it accepts and what it returns.</li>
<li>Not every language provides the same effects. For example, only some language have exceptions. Other languages have unique, exotic effects, such as <a href="https://www2.cs.arizona.edu/icon/">Icon's searching over multiple values</a> and Scheme or Ruby's continuations. Because monads can encode <em>any</em> effect, programmers can choose which ones are the best fit for a given application, rather than being stuck with what the language developers provided.</li>
</ol>
<p>One example of a program that can make sense in a variety of monads is an evaluator for arithmetic expressions.</p>
<h3 id="arithmetic-expressions"><a class="header" href="#arithmetic-expressions">Arithmetic Expressions</a></h3>
<p>An arithmetic expression is either a literal integer or a primitive binary operator applied to two expressions. The operators are addition, subtraction, multiplication, and division:</p>
<pre><code class="language-lean">inductive Expr (op : Type) where
  | const : Int → Expr op
  | prim : op → Expr op → Expr op → Expr op


inductive Arith where
  | plus
  | minus
  | times
  | div
</code></pre>
<p>The expression <code>2 + 3</code> is represented:</p>
<pre><code class="language-lean">open Expr in
open Arith in
def twoPlusThree : Expr Arith :=
  prim plus (const 2) (const 3)
</code></pre>
<p>and <code>14 / (45 - 5 * 9)</code> is represented:</p>
<pre><code class="language-lean">open Expr in
open Arith in
def fourteenDivided : Expr Arith :=
  prim div (const 14) (prim minus (const 45) (prim times (const 5) (const 9)))
</code></pre>
<h3 id="evaluating-expressions-2"><a class="header" href="#evaluating-expressions-2">Evaluating Expressions</a></h3>
<p>Because expressions include division, and division by zero is undefined, evaluation might fail.
One way to represent failure is to use <code>Option</code>:</p>
<pre><code class="language-lean">def evaluateOption : Expr Arith → Option Int
  | Expr.const i =&gt; pure i
  | Expr.prim p e1 e2 =&gt;
    evaluateOption e1 &gt;&gt;= fun v1 =&gt;
    evaluateOption e2 &gt;&gt;= fun v2 =&gt;
    match p with
    | Arith.plus =&gt; pure (v1 + v2)
    | Arith.minus =&gt; pure (v1 - v2)
    | Arith.times =&gt; pure (v1 * v2)
    | Arith.div =&gt; if v2 == 0 then none else pure (v1 / v2)
</code></pre>
<p>This definition uses the <code>Monad Option</code> instance to propagate failures from evaluating both branches of a binary operator.
However, the function mixes two concerns: evaluating subexpressions and applying a binary operator to the results.
It can be improved by splitting it into two functions:</p>
<pre><code class="language-lean">def applyPrim : Arith → Int → Int → Option Int
  | Arith.plus, x, y =&gt; pure (x + y)
  | Arith.minus, x, y =&gt; pure (x - y)
  | Arith.times, x, y =&gt; pure (x * y)
  | Arith.div, x, y =&gt; if y == 0 then none else pure (x / y)

def evaluateOption : Expr Arith → Option Int
  | Expr.const i =&gt; pure i
  | Expr.prim p e1 e2 =&gt;
    evaluateOption e1 &gt;&gt;= fun v1 =&gt;
    evaluateOption e2 &gt;&gt;= fun v2 =&gt;
    applyPrim p v1 v2
</code></pre>
<p>Running <code>#eval evaluateOption fourteenDivided</code> yields <code>none</code>, as expected, but this is not a very useful error message.
Because the code was written using <code>&gt;&gt;=</code> rather than by explicitly handling the <code>none</code> constructor, only a small modification is required for it to provide an error message on failure:</p>
<pre><code class="language-lean">def applyPrim : Arith → Int → Int → Except String Int
  | Arith.plus, x, y =&gt; pure (x + y)
  | Arith.minus, x, y =&gt; pure (x - y)
  | Arith.times, x, y =&gt; pure (x * y)
  | Arith.div, x, y =&gt;
    if y == 0 then
      Except.error s!&quot;Tried to divide {x} by zero&quot;
    else pure (x / y)


def evaluateExcept : Expr Arith → Except String Int
  | Expr.const i =&gt; pure i
  | Expr.prim p e1 e2 =&gt;
    evaluateExcept e1 &gt;&gt;= fun v1 =&gt;
    evaluateExcept e2 &gt;&gt;= fun v2 =&gt;
    applyPrim p v1 v2
</code></pre>
<p>The only difference is that the type signature mentions <code>Except String</code> instead of <code>Option</code>, and the failing case uses <code>Except.error</code> instead of <code>none</code>.
By making <code>evaluate</code> polymorphic over its monad and passing it <code>applyPrim</code> as an argument, a single evaluator becomes capable of both forms of error reporting:</p>
<pre><code class="language-lean">def applyPrimOption : Arith → Int → Int → Option Int
  | Arith.plus, x, y =&gt; pure (x + y)
  | Arith.minus, x, y =&gt; pure (x - y)
  | Arith.times, x, y =&gt; pure (x * y)
  | Arith.div, x, y =&gt;
    if y == 0 then
      none
    else pure (x / y)

def applyPrimExcept : Arith → Int → Int → Except String Int
  | Arith.plus, x, y =&gt; pure (x + y)
  | Arith.minus, x, y =&gt; pure (x - y)
  | Arith.times, x, y =&gt; pure (x * y)
  | Arith.div, x, y =&gt;
    if y == 0 then
      Except.error s!&quot;Tried to divide {x} by zero&quot;
    else pure (x / y)

def evaluateM [Monad m] (applyPrim : Arith → Int → Int → m Int): Expr Arith → m Int
  | Expr.const i =&gt; pure i
  | Expr.prim p e1 e2 =&gt;
    evaluateM applyPrim e1 &gt;&gt;= fun v1 =&gt;
    evaluateM applyPrim e2 &gt;&gt;= fun v2 =&gt;
    applyPrim p v1 v2
</code></pre>
<p>Using it with <code>applyPrimOption</code> works just like the first version of <code>evaluate</code>:</p>
<pre><code class="language-lean">#eval evaluateM applyPrimOption fourteenDivided
</code></pre>
<pre><code class="language-output info">none
</code></pre>
<p>Similarly, using it with <code>applyPrimExcept</code> works just like the version with error messages:</p>
<pre><code class="language-lean">#eval evaluateM applyPrimExcept fourteenDivided
</code></pre>
<pre><code class="language-output info">Except.error &quot;Tried to divide 14 by zero&quot;
</code></pre>
<p>The code can still be improved.
The functions <code>applyPrimOption</code> and <code>applyPrimExcept</code> differ only in their treatment of division, which can be extracted into another parameter to the evaluator:</p>
<pre><code class="language-lean">def applyDivOption (x : Int) (y : Int) : Option Int :=
    if y == 0 then
      none
    else pure (x / y)

def applyDivExcept (x : Int) (y : Int) : Except String Int :=
    if y == 0 then
      Except.error s!&quot;Tried to divide {x} by zero&quot;
    else pure (x / y)

def applyPrim [Monad m] (applyDiv : Int → Int → m Int) : Arith → Int → Int → m Int
  | Arith.plus, x, y =&gt; pure (x + y)
  | Arith.minus, x, y =&gt; pure (x - y)
  | Arith.times, x, y =&gt; pure (x * y)
  | Arith.div, x, y =&gt; applyDiv x y

def evaluateM [Monad m] (applyDiv : Int → Int → m Int): Expr Arith → m Int
  | Expr.const i =&gt; pure i
  | Expr.prim p e1 e2 =&gt;
    evaluateM applyDiv e1 &gt;&gt;= fun v1 =&gt;
    evaluateM applyDiv e2 &gt;&gt;= fun v2 =&gt;
    applyPrim applyDiv p v1 v2
</code></pre>
<p>In this refactored code, the fact that the two code paths differ only in their treatment of failure has been made fully apparent.</p>
<h3 id="further-effects"><a class="header" href="#further-effects">Further Effects</a></h3>
<p>Failure and exceptions are not the only kinds of effects that can be interesting when working with an evaluator.
While division's only side effect is failure, adding other primitive operators to the expressions make it possible to express other effects.</p>
<p>The first step is an additional refactoring, extracting division from the datatype of primitives:</p>
<pre><code class="language-lean">inductive Prim (special : Type) where
  | plus
  | minus
  | times
  | other : special → Prim special

inductive CanFail where
  | div
</code></pre>
<p>The name <code>CanFail</code> suggests that the effect introduced by division is potential failure.</p>
<p>The second step is to broaden the scope of the division handler argument to <code>evaluateM</code> so that it can process any special operator:</p>
<pre><code class="language-lean">def divOption : CanFail → Int → Int → Option Int
  | CanFail.div, x, y =&gt; if y == 0 then none else pure (x / y)

def divExcept : CanFail → Int → Int → Except String Int
  | CanFail.div, x, y =&gt;
    if y == 0 then
      Except.error s!&quot;Tried to divide {x} by zero&quot;
    else pure (x / y)

def applyPrim [Monad m] (applySpecial : special → Int → Int → m Int) : Prim special → Int → Int → m Int
  | Prim.plus, x, y =&gt; pure (x + y)
  | Prim.minus, x, y =&gt; pure (x - y)
  | Prim.times, x, y =&gt; pure (x * y)
  | Prim.other op, x, y =&gt; applySpecial op x y

def evaluateM [Monad m] (applySpecial : special → Int → Int → m Int): Expr (Prim special) → m Int
  | Expr.const i =&gt; pure i
  | Expr.prim p e1 e2 =&gt;
    evaluateM applySpecial e1 &gt;&gt;= fun v1 =&gt;
    evaluateM applySpecial e2 &gt;&gt;= fun v2 =&gt;
    applyPrim applySpecial p v1 v2
</code></pre>
<h4 id="no-effects"><a class="header" href="#no-effects">No Effects</a></h4>
<p>The type <code>Empty</code> has no constructors, and thus no values, like the <code>Nothing</code> type in Scala or Kotlin.
In Scala and Kotlin, <code>Nothing</code> can represent computations that never return a result, such as functions that crash the program, throw exceptions, or always fall into infinite loops.
An argument to a function or method of type <code>Nothing</code> indicates dead code, as there will never be a suitable argument value.
Lean doesn't support infinite loops and exceptions, but <code>Empty</code> is still useful as an indication to the type system that a function cannot be called.
Using the syntax <code>nomatch E</code> when <code>E</code> is an expression whose type has no constructors indicates to Lean that the current expression need not return a result, because it could never have been called. </p>
<p>Using <code>Empty</code> as the parameter to <code>Prim</code> indicates that there are no additional cases beyond <code>Prim.plus</code>, <code>Prim.minus</code>, and <code>Prim.times</code>, because it is impossible to come up with a value of type <code>Empty</code> to place in the <code>Prim.other</code> constructor.
Because a function to apply an operator of type <code>Empty</code> to two integers can never be called, it doesn't need to return a result.
Thus, it can be used in <em>any</em> monad:</p>
<pre><code class="language-lean">def applyEmpty [Monad m] (op : Empty) (_ : Int) (_ : Int) : m Int :=
  nomatch op
</code></pre>
<p>This can be used together with <code>Id</code>, the identity monad, to evaluate expressions that have no effects whatsoever:</p>
<pre><code class="language-lean">open Expr Prim in
#eval evaluateM (m := Id) applyEmpty (prim plus (const 5) (const (-14)))
</code></pre>
<pre><code class="language-output info">-9
</code></pre>
<h4 id="nondeterministic-search"><a class="header" href="#nondeterministic-search">Nondeterministic Search</a></h4>
<p>Instead of simply failing when encountering division by zero, it would also be sensible to backtrack and try a different input.
Given the right monad, the very same <code>evaluateM</code> can perform a nondeterministic search for a <em>set</em> of answers that do not result in failure.
This requires, in addition to division, some means of specifying a choice of results.
One way to do this is to add a function <code>choose</code> to the language of expressions that instructs the evaluator to pick either of its arguments while searching for non-failing results.</p>
<p>The result of the evaluator is now a multiset of values, rather than a single value.
The rules for evaluation into a multiset are:</p>
<ul>
<li>Constants \( n \) evaluate to singleton sets \( {n} \).</li>
<li>Arithmetic operators other than division are called on each pair from the Cartesian product of the operators, so \( X + Y \) evaluates to \( \{ x + y \mid x ∈ X, y ∈ Y \} \).</li>
<li>Division \( X / Y \) evaluates to \( \{ x / y \mid x ∈ X, y ∈ Y, y ≠ 0\} \). In other words, all \( 0 \) values in \( Y \)  are thrown out.</li>
<li>A choice \( \mathrm{choose}(x, y) \) evaluates to \( \{ x, y \} \).</li>
</ul>
<p>For example, \( 1 + \mathrm{choose}(2, 5) \) evaluates to \( \{ 3, 6 \} \), \(1 + 2 / 0 \) evaluates to \( \{\} \), and \( 90 / (\mathrm{choose}(-5, 5) + 5) \) evaluates to \( \{ 9 \} \).
Using multisets instead of true sets simplifies the code by removing the need to check for uniqueness of elements.</p>
<p>A monad that represents this non-deterministic effect must be able to represent a situation in which there are no answers, and a situation in which there is at least one answer together with any remaining answers:</p>
<pre><code class="language-lean">inductive Many (α : Type) where
  | none : Many α
  | more : α → (Unit → Many α) → Many α
</code></pre>
<p>This datatype looks very much like <code>List</code>.
The difference is that where <code>cons</code> stores the rest of the list, <code>more</code> stores a function that should compute the next value on demand.
This means that a consumer of <code>Many</code> can stop the search when some number of results have been found.</p>
<p>A single result is represented by a <code>more</code> constructor that returns no further results:</p>
<pre><code class="language-lean">def Many.one (x : α) : Many α := Many.more x (fun () =&gt; Many.none)
</code></pre>
<p>The union of two multisets of results can be computed by checking whether the first multiset is empty.
If so, the second multiset is the union.
If not, the union consists of the first element of the first multiset followed by the union of the rest of the first multiset with the second multiset:</p>
<pre><code class="language-lean">def Many.union : Many α → Many α → Many α
  | Many.none, ys =&gt; ys
  | Many.more x xs, ys =&gt; Many.more x (fun () =&gt; union (xs ()) ys)
</code></pre>
<p>It can be convenient to start a search process with a list of values.
<code>Many.fromList</code> converts a list into a multiset of results:</p>
<pre><code class="language-lean">def Many.fromList : List α → Many α
  | [] =&gt; Many.none
  | x :: xs =&gt; Many.more x (fun () =&gt; fromList xs)
</code></pre>
<p>Similarly, once a search has been specified, it can be convenient to extract either a number of values, or all the values:</p>
<pre><code class="language-lean">def Many.take : Nat → Many α → List α
  | 0, _ =&gt; []
  | _ + 1, Many.none =&gt; []
  | n + 1, Many.more x xs =&gt; x :: (xs ()).take n

def Many.takeAll : Many α → List α
  | Many.none =&gt; []
  | Many.more x xs =&gt; x :: (xs ()).takeAll
</code></pre>
<p>A <code>Monad Many</code> instance requires a <code>bind</code> operator.
In a nondeterministic search, sequencing two operations consists of taking all possibilities from the first step and running the rest of the program on each of them, taking the union of the results.
In other words, if the first step returns three possible answers, the second step needs to be tried for all three.
Because the second step can return any number of answers for each input, taking their union represents the entire search space.</p>
<pre><code class="language-lean">def Many.bind : Many α → (α → Many β) → Many β
  | Many.none, _ =&gt;
    Many.none
  | Many.more x xs, f =&gt;
    (f x).union (bind (xs ()) f)
</code></pre>
<p><code>Many.one</code> and <code>Many.bind</code> obey the monad contract.
To check that <code>Many.bind (Many.one v) f</code> is the same as <code>f v</code>, start by evaluating the expression as far as possible:</p>
<pre><code class="language-lean">Many.bind (Many.one v) f
===&gt;
Many.bind (Many.more v (fun () =&gt; Many.none)) f
===&gt;
(f v).union (Many.bind Many.none f)
===&gt;
(f v).union Many.none
</code></pre>
<p>The empty multiset is a right identity of <code>union</code>, so the answer is equivalent to <code>f v</code>.
To check that <code>Many.bind v Many.one</code> is the same as <code>v</code>, consider that <code>bind</code> takes the union of applying <code>Many.one</code> to each element of <code>v</code>.
In other words, if <code>v</code> has the form <code>{v1, v2, v3, ..., vn}</code>, then <code>Many.bind v Many.one</code> is <code>{v1} ∪ {v2} ∪ {v3} ∪ ... ∪ {vn}</code>, which is <code>{v1, v2, v3, ..., vn}</code>.</p>
<p>Finally, to check that <code>Many.bind</code> is associative, check that <code>Many.bind (Many.bind bind v f) g</code> is the same as <code>Many.bind v (fun x =&gt; Many.bind (f x) g)</code>.
If <code>v</code> has the form <code>{v1, v2, v3, ..., vn}</code>, then:</p>
<pre><code class="language-lean">Many.bind v f
===&gt;
f v1 ∪ f v2 ∪ f v3 ∪ ... ∪ f vn
</code></pre>
<p>which means that</p>
<pre><code class="language-lean">Many.bind (Many.bind bind v f) g
===&gt;
Many.bind (f v1) g ∪
Many.bind (f v2) g ∪
Many.bind (f v3) g ∪
... ∪
Many.bind (f vn) g
</code></pre>
<p>Similarly,</p>
<pre><code class="language-lean">Many.bind v (fun x =&gt; Many.bind (f x) g)
===&gt;
(fun x =&gt; Many.bind (f x) g) v1 ∪
(fun x =&gt; Many.bind (f x) g) v2 ∪
(fun x =&gt; Many.bind (f x) g) v3 ∪
... ∪
(fun x =&gt; Many.bind (f x) g) vn
===&gt;
Many.bind (f v1) g ∪
Many.bind (f v2) g ∪
Many.bind (f v3) g ∪
... ∪
Many.bind (f vn) g
</code></pre>
<p>Thus, both sides are equal, so <code>Many.bind</code> is associative.</p>
<p>The resulting monad instance is:</p>
<pre><code class="language-lean">instance : Monad Many where
  pure := Many.one
  bind := Many.bind
</code></pre>
<p>An example search using this monad finds all the combinations of numbers in a list that add to 15:</p>
<pre><code class="language-lean">def addsTo (goal : Nat) : List Nat → Many (List Nat)
  | [] =&gt;
    if goal == 0 then
      pure []
    else
      Many.none
  | x :: xs =&gt;
    if x &gt; goal then
      addsTo goal xs
    else
      (addsTo goal xs).union
        (addsTo (goal - x) xs &gt;&gt;= fun answer =&gt;
         pure (x :: answer))
</code></pre>
<p>The search process is recursive over the list.
The empty list is a successful search when the goal is <code>0</code>; otherwise, it fails.
When the list is non-empty, there are two possibilities: either the head of the list is greater than the goal, in which case it cannot participate in any successful searches, or it is not, in which case it can.
If the head of the list is <em>not</em> a candidate, then the search proceeds to the tail of the list.
If the head is a candidate, then there are two possibilities to be combined with <code>Many.union</code>: either the solutions found contain the head, or they do not.
The solutions that do not contain the head are found with a recursive call on the tail, while the solutions that do contain it result from subtracting the head from the goal, and then attaching the head to the solutions that result from the recursive call.</p>
<p>Returning to the arithmetic evaluator that produces multisets of results, the <code>both</code> and <code>neither</code> operators can be written as follows:</p>
<pre><code class="language-lean">inductive NeedsSearch
  | div
  | choose

def applySearch : NeedsSearch → Int → Int → Many Int
  | NeedsSearch.choose, x, y =&gt;
    Many.fromList [x, y]
  | NeedsSearch.div, x, y =&gt;
    if y == 0 then
      Many.none
    else Many.one (x / y)
</code></pre>
<p>Using these operators, the earlier examples can be evaluated:</p>
<pre><code class="language-lean">open Expr Prim NeedsSearch

#eval (evaluateM applySearch (prim plus (const 1) (prim (other choose) (const 2) (const 5)))).takeAll
</code></pre>
<pre><code class="language-output info">[3, 6]
</code></pre>
<pre><code class="language-lean">#eval (evaluateM applySearch (prim plus (const 1) (prim (other div) (const 2) (const 0)))).takeAll
</code></pre>
<pre><code class="language-output info">[]
</code></pre>
<pre><code class="language-lean">#eval (evaluateM applySearch (prim (other div) (const 90) (prim plus (prim (other choose) (const (-5)) (const 5)) (const 5)))).takeAll
</code></pre>
<pre><code class="language-output info">[9]
</code></pre>
<h4 id="custom-environments"><a class="header" href="#custom-environments">Custom Environments</a></h4>
<p>The evaluator can be made user-extensible by allowing strings to be used as operators, and then providing a mapping from strings to a function that implements them.
For example, users could extend the evaluator with a remainder operator or with one that returns the maximum of its two arguments.
The mapping from function names to function implementations is called an <em>environment</em>.</p>
<p>The environments needs to be passed in each recursive call.
Initially, it might seem that <code>evaluateM</code> needs an extra argument to hold the environment, and that this argument should be passed to each recursive invocation.
However, passing an argument like this is another form of monad, so an appropriate <code>Monad</code> instance allows the evaluator to be used unchanged.</p>
<p>Using functions as a monad is typically called a <em>reader</em> monad.
When evaluating expressions in the reader monad, the following rules are used:</p>
<ul>
<li>Constants \( n \) evaluate to constant functions \( λ e . n \),</li>
<li>Arithmetic operators evaluate to functions that pass their arguments on, so \( f + g \) evaluates to \( λ e . f(e) + g(e) \), and</li>
<li>Custom operators evaluate to the result of applying the custom operator to the arguments, so \( f \ \mathrm{OP}\ g \) evaluates to
\[
λ e .
\begin{cases}
h(f(e), g(e)) &amp; \mathrm{if}\ e\ \mathrm{contains}\ (\mathrm{OP}, h) \\
0 &amp; \mathrm{otherwise}
\end{cases}
\]
with \( 0 \) serving as a fallback in case an unknown operator is applied.</li>
</ul>
<p>To define the reader monad in Lean, the first step is to define the <code>Reader</code> type and the effect that allows users to get ahold of the environment:</p>
<pre><code class="language-lean">def Reader (ρ : Type) (α : Type) : Type := ρ → α

def read : Reader ρ ρ := fun env =&gt; env
</code></pre>
<p>By convention, the Greek letter <code>ρ</code>, which is pronounced &quot;rho&quot;, is used for environments.</p>
<p>The fact that constants in arithmetic expressions evaluate to constant functions suggests that the appropriate definition of <code>pure</code> for <code>Reader</code> is a a constant function:</p>
<pre><code class="language-lean">def Reader.pure (x : α) : Reader ρ α := fun _ =&gt; x
</code></pre>
<p>On the other hand, <code>bind</code> is a bit tricker.
Its type is <code>Reader ρ α → (α → Reader ρ β) → Reader ρ β</code>.
This type can be easier to understand by expanding the definitions of <code>Reader</code>, which yields <code>(ρ → α) → (α → ρ → β) → ρ → β</code>.
It should take an environment-accepting function as its first argument, while the second argument should transform the result of the environment-accepting function into yet another environment-accepting function.
The result of combining these is itself a function, waiting for an environment.</p>
<p>It's possible to use Lean interactively to get help writing this function.
The first step is to write down the arguments and return type, being very explicit in order to get as much help as possible, with an underscore for the definition's body:</p>
<pre><code class="language-lean">def Reader.bind {ρ : Type} {α : Type} {β : Type}
  (result : ρ → α) (next : α → ρ → β) : ρ → β :=
  _
</code></pre>
<p>Lean provides a message that describes which variables are available in scope, and the type that's expected for the result.
The <code>⊢</code> symbol, called a <em>turnstile</em> due to its resemblance to subway entrances, separates the local variables from the desired type, which is <code>ρ → β</code> in this message:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
ρ α β : Type
result : ρ → α
next : α → ρ → β
⊢ ρ → β
</code></pre>
<p>Because the return type is a function, a good first step is to wrap a <code>fun</code> around the underscore:</p>
<pre><code class="language-lean">def Reader.bind {ρ : Type} {α : Type} {β : Type}
  (result : ρ → α) (next : α → ρ → β) : ρ → β :=
  fun env =&gt; _
</code></pre>
<p>The resulting message now shows the function's argument as a local variable:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
ρ α β : Type
result : ρ → α
next : α → ρ → β
env : ρ
⊢ β
</code></pre>
<p>The only thing in the context that can produce a <code>β</code> is <code>next</code>, and it will require two arguments to do so.
Each argument can itself be an underscore:</p>
<pre><code class="language-lean">def Reader.bind {ρ : Type} {α : Type} {β : Type}
  (result : ρ → α) (next : α → ρ → β) : ρ → β :=
  fun env =&gt; next _ _
</code></pre>
<p>The two underscores have the following respective messages associated with them:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
ρ α β : Type
result : ρ → α
next : α → ρ → β
env : ρ
⊢ α
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
ρ α β : Type
result : ρ → α
next : α → ρ → β
env : ρ
⊢ ρ
</code></pre>
<p>Attacking the first underscore, only one thing in the context can produce an <code>α</code>, namely <code>result</code>:</p>
<pre><code class="language-lean">def Reader.bind {ρ : Type} {α : Type} {β : Type}
  (result : ρ → α) (next : α → ρ → β) : ρ → β :=
  fun env =&gt; next (result _) _
</code></pre>
<p>Now, both underscores have the same error:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
ρ α β : Type
result : ρ → α
next : α → ρ → β
env : ρ
⊢ ρ
</code></pre>
<p>Happily, both underscores can be replaced by <code>env</code>, yielding:</p>
<pre><code class="language-lean">def Reader.bind {ρ : Type} {α : Type} {β : Type}
  (result : ρ → α) (next : α → ρ → β) : ρ → β :=
  fun env =&gt; next (result env) env
</code></pre>
<p>The final version can be obtained by undoing the expansion of <code>Reader</code> and cleaning up the explicit details:</p>
<pre><code class="language-lean">def Reader.bind (result : Reader ρ α) (next : α → Reader ρ β) : Reader ρ β :=
  fun env =&gt; next (result env) env
</code></pre>
<p>It's not always possible to write correct functions by simply &quot;following the types&quot;, and it carries the risk of not understanding the resulting program.
However, it can also be easier to understand a program that has been written than one that has not, and the process of filling in the underscores can bring insights.
In this case, <code>Reader.bind</code> works just like <code>bind</code> for <code>Id</code>, except it accepts an additional argument that it then passes down to its arguments, and this intuition can help in understanding how it works.</p>
<p><code>Reader.pure</code>, which generates constant functions, and <code>Reader.bind</code> obey the monad contract.
To check that <code>Reader.bind (Reader.pure v) f</code> is the same as <code>f v</code>, it's enough to replace definitions until the last step:</p>
<pre><code class="language-lean">Reader.bind (Reader.pure v) f
===&gt;
fun env =&gt; f ((Reader.pure v) env) env
===&gt;
fun env =&gt; f ((fun _ =&gt; v) env) env
===&gt;
fun env =&gt; f v env
===&gt;
f v
</code></pre>
<p>For every function <code>f</code>, <code>fun x =&gt; f x</code> is the same as <code>f</code>, so the first part of the contract is satisfied.
To check that <code>Reader.bind r Reader.pure</code> is the same as <code>r</code>, a similar technique works:</p>
<pre><code class="language-lean">Reader.bind r Reader.pure
===&gt;
fun env =&gt; Reader.pure (r env) env
===&gt;
fun env =&gt; (fun _ =&gt; (r env)) env
===&gt;
fun env =&gt; r env
</code></pre>
<p>Because reader actions <code>r</code> are themselves functions, this is the same as <code>r</code>.
To check associativity, the same thing can be done for both <code>Reader.bind (Reader.bind r f) g</code> and <code>Reader.bind r (fun x =&gt; Reader.bind (f x) g)</code>:</p>
<pre><code class="language-lean">Reader.bind (Reader.bind r f) g
===&gt;
fun env =&gt; g ((Reader.bind r f) env) env
===&gt;
fun env =&gt; g ((fun env' =&gt; f (r env') env') env) env
===&gt;
fun env =&gt; g (f (r env) env) env
</code></pre>
<pre><code class="language-lean">Reader.bind r (fun x =&gt; Reader.bind (f x) g)
===&gt;
Reader.bind r (fun x =&gt; fun env =&gt; g (f x env) env)
===&gt;
fun env =&gt; (fun x =&gt; fun env' =&gt; g (f x env') env') (r env) env
===&gt;
fun env =&gt; (fun env' =&gt; g (f (r env) env') env') env
===&gt;
fun env =&gt; g (f (r env) env) env
</code></pre>
<p>Thus, a <code>Monad (Reader ρ)</code> instance is justified:</p>
<pre><code class="language-lean">instance : Monad (Reader ρ) where
  pure x := fun _ =&gt; x
  bind x f := fun env =&gt; f (x env) env
</code></pre>
<p>The custom environments that will be passed to the expression evaluator can be represented as lists of pairs:</p>
<pre><code class="language-lean">abbrev Env : Type := List (String × (Int → Int → Int))
</code></pre>
<p>For instance, <code>exampleEnv</code> contains maximum and modulus functions:</p>
<pre><code class="language-lean">def exampleEnv : Env := [(&quot;max&quot;, max), (&quot;mod&quot;, (· % ·))]
</code></pre>
<p>Lean already has a function <code>List.lookup</code> that finds the value associated with a key in a list of pairs, so <code>applyPrimReader</code> needs only check whether the custom function is present in the environment. It returns <code>0</code> if the function is unknown:</p>
<pre><code class="language-lean">def applyPrimReader (op : String) (x : Int) (y : Int) : Reader Env Int :=
  read &gt;&gt;= fun env =&gt;
  match env.lookup op with
  | none =&gt; pure 0
  | some f =&gt; pure (f x y)
</code></pre>
<p>Using <code>evaluateM</code> with <code>applyPrimReader</code> and an expression results in a function that expects an environment.
Luckily, <code>exampleEnv</code> is available:</p>
<pre><code class="language-lean">open Expr Prim in
#eval evaluateM applyPrimReader (prim (other &quot;max&quot;) (prim plus (const 5) (const 4)) (prim times (const 3) (const 2))) exampleEnv
</code></pre>
<pre><code class="language-output info">9
</code></pre>
<p>Like <code>Many</code>, <code>Reader</code> is an example of an effect that is difficult to encode in most languages, but type classes and monads make it just as convenient as any other effect.
The dynamic or special variables found in Common Lisp, Clojure, and Emacs Lisp can be used like <code>Reader</code>.
Similarly, Scheme and Racket's parameter objects are an effect that exactly correspond to <code>Reader</code>.
The Kotlin idiom of context objects can solve a similar problem, but they are fundamentally a means of passing function arguments automatically, so this idiom is more like the encoding as a reader monad than it is an effect in the language.</p>
<h2 id="exercises-10"><a class="header" href="#exercises-10">Exercises</a></h2>
<h3 id="checking-contracts"><a class="header" href="#checking-contracts">Checking Contracts</a></h3>
<p>Check the monad contract for <code>State σ</code> and <code>Except ε</code>.</p>
<h3 id="readers-with-failure"><a class="header" href="#readers-with-failure">Readers with Failure</a></h3>
<p>Adapt the reader monad example so that it can also indicate failure when the custom operator is not defined, rather than just returning zero.
In other words, given these definitions:</p>
<pre><code class="language-lean">def ReaderOption (ρ : Type) (α : Type) : Type := ρ → Option α

def ReaderExcept (ε : Type) (ρ : Type) (α : Type) : Type := ρ → Except ε α
</code></pre>
<p>do the following:</p>
<ol>
<li>Write suitable <code>pure</code> and <code>bind</code> functions</li>
<li>Check that these functions satisfy the <code>Monad</code> contract</li>
<li>Write <code>Monad</code> instances for <code>ReaderOption</code> and <code>ReaderExcept</code></li>
<li>Define suitable <code>applyPrim</code> operators and test them with <code>evaluateM</code> on some example expressions</li>
</ol>
<h3 id="a-tracing-evaluator"><a class="header" href="#a-tracing-evaluator">A Tracing Evaluator</a></h3>
<p>The <code>WithLog</code> type can be used with the evaluator to add optional tracing of some operations.
In particular, the type <code>ToTrace</code> can serve as a signal to trace a given operator:</p>
<pre><code class="language-lean">inductive ToTrace (α : Type) : Type where
  | trace : α → ToTrace α
</code></pre>
<p>For the tracing evaluator, expressions should have type <code>Expr (Prim (ToTrace (Prim Empty)))</code>.
This says that the operators in the expression consist of addition, subtraction, and multiplication, augmented with traced versions of each. The innermost argument is <code>Empty</code> to signal that there are no further special operators inside of <code>trace</code>, only the three basic ones.</p>
<p>Do the following:</p>
<ol>
<li>Implement a <code>Monad (WithLog logged)</code> instance</li>
<li>Write an <code>applyTraced</code> function to apply traced operators to their arguments, logging both the operator and the arguments, with type <code>ToTrace (Prim Empty) → Int → Int → WithLog (Prim Empty × Int × Int) Int</code></li>
</ol>
<p>If the exercise has been completed correctly, then</p>
<pre><code class="language-lean">open Expr Prim ToTrace in
#eval evaluateM applyTraced (prim (other (trace times)) (prim (other (trace plus)) (const 1) (const 2)) (prim (other (trace minus)) (const 3) (const 4)))
</code></pre>
<p>should result in</p>
<pre><code class="language-output info">{ log := [(Prim.plus, 1, 2), (Prim.minus, 3, 4), (Prim.times, 3, -1)], val := -3 }
</code></pre>
<p>Hint: values of type <code>Prim Empty</code> will appear in the resulting log. In order to display them as a result of <code>#eval</code>, the following instances are required:</p>
<pre><code class="language-lean">deriving instance Repr for WithLog
deriving instance Repr for Empty
deriving instance Repr for Prim
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="do-notation-for-monads"><a class="header" href="#do-notation-for-monads"><code>do</code>-Notation for Monads</a></h1>
<p>While APIs based on monads are very powerful, the explicit use of <code>&gt;&gt;=</code> with anonymous functions is still somewhat noisy.
Just as infix operators are used instead of explicit calls to <code>HAdd.hAdd</code>, Lean provides a syntax for monads called <em><code>do</code>-notation</em> that can make programs that use monads easier to read and write.
This is the very same <code>do</code>-notation that is used to write programs in <code>IO</code>, and <code>IO</code> is also a monad.</p>
<p>In <a href="monads/../hello-world.html">Hello, World!</a>, the <code>do</code> syntax is used to combine <code>IO</code> actions, but the meaning of these programs is explained directly.
Understanding how to program with monads means that <code>do</code> can now be explained in terms of how it translates into uses of the underlying monad operators.</p>
<p>The first translation of <code>do</code> is used when the only statement in the <code>do</code> is a single expression <code>E</code>.
In this case, the <code>do</code> is removed, so</p>
<pre><code class="language-lean">do E
</code></pre>
<p>translates to</p>
<pre><code class="language-lean">E
</code></pre>
<p>The second translation is used when the first statement of the <code>do</code> is a <code>let</code> with an arrow, binding a local variable.
This translates to a use of <code>&gt;&gt;=</code> together with a function that binds that very same variable, so</p>
<pre><code class="language-lean">do let x ← E1
   Stmt
   ...
   En
</code></pre>
<p>translates to</p>
<pre><code class="language-lean">E1 &gt;&gt;= fun x =&gt;
do Stmt
   ...
   En
</code></pre>
<p>When the first statement of the <code>do</code> block is an expression, then it is considered to be a monadic action that returns <code>Unit</code>, so the function matches the <code>Unit</code> constructor and</p>
<pre><code class="language-lean">do E1
   Stmt
   ...
   En
</code></pre>
<p>translates to</p>
<pre><code class="language-lean">E1 &gt;&gt;= fun () =&gt;
do Stmt
   ...
   En
</code></pre>
<p>Finally, when the first statement of the <code>do</code> block is a <code>let</code> that uses <code>:=</code>, the translated form is an ordinary let expression, so</p>
<pre><code class="language-lean">do let x := E1
   Stmt
   ...
   En
</code></pre>
<p>translates to</p>
<pre><code class="language-lean">let x := E1
do Stmt
   ...
   En
</code></pre>
<p>The definition of <code>firstThirdFifthSeventh</code> that uses the <code>Monad</code> class looks like this:</p>
<pre><code class="language-lean">def firstThirdFifthSeventh [Monad m] (lookup : List α → Nat → m α) (xs : List α) : m (α × α × α × α) :=
  lookup xs 0 &gt;&gt;= fun first =&gt;
  lookup xs 2 &gt;&gt;= fun third =&gt;
  lookup xs 4 &gt;&gt;= fun fifth =&gt;
  lookup xs 6 &gt;&gt;= fun seventh =&gt;
  pure (first, third, fifth, seventh)
</code></pre>
<p>Using <code>do</code>-notation, it becomes significantly more readable:</p>
<pre><code class="language-lean">def firstThirdFifthSeventh [Monad m] (lookup : List α → Nat → m α) (xs : List α) : m (α × α × α × α) := do
  let first ← lookup xs 0
  let third ← lookup xs 2
  let fifth ← lookup xs 4
  let seventh ← lookup xs 6
  pure (first, third, fifth, seventh)
</code></pre>
<p>Without the <code>Monad</code> type class, the function <code>number</code> that numbers the nodes of a tree was written:</p>
<pre><code class="language-lean">def number (t : BinTree α) : BinTree (Nat × α) :=
  let rec helper : BinTree α → State Nat (BinTree (Nat × α))
    | BinTree.leaf =&gt; ok BinTree.leaf
    | BinTree.branch left x right =&gt;
      helper left ~~&gt; fun numberedLeft =&gt;
      get ~~&gt; fun n =&gt;
      set (n + 1) ~~&gt; fun () =&gt;
      helper right ~~&gt; fun numberedRight =&gt;
      ok (BinTree.branch numberedLeft (n, x) numberedRight)
  (helper t 0).snd
</code></pre>
<p>With <code>Monad</code> and <code>do</code>, its definition is much less noisy:</p>
<pre><code class="language-lean">def number (t : BinTree α) : BinTree (Nat × α) :=
  let rec helper : BinTree α → State Nat (BinTree (Nat × α))
    | BinTree.leaf =&gt; pure BinTree.leaf
    | BinTree.branch left x right =&gt; do
      let numberedLeft ← helper left
      let n ← get
      set (n + 1)
      let numberedRight ← helper right
      ok (BinTree.branch numberedLeft (n, x) numberedRight)
  (helper t 0).snd
</code></pre>
<p>All of the conveniences from <code>do</code> with <code>IO</code> are also available when using it with other monads.
For example, nested actions also work in any monad.
The original definition of <code>mapM</code> was:</p>
<pre><code class="language-lean">def mapM [Monad m] (f : α → m β) : List α → m (List β)
  | [] =&gt; pure []
  | x :: xs =&gt;
    f x &gt;&gt;= fun hd =&gt;
    mapM f xs &gt;&gt;= fun tl =&gt;
    pure (hd :: tl)
</code></pre>
<p>With <code>do</code>-notation, it can be written:</p>
<pre><code class="language-lean">def mapM [Monad m] (f : α → m β) : List α → m (List β)
  | [] =&gt; pure []
  | x :: xs =&gt; do
    let hd ← f x
    let tl ← mapM f xs
    pure (hd :: tl)
</code></pre>
<p>Using nested actions makes it almost as short as the original non-monadic <code>map</code>:</p>
<pre><code class="language-lean">def mapM [Monad m] (f : α → m β) : List α → m (List β)
  | [] =&gt; pure []
  | x :: xs =&gt; do
    pure ((← f x) :: (← mapM f xs))
</code></pre>
<p>Using nested actions, <code>number</code> can be made much more concise:</p>
<pre><code class="language-lean">def increment : State Nat Nat := do
  let n ← get
  set (n + 1)
  pure n

def number (t : BinTree α) : BinTree (Nat × α) :=
  let rec helper : BinTree α → State Nat (BinTree (Nat × α))
    | BinTree.leaf =&gt; pure BinTree.leaf
    | BinTree.branch left x right =&gt; do
      pure (BinTree.branch (← helper left) ((← increment), x) (← helper right))
  (helper t 0).snd
</code></pre>
<h2 id="exercises-11"><a class="header" href="#exercises-11">Exercises</a></h2>
<ul>
<li>Rewrite <code>evaluateM</code>, its helpers, and the different specific use cases using <code>do</code>-notation instead of explicit calls to <code>&gt;&gt;=</code>.</li>
<li>Rewrite <code>firstThirdFifthSeventh</code> using nested actions.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-io-monad"><a class="header" href="#the-io-monad">The IO Monad</a></h1>
<p><code>IO</code> as a monad can be understood from two perspectives, which were described in the section on <a href="monads/../hello-world/running-a-program.html">running programs</a>.
Each can help to understand the meanings of <code>pure</code> and <code>bind</code> for <code>IO</code>.</p>
<p>From the first perspective, an <code>IO</code> action is an instruction to Lean's run-time system.
For example, the instruction might be &quot;read a string from this file descriptor, then re-invoke the pure Lean code with the string&quot;.
This perspective is an <em>exterior</em> one, viewing the program from the perspective of the operating system.
In this case, <code>pure</code> is an <code>IO</code> action that does not request any effects from the RTS, and <code>bind</code> instructs the RTS to first carry out one potentially-effectful operation and then invoke the rest of the program with the resulting value.</p>
<p>From the second perspective, an <code>IO</code> action transforms the whole world.
<code>IO</code> actions are actually pure, because they receive a unique world as an argument and then return the changed world.
This perspective is an <em>interior</em> one that matches how <code>IO</code> is represented inside of Lean.
The world is represented in Lean as a token, and the <code>IO</code> monad is structured to make sure that each token is used exactly once.</p>
<p>To see how this works, it can be helpful to peel back one definition at a time.
The <code>#print</code> command reveals the internals of Lean datatypes and definitions.
For example,</p>
<pre><code class="language-lean">#print Nat
</code></pre>
<p>results in</p>
<pre><code class="language-output info">inductive Nat : Type
number of parameters: 0
constructors:
Nat.zero : Nat
Nat.succ : Nat → Nat
</code></pre>
<p>and</p>
<pre><code class="language-lean">#print Char.isAlpha
</code></pre>
<p>results in</p>
<pre><code class="language-output info">def Char.isAlpha : Char → Bool :=
fun c =&gt; Char.isUpper c || Char.isLower c
</code></pre>
<p>Sometimes, the output of <code>#print</code> includes Lean features that have not yet been presented in this book.
For example,</p>
<pre><code class="language-lean">#print List.isEmpty
</code></pre>
<p>produces</p>
<pre><code class="language-output info">def List.isEmpty.{u} : {α : Type u} → List α → Bool :=
fun {α} x =&gt;
  match x with
  | [] =&gt; true
  | head :: tail =&gt; false
</code></pre>
<p>which includes a <code>.{u}</code> after the definition's name, and annotates types as <code>Type u</code> rather than just <code>Type</code>.
This can be safely ignored for now.</p>
<p>Printing the definition of <code>IO</code> shows that it's defined in terms of simpler structures:</p>
<pre><code class="language-lean">#print IO
</code></pre>
<pre><code class="language-output info">@[reducible] def IO : Type → Type :=
EIO IO.Error
</code></pre>
<p><code>IO.Error</code> represents all the errors that could be thrown by an <code>IO</code> action:</p>
<pre><code class="language-lean">#print IO.Error
</code></pre>
<pre><code class="language-output info">inductive IO.Error : Type
number of parameters: 0
constructors:
IO.Error.alreadyExists : Option String → UInt32 → String → IO.Error
IO.Error.otherError : UInt32 → String → IO.Error
IO.Error.resourceBusy : UInt32 → String → IO.Error
IO.Error.resourceVanished : UInt32 → String → IO.Error
IO.Error.unsupportedOperation : UInt32 → String → IO.Error
IO.Error.hardwareFault : UInt32 → String → IO.Error
IO.Error.unsatisfiedConstraints : UInt32 → String → IO.Error
IO.Error.illegalOperation : UInt32 → String → IO.Error
IO.Error.protocolError : UInt32 → String → IO.Error
IO.Error.timeExpired : UInt32 → String → IO.Error
IO.Error.interrupted : String → UInt32 → String → IO.Error
IO.Error.noFileOrDirectory : String → UInt32 → String → IO.Error
IO.Error.invalidArgument : Option String → UInt32 → String → IO.Error
IO.Error.permissionDenied : Option String → UInt32 → String → IO.Error
IO.Error.resourceExhausted : Option String → UInt32 → String → IO.Error
IO.Error.inappropriateType : Option String → UInt32 → String → IO.Error
IO.Error.noSuchThing : Option String → UInt32 → String → IO.Error
IO.Error.unexpectedEof : IO.Error
IO.Error.userError : String → IO.Error
</code></pre>
<p><code>EIO ε α</code> represents <code>IO</code> actions that will either terminate with an error of type <code>ε</code> or succeed with a value of type <code>α</code>.
This means that, like the <code>Except ε</code> monad, the <code>IO</code> monad includes the ability to define error handling and exceptions.</p>
<p>Peeling back another layer, <code>EIO</code> is itself defined in terms of a simpler structure:</p>
<pre><code class="language-lean">#print EIO
</code></pre>
<pre><code class="language-output info">def EIO : Type → Type → Type :=
fun ε =&gt; EStateM ε IO.RealWorld
</code></pre>
<p>The <code>EStateM</code> monad includes both errors and state—it's a combination of <code>Except</code> and <code>State</code>.
It is defined using another type, <code>EStateM.Result</code>:</p>
<pre><code class="language-lean">#print EStateM
</code></pre>
<pre><code class="language-output info">def EStateM.{u} : Type u → Type u → Type u → Type u :=
fun ε σ α =&gt; σ → EStateM.Result ε σ α
</code></pre>
<p>In other words, a program with type <code>EStateM ε σ α</code> is a function that accepts an initial state of type <code>σ</code> and returns an <code>EStateM.Result ε σ α</code>.</p>
<p><code>EStateM.Result</code> is very much like the definition of <code>Except</code>, with one constructor that indicates a successful termination and one constructor that indicates an error:</p>
<pre><code class="language-lean">#print EStateM.Result
</code></pre>
<pre><code class="language-output info">inductive EStateM.Result.{u} : Type u → Type u → Type u → Type u
number of parameters: 3
constructors:
EStateM.Result.ok : {ε σ α : Type u} → α → σ → EStateM.Result ε σ α
EStateM.Result.error : {ε σ α : Type u} → ε → σ → EStateM.Result ε σ α
</code></pre>
<p>Just like <code>Except ε α</code>, the <code>ok</code> constructor includes a result of type <code>α</code>, and the <code>error</code> constructor includes an exception of type <code>ε</code>.
Unlike <code>Except</code>, both constructors have an additional state field that includes the final state of the computation.</p>
<p>The <code>Monad</code> instance for <code>EStateM ε σ</code> requires <code>pure</code> and <code>bind</code>.
Just as with <code>State</code>, the implementation of <code>pure</code> for <code>EStateM</code> accepts an initial state and returns it unchanged, and just as with <code>Except</code>, it returns its argument in the <code>ok</code> constructor:</p>
<pre><code class="language-lean">#print EStateM.pure
</code></pre>
<pre><code class="language-output info">protected def EStateM.pure.{u} : {ε σ α : Type u} → α → EStateM ε σ α :=
fun {ε σ α} a s =&gt; EStateM.Result.ok a s
</code></pre>
<p><code>protected</code> means that the full name <code>EStateM.pure</code> is needed even if the <code>EStateM</code> namespace has been opened.</p>
<p>Similarly, <code>bind</code> for <code>EStateM</code> takes an initial state as an argument.
It passes this initial state to its first action.
Like <code>bind</code> for <code>Except</code>, it then checks whether the result is an error.
If so, the error is returned unchanged and the second argument to <code>bind</code> remains unused.
If the result was a success, then the second argument is applied to both the returned value and to the resulting state.</p>
<pre><code class="language-lean">#print EStateM.bind
</code></pre>
<pre><code class="language-output info">protected def EStateM.bind.{u} : {ε σ α β : Type u} → EStateM ε σ α → (α → EStateM ε σ β) → EStateM ε σ β :=
fun {ε σ α β} x f s =&gt;
  match x s with
  | EStateM.Result.ok a s =&gt; f a s
  | EStateM.Result.error e s =&gt; EStateM.Result.error e s
</code></pre>
<p>Putting all of this together, <code>IO</code> is a monad that tracks state and errors at the same time.
The collection of available errors is that given by the datatype <code>IO.Error</code>, which has constructors that describe many things that can go wrong in a program.
The state is a type that represents the real world, called <code>IO.RealWorld</code>.
Each basic <code>IO</code> action receives this real world and returns another one, paired either with an error or a result.
In <code>IO</code>, <code>pure</code> returns the world unchanged, while <code>bind</code> passes the modified world from one action into the next action.</p>
<p>Because the entire universe doesn't fit in a computer's memory, the world being passed around is just a representation.
So long as world tokens are not re-used, the representation is safe.
This means that world tokens do not need to contain any data at all:</p>
<pre><code class="language-lean">#print IO.RealWorld
</code></pre>
<pre><code class="language-output info">def IO.RealWorld : Type :=
Unit
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="additional-conveniences-3"><a class="header" href="#additional-conveniences-3">Additional Conveniences</a></h1>
<h2 id="shared-argument-types"><a class="header" href="#shared-argument-types">Shared Argument Types</a></h2>
<p>When defining a function that takes multiple arguments that have the same type, both can be written before the same colon.
For example,</p>
<pre><code class="language-lean">def equal? [BEq α] (x : α) (y : α) : Option α :=
  if x == y then
    some x
  else
    none
</code></pre>
<p>can be written</p>
<pre><code class="language-lean">def equal? [BEq α] (x y : α) : Option α :=
  if x == y then
    some x
  else
    none
</code></pre>
<p>This is especially useful when the type signature is large.</p>
<h2 id="leading-dot-notation"><a class="header" href="#leading-dot-notation">Leading Dot Notation</a></h2>
<p>The constructors of an inductive type are in a namespace.
This allows multiple related inductive types to use the same constructor names, but it can lead to programs becoming verbose.
In contexts where the inductive type in question is known, the namespace can be omitted by preceding the constructor's name with a dot, and Lean uses the expected type to resolve the constructor names.
For example, a function that mirrors a binary tree can be written:</p>
<pre><code class="language-lean">def BinTree.mirror : BinTree α → BinTree α
  | BinTree.leaf =&gt; BinTree.leaf
  | BinTree.branch l x r =&gt; BinTree.branch (mirror r) x (mirror l)
</code></pre>
<p>Omitting the namespaces makes it significantly shorter, at the cost of making the program harder to read in contexts like code review tools that don't include the Lean compiler:</p>
<pre><code class="language-lean">def BinTree.mirror : BinTree α → BinTree α
  | .leaf =&gt; .leaf
  | .branch l x r =&gt; .branch (mirror r) x (mirror l)
</code></pre>
<p>Using the expected type of an expression to disambiguate a namespace is also applicable to names other than constructors.
If <code>BinTree.empty</code> is defined as an alternative way of creating <code>BinTree</code>s, then it can also be used with dot notation:</p>
<pre><code class="language-lean">def BinTree.empty : BinTree α := .leaf

#check (.empty : BinTree Nat)
</code></pre>
<pre><code class="language-output info">BinTree.empty : BinTree Nat
</code></pre>
<h2 id="or-patterns"><a class="header" href="#or-patterns">Or-Patterns</a></h2>
<p>In contexts that allow multiple patterns, such as <code>match</code>-expressions, multiple patterns may share their result expressions.
The datatype <code>Weekday</code> that represents days of the week:</p>
<pre><code class="language-lean">inductive Weekday where
  | monday
  | tuesday
  | wednesday
  | thursday
  | friday
  | saturday
  | sunday
  deriving Repr
</code></pre>
<p>Pattern matching can be used to check whether a day is a weekend:</p>
<pre><code class="language-lean">def Weekday.isWeekend (day : Weekday) : Bool :=
  match day with
  | Weekday.saturday =&gt; true
  | Weekday.sunday =&gt; true
  | _ =&gt; false
</code></pre>
<p>This can already be simplified by using constructor dot notation:</p>
<pre><code class="language-lean">def Weekday.isWeekend (day : Weekday) : Bool :=
  match day with
  | .saturday =&gt; true
  | .sunday =&gt; true
  | _ =&gt; false
</code></pre>
<p>Because both weekend patterns have the same result expression (<code>true</code>), they can be condensed into one:</p>
<pre><code class="language-lean">def Weekday.isWeekend (day : Weekday) : Bool :=
  match day with
  | .saturday | .sunday =&gt; true
  | _ =&gt; false
</code></pre>
<p>This can be further simplified into a version in which the argument is not named:</p>
<pre><code class="language-lean">def Weekday.isWeekend : Weekday → Bool
  | .saturday | .sunday =&gt; true
  | _ =&gt; false
</code></pre>
<p>Behind the scenes, the result expression is simply duplicated across each pattern.
This means that patterns can bind variables, as in this example that removes the <code>inl</code> and <code>inr</code> constructors from a sum type in which both contain the same type of value:</p>
<pre><code class="language-lean">def condense : α ⊕ α → α
  | .inl x | .inr x =&gt; x
</code></pre>
<p>Because the result expression is duplicated, the variables bound by the patterns are not required to have the same types.
Overloaded functions that work for multiple types may be used to write a single result expression that works for patterns that bind variables of different types:</p>
<pre><code class="language-lean">def stringy : Nat ⊕ Weekday → String
  | .inl x | .inr x =&gt; s!&quot;It is {repr x}&quot;
</code></pre>
<p>In practice, only variables shared in all patterns can be referred to in the result expression, because the result must make sense for each pattern.
In <code>getTheNat</code>, only <code>n</code> can be accessed, and attempts to use either <code>x</code> or <code>y</code> lead to errors.</p>
<pre><code class="language-lean">def getTheNat : (Nat × α) ⊕ (Nat × β) → Nat
  | .inl (n, x) | .inr (n, y) =&gt; n
</code></pre>
<p>Attempting to access <code>x</code> in a similar definition causes an error because there is no <code>x</code> available in the second pattern:</p>
<pre><code class="language-lean">def getTheAlpha : (Nat × α) ⊕ (Nat × α) → α
  | .inl (n, x) | .inr (n, y) =&gt; x
</code></pre>
<pre><code class="language-output error">unknown identifier 'x'
</code></pre>
<p>The fact that the result expression is essentially copy-pasted to each branch of the pattern match can lead to some surprising behavior.
For example, the following definitions are acceptable because the <code>inr</code> version of the result expression refers to the global definition of <code>str</code>:</p>
<pre><code class="language-lean">def str := &quot;Some string&quot;

def getTheString : (Nat × String) ⊕ (Nat × β) → String
  | .inl (n, str) | .inr (n, y) =&gt; str
</code></pre>
<p>Calling this function on both constructors reveals the confusing behavior.
In the first case, a type annotation is needed to tell Lean which type <code>β</code> should be:</p>
<pre><code class="language-lean">#eval getTheString (.inl (20, &quot;twenty&quot;) : (Nat × String) ⊕ (Nat × String))
</code></pre>
<pre><code class="language-output info">&quot;twenty&quot;
</code></pre>
<p>In the second case, the global definition is used:</p>
<pre><code class="language-lean">#eval getTheString (.inr (20, &quot;twenty&quot;))
</code></pre>
<pre><code class="language-output info">&quot;Some string&quot;
</code></pre>
<p>Using or-patterns can vastly simplify some definitions and increase their clarity, as in <code>Weekday.isWeekend</code>.
Because there is a potential for confusing behavior, it's a good idea to be careful when using them, especially when variables of multiple types or disjoint sets of variables are involved.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-3"><a class="header" href="#summary-3">Summary</a></h1>
<h2 id="encoding-side-effects"><a class="header" href="#encoding-side-effects">Encoding Side Effects</a></h2>
<p>Lean is a pure functional language.
This means that it does not include side effects such as mutable variables, logging, or exceptions.
However, most side effects can be <em>encoded</em> using a combination of functions and inductive types or structures.
For example, mutable state can be encoded as a function from an initial state to a pair of a final state and a result, and exceptions can be encoded as an inductive type with constructors for successful termination and errors.</p>
<p>Each set of encoded effects is a type.
As a result, if a program uses these encoded effects, then this is apparent in its type.
Functional programming does not mean that programs can't use effects, it simply requires that they be <em>honest</em> about which effects they use.
A Lean type signature describes not only the types of arguments that a function expects and the type of result that it returns, but also which effects it may use.</p>
<h2 id="the-monad-type-class-1"><a class="header" href="#the-monad-type-class-1">The Monad Type Class</a></h2>
<p>It's possible to write purely functional programs in languages that allow effects anywhere.
For example, <code>2 + 3</code> is a valid Python program that has no effects at all.
Similarly, combining programs that have effects requires a way to state the order in which the effects must occur.
It matters whether an exception is thrown before or after modifying a variable, after all.</p>
<p>The type class <code>Monad</code> captures these two important properties.
It has two methods: <code>pure</code> represents programs that have no effects, and <code>bind</code> sequences effectful programs.
The contract for <code>Monad</code> instances ensures that <code>bind</code> and <code>pure</code> actually capture pure computation and sequencing.</p>
<h2 id="do-notation-for-monads-1"><a class="header" href="#do-notation-for-monads-1"><code>do</code>-Notation for Monads</a></h2>
<p>Rather than being limited to <code>IO</code>, <code>do</code>-notation works for any monad.
It allows programs that use monads to be written in a style that is reminiscent of statement-oriented languages, with statements sequenced after one another.
Additionally, <code>do</code>-notation enables a number of additional convenient shorthands, such as nested actions.
A program written with <code>do</code> is translated to applications of <code>&gt;&gt;=</code> behind the scenes.</p>
<h2 id="custom-monads"><a class="header" href="#custom-monads">Custom Monads</a></h2>
<p>Different languages provide different sets of side effects.
While most languages feature mutable variables and file I/O, not all have features like exceptions.
Other languages offer effects that are rare or unique, like Icon's search-based program execution, Scheme and Ruby's continuations, and Common Lisp's resumable exceptions.
An advantage to encoding effects with monads is that programs are not limited to the set of effects that are provided by the language.
Because Lean is designed to make programming with any monad convenient, programmers are free to choose exactly the set of side effects that make sense for any given application.</p>
<h2 id="the-io-monad-1"><a class="header" href="#the-io-monad-1">The <code>IO</code> Monad</a></h2>
<p>Programs that can affect the real world are written as <code>IO</code> actions in Lean.
<code>IO</code> is one monad among many.
The <code>IO</code> monad encodes state and exceptions, with the state being used to keep track of the state of the world and the exceptions modeling failure and recovery.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="functors-applicative-functors-and-monads"><a class="header" href="#functors-applicative-functors-and-monads">Functors, Applicative Functors, and Monads</a></h1>
<p><code>Functor</code> and <code>Monad</code> both describe operations for types that are still waiting for a type argument.
One way to understand them is that <code>Functor</code> describes containers in which the contained data can be transformed, and <code>Monad</code> describes an encoding of programs with side effects.
This understanding is incomplete, however.
After all, <code>Option</code> has instances for both <code>Functor</code> and <code>Monad</code>, and simultaneously represents an optional value <em>and</em> a computation that might fail to return a value.</p>
<p>From the perspective of data structures, <code>Option</code> is a bit like a nullable type or like a list that can contain at most one entry.
From the perspective of control structures, <code>Option</code> represents a computation that might terminate early without a result.
Typically, programs that use the <code>Functor</code> instance are easiest to think of as using <code>Option</code> as a data structure, while programs that use the <code>Monad</code> instance are easiest to think of as using <code>Option</code> to allow early failure, but learning to use both of these perspectives fluently is an important part of becoming proficient at functional programming.</p>
<p>There is a deeper relationship between functors and monads.
It turns out that <em>every monad is a functor</em>.
Another way to say this is that the monad abstraction is more powerful than the functor abstraction, because not every functor is a monad.
Furthermore, there is an additional intermediate abstraction, called <em>applicative functors</em>, that has enough power to write many interesting programs and yet permits libraries that cannot use the <code>Monad</code> interface.
The type class <code>Applicative</code> provides the overloadable operations of applicative functors.
Every monad is an applicative functor, and every applicative functor is a functor, but the converses do not hold.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="structures-and-inheritance"><a class="header" href="#structures-and-inheritance">Structures and Inheritance</a></h1>
<p>In order to understand the full definitions of <code>Functor</code>, <code>Applicative</code>, and <code>Monad</code>, another Lean feature is necessary: structure inheritance.
Structure inheritance allows one structure type to provide the interface of another, along with additional fields.
This can be useful when modeling concepts that have a clear taxonomic relationship.
For example, take a model of mythical creatures.
Some of them are large, and some are small:</p>
<pre><code class="language-lean">structure MythicalCreature where
  large : Bool
deriving Repr
</code></pre>
<p>Behind the scenes, defining the <code>MythicalCreature</code> structure creates an inductive type with a single constructor called <code>mk</code>:</p>
<pre><code class="language-lean">#check MythicalCreature.mk
</code></pre>
<pre><code class="language-output info">MythicalCreature.mk (large : Bool) : MythicalCreature
</code></pre>
<p>Similarly, a function <code>MythicalCreature.large</code> is created that actually extracts the field from the constructor:</p>
<pre><code class="language-lean">#check MythicalCreature.large
</code></pre>
<pre><code class="language-output info">MythicalCreature.large (self : MythicalCreature) : Bool
</code></pre>
<p>In most old stories, each monster can be defeated in some way.
A description of a monster should include this information, along with whether it is large:</p>
<pre><code class="language-lean">structure Monster extends MythicalCreature where
  vulnerability : String
deriving Repr
</code></pre>
<p>The <code>extends MythicalCreature</code> in the heading states that every monster is also mythical.
To define a <code>Monster</code>, both the fields from <code>MythicalCreature</code> and the fields from <code>Monster</code> should be provided.
A troll is a large monster that is vulnerable to sunlight:</p>
<pre><code class="language-lean">def troll : Monster where
  large := true
  vulnerability := &quot;sunlight&quot;
</code></pre>
<p>Behind the scenes, inheritance is implemented using composition.
The constructor <code>Monster.mk</code> takes a <code>MythicalCreature</code> as its argument:</p>
<pre><code class="language-lean">#check Monster.mk
</code></pre>
<pre><code class="language-output info">Monster.mk (toMythicalCreature : MythicalCreature) (vulnerability : String) : Monster
</code></pre>
<p>In addition to defining functions to extract the value of each new field, a function <code>Monster.toMythicalCreature</code> is defined with type <code>Monster → MythicalCreature</code>.
This can be used to extract the underlying creature.</p>
<p>Moving up the inheritance hierarchy in Lean is not the same thing as upcasting in object-oriented languages.
An upcast operator causes a value from a derived class to be treated as an instance of the parent class, but the value retains its identity and structure.
In Lean, however, moving up the inheritance hierarchy actually erases the underlying information.
To see this in action, consider the result of evaluating <code>troll.toMythicalCreature</code>:</p>
<pre><code class="language-lean">#eval troll.toMythicalCreature
</code></pre>
<pre><code class="language-output info">{ large := true }
</code></pre>
<p>Only the fields of <code>MythicalCreature</code> remain.</p>
<p>Just like the <code>where</code> syntax, curly-brace notation with field names also works with structure inheritance:</p>
<pre><code class="language-lean">def troll : Monster := {large := true, vulnerability := &quot;sunlight&quot;}
</code></pre>
<p>However, the anonymous angle-bracket notation that delegates to the underlying constructor reveals the internal details:</p>
<pre><code class="language-lean">def troll : Monster := ⟨true, &quot;sunlight&quot;⟩
</code></pre>
<pre><code class="language-output error">application type mismatch
  Monster.mk true
argument
  true
has type
  Bool : Type
but is expected to have type
  MythicalCreature : Type
</code></pre>
<p>An extra set of angle brackets is required, which invokes <code>MythicalCreature.mk</code> on <code>true</code>:</p>
<pre><code class="language-lean">def troll : Monster := ⟨⟨true⟩, &quot;sunlight&quot;⟩
</code></pre>
<p>Lean's dot notation is capable of taking inheritance into account.
In other words, the existing <code>MythicalCreature.large</code> can be used with a <code>Monster</code>, and Lean automatically inserts the call to <code>Monster.toMythicalCreature</code> before the call to <code>MythicalCreature.large</code>.
However, this only occurs when using dot notation, and applying the field lookup function using normal function call syntax results in a type error:</p>
<pre><code class="language-lean">#eval MythicalCreature.large troll
</code></pre>
<pre><code class="language-output error">application type mismatch
  troll.large
argument
  troll
has type
  Monster : Type
but is expected to have type
  MythicalCreature : Type
</code></pre>
<p>Dot notation can also take inheritance into account for user-defined functions.
A small creature is one that is not large:</p>
<pre><code class="language-lean">def MythicalCreature.small (c : MythicalCreature) : Bool := !c.large
</code></pre>
<p>Evaluating <code>troll.small</code> yields <code>false</code>, while attempting to evaluate <code>MythicalCreature.small troll</code> results in:</p>
<pre><code class="language-output error">application type mismatch
  MythicalCreature.small troll
argument
  troll
has type
  Monster : Type
but is expected to have type
  MythicalCreature : Type
</code></pre>
<h3 id="multiple-inheritance"><a class="header" href="#multiple-inheritance">Multiple Inheritance</a></h3>
<p>A helper is a mythical creature that can provide assistance when given the correct payment:</p>
<pre><code class="language-lean">structure Helper extends MythicalCreature where
  assistance : String
  payment : String
deriving Repr
</code></pre>
<p>For example, a <em>nisse</em> is a kind of small elf that's known to help around the house when provided with tasty porridge:</p>
<pre><code class="language-lean">def nisse : Helper where
  large := false
  assistance := &quot;household tasks&quot;
  payment := &quot;porridge&quot;
</code></pre>
<p>If domesticated, trolls make excellent helpers.
They are strong enough to plow a whole field in a single night, though they require model goats to keep them satisfied with their lot in life.
A monstrous assistant is a monster that is also a helper:</p>
<pre><code class="language-lean">structure MonstrousAssistant extends Monster, Helper where
deriving Repr
</code></pre>
<p>A value of this structure type must fill in all of the fields from both parent structures:</p>
<pre><code class="language-lean">def domesticatedTroll : MonstrousAssistant where
  large := false
  assistance := &quot;heavy labor&quot;
  payment := &quot;toy goats&quot;
  vulnerability := &quot;sunlight&quot;
</code></pre>
<p>Both of the parent structure types extend <code>MythicalCreature</code>.
If multiple inheritance were implemented naïvely, then this could lead to a &quot;diamond problem&quot;, where it would be unclear which path to <code>large</code> should be taken from a given <code>MonstrousAssistant</code>.
Should it take <code>large</code> from the contained <code>Monster</code> or from the contained <code>Helper</code>?
In Lean, the answer is that the first specified path to the grandparent structure is taken, and the additional parent structures' fields are copied rather than having the new structure include both parents directly.</p>
<p>This can be seen by examining the signature of the constructor for <code>MonstrousAssistant</code>:</p>
<pre><code class="language-lean">#check MonstrousAssistant.mk
</code></pre>
<pre><code class="language-output info">MonstrousAssistant.mk (toMonster : Monster) (assistance payment : String) : MonstrousAssistant
</code></pre>
<p>It takes a <code>Monster</code> as an argument, along with the two fields that <code>Helper</code> introduces on top of <code>MythicalCreature</code>.
Similarly, while <code>MonstrousAssistant.toMonster</code> merely extracts the <code>Monster</code> from the constructor, <code>MonstrousAssistant.toHelper</code> has no <code>Helper</code> to extract.
The <code>#print</code> command exposes its implementation:</p>
<pre><code class="language-lean">#print MonstrousAssistant.toHelper
</code></pre>
<pre><code class="language-output info">@[reducible] def MonstrousAssistant.toHelper : MonstrousAssistant → Helper :=
fun self =&gt;
  { toMythicalCreature := self.toMonster.toMythicalCreature, assistance := self.assistance, payment := self.payment }
</code></pre>
<p>This function constructs a <code>Helper</code> from the fields of <code>MonstrousAssistant</code>.
The <code>@[reducible]</code> attribute has the same effect as writing <code>abbrev</code>.</p>
<h3 id="default-declarations"><a class="header" href="#default-declarations">Default Declarations</a></h3>
<p>When one structure inherits from another, default field definitions can be used to instantiate the parent structure's fields based on the child structure's fields.
If more size specificity is required than whether a creature is large or not, a dedicated datatype describing sizes can be used together with inheritance, yielding a structure in which the <code>large</code> field is computed from the contents of the <code>size</code> field:</p>
<pre><code class="language-lean">inductive Size where
  | small
  | medium
  | large
deriving BEq

structure SizedCreature extends MythicalCreature where
  size : Size
  large := size == Size.large
</code></pre>
<p>This default definition is only a default definition, however.
Unlike property inheritance in a language like C# or Scala, the definitions in the child structure are only used when no specific value for <code>large</code> is provided, and nonsensical results can occur:</p>
<pre><code class="language-lean">def nonsenseCreature : SizedCreature where
  large := false
  size := .large
</code></pre>
<p>If the child structure should not deviate from the parent structure, there are a few options:</p>
<ol>
<li>Documenting the relationship, as is done for <code>BEq</code> and <code>Hashable</code></li>
<li>Defining a proposition that the fields are related appropriately, and designing the API to require evidence that the proposition is true where it matters</li>
<li>Not using inheritance at all</li>
</ol>
<p>The second option could look like this:</p>
<pre><code class="language-lean">abbrev SizesMatch (sc : SizedCreature) : Prop :=
  sc.large = (sc.size == Size.large)
</code></pre>
<p>Note that a single equality sign is used to indicate the equality <em>proposition</em>, while a double equality sign is used to indicate a function that checks equality and returns a <code>Bool</code>.
<code>SizesMatch</code> is defined as an <code>abbrev</code> because it should automatically be unfolded in proofs, so that <code>simp</code> can see the equality that should be proven.</p>
<p>A <em>huldre</em> is a medium-sized mythical creature—in fact, they are the same size as humans.
The two sized fields on <code>huldre</code> match one another:</p>
<pre><code class="language-lean">def huldre : SizedCreature where
  size := .medium

example : SizesMatch huldre := by
  simp
</code></pre>
<h3 id="type-class-inheritance"><a class="header" href="#type-class-inheritance">Type Class Inheritance</a></h3>
<p>Behind the scenes, type classes are structures.
Defining a new type class defines a new structure, and defining an instance creates a value of that structure type.
They are then added to internal tables in Lean that allow it to find the instances upon request.
A consequence of this is that type classes may inherit from other type classes.</p>
<p>Because it uses precisely the same language features, type class inheritance supports all the features of structure inheritance, including multiple inheritance, default implementations of parent types' methods, and automatic collapsing of diamonds.
This is useful in many of the same situations that multiple interface inheritance is useful in languages like Java, C# and Kotlin.
By carefully designing type class inheritance hierarchies, programmers can get the best of both worlds: a fine-grained collection of independently-implementable abstractions, and automatic construction of these specific abstractions from larger, more general abstractions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="applicative-functors"><a class="header" href="#applicative-functors">Applicative Functors</a></h1>
<p>An <em>applicative functor</em> is a functor that has two additional operations available: <code>pure</code> and <code>seq</code>.
<code>pure</code> is the same operator used in <code>Monad</code>, because <code>Monad</code> in fact inherits from <code>Applicative</code>.
<code>seq</code> is much like <code>map</code>: it allows a function to be used in order to transform the contents of a datatype.
However, with <code>seq</code>, the function is itself contained in the datatype: <code>f (α → β) → (Unit → f α) → f β</code>.
Having the function under the type <code>f</code> allows the <code>Applicative</code> instance to control how the function is applied, while <code>Functor.map</code> unconditionally applies a function.
The second argument has a type that begins with <code>Unit →</code> to allow the definition of <code>seq</code> to short-circuit in cases where the function will never be applied.</p>
<p>The value of this short-circuiting behavior can be seen in the instance of <code>Applicative Option</code>:</p>
<pre><code class="language-lean">instance : Applicative Option where
  pure x := .some x
  seq f x :=
    match f with
    | none =&gt; none
    | some g =&gt; g &lt;$&gt; x ()
</code></pre>
<p>In this case, if there is no function for <code>seq</code> to apply, then there is no need to compute its argument, so <code>x</code> is never called.
The same consideration informs the instance of <code>Applicative</code> for <code>Except</code>:</p>
<pre><code class="language-lean">instance : Applicative (Except ε) where
  pure x := .ok x
  seq f x :=
    match f with
    | .error e =&gt; .error e
    | .ok g =&gt; g &lt;$&gt; x ()
</code></pre>
<p>This short-circuiting behavior depends only on the <code>Option</code> or <code>Except</code> structures that <em>surround</em> the function, rather than on the function itself.</p>
<p>Monads can be seen as a way of capturing the notion of sequentially executing statements into a pure functional language.
The result of one statement can affect which further statements run.
This can be seen in the type of <code>bind</code>: <code>m α → (α → m β) → m β</code>.
The first statement's resulting value is an input into a function that computes the next statement to execute.
Successive uses of <code>bind</code> are like a sequence of statements in an imperative programming language, and <code>bind</code> is powerful enough to implement control structures like conditionals and loops.</p>
<p>Following this analogy, <code>Applicative</code> captures function application in a language that has side effects.
The arguments to a function in languages like Kotlin or C# are evaluated from left to right.
Side effects performed by earlier arguments occur before those performed by later arguments.
A function is not powerful enough to implement custom short-circuiting operators that depend on the specific <em>value</em> of an argument, however.</p>
<p>Typically, <code>seq</code> is not invoked directly.
Instead, the operator <code>&lt;*&gt;</code> is used.
This operator wraps its second argument in <code>fun () =&gt; ...</code>, simplifying the call site.
In other words, <code>E1 &lt;*&gt; E2</code> is syntactic sugar for <code>Seq.seq E1 (fun () =&gt; E2)</code>.</p>
<p>The key feature that allows <code>seq</code> to be used with multiple arguments is that a multiple-argument Lean function is really a single-argument function that returns another function that's waiting for the rest of the arguments.
In other words, if the first argument to <code>seq</code> is awaiting multiple arguments, then the result of the <code>seq</code> will be awaiting the rest.
For example, <code>some Plus.plus</code> can have the type <code>Option (Nat → Nat → Nat)</code>.
Providing one argument, <code>some Plus.plus &lt;*&gt; some 4</code>, results in the type <code>Option (Nat → Nat)</code>.
This can itself be used with <code>seq</code>, so <code>some Plus.plus &lt;*&gt; some 4 &lt;*&gt; some 7</code> has the type <code>Option Nat</code>.</p>
<p>Not every functor is applicative.
<code>Pair</code> is like the built-in product type <code>Prod</code>:</p>
<pre><code class="language-lean">structure Pair (α β : Type) : Type where
  first : α
  second : β
</code></pre>
<p>Like <code>Except</code>, <code>Pair</code> has type <code>Type → Type → Type</code>.
This means that <code>Pair α</code> has type <code>Type → Type</code>, and a <code>Functor</code> instance is possible:</p>
<pre><code class="language-lean">instance : Functor (Pair α) where
  map f x := ⟨x.first, f x.second⟩
</code></pre>
<p>This instance obeys the <code>Functor</code> contract.</p>
<p>The two properties to check are that <code>id &lt;$&gt; Pair.mk x y = Pair.mk x y</code> and that <code>f &lt;$&gt; g &lt;$&gt; Pair.mk x y = (f ∘ g) &lt;$&gt; Pair.mk x y</code>.
The first property can be checked by just stepping through the evaluation of the left side, and noticing that it evaluates to the right side:</p>
<pre><code class="language-lean">id &lt;$&gt; Pair.mk x y
===&gt;
Pair.mk x (id y)
===&gt;
Pair.mk x y
</code></pre>
<p>The second can be checked by stepping through both sides, and noting that they yield the same result:</p>
<pre><code class="language-lean">f &lt;$&gt; g &lt;$&gt; Pair.mk x y
===&gt;
f &lt;$&gt; Pair.mk x (g y)
===&gt;
Pair.mk x (f (g y))

(f ∘ g) &lt;$&gt; Pair.mk x y
===&gt;
Pair.mk x ((f ∘ g) y)
===&gt;
Pair.mk x (f (g y))
</code></pre>
<p>Attempting to define an <code>Applicative</code> instance, however, does not work so well.
It will require a definition of <code>pure</code>:</p>
<pre><code class="language-lean">def Pair.pure (x : β) : Pair α β := _
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
β α : Type
x : β
⊢ Pair α β
</code></pre>
<p>There is a value with type <code>β</code> in scope (namely <code>x</code>), and the error message from the underscore suggests that the next step is to use the constructor <code>Pair.mk</code>:</p>
<pre><code class="language-lean">def Pair.pure (x : β) : Pair α β := Pair.mk _ x
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder for argument 'first'
context:
β α : Type
x : β
⊢ α
</code></pre>
<p>Unfortunately, there is no <code>α</code> available.
Because <code>pure</code> would need to work for <em>all possible types</em> α to define an instance of <code>Applicative (Pair α)</code>, this is impossible.
After all, a caller could choose <code>α</code> to be <code>Empty</code>, which has no values at all.</p>
<h2 id="a-non-monadic-applicative"><a class="header" href="#a-non-monadic-applicative">A Non-Monadic Applicative</a></h2>
<p>When validating user input to a form, it's generally considered to be best to provide many errors at once, rather than one error at a time.
This allows the user to have an overview of what is needed to please the computer, rather than feeling badgered as they correct the errors field by field.</p>
<p>Ideally, validating user input will be visible in the type of the function that's doing the validating.
It should return a datatype that is specific—checking that a text box contains a number should return an actual numeric type, for instance.
A validation routine could throw an exception when the input does not pass validation.
Exceptions have a major drawback, however: they terminate the program at the first error, making it impossible to accumulate a list of errors.</p>
<p>On the other hand, the common design pattern of accumulating a list of errors and then failing when it is non-empty is also problematic.
A long nested sequences of <code>if</code> statements that validate each sub-section of the input data is hard to maintain, and it's easy to lose track of an error message or two.
Ideally, validation can be performed using an API that enables a new value to be returned yet automatically tracks and accumulates error messages.</p>
<p>An applicative functor called <code>Validate</code> provides one way to implement this style of API.
Like the <code>Except</code> monad, <code>Validate</code> allows a new value to be constructed that characterizes the validated data accurately.
Unlike <code>Except</code>, it allows multiple errors to be accumulated, without a risk of forgetting to check whether the list is empty.</p>
<h3 id="user-input"><a class="header" href="#user-input">User Input</a></h3>
<p>As an example of user input, take the following structure:</p>
<pre><code class="language-lean">structure RawInput where
  name : String
  birthYear : String
</code></pre>
<p>The business logic to be implemented is the following:</p>
<ol>
<li>The name may not be empty</li>
<li>The birth year must be numeric and non-negative</li>
<li>The birth year must be greater than 1900, and less than or equal to the year in which the form is validated</li>
</ol>
<p>Representing these as a datatype will require a new feature, called <em>subtypes</em>.
With this tool in hand, a validation framework can be written that uses an applicative functor to track errors, and these rules can be implemented in the framework.</p>
<h3 id="subtypes"><a class="header" href="#subtypes">Subtypes</a></h3>
<p>Representing these conditions is easiest with one additional Lean type, called <code>Subtype</code>:</p>
<pre><code class="language-lean">structure Subtype {α : Type} (p : α → Prop) where
  val : α
  property : p val
</code></pre>
<p>This structure has two type parameters: an implicit parameter that is the type of data <code>α</code>, and an explicit parameter <code>p</code> that is a predicate over <code>α</code>.
A <em>predicate</em> is a logical statement with a variable in it that can be replaced with a value to yield an actual statement, like the <a href="functor-applicative-monad/../type-classes/indexing.html#overloading-indexing">parameter to <code>GetElem</code></a> that describes what it means for an index to be in bounds for a lookup.
In the case of <code>Subtype</code>, the predicate slices out some subset of the values of <code>α</code> for which the predicate holds.
The structure's two fields are, respectively, a value from <code>α</code> and evidence that the value satisfies the predicate <code>p</code>.
Lean has special syntax for <code>Subtype</code>.
If <code>p</code> has type <code>α → Prop</code>, then the type <code>Subtype p</code> can also be written <code>{x : α // p x}</code>, or even <code>{x // p x}</code> when the type can be inferred automatically.</p>
<p><a href="functor-applicative-monad/../type-classes/pos.html">Representing positive numbers as inductive types</a> is clear and easy to program with.
However, it has a key disadvantage.
While <code>Nat</code> and <code>Int</code> have the structure of ordinary inductive types from the perspective of Lean programs, the compiler treats them specially and uses fast arbitrary-precision number libraries to implement them.
This is not the case for additional user-defined types.
However, a subtype of <code>Nat</code> that restricts it to non-zero numbers allows the new type to use the efficient representation while still ruling out zero at compile time:</p>
<pre><code class="language-lean">def FastPos : Type := {x : Nat // x &gt; 0}
</code></pre>
<p>The smallest fast positive number is still one.
Now, instead of being a constructor of an inductive type, it's an instance of a structure that's constructed with angle brackets.
The first argument is the underlying <code>Nat</code>, and the second argument is the evidence that said <code>Nat</code> is greater than zero:</p>
<pre><code class="language-leantac">def one : FastPos := ⟨1, by simp⟩
</code></pre>
<p>The <code>OfNat</code> instance is very much like that for <code>Pos</code>, except it uses a short tactic proof to provide evidence that <code>n + 1 &gt; 0</code>:</p>
<pre><code class="language-leantac">instance : OfNat FastPos (n + 1) where
  ofNat := ⟨n + 1, by simp_arith⟩
</code></pre>
<p>The <code>simp_arith</code> tactic is a version of <code>simp</code> that takes additional arithmetic identities into account.</p>
<p>Subtypes are a two-edged sword.
They allow efficient representation of validation rules, but they transfer the burden of maintaining these rules to the users of the library, who have to <em>prove</em> that they are not violating important invariants.
Generally, it's a good idea to use them internally to a library, providing an API to users that automatically ensures that all invariants are satisfied, with any necessary proofs being internal to the library.</p>
<p>Checking whether a value of type <code>α</code> is in the subtype <code>{x : α // p x}</code> usually requires that the proposition <code>p x</code> be decidable.
The <a href="functor-applicative-monad/../type-classes/standard-classes.html#equality-and-ordering">section on equality and ordering classes</a> describes how decidable propositions can be used with <code>if</code>.
When <code>if</code> is used with a decidable proposition, a name can be provided.
In the <code>then</code> branch, the name is bound to evidence that the proposition is true, and in the <code>else</code> branch, it is bound to evidence that the proposition is false.
This comes in handy when checking whether a given <code>Nat</code> is positive:</p>
<pre><code class="language-lean">def Nat.asFastPos? (n : Nat) : Option FastPos :=
  if h : n &gt; 0 then
    some ⟨n, h⟩
  else none
</code></pre>
<p>In the <code>then</code> branch, <code>h</code> is bound to evidence that <code>n &gt; 0</code>, and this evidence can be used as the second argument to <code>Subtype</code>'s constructor.</p>
<h3 id="validated-input"><a class="header" href="#validated-input">Validated Input</a></h3>
<p>The validated user input is a structure that expresses the business logic using multiple techniques:</p>
<ul>
<li>The structure type itself encodes the year in which it was checked for validity, so that <code>CheckedInput 2019</code> is not the same type as <code>CheckedInput 2020</code></li>
<li>The birth year is represented as a <code>Nat</code> rather than a <code>String</code></li>
<li>Subtypes are used to constrain the allowed values in the name and birth year fields</li>
</ul>
<pre><code class="language-lean">structure CheckedInput (thisYear : Nat) : Type where
  name : {n : String // n ≠ &quot;&quot;}
  birthYear : {y : Nat // y &gt; 1900 ∧ y ≤ thisYear}
</code></pre>
<p>An input validator should take the current year and a <code>RawInput</code> as arguments, returning either a checked input or at least one validation failure.
This is represented by the <code>Validate</code> type:</p>
<pre><code class="language-lean">inductive Validate (ε α : Type) : Type where
  | ok : α → Validate ε α
  | errors : NonEmptyList ε → Validate ε α
</code></pre>
<p>It looks very much like <code>Except</code>.
The only difference is that the <code>error</code> constructor may contain more than one failure.</p>
<p>Validate is a functor.
Mapping a function over it transforms any successful value that might be present, just as in the <code>Functor</code> instance for <code>Except</code>:</p>
<pre><code class="language-lean">instance : Functor (Validate ε) where
  map f
   | .ok x =&gt; .ok (f x)
   | .errors errs =&gt; .errors errs
</code></pre>
<p>The <code>Applicative</code> instance for <code>Validate</code> has an important difference from the instance for <code>Except</code>: while the instance for <code>Except</code> terminates at the first error encountered, the instance for <code>Validate</code> is careful to accumulate all errors from <em>both</em> the function and the argument branches:</p>
<pre><code class="language-lean">instance : Applicative (Validate ε) where
  pure := .ok
  seq f x :=
    match f with
    | .ok g =&gt; g &lt;$&gt; (x ())
    | .errors errs =&gt;
      match x () with
      | .ok _ =&gt; .errors errs
      | .errors errs' =&gt; .errors (errs ++ errs')
</code></pre>
<p>Using <code>.errors</code> together with the constructor for <code>NonEmptyList</code> is a bit verbose.
Helpers like <code>reportError</code> make code more readable.
In this application, error reports will consist of field names paired with messages:</p>
<pre><code class="language-lean">def Field := String

def reportError (f : Field) (msg : String) : Validate (Field × String) α :=
  .errors { head := (f, msg), tail := [] }
</code></pre>
<p>The <code>Applicative</code> instance for <code>Validate</code> allows the checking procedures for each field to be written independently and then composed.
Checking a name consists of ensuring that a string is non-empty, then returning evidence of this fact in the form of a <code>Subtype</code>.
This uses the evidence-binding version of <code>if</code>:</p>
<pre><code class="language-lean">def checkName (name : String) : Validate (Field × String) {n : String // n ≠ &quot;&quot;} :=
  if h : name = &quot;&quot; then
    reportError &quot;name&quot; &quot;Required&quot;
  else pure ⟨name, h⟩
</code></pre>
<p>In the <code>then</code> branch, <code>h</code> is bound to evidence that <code>name = &quot;&quot;</code>, while it is bound to evidence that <code>¬name = &quot;&quot;</code> in the <code>else</code> branch.</p>
<p>It's certainly the case that some validation errors make other checks impossible.
For example, it makes no sense to check whether the birth year field is greater than 1900 if a confused user wrote the word <code>&quot;syzygy&quot;</code> instead of a number.
Checking the allowed range of the number is only meaningful after ensuring that the field in fact contains a number.
This can be expressed using the function <code>andThen</code>:</p>
<pre><code class="language-lean">def Validate.andThen (val : Validate ε α) (next : α → Validate ε β) : Validate ε β :=
  match val with
  | .errors errs =&gt; .errors errs
  | .ok x =&gt; next x
</code></pre>
<p>While this function's type signature makes it suitable to be used as <code>bind</code> in a <code>Monad</code> instance, there are good reasons not to do so.
They are described <a href="functor-applicative-monad/applicative-contract.html#additional-stipulations">in the section that describes the <code>Applicative</code> contract</a>.</p>
<p>To check that the birth year is a number, a built-in function called <code>String.toNat? : String → Option Nat</code> is useful.
It's most user-friendly to eliminate leading and trailing whitespace first using <code>String.trim</code>:</p>
<pre><code class="language-lean">def checkYearIsNat (year : String) : Validate (Field × String) Nat :=
  match year.trim.toNat? with
  | none =&gt; reportError &quot;birth year&quot; &quot;Must be digits&quot;
  | some n =&gt; pure n
</code></pre>
<p>To check that the provided year is in the expected range, nested uses of the evidence-providing form of <code>if</code> are in order:</p>
<pre><code class="language-leantac">def checkBirthYear (thisYear year : Nat) : Validate (Field × String) {y : Nat // y &gt; 1900 ∧ y ≤ thisYear} :=
  if h : year &gt; 1900 then
    if h' : year ≤ thisYear then
      pure ⟨year, by simp [*]⟩
    else reportError &quot;birth year&quot; s!&quot;Must be no later than {thisYear}&quot;
  else reportError &quot;birth year&quot; &quot;Must be after 1900&quot;
</code></pre>
<p>Finally, these three components can be combined using <code>seq</code>:</p>
<pre><code class="language-lean">def checkInput (year : Nat) (input : RawInput) : Validate (Field × String) (CheckedInput year) :=
  pure CheckedInput.mk &lt;*&gt;
    checkName input.name &lt;*&gt;
    (checkYearIsNat input.birthYear).andThen fun birthYearAsNat =&gt;
      checkBirthYear year birthYearAsNat
</code></pre>
<p>Testing <code>checkInput</code> shows that it can indeed return multiple pieces of feedback:</p>
<pre><code class="language-lean">#eval checkInput 2023 {name := &quot;David&quot;, birthYear := &quot;1984&quot;}
</code></pre>
<pre><code class="language-output info">Validate.ok { name := &quot;David&quot;, birthYear := 1984 }
</code></pre>
<pre><code class="language-lean">#eval checkInput 2023 {name := &quot;&quot;, birthYear := &quot;2045&quot;}
</code></pre>
<pre><code class="language-output info">Validate.errors { head := (&quot;name&quot;, &quot;Required&quot;), tail := [(&quot;birth year&quot;, &quot;Must be no later than 2023&quot;)] }
</code></pre>
<pre><code class="language-lean">#eval checkInput 2023 {name := &quot;David&quot;, birthYear := &quot;syzygy&quot;}
</code></pre>
<pre><code class="language-output info">Validate.errors { head := (&quot;birth year&quot;, &quot;Must be digits&quot;), tail := [] }
</code></pre>
<p>Form validation with <code>checkInput</code> illustrates a key advantage of <code>Applicative</code> over <code>Monad</code>.
Because <code>&gt;&gt;=</code> provides enough power to modify the rest of the program's execution based on the value from the first step, it <em>must</em> receive a value from the first step to pass on.
If no value is received (e.g. because an error has occurred), then <code>&gt;&gt;=</code> cannot execute the rest of the program.
<code>Validate</code> demonstrates why it can be useful to run the rest of the program anyway: in cases where the earlier data isn't needed, running the rest of the program can yield useful information (in this case, more validation errors).
<code>Applicative</code>'s <code>&lt;*&gt;</code> may run both of its arguments before recombining the results.
Similarly, <code>&gt;&gt;=</code> forces sequential execution.
Each step must complete before the next may run.
This is generally useful, but it makes it impossible to have parallel execution of different threads that naturally emerges from the program's actual data dependencies.
A more powerful abstraction like <code>Monad</code> increases the flexibility that's available to the API consumer, but it decreases the flexibility that is available to the API implementor.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-applicative-contract"><a class="header" href="#the-applicative-contract">The Applicative Contract</a></h1>
<p>Just like <code>Functor</code>, <code>Monad</code>, and types that implement <code>BEq</code> and <code>Hashable</code>, <code>Applicative</code> has a set of rules that all instances should adhere to.</p>
<p>There are four rules that an applicative functor should follow:</p>
<ol>
<li>It should respect identity, so <code>pure id &lt;*&gt; v = v</code></li>
<li>It should respect function composition, so <code>pure (· ∘ ·) &lt;*&gt; u &lt;*&gt; v &lt;*&gt; w = u &lt;*&gt; (v &lt;*&gt; w)</code></li>
<li>Sequencing pure operations should be a no-op, so <code>pure f &lt;*&gt; pure x = pure (f x)</code></li>
<li>The ordering of pure operations doesn't matter, so <code>u &lt;*&gt; pure x = pure (fun f =&gt; f x) &lt;*&gt; u</code></li>
</ol>
<p>To check these for the <code>Applicative Option</code> instance, start by expanding <code>pure</code> into <code>some</code>.</p>
<p>The first rule states that <code>some id &lt;*&gt; v = v</code>.
The definition of <code>seq</code> for <code>Option</code> states that this is the same as <code>id &lt;$&gt; v = v</code>, which is one of the <code>Functor</code> rules that have already been checked.</p>
<p>The second rule states that <code>some (· ∘ ·) &lt;*&gt; u &lt;*&gt; v &lt;*&gt; w = u &lt;*&gt; (v &lt;*&gt; w)</code>.
If any of <code>u</code>, <code>v</code>, or <code>w</code> is <code>none</code>, then both sides are <code>none</code>, so the property holds.
Assuming that <code>u</code> is <code>some f</code>, that <code>v</code> is <code>some g</code>, and that <code>w</code> is <code>some x</code>, then this is equivalent to saying that <code>some (· ∘ ·) &lt;*&gt; some f &lt;*&gt; some g &lt;*&gt; some x = some f &lt;*&gt; (some g &lt;*&gt; some x)</code>.
Evaluating the two sides yields the same result:</p>
<pre><code class="language-lean">some (· ∘ ·) &lt;*&gt; some f &lt;*&gt; some g &lt;*&gt; some x
===&gt;
some (f ∘ ·) &lt;*&gt; some g &lt;*&gt; some x
===&gt;
some (f ∘ g) &lt;*&gt; some x
===&gt;
some ((f ∘ g) x)
===&gt;
some (f (g x))

some f &lt;*&gt; (some g &lt;*&gt; some x)
===&gt;
some f &lt;*&gt; (some (g x))
===&gt;
some (f (g x))
</code></pre>
<p>The third rule follows directly from the definition of <code>seq</code>:</p>
<pre><code class="language-lean">some f &lt;*&gt; some x
===&gt;
f &lt;$&gt; some x
===&gt;
some (f x)
</code></pre>
<p>In the fourth case, assume that <code>u</code> is <code>some f</code>, because if it's <code>none</code>, both sides of the equation are <code>none</code>.
<code>some f &lt;*&gt; some x</code> evaluates directly to <code>some (f x)</code>, as does <code>some (fun g =&gt; g x) &lt;*&gt; some f</code>.</p>
<h2 id="all-applicatives-are-functors"><a class="header" href="#all-applicatives-are-functors">All Applicatives are Functors</a></h2>
<p>The two operators for <code>Applicative</code> are enough to define <code>map</code>:</p>
<pre><code class="language-lean">def map [Applicative f] (g : α → β) (x : f α) : f β :=
  pure g &lt;*&gt; x
</code></pre>
<p>This can only be used to implement <code>Functor</code> if the contract for <code>Applicative</code> guarantees the contract for <code>Functor</code>, however.
The first rule of <code>Functor</code> is that <code>id &lt;$&gt; x = x</code>, which follows directly from the first rule for <code>Applicative</code>.
The second rule of <code>Functor</code> is that <code>map (f ∘ g) x = map f (map g x)</code>.
Unfolding the definition of <code>map</code> here results in <code>pure (f ∘ g) &lt;*&gt; x = pure f &lt;*&gt; (pure g &lt;*&gt; x)</code>.
Using the rule that sequencing pure operations is a no-op, the left side can be rewritten to <code>pure (· ∘ ·) &lt;*&gt; pure f &lt;*&gt; pure g &lt;*&gt; x</code>.
This is an instance of the rule that states that applicative functors respect function composition.</p>
<p>This justifies a definition of <code>Applicative</code> that extends <code>Functor</code>, with a default definition of <code>map</code> given in terms of <code>pure</code> and <code>seq</code>:</p>
<pre><code class="language-lean">class Applicative (f : Type → Type) extends Functor f where
  pure : α → f α
  seq : f (α → β) → (Unit → f α) → f β
  map g x := seq (pure g) (fun () =&gt; x)
</code></pre>
<h2 id="all-monads-are-applicative-functors"><a class="header" href="#all-monads-are-applicative-functors">All Monads are Applicative Functors</a></h2>
<p>An instance of <code>Monad</code> already requires an implementation of <code>pure</code>.
Together with <code>bind</code>, this is enough to define <code>seq</code>:</p>
<pre><code class="language-lean">def seq [Monad m] (f : m (α → β)) (x : Unit → m α) : m β := do
  let g ← f
  let y ← x ()
  pure (g y)
</code></pre>
<p>Once again, checking that the <code>Monad</code> contract implies the <code>Applicative</code> contract will allow this to be used as a default definition for <code>seq</code> if <code>Monad</code> extends <code>Applicative</code>.</p>
<p>The rest of this section consists of an argument that this implementation of <code>seq</code> based on <code>bind</code> in fact satisfies the <code>Applicative</code> contract.
One of the beautiful things about functional programming is that this kind of argument can be worked out on a piece of paper with a pencil, using the kinds of evaluation rules from <a href="functor-applicative-monad/../getting-to-know/evaluating.html">the initial section on evaluating expressions</a>.
Thinking about the meanings of the operations while reading these arguments can sometimes help with understanding.</p>
<p>Replacing <code>do</code>-notation with explicit uses of <code>&gt;&gt;=</code> makes it easier to apply the <code>Monad</code> rules:</p>
<pre><code class="language-lean">def seq [Monad m] (f : m (α → β)) (x : Unit → m α) : m β := do
  f &gt;&gt;= fun g =&gt;
  x () &gt;&gt;= fun y =&gt;
  pure (g y)
</code></pre>
<p>To check that this definition respects identity, check that <code>seq (pure id) (fun () =&gt; v) = v</code>.
The left hand side is equivalent to <code>pure id &gt;&gt;= fun g =&gt; (fun () =&gt; v) () &gt;&gt;= fun y =&gt; pure (g y)</code>.
The unit function in the middle can be eliminated immediately, yielding <code>pure id &gt;&gt;= fun g =&gt; v &gt;&gt;= fun y =&gt; pure (g y)</code>.
Using the fact that <code>pure</code> is a left identity of <code>&gt;&gt;=</code>, this is the same as <code>v &gt;&gt;= fun y =&gt; pure (id y)</code>, which is <code>v &gt;&gt;= fun y =&gt; pure y</code>.
Because <code>fun x =&gt; f x</code> is the same as <code>f</code>, this is the same as <code>v &gt;&gt;= pure</code>, and the fact that <code>pure</code> is a right identity of <code>&gt;&gt;=</code> can be used to get <code>v</code>.</p>
<p>This kind of informal reasoning can be made easier to read with a bit of reformatting.
In the following chart, read &quot;EXPR1 ={ REASON }= EXPR2&quot; as &quot;EXPR1 is the same as EXPR2 because REASON&quot;:</p>
<div class="equational">
<div class="term">
<pre><code class="language-lean hljs">pure id >>= fun g => v >>= fun y => pure (g y)</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">pure</code> is a left identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">v >>= fun y => pure (id y)</code></pre>
</div>
<div class="explanation">
={ <em>Reduce the call to <code class="hljs">id</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">v >>= fun y => pure y</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">fun x => f x</code> is the same as <code class="hljs">f</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">v >>= pure</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">pure</code> is a right identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">v</code></pre>
</div>
</div>
<p>To check that it respects function composition, check that <code>pure (· ∘ ·) &lt;*&gt; u &lt;*&gt; v &lt;*&gt; w = u &lt;*&gt; (v &lt;*&gt; w)</code>.
The first step is to replace <code>&lt;*&gt;</code> with this definition of <code>seq</code>.
After that, a (somewhat long) series of steps that use the identity and associativity rules from the <code>Monad</code> contract is enough to get from one to the other:</p>
<div class="equational">
<div class="term">
<pre><code class="language-lean hljs">seq (seq (seq (pure (· ∘ ·)) (fun _ => u))
      (fun _ => v))
  (fun _ => w)</code></pre>
</div>
<div class="explanation">
={ <em>Definition of <code class="hljs">seq</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">((pure (· ∘ ·) >>= fun f =>
   u >>= fun x =>
   pure (f x)) >>= fun g =>
  v >>= fun y =>
  pure (g y)) >>= fun h =>
 w >>= fun z =>
 pure (h z)</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">pure</code> is a left identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">((u >>= fun x =>
   pure (x ∘ ·)) >>= fun g =>
   v >>= fun y =>
  pure (g y)) >>= fun h =>
 w >>= fun z =>
 pure (h z)</code></pre>
</div>
<div class="explanation">
={ <em>Insertion of parentheses for clarity</em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">((u >>= fun x =>
   pure (x ∘ ·)) >>= (fun g =>
   v >>= fun y =>
  pure (g y))) >>= fun h =>
 w >>= fun z =>
 pure (h z)</code></pre>
</div>
<div class="explanation">
={ <em>Associativity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">(u >>= fun x =>
  pure (x ∘ ·) >>= fun g =>
 v  >>= fun y => pure (g y)) >>= fun h =>
 w >>= fun z =>
 pure (h z)</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">pure</code> is a left identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">(u >>= fun x =>
  v >>= fun y =>
  pure (x ∘ y)) >>= fun h =>
 w >>= fun z =>
 pure (h z)</code></pre>
</div>
<div class="explanation">
={ <em>Associativity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun x =>
v >>= fun y =>
pure (x ∘ y) >>= fun h =>
w >>= fun z =>
pure (h z)</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">pure</code> is a left identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun x =>
v >>= fun y =>
w >>= fun z =>
pure ((x ∘ y) z)</code></pre>
</div>
<div class="explanation">
={ <em>Definition of function composition</em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun x =>
v >>= fun y =>
w >>= fun z =>
pure (x (y z))</code></pre>
</div>
<div class="explanation">
={ <em>Time to start moving backwards!<code class="hljs">pure</code> is a left identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun x =>
v >>= fun y =>
w >>= fun z =>
pure (y z) >>= fun q =>
pure (x q)</code></pre>
</div>
<div class="explanation">
={ <em>Associativity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun x =>
v >>= fun y =>
 (w >>= fun p =>
  pure (y p)) >>= fun q =>
 pure (x q)</code></pre>
</div>
<div class="explanation">
={ <em>Associativity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun x =>
 (v >>= fun y =>
  w >>= fun q =>
  pure (y q)) >>= fun z =>
 pure (x z)</code></pre>
</div>
<div class="explanation">
={ <em>This includes the definition of <code class="hljs">seq</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun x =>
seq v (fun () => w) >>= fun q =>
pure (x q)</code></pre>
</div>
<div class="explanation">
={ <em>This also includes the definition of <code class="hljs">seq</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">seq u (fun () => seq v (fun () => w))</code></pre>
</div>
</div>
<p>To check that sequencing pure operations is a no-op:</p>
<div class="equational">
<div class="term">
<pre><code class="language-lean hljs">seq (pure f) (fun () => pure x)</code></pre>
</div>
<div class="explanation">
={ <em>Replacing <code class="hljs">seq</code> with its definition</em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">pure f >>= fun g =>
pure x >>= fun y =>
pure (g y)</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">pure</code> is a left identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">pure f >>= fun g =>
pure (g x)</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">pure</code> is a left identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">pure (f x)</code></pre>
</div>
</div>
<p>And finally, to check that the ordering of pure operations doesn't matter:</p>
<div class="equational">
<div class="term">
<pre><code class="language-lean hljs">seq u (fun () => pure x)</code></pre>
</div>
<div class="explanation">
={ <em>Definition of <code class="hljs">seq</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun f =>
pure x >>= fun y =>
pure (f y)</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">pure</code> is a left identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun f =>
pure (f x)</code></pre>
</div>
<div class="explanation">
={ <em>Clever replacement of one expression by an equivalent one that makes the rule match</em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">u >>= fun f =>
pure ((fun g => g x) f)</code></pre>
</div>
<div class="explanation">
={ <em><code class="hljs">pure</code> is a left identity of <code class="hljs">>>=</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">pure (fun g => g x) >>= fun h =>
u >>= fun f =>
pure (h f)</code></pre>
</div>
<div class="explanation">
={ <em>Definition of <code class="hljs">seq</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">seq (pure (fun f => f x)) (fun () => u)</code></pre>
</div>
</div>
<p>This justifies a definition of <code>Monad</code> that extends <code>Applicative</code>, with a default definition of <code>seq</code>:</p>
<pre><code class="language-lean">class Monad (m : Type → Type) extends Applicative m where
  bind : m α → (α → m β) → m β
  seq f x :=
    bind f fun g =&gt;
    bind (x ()) fun y =&gt;
    pure (g y)
</code></pre>
<p><code>Applicative</code>'s own default definition of <code>map</code> means that every <code>Monad</code> instance automatically generates <code>Applicative</code> and <code>Functor</code> instances as well.</p>
<h2 id="additional-stipulations"><a class="header" href="#additional-stipulations">Additional Stipulations</a></h2>
<p>In addition to adhering to the individual contracts associated with each type class, combined implementations <code>Functor</code>, <code>Applicative</code> and <code>Monad</code> should work equivalently to these default implementations.
In other words, a type that provides both <code>Applicative</code> and <code>Monad</code> instances should not have an implementation of <code>seq</code> that works differently from the version that the <code>Monad</code> instance generates as a default implementation.
This is important because polymorphic functions may be refactored to replace a use of <code>&gt;&gt;=</code> with an equivalent use of <code>&lt;*&gt;</code>, or a use of <code>&lt;*&gt;</code> with an equivalent use of <code>&gt;&gt;=</code>.
This refactoring should not change the meaning of programs that use this code.</p>
<p>This rule explains why <code>Validate.andThen</code> should not be used to implement <code>bind</code> in a <code>Monad</code> instance.
On its own, it obeys the monad contract.
However, when it is used to implement <code>seq</code>, the behavior is not equivalent to <code>seq</code> itself.
To see where they differ, take the example of two computations, both of which return errors.
Start with an example of a case where two errors should be returned, one from validating a function (which could have just as well resulted from a prior argument to the function), and one from validating an argument:</p>
<pre><code class="language-lean">def notFun : Validate String (Nat → String) :=
  .errors { head := &quot;First error&quot;, tail := [] }

def notArg : Validate String Nat :=
  .errors { head := &quot;Second error&quot;, tail := [] }
</code></pre>
<p>Combining them with the version of <code>&lt;*&gt;</code> from <code>Validate</code>'s <code>Applicative</code> instance results in both errors being reported to the user:</p>
<pre><code class="language-lean">notFun &lt;*&gt; notArg
===&gt;
match notFun with
| .ok g =&gt; g &lt;$&gt; notArg
| .errors errs =&gt;
  match notArg with
  | .ok _ =&gt; .errors errs
  | .errors errs' =&gt; .errors (errs ++ errs')
===&gt;
match notArg with
| .ok _ =&gt; .errors { head := &quot;First error&quot;, tail := [] }
| .errors errs' =&gt; .errors ({ head := &quot;First error&quot;, tail := [] } ++ errs')
===&gt;
.errors ({ head := &quot;First error&quot;, tail := [] } ++ { head := &quot;Second error&quot;, tail := []})
===&gt;
.errors { head := &quot;First error&quot;, tail := [&quot;Second error&quot;]}
</code></pre>
<p>Using the version of <code>seq</code> that was implemented with <code>&gt;&gt;=</code>, here rewritten to <code>andThen</code>, results in only the first error being available:</p>
<pre><code class="language-lean">seq notFun (fun () =&gt; notArg)
===&gt;
notFun.andThen fun g =&gt;
notArg.andThen fun y =&gt;
pure (g y)
===&gt;
match notFun with
| .errors errs =&gt; .errors errs
| .ok val =&gt;
  (fun g =&gt;
    notArg.andThen fun y =&gt;
    pure (g y)) val
===&gt;
.errors { head := &quot;First error&quot;, tail := [] }
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="alternatives"><a class="header" href="#alternatives">Alternatives</a></h1>
<h2 id="recovery-from-failure"><a class="header" href="#recovery-from-failure">Recovery from Failure</a></h2>
<p><code>Validate</code> can also be used in situations where there is more than one way for input to be acceptable.
For the input form <code>RawInput</code>, an alternative set of business rules that implement conventions from a legacy system might be the following:</p>
<ol>
<li>All human users must provide a birth year that is four digits.</li>
<li>Users born prior to 1970 do not need to provide names, due to incomplete older records.</li>
<li>Users born after 1970 must provide names.</li>
<li>Companies should enter <code>&quot;FIRM&quot;</code> as their year of birth and provide a company name.</li>
</ol>
<p>No particular provision is made for users born in 1970.
It is expected that they will either give up, lie about their year of birth, or call.
The company considers this an acceptable cost of doing business.</p>
<p>The following inductive type captures the values that can be produced from these stated rules:</p>
<pre><code class="language-lean">abbrev NonEmptyString := {s : String // s ≠ &quot;&quot;}

inductive LegacyCheckedInput where
  | humanBefore1970 :
    (birthYear : {y : Nat // y &gt; 999 ∧ y &lt; 1970}) →
    String →
    LegacyCheckedInput
  | humanAfter1970 :
    (birthYear : {y : Nat // y &gt; 1970}) →
    NonEmptyString →
    LegacyCheckedInput
  | company :
    NonEmptyString →
    LegacyCheckedInput
deriving Repr
</code></pre>
<p>A validator for these rules is more complicated, however, as it must address all three cases.
While it can be written as a series of nested <code>if</code> expressions, it's easier to design the three cases independently and then combine them.
This requires a means of recovering from failure while preserving error messages:</p>
<pre><code class="language-lean">def Validate.orElse (a : Validate ε α) (b : Unit → Validate ε α) : Validate ε α :=
  match a with
  | .ok x =&gt; .ok x
  | .errors errs1 =&gt;
    match b () with
    | .ok x =&gt; .ok x
    | .errors errs2 =&gt; .errors (errs1 ++ errs2)
</code></pre>
<p>This pattern of recovery from failures is common enough that Lean has built-in syntax for it, attached to a type class named <code>OrElse</code>:</p>
<pre><code class="language-lean">class OrElse (α : Type) where
  orElse : α → (Unit → α) → α
</code></pre>
<p>The expression <code>E1 &lt;|&gt; E2</code> is short for <code>OrElse.orElse E1 (fun () =&gt; E2)</code>.
An instance of <code>OrElse</code> for <code>Validate</code> allows this syntax to be used for error recovery:</p>
<pre><code class="language-lean">instance : OrElse (Validate ε α) where
  orElse := Validate.orElse
</code></pre>
<p>The validator for <code>LegacyCheckedInput</code> can be built from a validator for each constructor.
The rules for a company state that the birth year should be the string <code>&quot;FIRM&quot;</code> and that the name should be non-empty.
The constructor <code>LegacyCheckedInput.company</code>, however, has no representation of the birth year at all, so there's no easy way to carry it out using <code>&lt;*&gt;</code>.
The key is to use a function with <code>&lt;*&gt;</code> that ignores its argument.</p>
<p>Checking that a Boolean condition holds without recording any evidence of this fact in a type can be accomplished with <code>checkThat</code>:</p>
<pre><code class="language-lean">def checkThat (condition : Bool) (field : Field) (msg : String) : Validate (Field × String) Unit :=
  if condition then pure () else reportError field msg
</code></pre>
<p>This definition of <code>checkCompany</code> uses <code>checkThat</code>, and then throws away the resulting <code>Unit</code> value:</p>
<pre><code class="language-lean">def checkCompany (input : RawInput) : Validate (Field × String) LegacyCheckedInput :=
  pure (fun () name =&gt; .company name) &lt;*&gt;
    checkThat (input.birthYear == &quot;FIRM&quot;) &quot;birth year&quot; &quot;FIRM if a company&quot; &lt;*&gt;
    checkName input.name
</code></pre>
<p>However, this definition is quite noisy.
It can be simplified in two ways.
The first is to replace the first use of <code>&lt;*&gt;</code> with a specialized version that automatically ignores the value returned by the first argument, called <code>*&gt;</code>.
This operator is also controlled by a type class, called <code>SeqRight</code>, and <code>E1 *&gt; E2</code> is syntactic sugar for <code>SeqRight.seqRight E1 (fun () =&gt; E2)</code>:</p>
<pre><code class="language-lean">class SeqRight (f : Type → Type) where
  seqRight : f α → (Unit → f β) → f β
</code></pre>
<p>There is a default implementation of <code>seqRight</code> in terms of <code>seq</code>: <code>seqRight (a : f α) (b : Unit → f β) : f β := pure (fun _ x =&gt; x) &lt;*&gt; a &lt;*&gt; b ()</code>.</p>
<p>Using <code>seqRight</code>, <code>checkCompany</code> becomes simpler:</p>
<pre><code class="language-lean">def checkCompany (input : RawInput) : Validate (Field × String) LegacyCheckedInput :=
  checkThat (input.birthYear == &quot;FIRM&quot;) &quot;birth year&quot; &quot;FIRM if a company&quot; *&gt;
  pure .company &lt;*&gt; checkName input.name
</code></pre>
<p>One more simplification is possible.
For every <code>Applicative</code>, <code>pure F &lt;*&gt; E</code> is equivalent to <code>f &lt;$&gt; E</code>.
In other words, using <code>seq</code> to apply a function that was placed into the <code>Applicative</code> type using <code>pure</code> is overkill, and the function could have just been applied using <code>Functor.map</code>.
This simplification yields:</p>
<pre><code class="language-lean">def checkCompany (input : RawInput) : Validate (Field × String) LegacyCheckedInput :=
  checkThat (input.birthYear == &quot;FIRM&quot;) &quot;birth year&quot; &quot;FIRM if a company&quot; *&gt;
  .company &lt;$&gt; checkName input.name
</code></pre>
<p>The remaining two constructors of <code>LegacyCheckedInput</code> use subtypes for their fields.
A general-purpose tool for checking subtypes will make these easier to read:</p>
<pre><code class="language-lean">def checkSubtype {α : Type} (v : α) (p : α → Prop) [Decidable (p v)] (err : ε) : Validate ε {x : α // p x} :=
  if h : p v then
    pure ⟨v, h⟩
  else
    .errors { head := err, tail := [] }
</code></pre>
<p>In the function's argument list, it's important that the type class <code>[Decidable (p v)]</code> occur after the specification of the arguments <code>v</code> and <code>p</code>.
Otherwise, it would refer to an additional set of automatic implicit arguments, rather than to the manually-provided values.
The <code>Decidable</code> instance is what allows the proposition <code>p v</code> to be checked using <code>if</code>.</p>
<p>The two human cases do not need any additional tools:</p>
<pre><code class="language-lean">def checkHumanBefore1970 (input : RawInput) : Validate (Field × String) LegacyCheckedInput :=
  (checkYearIsNat input.birthYear).andThen fun y =&gt;
    .humanBefore1970 &lt;$&gt;
      checkSubtype y (fun x =&gt; x &gt; 999 ∧ x &lt; 1970) (&quot;birth year&quot;, &quot;less than 1970&quot;) &lt;*&gt;
      pure input.name

def checkHumanAfter1970 (input : RawInput) : Validate (Field × String) LegacyCheckedInput :=
  (checkYearIsNat input.birthYear).andThen fun y =&gt;
    .humanAfter1970 &lt;$&gt;
      checkSubtype y (· &gt; 1970) (&quot;birth year&quot;, &quot;greater than 1970&quot;) &lt;*&gt;
      checkName input.name
</code></pre>
<p>The validators for the three cases can be combined using <code>&lt;|&gt;</code>:</p>
<pre><code class="language-lean">def checkLegacyInput (input : RawInput) : Validate (Field × String) LegacyCheckedInput :=
  checkCompany input &lt;|&gt; checkHumanBefore1970 input &lt;|&gt; checkHumanAfter1970 input
</code></pre>
<p>The successful cases return constructors of <code>LegacyCheckedInput</code>, as expected:</p>
<pre><code class="language-lean">#eval checkLegacyInput ⟨&quot;Johnny's Troll Groomers&quot;, &quot;FIRM&quot;⟩
</code></pre>
<pre><code class="language-output info">Validate.ok (LegacyCheckedInput.company &quot;Johnny's Troll Groomers&quot;)
</code></pre>
<pre><code class="language-lean">#eval checkLegacyInput ⟨&quot;Johnny&quot;, &quot;1963&quot;⟩
</code></pre>
<pre><code class="language-output info">Validate.ok (LegacyCheckedInput.humanBefore1970 1963 &quot;Johnny&quot;)
</code></pre>
<pre><code class="language-lean">#eval checkLegacyInput ⟨&quot;&quot;, &quot;1963&quot;⟩
</code></pre>
<pre><code class="language-output info">Validate.ok (LegacyCheckedInput.humanBefore1970 1963 &quot;&quot;)
</code></pre>
<p>The worst possible input returns all the possible failures:</p>
<pre><code class="language-lean">#eval checkLegacyInput ⟨&quot;&quot;, &quot;1970&quot;⟩
</code></pre>
<pre><code class="language-output info">Validate.errors
  { head := (&quot;birth year&quot;, &quot;FIRM if a company&quot;),
    tail := [(&quot;name&quot;, &quot;Required&quot;),
             (&quot;birth year&quot;, &quot;less than 1970&quot;),
             (&quot;birth year&quot;, &quot;greater than 1970&quot;),
             (&quot;name&quot;, &quot;Required&quot;)] }
</code></pre>
<h2 id="the-alternative-class"><a class="header" href="#the-alternative-class">The <code>Alternative</code> Class</a></h2>
<p>Many types support a notion of failure and recovery.
The <code>Many</code> monad from the section on <a href="functor-applicative-monad/../monads/arithmetic.html#nondeterministic-search">evaluating arithmetic expressions in a variety of monads</a> is one such type, as is <code>Option</code>.
Both support failure without providing a reason (unlike, say, <code>Except</code> and <code>Validate</code>, which require some indication of what went wrong).</p>
<p>The <code>Alternative</code> class describes applicative functors that have additional operators for failure and recovery:</p>
<pre><code class="language-lean">class Alternative (f : Type → Type) extends Applicative f where
  failure : f α
  orElse : f α → (Unit → f α) → f α
</code></pre>
<p>Just as implementors of <code>Add α</code> get <code>HAdd α α α</code> instances for free, implementors of <code>Alternative</code> get <code>OrElse</code> instances for free:</p>
<pre><code class="language-lean">instance [Alternative f] : OrElse (f α) where
  orElse := Alternative.orElse
</code></pre>
<p>The implementation of <code>Alternative</code> for <code>Option</code> keeps the first none-<code>none</code> argument:</p>
<pre><code class="language-lean">instance : Alternative Option where
  failure := none
  orElse
    | some x, _ =&gt; some x
    | none, y =&gt; y ()
</code></pre>
<p>Similarly, the implementation for <code>Many</code> follows the general structure of <code>Many.union</code>, with minor differences due to the laziness-inducing <code>Unit</code> parameters being placed differently:</p>
<pre><code class="language-lean">def Many.orElse : Many α → (Unit → Many α) → Many α
  | .none, ys =&gt; ys ()
  | .more x xs, ys =&gt; .more x (fun () =&gt; orElse (xs ()) ys)

instance : Alternative Many where
  failure := .none
  orElse := Many.orElse
</code></pre>
<p>Like other type classes, <code>Alternative</code> enables the definition of a variety of operations that work for <em>any</em> applicative functor that implements <code>Alternative</code>.
One of the most important is <code>guard</code>, which causes <code>failure</code> when a decidable proposition is false:</p>
<pre><code class="language-lean">def guard [Alternative f] (p : Prop) [Decidable p] : f Unit :=
  if p then
    pure ()
  else failure
</code></pre>
<p>It is very useful in monadic programs to terminate execution early.
In <code>Many</code>, it can be used to filter out a whole branch of a search, as in the following program that computes all even divisors of a natural number:</p>
<pre><code class="language-lean">def Many.countdown : Nat → Many Nat
  | 0 =&gt; .none
  | n + 1 =&gt; .more n (fun () =&gt; countdown n)

def evenDivisors (n : Nat) : Many Nat := do
  let k ← Many.countdown (n + 1)
  guard (k % 2 = 0)
  guard (n % k = 0)
  pure k
</code></pre>
<p>Running it on <code>20</code> yields the expected results:</p>
<pre><code class="language-lean">#eval (evenDivisors 20).takeAll
</code></pre>
<pre><code class="language-output info">[20, 10, 4, 2]
</code></pre>
<h2 id="exercises-12"><a class="header" href="#exercises-12">Exercises</a></h2>
<h3 id="improve-validation-friendliness"><a class="header" href="#improve-validation-friendliness">Improve Validation Friendliness</a></h3>
<p>The errors returned from <code>Validate</code> programs that use <code>&lt;|&gt;</code> can be difficult to read, because inclusion in the list of errors simply means that the error can be reached through <em>some</em> code path.
A more structured error report can be used to guide the user through the process more accurately:</p>
<ul>
<li>Replace the <code>NonEmptyList</code> in <code>Validate.error</code> with a bare type variable, and then update the definitions of the <code>Applicative (Validate ε)</code> and <code>OrElse (Validate ε α)</code> instances to require only that there be an <code>Append ε</code> instance available.</li>
<li>Define a function <code>Validate.mapErrors : Validate ε α → (ε → ε') → Validate ε' α</code> that transforms all the errors in a validation run.</li>
<li>Using the datatype <code>TreeError</code> to represent errors, rewrite the legacy validation system to track its path through the three alternatives.</li>
<li>Write a function <code>report : TreeError → String</code> that outputs a user-friendly view of the <code>TreeError</code>'s accumulated warnings and errors.</li>
</ul>
<pre><code class="language-lean">inductive TreeError where
  | field : Field → String → TreeError
  | path : String → TreeError → TreeError
  | both : TreeError → TreeError → TreeError

instance : Append TreeError where
  append := .both
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="universes"><a class="header" href="#universes">Universes</a></h1>
<p>In the interests of simplicity, this book has thus far papered over an important feature of Lean: <em>universes</em>.
A universe is a type that classifies other types.
Two of them are familiar: <code>Type</code> and <code>Prop</code>.
<code>Type</code> classifies ordinary types, such as <code>Nat</code>, <code>String</code>, <code>Int → String × Char</code>, and <code>IO Unit</code>.
<code>Prop</code> classifies propositions that may be true or false, such as <code>&quot;nisse&quot; = &quot;elf&quot;</code> or <code>3 &gt; 2</code>.
The type of <code>Prop</code> is <code>Type</code>:</p>
<pre><code class="language-lean">#check Prop
</code></pre>
<pre><code class="language-output info">Prop : Type
</code></pre>
<p>For technical reasons, more universes than these two are needed.
In particular, <code>Type</code> cannot itself be a <code>Type</code>.
This would allow a logical paradox to be constructed and undermine Lean's usefulness as a theorem prover.</p>
<p>The formal argument for this is known as <em>Girard's Paradox</em>.
It related to a better-known paradox known as <em>Russell's Paradox</em>, which was used to show that early versions of set theory were inconsistent.
In these set theories, a set can be defined by a property.
For example, one might have the set of all red things, the set of all fruit, the set of all natural numbers, or even the set of all sets.
Given a set, one can ask whether a given element is contained in it.
For instance, a bluebird is not contained in the set of all red things, but the set of all red things is contained in the set of all sets.
Indeed, the set of all sets even contains itself.</p>
<p>What about the set of all sets that do not contain themselves?
It contains the set of all red things, as the set of all red things is not itself red.
It does not contain the set of all sets, because the set of all sets contains itself.
But does it contain itself?
If it does contain itself, then it cannot contain itself.
But if it does not, then it must.</p>
<p>This is a contradiction, which demonstrates that something was wrong with the initial assumptions.
In particular, allowing sets to be constructed by providing an arbitrary property is too powerful.
Later versions of set theory restrict the formation of sets to remove the paradox.</p>
<p>A related paradox can be constructed in versions of dependent type theory that assign the type <code>Type</code> to <code>Type</code>.
To ensure that Lean has consistent logical foundations and can be used as a tool for mathematics, <code>Type</code> needs to have some other type.
This type is called <code>Type 1</code>:</p>
<pre><code class="language-lean">#check Type
</code></pre>
<pre><code class="language-output info">Type : Type 1
</code></pre>
<p>Similarly, <code>Type 1</code> is a <code>Type 2</code>,
<code>Type 2</code> is a <code>Type 3</code>,
<code>Type 3</code> is a <code>Type 4</code>, and so forth.</p>
<p>Function types occupy the smallest universe that can contain both the argument type and the return type.
This means that <code>Nat → Nat</code> is a <code>Type</code>, <code>Type → Type</code> is a <code>Type 1</code>, and <code>Type 1 → Type 2</code> is a <code>Type 3</code>.</p>
<p>There is one exception to this rule.
If the return type of a function is a <code>Prop</code>, then the whole function type is in <code>Prop</code>, even if the argument is in a larger universe such as <code>Type</code> or even <code>Type 1</code>.
In particular, this means that predicates over values that have ordinary types are in <code>Prop</code>.
For example, the type <code>(n : Nat) → n = n + 0</code> represents a function from a <code>Nat</code> to evidence that it is equal to itself plus zero.
Even though <code>Nat</code> is in <code>Type</code>, this function type is in <code>Prop</code> due to this rule.
Similarly, even though <code>Type</code> is in <code>Type 1</code>, the function type <code>Type → 2 + 2 = 4</code> is still in <code>Prop</code>.</p>
<h2 id="user-defined-types"><a class="header" href="#user-defined-types">User Defined Types</a></h2>
<p>Structures and inductive datatypes can be declared to inhabit particular universes.
Lean then checks whether each datatype avoids paradoxes by being in a universe that's large enough to prevent it from containing its own type.
For instance, in the following declaration, <code>MyList</code> is declared to reside in <code>Type</code>, and so is its type argument <code>α</code>:</p>
<pre><code class="language-lean">inductive MyList (α : Type) : Type where
  | nil : MyList α
  | cons : α → MyList α → MyList α
</code></pre>
<p><code>MyList</code> itself is a <code>Type → Type</code>.
This means that it cannot be used to contain actual types, because then its argument would be <code>Type</code>, which is a <code>Type 1</code>:</p>
<pre><code class="language-lean">def myListOfNat : MyList Type :=
  .cons Nat .nil
</code></pre>
<pre><code class="language-output error">application type mismatch
  MyList Type
argument
  Type
has type
  Type 1 : Type 2
but is expected to have type
  Type : Type 1
</code></pre>
<p>Updating <code>MyList</code> so that its argument is a <code>Type 1</code> results in a definition rejected by Lean:</p>
<pre><code class="language-lean">inductive MyList (α : Type 1) : Type where
  | nil : MyList α
  | cons : α → MyList α → MyList α
</code></pre>
<pre><code class="language-output error">invalid universe level in constructor 'MyList.cons', parameter has type
  α
at universe level
  2
it must be smaller than or equal to the inductive datatype universe level
  1
</code></pre>
<p>This error occurs because the argument to <code>cons</code> with type <code>α</code> is from a larger universe than <code>MyList</code>.
Placing <code>MyList</code> itself in <code>Type 1</code> solves this issue, but at the cost of <code>MyList</code> now being itself inconvenient to use in contexts that expect a <code>Type</code>.</p>
<p>The specific rules that govern whether a datatype is allowed are somewhat complicated.
Generally speaking, it's easiest to start with the datatype in the same universe as the largest of its arguments.
Then, if Lean rejects the definition, increase its level by one, which will usually go through.</p>
<h2 id="universe-polymorphism"><a class="header" href="#universe-polymorphism">Universe Polymorphism</a></h2>
<p>Defining a datatype in a specific universe can lead to code duplication.
Placing <code>MyList</code> in <code>Type → Type</code> means that it can't be used for an actual list of types.
Placing it in <code>Type 1 → Type 1</code> means that it can't be used for a list of lists of types.
Rather than copy-pasting the datatype to create versions in <code>Type</code>, <code>Type 1</code>, <code>Type 2</code>, and so on, a feature called <em>universe polymorphism</em> can be used to write a single definition that can be instantiated in any of these universes.</p>
<p>Ordinary polymorphic types use variables to stand for types in a definition.
This allows Lean to fill in the variables differently, which enables these definitions to be used with a variety of types.
Similarly, universe polymorphism allows variables to stand for universes in a definition, enabling Lean to fill them in differently so that they can be used with a variety of universes.
Just as type arguments are conventionally named with Greek letters, universe arguments are conventionally named <code>u</code>, <code>v</code>, and <code>w</code>.</p>
<p>This definition of <code>MyList</code> doesn't specify a particular universe level, but instead uses a variable <code>u</code> to stand for any level.
If the resulting datatype is used with <code>Type</code>, then <code>u</code> is <code>0</code>, and if it's used with <code>Type 3</code>, then <code>u</code> is <code>3</code>:</p>
<pre><code class="language-lean">inductive MyList (α : Type u) : Type u where
  | nil : MyList α
  | cons : α → MyList α → MyList α
</code></pre>
<p>With this definition, the same definition of <code>MyList</code> can be used to contain both actual natural numbers and the natural number type itself:</p>
<pre><code class="language-lean">def myListOfNumbers : MyList Nat :=
  .cons 0 (.cons 1 .nil)

def myListOfNat : MyList Type :=
  .cons Nat .nil
</code></pre>
<p>It can even contain itself:</p>
<pre><code class="language-lean">def myListOfList : MyList (Type → Type) :=
  .cons MyList .nil
</code></pre>
<p>It would seem that this would make it possible to write a logical paradox.
After all, the whole point of the universe system is to rule out self-referential types.
Behind the scenes, however, each occurrence of <code>MyList</code> is provided with a universe level argument.
In essence, the universe-polymorphic definition of <code>MyList</code> created a <em>copy</em> of the datatype at each level, and the level argument selects which copy is to be used.
These level arguments are written with a dot and curly braces, so <code>MyList.{0} : Type → Type</code>, <code>MyList.{1} : Type 1 → Type 1</code>, and <code>MyList.{2} : Type 2 → Type 2</code>.</p>
<p>Writing the levels explicitly, the prior example becomes:</p>
<pre><code class="language-lean">def myListOfNumbers : MyList.{0} Nat :=
  .cons 0 (.cons 1 .nil)

def myListOfNat : MyList.{1} Type :=
  .cons Nat .nil

def myListOfList : MyList.{1} (Type → Type) :=
  .cons MyList.{0} .nil
</code></pre>
<p>When a universe-polymorphic definition takes multiple types as arguments, it's a good idea to give each argument its own level variable for maximum flexibility.
For example, a version of <code>Sum</code> with a single level argument can be written as follows:</p>
<pre><code class="language-lean">inductive Sum (α : Type u) (β : Type u) : Type u where
  | inl : α → Sum α β
  | inr : β → Sum α β
</code></pre>
<p>This definition can be used at multiple levels:</p>
<pre><code class="language-lean">def stringOrNat : Sum String Nat := .inl &quot;hello&quot;

def typeOrType : Sum Type Type := .inr Nat
</code></pre>
<p>However, it requires that both arguments be in the same universe:</p>
<pre><code class="language-lean">def stringOrType : Sum String Type := .inr Nat
</code></pre>
<pre><code class="language-output error">application type mismatch
  Sum String Type
argument
  Type
has type
  Type 1 : Type 2
but is expected to have type
  Type : Type 1
</code></pre>
<p>This datatype can be made more flexible by using different variables for the two type arguments' universe levels, and then declaring that the resulting datatype is in the largest of the two:</p>
<pre><code class="language-lean">inductive Sum (α : Type u) (β : Type v) : Type (max u v) where
  | inl : α → Sum α β
  | inr : β → Sum α β
</code></pre>
<p>This allows <code>Sum</code> to be used with arguments from different universes:</p>
<pre><code class="language-lean">def stringOrType : Sum String Type := .inr Nat
</code></pre>
<p>In positions where Lean expects a universe level, any of the following are allowed:</p>
<ul>
<li>A concrete level, like <code>0</code> or <code>1</code></li>
<li>A variable that stands for a level, such as <code>u</code> or <code>v</code></li>
<li>The maximum of two levels, written as <code>max</code> applied to the levels</li>
<li>A level increase, written with <code>+ 1</code></li>
</ul>
<h3 id="writing-universe-polymorphic-definitions"><a class="header" href="#writing-universe-polymorphic-definitions">Writing Universe-Polymorphic Definitions</a></h3>
<p>Until now, every datatype defined in this book has been in <code>Type</code>, the smallest universe of data.
When presenting polymorphic datatypes from the Lean standard library, such as <code>List</code> and <code>Sum</code>, this book created non-universe-polymorphic versions of them.
The real versions use universe polymorphism to enable code re-use between type-level and non-type-level programs.</p>
<p>There are a few general guidelines to follow when writing universe-polymorphic types.
First off, independent type arguments should have different universe variables, which enables the polymorphic definition to be used with a wider variety of arguments, increasing the potential for code reuse.
Secondly, the whole type is itself typically either in the maximum of all the universe variables, or one greater than this maximum.
Try the smaller of the two first.
Finally, it's a good idea to put the new type in as small of a universe as possible, which allows it to be used more flexibly in other contexts.
Non-polymorphic types, such as <code>Nat</code> and <code>String</code>, can be placed directly in <code>Type 0</code>.</p>
<h3 id="prop-and-polymorphism"><a class="header" href="#prop-and-polymorphism"><code>Prop</code> and Polymorphism</a></h3>
<p>Just as <code>Type</code>, <code>Type 1</code>, and so on describe types that classify programs and data, <code>Prop</code> classifies logical propositions.
A type in <code>Prop</code> describes what counts as convincing evidence for the truth of a statement.
Propositions are like ordinary types in many ways: they can be declared inductively, they can have constructors, and functions can take propositions as arguments.
However, unlike datatypes, it typically doesn't matter <em>which</em> evidence is provided for the truth of a statement, only <em>that</em> evidence is provided.
On the other hand, it is very important that a program not only return a <code>Nat</code>, but that it's the <em>correct</em> <code>Nat</code>.</p>
<p><code>Prop</code> is at the bottom of the universe hierarchy, and the type of <code>Prop</code> is <code>Type</code>.
This means that <code>Prop</code> is a suitable argument to provide to <code>List</code>, for the same reason that <code>Nat</code> is.
Lists of propositions have type <code>List Prop</code>:</p>
<pre><code class="language-lean">def someTruePropositions : List Prop := [
  1 + 1 = 2,
  &quot;Hello, &quot; ++ &quot;world!&quot; = &quot;Hello, world!&quot;
]
</code></pre>
<p>Filling out the universe argument explicitly demonstrates that <code>Prop</code> is a <code>Type</code>:</p>
<pre><code class="language-lean">def someTruePropositions : List.{0} Prop := [
  1 + 1 = 2,
  &quot;Hello, &quot; ++ &quot;world!&quot; = &quot;Hello, world!&quot;
]
</code></pre>
<p>Behind the scenes, <code>Prop</code> and <code>Type</code> are united into a single hierarchy called <code>Sort</code>.
<code>Prop</code> is the same as <code>Sort 0</code>, <code>Type 0</code> is <code>Sort 1</code>, <code>Type 1</code> is <code>Sort 2</code>, and so forth.
In fact, <code>Type u</code> is the same as <code>Sort (u+1)</code>.
When writing programs with Lean, this is typically not relevant, but it may occur in error messages from time to time, and it explains the name of the <code>CoeSort</code> class.
Additionally, having <code>Prop</code> as <code>Sort 0</code> allows one more universe operator to become useful.
The universe level <code>imax u v</code> is <code>0</code> when <code>v</code> is <code>0</code>, or the larger of <code>u</code> or <code>v</code> otherwise.
Together with <code>Sort</code>, this allows the special rule for functions that return <code>Prop</code>s to be used when writing code that should be as portable as possible between <code>Prop</code> and <code>Type</code> universes.</p>
<h2 id="polymorphism-in-practice"><a class="header" href="#polymorphism-in-practice">Polymorphism in Practice</a></h2>
<p>In the remainder of the book, definitions of polymorphic datatypes, structures, and classes will use universe polymorphism in order to be consistent with the Lean standard library.
This will enable the complete presentation of the <code>Functor</code>, <code>Applicative</code>, and <code>Monad</code> classes to be completely consistent with their actual definitions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-complete-definitions"><a class="header" href="#the-complete-definitions">The Complete Definitions</a></h1>
<p>Now that all the relevant language features have been presented, this section describes the complete, honest definitions of <code>Functor</code>, <code>Applicative</code>, and <code>Monad</code> as they occur in the Lean standard library.
For the sake of understanding, no details are omitted.</p>
<h2 id="functor"><a class="header" href="#functor">Functor</a></h2>
<p>The complete definition of the <code>Functor</code> class makes use of universe polymorphism and a default method implementation:</p>
<pre><code class="language-lean">class Functor (f : Type u → Type v) : Type (max (u+1) v) where
  map : {α β : Type u} → (α → β) → f α → f β
  mapConst : {α β : Type u} → α → f β → f α :=
    Function.comp map (Function.const _)
</code></pre>
<p>In this definition, <code>Function.comp</code> is function composition, which is typically written with the <code>∘</code> operator.
<code>Function.const</code> is the <em>constant function</em>, which is a two-argument function that ignores its second argument.
Applying this function to only one argument produces a function that always returns the same value, which is useful when an API demands a function but a program doesn't need to compute different results for different arguments.
A simple version of <code>Function.const</code> can be written as follows:</p>
<pre><code class="language-lean">def simpleConst  (x : α) (_ : β) : α := x
</code></pre>
<p>Using it with one argument as the function argument to <code>List.map</code> demonstrates its utility:</p>
<pre><code class="language-lean">#eval [1, 2, 3].map (simpleConst &quot;same&quot;)
</code></pre>
<pre><code class="language-output info">[&quot;same&quot;, &quot;same&quot;, &quot;same&quot;]
</code></pre>
<p>The actual function has the following signature:</p>
<pre><code class="language-output info">Function.const.{u, v} {α : Sort u} (β : Sort v) (a : α) (a✝ : β) : α
</code></pre>
<p>Here, the type argument <code>β</code> is an explicit argument, so the default definition of <code>Functor.mapConst</code> provides an <code>_</code> argument that instructs Lean to find a unique type to pass to <code>Function.const</code> that would cause the program to type check.
<code>(Function.comp map (Function.const _) : α → f β → f α)</code> is equivalent to <code>fun (x : α) (y : f β) =&gt; map (fun _ =&gt; x) y</code>.</p>
<p>The <code>Functor</code> type class inhabits a universe that is the greater of <code>u+1</code> and <code>v</code>.
Here, <code>u</code> is the level of universes accepted as arguments to <code>f</code>, while <code>v</code> is the universe returned by <code>f</code>.
To see why the structure that implements the <code>Functor</code> type class must be in a universe that's larger than <code>u</code>, begin with a simplified definition of the class:</p>
<pre><code class="language-lean">class Functor (f : Type u → Type v) : Type (max (u+1) v) where
  map : {α β : Type u} → (α → β) → f α → f β
</code></pre>
<p>This type class's structure type is equivalent to the following inductive type:</p>
<pre><code class="language-lean">inductive Functor (f : Type u → Type v) : Type (max (u+1) v) where
  | mk : ({α β : Type u} → (α → β) → f α → f β) → Functor f
</code></pre>
<p>The implementation of the <code>map</code> method that is passed as an argument to <code>Functor.mk</code> contains a function that takes two types in <code>Type u</code> as arguments.
This means that the type of the function itself is in <code>Type (u+1)</code>, so <code>Functor</code> must also be at a level that is at least <code>u+1</code>.
Similarly, other arguments to the function have a type built by applying <code>f</code>, so it must also have a level that is at least <code>v</code>.
All the type classes in this section share this property.</p>
<h2 id="applicative"><a class="header" href="#applicative">Applicative</a></h2>
<p>The <code>Applicative</code> type class is actually built from a number of smaller classes that each contain some of the relevant methods.
The first are <code>Pure</code> and <code>Seq</code>, which contain <code>pure</code> and <code>seq</code> respectively:</p>
<pre><code class="language-lean">class Pure (f : Type u → Type v) : Type (max (u+1) v) where
  pure {α : Type u} : α → f α

class Seq (f : Type u → Type v) : Type (max (u+1) v) where
  seq : {α β : Type u} → f (α → β) → (Unit → f α) → f β
</code></pre>
<p>In addition to these, <code>Applicative</code> also depends on <code>SeqRight</code> and an analogous <code>SeqLeft</code> class:</p>
<pre><code class="language-lean">class SeqRight (f : Type u → Type v) : Type (max (u+1) v) where
  seqRight : {α β : Type u} → f α → (Unit → f β) → f β

class SeqLeft (f : Type u → Type v) : Type (max (u+1) v) where
  seqLeft : {α β : Type u} → f α → (Unit → f β) → f α
</code></pre>
<p>The <code>seqRight</code> function, which was introduced in the <a href="functor-applicative-monad/alternative.html">section about alternatives and validation</a>, is easiest to understand from the perspective of effects.
<code>E1 *&gt; E2</code>, which desugars to <code>SeqRight.seqRight E1 (fun () =&gt; E2)</code>, can be understood as first executing <code>E1</code>, and then <code>E2</code>, resulting only in <code>E2</code>'s result.
Effects from <code>E1</code> may result in <code>E2</code> not being run, or being run multiple times.
Indeed, if <code>f</code> has a <code>Monad</code> instance, then <code>E1 *&gt; E2</code> is equivalent to <code>do let _ ← E1; E2</code>, but <code>seqRight</code> can be used with types like <code>Validate</code> that are not monads.</p>
<p>Its cousin <code>seqLeft</code> is very similar, except the leftmost expression's value is returned.
<code>E1 &lt;* E2</code> desugars to <code>SeqLeft.seqLeft E1 (fun () =&gt; E2)</code>.
<code>SeqLeft.seqLeft</code> has type <code>f α → (Unit → f β) → f α</code>, which is identical to that of <code>seqRight</code> except for the fact that it returns <code>f α</code>.
<code>E1 &lt;* E2</code> can be understood as a program that first executes <code>E1</code>, and then <code>E2</code>, returning the original result for <code>E1</code>.
If <code>f</code> has a <code>Monad</code> instance, then <code>E1 &lt;* E2</code> is equivalent to <code>do let x ← E1; _ ← E2; pure x</code>.
Generally speaking, <code>seqLeft</code> is useful for specifying extra conditions on a value in a validation or parser-like workflow without changing the value itself.</p>
<p>The definition of <code>Applicative</code> extends all these classes, along with <code>Functor</code>:</p>
<pre><code class="language-lean">class Applicative (f : Type u → Type v) extends Functor f, Pure f, Seq f, SeqLeft f, SeqRight f where
  map      := fun x y =&gt; Seq.seq (pure x) fun _ =&gt; y
  seqLeft  := fun a b =&gt; Seq.seq (Functor.map (Function.const _) a) b
  seqRight := fun a b =&gt; Seq.seq (Functor.map (Function.const _ id) a) b
</code></pre>
<p>A complete definition of <code>Applicative</code> requires only definitions for <code>pure</code> and <code>seq</code>.
This is because there are default definitions for all of the methods from <code>Functor</code>, <code>SeqLeft</code>, and <code>SeqRight</code>.
The <code>mapConst</code> method of <code>Functor</code> has its own default implementation in terms of <code>Functor.map</code>.
These default implementations should only be overridden with new functions that are behaviorally equivalent, but more efficient.
The default implementations should be seen as specifications for correctness as well as automatically-created code.</p>
<p>The default implementation for <code>seqLeft</code> is very compact.
Replacing some of the names with their syntactic sugar or their definitions can provide another view on it, so:</p>
<pre><code class="language-lean">fun a b =&gt; Seq.seq (Functor.map (Function.const _) a) b
</code></pre>
<p>becomes</p>
<pre><code class="language-lean">fun a b =&gt; Seq.seq ((fun x _ =&gt; x) &lt;$&gt; a) b
</code></pre>
<p>How should <code>(fun x _ =&gt; x) &lt;$&gt; a</code> be understood?
Here, <code>a</code> has type <code>f α</code>, and <code>f</code> is a functor.
If <code>f</code> is <code>List</code>, then <code>(fun x _ =&gt; x) &lt;$&gt; [1, 2, 3]</code> evaluates to <code>[fun _ =&gt; 1, fun _ =&gt; 2, fun _ =&gt; 3]</code>.
If <code>f</code> is <code>Option</code>, then <code>(fun x _ =&gt; x) &lt;$&gt; some &quot;hello&quot;</code> evaluates to <code>some (fun _ =&gt; &quot;hello&quot;)</code>.
In each case, the values in the functor are replaced by functions that return the original value, ignoring their argument.
When combined with <code>seq</code>, this function discards the values from <code>seq</code>'s second argument.</p>
<p>The default implementation for <code>seqRight</code> is very similar, except <code>const</code> has an additional argument <code>id</code>.
This definition can be understood similarly, by first introducing some standard syntactic sugar and then replacing some names with their definitions:</p>
<pre><code class="language-lean">fun a b =&gt; Seq.seq (Functor.map (Function.const _ id) a) b
===&gt;
fun a b =&gt; Seq.seq ((fun _ =&gt; id) &lt;$&gt; a) b
===&gt;
fun a b =&gt; Seq.seq ((fun _ =&gt; fun x =&gt; x) &lt;$&gt; a) b
===&gt;
fun a b =&gt; Seq.seq ((fun _ x =&gt; x) &lt;$&gt; a) b
</code></pre>
<p>How should <code>(fun _ x =&gt; x) &lt;$&gt; a</code> be understood?
Once again, examples are useful.
<code>(fun _ x =&gt; x) &lt;$&gt; [1, 2, 3]</code> is equivalent to <code>[fun x =&gt; x, fun x =&gt; x, fun x =&gt; x]</code>, and <code>(fun _ x =&gt; x) &lt;$&gt; some &quot;hello&quot;</code> is equivalent to <code>some (fun x =&gt; x)</code>.
In other words, <code>(fun _ x =&gt; x) &lt;$&gt; a</code> preserves the overall shape of <code>a</code>, but each value is replaced by the identity function.
From the perspective of effects, the side effects of <code>a</code> occur, but the values are thrown out when it is used with <code>seq</code>.</p>
<h2 id="monad"><a class="header" href="#monad">Monad</a></h2>
<p>Just as the constituent operations of <code>Applicative</code> are split into their own type classes, <code>Bind</code> has its own class as well:</p>
<pre><code class="language-lean">class Bind (m : Type u → Type v) where
  bind : {α β : Type u} → m α → (α → m β) → m β
</code></pre>
<p><code>Monad</code> extends <code>Applicative</code> with <code>Bind</code>:</p>
<pre><code class="language-lean">class Monad (m : Type u → Type v) extends Applicative m, Bind m : Type (max (u+1) v) where
  map      f x := bind x (Function.comp pure f)
  seq      f x := bind f fun y =&gt; Functor.map y (x ())
  seqLeft  x y := bind x fun a =&gt; bind (y ()) (fun _ =&gt; pure a)
  seqRight x y := bind x fun _ =&gt; y ()
</code></pre>
<p>Tracing the collection of inherited methods and default methods from the entire hierarchy shows that a <code>Monad</code> instance requires only implementations of <code>bind</code> and <code>pure</code>.
In other words, <code>Monad</code> instances automatically yield implementations of <code>seq</code>, <code>seqLeft</code>, <code>seqRight</code>, <code>map</code>, and <code>mapConst</code>.
From the perspective of API boundaries, any type with a <code>Monad</code> instance gets instances for <code>Bind</code>, <code>Pure</code>, <code>Seq</code>, <code>Functor</code>, <code>SeqLeft</code>, and <code>SeqRight</code>.</p>
<h2 id="exercises-13"><a class="header" href="#exercises-13">Exercises</a></h2>
<ol>
<li>Understand the default implementations of <code>map</code>, <code>seq</code>, <code>seqLeft</code>, and <code>seqRight</code> in <code>Monad</code> by working through examples such as <code>Option</code> and <code>Except</code>. In other words, subsitute their definitions for <code>bind</code> and <code>pure</code> into the default definitions, and simplify them to recover the versions <code>map</code>, <code>seq</code>, <code>seqLeft</code>, and <code>seqRight</code> that would be written by hand.</li>
<li>On paper or in a text file, prove to yourself that the default implementations of <code>map</code> and <code>seq</code> satisfy the contracts for <code>Functor</code> and <code>Applicative</code>. In this argument, you're allowed to use the rules from the <code>Monad</code> contract as well as ordinary expression evaluation.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-4"><a class="header" href="#summary-4">Summary</a></h1>
<h2 id="type-classes-and-structures"><a class="header" href="#type-classes-and-structures">Type Classes and Structures</a></h2>
<p>Behind the scenes, type classes are represented by structures.
Defining a class defines a structure, and additionally creates an empty table of instances.
Defining an instance creates a value that either has the structure as its type or is a function that can return the structure, and additionally adds an entry to the table.
Instance search consists of constructing an instance by consulting the instance tables.
Both structures and classes may provide default values for fields (which are default implementations of methods).</p>
<h2 id="structures-and-inheritance-1"><a class="header" href="#structures-and-inheritance-1">Structures and Inheritance</a></h2>
<p>Structures may inherit from other structures.
Behind the scenes, a structure that inherits from another structure contains an instance of the original structure as a field.
In other words, inheritance is implemented with composition.
When multiple inheritance is used, only the unique fields from the additional parent structures are used to avoid a diamond problem, and the functions that would normally extract the parent value are instead organized to construct one.
Record dot notation takes structure inheritance into account.</p>
<p>Because type classes are just structures with some additional automation applied, all of these features are available in type classes.
Together with default methods, this can be used to create a fine-grained hierarchy of interfaces that nonetheless does not impose a large burden on clients, because the small classes that the large classes inherit from can be automatically implemented.</p>
<h2 id="applicative-functors-1"><a class="header" href="#applicative-functors-1">Applicative Functors</a></h2>
<p>An applicative functor is a functor with two additional operations:</p>
<ul>
<li><code>pure</code>, which is the same operator as that for <code>Monad</code></li>
<li><code>seq</code>, which allows a function to be applied in the context of the functor.</li>
</ul>
<p>While monads can represent arbitrary programs with control flow, applicative functors can only run function arguments from left to right.
Because they are less powerful, they provide less control to programs written against the interface, while the implementor of the method has a greater degree of freedom.
Some useful types can implement <code>Applicative</code> but not <code>Monad</code>.</p>
<p>In fact, the type classes <code>Functor</code>, <code>Applicative</code>, and <code>Monad</code> form a hierarchy of power.
Moving up the hierarchy, from <code>Functor</code> towards <code>Monad</code>, allows more powerful programs to be written, but fewer types implement the more powerful classes.
Polymorphic programs should be written to use as weak of an abstraction as possible, while datatypes should be given instances that are as powerful as possible.
This maximizes code re-use.
The more powerful type classes extend the less powerful ones, which means that an implementation of <code>Monad</code> provides implementations of <code>Functor</code> and <code>Applicative</code> for free.</p>
<p>Each class has a set of methods to be implemented and a corresponding contract that specifies additional rules for the methods.
Programs that are written against these interfaces expect that the additional rules are followed, and may be buggy if they are not.
The default implementations of <code>Functor</code>'s methods in terms of <code>Applicative</code>'s, and of <code>Applicative</code>'s in terms of <code>Monad</code>'s, will obey these rules.</p>
<h2 id="universes-1"><a class="header" href="#universes-1">Universes</a></h2>
<p>To allow Lean to be used as both a programming language and a theorem prover, some restrictions on the language are necessary.
This includes restrictions on recursive functions that ensure that they all either terminate or are marked as <code>partial</code> and written to return types that are not uninhabited.
Additionally, it must be impossible to represent certain kinds of logical paradoxes as types.</p>
<p>One of the restrictions that rules out certain paradoxes is that every type is assigned to a <em>universe</em>.
Universes are types such as <code>Prop</code>, <code>Type</code>, <code>Type 1</code>, <code>Type 2</code>, and so forth.
These types describe other types—just as <code>0</code> and <code>17</code> are described by <code>Nat</code>, <code>Nat</code> is itself described by <code>Type</code>, and <code>Type</code> is described by <code>Type 1</code>.
The type of functions that take a type as an argument must be a larger universe than the argument's universe.</p>
<p>Because each declared datatype has a universe, writing code that uses types like data would quickly become annoying, requiring each polymorphic type to be copy-pasted to take arguments from <code>Type 1</code>.
A feature called <em>universe polymorphism</em> allows Lean programs and datatypes to take universe levels as arguments, just as ordinary polymorphism allows programs to take types as arguments.
Generally speaking, Lean libraries should use universe polymorphism when implementing libraries of polymorphic operations.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="monad-transformers"><a class="header" href="#monad-transformers">Monad Transformers</a></h1>
<p>A monad is a way to encode some collection of side effects in a pure language.
Different monads provide different effects, such as state and error handling.
Many monads even provide useful effects that aren't available in most languages, such as nondeterministic searches, readers, and even continuations.</p>
<p>A typical application has a core set of easily testable functions written without monads paired with an outer wrapper that uses a monad to encode the necessary application logic.
These monads are constructed from well-known components.
For example:</p>
<ul>
<li>Mutable state is encoded with a function parameter and a return value that have the same type</li>
<li>Error handling is encoded by having a return type that is similar to <code>Except</code>, with constructors for success and failure</li>
<li>Logging is encoded by pairing the return value with the log</li>
</ul>
<p>Writing each monad by hand is tedious, however, involving boilerplate definitions of the various type classes.
Each of these components can also be extracted to a definition that modifies some other monad to add an additional effect.
Such a definition is called a <em>monad transformer</em>.
A concrete monad can be build from a collection of monad transformers, which enables much more code re-use.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="combining-io-and-reader"><a class="header" href="#combining-io-and-reader">Combining IO and Reader</a></h1>
<p>One case where a reader monad can be useful is when there is some notion of the &quot;current configuration&quot; of the application that is passed through many recursive calls.
An example of such a program is <code>tree</code>, which recursively prints the files in the current directory and its subdirectories, indicating their tree structure using characters.
The version of <code>tree</code> in this chapter, called <code>doug</code> after the mighty Douglas Fir tree that adorns the west coast of North America, provides the option of Unicode box-drawing characters or their ASCII equivalents when indicating directory structure.</p>
<p>For example, the following commands create a directory structure and some empty files in a directory called <code>doug-demo</code>:</p>
<pre><code>$ cd doug-demo
$ mkdir -p a/b/c
$ mkdir -p a/d
$ mkdir -p a/e/f
$ touch a/b/hello
$ touch a/d/another-file
$ touch a/e/still-another-file-again
</code></pre>
<p>Running <code>doug</code> results in the following:</p>
<pre><code>$ doug
├── doug-demo/
│   ├── a/
│   │   ├── b/
│   │   │   ├── hello
│   │   │   ├── c/
│   │   ├── d/
│   │   │   ├── another-file
│   │   ├── e/
│   │   │   ├── still-another-file-again
│   │   │   ├── f/
</code></pre>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p>Internally, <code>doug</code> passes a configuration value downwards as it recursively traverses the directory structure.
This configuration contains two fields: <code>useASCII</code> determines whether to use Unicode box-drawing characters or ASCII vertical line and dash characters to indicate structure, and <code>currentPrefix</code> contains a string to prepend to each line of output.
As the current directory deepens, the prefix string accumulates indicators of being in a directory.
The configuration is a structure:</p>
<pre><code class="language-lean">structure Config where
  useASCII : Bool := false
  currentPrefix : String := &quot;&quot;
</code></pre>
<p>This structure has default definitions for both fields.
The default <code>Config</code> uses Unicode display with no prefix.</p>
<p>Users who invoke <code>doug</code> will need to be able to provide command-line arguments.
The usage information is as follows:</p>
<pre><code class="language-lean">def usage : String :=
  &quot;Usage: doug [--ascii]
Options:
\t--ascii\tUse ASCII characters to display the directory structure&quot;
</code></pre>
<p>Accordingly, a configuration can be constructed by examining a list of command-line arguments:</p>
<pre><code class="language-lean">def configFromArgs : List String → Option Config
  | [] =&gt; some {} -- both fields default
  | [&quot;--ascii&quot;] =&gt; some {useASCII := true}
  | _ =&gt; none
</code></pre>
<p>The <code>main</code> function is a wrapper around an inner worker, called <code>dirTree</code>, that shows the contents of a directory using a configuration.
Before calling <code>dirTree</code>, <code>main</code> is responsible for processing command-line arguments.
It must also return the appropriate exit code to the operating system:</p>
<pre><code class="language-lean">def main (args : List String) : IO UInt32 := do
  match configFromArgs args with
  | some config =&gt;
    dirTree config (← IO.currentDir)
    pure 0
  | none =&gt;
    IO.eprintln s!&quot;Didn't understand argument(s) {&quot; &quot;.separate args}\n&quot;
    IO.eprintln usage
    pure 1
</code></pre>
<p>Not all paths should be shown in the directory tree.
In particular, files named <code>.</code> or <code>..</code> should be skipped, as they are actually features used for navigation rather than files <em>per se</em>.
Of those files that should be shown, there are two kinds: ordinary files and directories:</p>
<pre><code class="language-lean">inductive Entry where
  | file : String → Entry
  | dir : String → Entry
</code></pre>
<p>To determine whether a file should be shown, along with which kind of entry it is, <code>doug</code> uses <code>toEntry</code>:</p>
<pre><code class="language-lean">def toEntry (path : System.FilePath) : IO (Option Entry) := do
  match path.components.getLast? with
  | none =&gt; pure (some (.dir &quot;&quot;))
  | some &quot;.&quot; | some &quot;..&quot; =&gt; pure none
  | some name =&gt;
    pure (some (if (← path.isDir) then .dir name else .file name))
</code></pre>
<p><code>System.FilePath.components</code> converts a path into a list of path components, splitting the name at directory separators.
If there is no last component, then the path is the root directory.
If the last component is a special navigation file (<code>.</code> or <code>..</code>), then the file should be excluded.
Otherwise, directories and files are wrapped in the corresponding constructors.</p>
<p>Lean's logic has no way to know that directory trees are finite.
Indeed, some systems allow the construction of circular directory structures.
Thus, <code>dirTree</code> is declared <code>partial</code>:</p>
<pre><code class="language-lean">partial def dirTree (cfg : Config) (path : System.FilePath) : IO Unit := do
  match ← toEntry path with
  | none =&gt; pure ()
  | some (.file name) =&gt; showFileName cfg name
  | some (.dir name) =&gt;
    showDirName cfg name
    let contents ← path.readDir
    let newConfig := cfg.inDirectory
    doList contents.toList fun d =&gt;
      dirTree newConfig d.path
</code></pre>
<p>The call to <code>toEntry</code> is a <a href="monad-transformers/../hello-world/conveniences.html#nested-actions">nested action</a>—the parentheses are optional in positions where the arrow couldn't have any other meaning, such as <code>match</code>.
When the filename doesn't correspond to an entry in the tree (e.g. because it is <code>..</code>), <code>dirTree</code> does nothing.
When the filename points to an ordinary file, <code>dirTree</code> calls a helper to show it with the current configuration.
When the filename points to a directory, it is shown with a helper, and then its contents are recursively shown in a new configuration in which the prefix has been extended to account for being in a new directory.</p>
<p>Showing the names of files and directories is achieved with <code>showFileName</code> and <code>showDirName</code>:</p>
<pre><code class="language-lean">def showFileName (cfg : Config) (file : String) : IO Unit := do
  IO.println (cfg.fileName file)

def showDirName (cfg : Config) (dir : String) : IO Unit := do
  IO.println (cfg.dirName dir)
</code></pre>
<p>Both of these helpers delegate to functions on <code>Config</code> that take the ASCII vs Unicode setting into account:</p>
<pre><code class="language-lean">def Config.preFile (cfg : Config) :=
  if cfg.useASCII then &quot;|--&quot; else &quot;├──&quot;

def Config.preDir (cfg : Config) :=
  if cfg.useASCII then &quot;|  &quot; else &quot;│  &quot;

def Config.fileName (cfg : Config) (file : String) : String :=
  s!&quot;{cfg.currentPrefix}{cfg.preFile} {file}&quot;

def Config.dirName (cfg : Config) (dir : String) : String :=
  s!&quot;{cfg.currentPrefix}{cfg.preFile} {dir}/&quot;
</code></pre>
<p>Similarly, <code>Config.inDirectory</code> extends the prefix with a directory marker:</p>
<pre><code class="language-lean">def Config.inDirectory (cfg : Config) : Config :=
  {cfg with currentPrefix := cfg.preDir ++ &quot; &quot; ++ cfg.currentPrefix}
</code></pre>
<p>Iterating an IO action over a list of directory contents is achieved using <code>doList</code>.
Because <code>doList</code> carries out all the actions in a list and does not base control-flow decisions on the values returned by any of the actions, the full power of <code>Monad</code> is not necessary, and it will work for any <code>Applicative</code>:</p>
<pre><code class="language-lean">def doList [Applicative f] : List α → (α → f Unit) → f Unit
  | [], _ =&gt; pure ()
  | x :: xs, action =&gt;
    action x *&gt;
    doList xs action
</code></pre>
<h2 id="using-a-custom-monad"><a class="header" href="#using-a-custom-monad">Using a Custom Monad</a></h2>
<p>While this implementation of <code>doug</code> works, manually passing the configuration around is verbose and error-prone.
The type system will not catch it if the wrong configuration is passed downwards, for instance.
A reader effect ensures that the same configuration is passed to all recursive calls, unless it is manually overridden, and it helps make the code less verbose.</p>
<p>To create a version of <code>IO</code> that is also a reader of <code>Config</code>, first define the type and its <code>Monad</code> instance, following the recipe from <a href="monad-transformers/../monads/arithmetic.html#custom-environments">the evaluator example</a>:</p>
<pre><code class="language-lean">def ConfigIO (α : Type) : Type :=
  Config → IO α

instance : Monad ConfigIO where
  pure x := fun _ =&gt; pure x
  bind result next := fun cfg =&gt; do
    let v ← result cfg
    next v cfg
</code></pre>
<p>The difference between this <code>Monad</code> instance and the one for <code>Reader</code> is that this one uses <code>do</code>-notation in the <code>IO</code> monad as the body of the function that <code>bind</code> returns, rather than applying <code>next</code> directly to the value returned from <code>result</code>.
Any <code>IO</code> effects performed by <code>result</code> must occur before <code>next</code> is invoked, which is ensured by the <code>IO</code> monad's <code>bind</code> operator.
<code>ConfigIO</code> is not universe polymorphic because the underlying <code>IO</code> type is also not universe polymorphic.</p>
<p>Running a <code>ConfigIO</code> action involves transforming it into an <code>IO</code> action by providing it with a configuration:</p>
<pre><code class="language-lean">def ConfigIO.run (action : ConfigIO α) (cfg : Config) : IO α :=
  action cfg
</code></pre>
<p>This function is not really necessary, as a caller could simply provide the configuration directly.
However, naming the operation can make it easier to see which parts of the code are intended to run in which monad.</p>
<p>The next step is to define a means of accessing the current configuration as part of <code>ConfigIO</code>:</p>
<pre><code class="language-lean">def currentConfig : ConfigIO Config :=
  fun cfg =&gt; pure cfg
</code></pre>
<p>This is just like <code>read</code> from <a href="monad-transformers/../monads/arithmetic.html#custom-environments">the evaluator example</a>, except it uses <code>IO</code>'s <code>pure</code> to return its value rather than doing so directly.
Because entering a directory modifies the current configuration for the scope of a recursive call, it will be necessary to have a way to override a configuration:</p>
<pre><code class="language-lean">def locally (change : Config → Config) (action : ConfigIO α) : ConfigIO α :=
  fun cfg =&gt; action (change cfg)
</code></pre>
<p>Much of the code used in <code>doug</code> has no need for configurations, and <code>doug</code> calls ordinary Lean <code>IO</code> actions from the standard library that certainly don't need a <code>Config</code>.
Ordinary <code>IO</code> actions can be run using <code>runIO</code>, which ignores the configuration argument:</p>
<pre><code class="language-lean">def runIO (action : IO α) : ConfigIO α :=
  fun _ =&gt; action
</code></pre>
<p>With these components, <code>showFileName</code> and <code>showDirName</code> can be updated to take their configuration arguments implicitly through the <code>ConfigIO</code> monad.
They use <a href="monad-transformers/../hello-world/conveniences.html#nested-actions">nested actions</a> to retrieve the configuration, and <code>runIO</code> to actually execute the call to <code>IO.println</code>:</p>
<pre><code class="language-lean">def showFileName (file : String) : ConfigIO Unit := do
  runIO (IO.println ((← currentConfig).fileName file))

def showDirName (dir : String) : ConfigIO Unit := do
  runIO (IO.println ((← currentConfig).dirName dir))
</code></pre>
<p>In the new version of <code>dirTree</code>, the calls to <code>toEntry</code> and <code>System.FilePath.readDir</code> are wrapped in <code>runIO</code>.
Additionally, instead of building a new configuration and then requiring the programmer to keep track of which one to pass to recursive calls, it uses <code>locally</code> to naturally delimit the modified configuration to only a small region of the program, in which it is the <em>only</em> valid configuration:</p>
<pre><code class="language-lean">partial def dirTree (path : System.FilePath) : ConfigIO Unit := do
  match ← runIO (toEntry path) with
    | none =&gt; pure ()
    | some (.file name) =&gt; showFileName name
    | some (.dir name) =&gt;
      showDirName name
      let contents ← runIO path.readDir
      locally (·.inDirectory)
        (doList contents.toList fun d =&gt;
          dirTree d.path)
</code></pre>
<p>The new version of <code>main</code> uses <code>ConfigIO.run</code> to invoke <code>dirTree</code> with the initial configuration:</p>
<pre><code class="language-lean">def main (args : List String) : IO UInt32 := do
    match configFromArgs args with
    | some config =&gt;
      (dirTree (← IO.currentDir)).run config
      pure 0
    | none =&gt;
      IO.eprintln s!&quot;Didn't understand argument(s) {&quot; &quot;.separate args}\n&quot;
      IO.eprintln usage
      pure 1
</code></pre>
<p>This custom monad has a number of advantages over passing configurations manually:</p>
<ol>
<li>It is easier to ensure that configurations are passed down unchanged, except when changes are desired</li>
<li>The concern of passing the configuration onwards is more clearly separated from the concern of printing directory contents</li>
<li>As the program grows, there will be more and more intermediate layers that do nothing with configurations except propagate them, and these layers don't need to be rewritten as the configuration logic changes</li>
</ol>
<p>However, there are also some clear downsides:</p>
<ol>
<li>As the program evolves and the monad requires more features, each of the basic operators such as <code>locally</code> and <code>currentConfig</code> will need to be updated</li>
<li>Wrapping ordinary <code>IO</code> actions in <code>runIO</code> is noisy and distracts from the flow of the program</li>
<li>Writing monads instances by hand is repetitive, and the technique for adding a reader effect to another monad is a design pattern that requires documentation and communication overhead</li>
</ol>
<p>Using a technique called <em>monad transformers</em>, all of these downsides can be addressed.
A monad transformer takes a monad as an argument and returns a new monad.
Monad transformers consist of:</p>
<ol>
<li>A definition of the transformer itself, which is typically a function from types to types</li>
<li>A <code>Monad</code> instance that assumes the inner type is already a monad</li>
<li>An operator to &quot;lift&quot; an action from the inner monad to the transformed monad, akin to <code>runIO</code></li>
</ol>
<h2 id="adding-a-reader-to-any-monad"><a class="header" href="#adding-a-reader-to-any-monad">Adding a Reader to Any Monad</a></h2>
<p>Adding a reader effect to <code>IO</code> was accomplished in <code>ConfigIO</code> by wrapping <code>IO α</code> in a function type.
The Lean standard library contains a function that can do this to <em>any</em> polymorphic type, called <code>ReaderT</code>:</p>
<pre><code class="language-lean">def ReaderT (ρ : Type u) (m : Type u → Type v) (α : Type u) : Type (max u v) :=
  ρ → m α
</code></pre>
<p>Its arguments are as follows:</p>
<ul>
<li><code>ρ</code> is the environment that is accessible to the reader</li>
<li><code>m</code> is the monad that is being transformed, such as <code>IO</code></li>
<li><code>α</code> is the type of values being returned by the monadic computation
Both <code>α</code> and <code>ρ</code> are in the same universe because the operator that retrieves the environment in the monad will have type <code>m ρ</code>.</li>
</ul>
<p>With <code>ReaderT</code>, <code>ConfigIO</code> becomes:</p>
<pre><code class="language-lean">abbrev ConfigIO (α : Type) : Type := ReaderT Config IO α
</code></pre>
<p>It is an <code>abbrev</code> because <code>ReaderT</code> has many useful features defined in the standard library that a non-reducible definition would hide.
Rather than taking responsibility for making these work directly for <code>ConfigIO</code>, it's easier to simply have <code>ConfigIO</code> behave identically to <code>ReaderT Config IO</code>.</p>
<p>The manually-written <code>currentConfig</code> obtained the environment out of the reader.
This effect can be defined in a generic form for all uses of <code>ReaderT</code>, under the name <code>read</code>:</p>
<pre><code class="language-lean">def read [Monad m] : ReaderT ρ m ρ :=
   fun env =&gt; pure env
</code></pre>
<p>However, not every monad that provides a reader effect is built with <code>ReaderT</code>.
The type class <code>MonadReader</code> allows any monad to provide a <code>read</code> operator:</p>
<pre><code class="language-lean">class MonadReader (ρ : outParam (Type u)) (m : Type u → Type v) : Type (max (u + 1) v) where
  read : m ρ

instance [Monad m] : MonadReader ρ (ReaderT ρ m) where
  read := fun env =&gt; pure env

export MonadReader (read)
</code></pre>
<p>The type <code>ρ</code> is an output parameter because any given monad typically only provides a single type of environment through a reader, so automatically selecting it when the monad is known makes programs more convenient to write.</p>
<p>The <code>Monad</code> instance for <code>ReaderT</code> is essentially the same as the <code>Monad</code> instance for <code>ConfigIO</code>, except <code>IO</code> has been replaced by some arbitrary monad argument <code>m</code>:</p>
<pre><code class="language-lean">instance [Monad m] : Monad (ReaderT ρ m) where
  pure x := fun _ =&gt; pure x
  bind result next := fun env =&gt; do
    let v ← result env
    next v env
</code></pre>
<p>The next step is to eliminate uses of <code>runIO</code>.
When Lean encounters a mismatch in monad types, it automatically attempts to use a type class called <code>MonadLift</code> to transform the actual monad into the expected monad.
This process is similar to the use of coercions.
<code>MonadLift</code> is defined as follows:</p>
<pre><code class="language-lean">class MonadLift (m : Type u → Type v) (n : Type u → Type w) where
  monadLift : {α : Type u} → m α → n α
</code></pre>
<p>The method <code>monadLift</code> translates from the monad <code>m</code> to the monad <code>n</code>.
The process is called &quot;lifting&quot; because it takes an action in the embedded monad and makes it into an action in the surrounding monad.
In this case, it will be used to &quot;lift&quot; from <code>IO</code> to <code>ReaderT Config IO</code>, though the instance works for <em>any</em> inner monad <code>m</code>:</p>
<pre><code class="language-lean">instance : MonadLift m (ReaderT ρ m) where
  monadLift action := fun _ =&gt; action
</code></pre>
<p>The implementation of <code>monadLift</code> is very similar to that of <code>runIO</code>.
Indeed, it is enough to define <code>showFileName</code> and <code>showDirName</code> without using <code>runIO</code>:</p>
<pre><code class="language-lean">def showFileName (file : String) : ConfigIO Unit := do
  IO.println s!&quot;{(← read).currentPrefix} {file}&quot;

def showDirName (dir : String) : ConfigIO Unit := do
  IO.println s!&quot;{(← read).currentPrefix} {dir}/&quot;
</code></pre>
<p>One final operation from the original <code>ConfigIO</code> remains to be translated to a use of <code>ReaderT</code>: <code>locally</code>.
The definition can be translated directly to <code>ReaderT</code>, but the Lean standard library provides a more general version.
The standard version is called <code>withReader</code>, and it is part of a type class called <code>MonadWithReader</code>:</p>
<pre><code class="language-lean">class MonadWithReader (ρ : outParam (Type u)) (m : Type u → Type v) where
  withReader {α : Type u} : (ρ → ρ) → m α → m α
</code></pre>
<p>Just as in <code>MonadReader</code>, the environment <code>ρ</code> is an <code>outParam</code>.
The <code>withReader</code> operation is exported, so that it doesn't need to be written with the type class name before it:</p>
<pre><code class="language-lean">export MonadWithReader (withReader)
</code></pre>
<p>The instance for <code>ReaderT</code> is essentially the same as the definition of <code>locally</code>:</p>
<pre><code class="language-lean">instance : MonadWithReader ρ (ReaderT ρ m) where
  withReader change action :=
    fun cfg =&gt; action (change cfg)
</code></pre>
<p>With these definitions in place, the new version of <code>dirTree</code> can be written:</p>
<pre><code class="language-lean">partial def dirTree (path : System.FilePath) : ConfigIO Unit := do
  match ← toEntry path with
    | none =&gt; pure ()
    | some (.file name) =&gt; showFileName name
    | some (.dir name) =&gt;
      showDirName name
      let contents ← path.readDir
      withReader (·.inDirectory)
        (doList contents.toList fun d =&gt;
          dirTree d.path)
</code></pre>
<p>Aside from replacing <code>locally</code> with <code>withReader</code>, it is the same as before.</p>
<p>Replacing the custom <code>ConfigIO</code> type with <code>ReaderT</code> did not save a large number of lines of code in this section.
However, rewriting the code using components from the standard library does have long-term benefits.
First, readers who know about <code>ReaderT</code> don't need to take time to understand the <code>Monad</code> instance for <code>ConfigIO</code>, working backwards to the meaning of monad itself.
Instead, they can be confident in their initial understanding.
Next, adding further effects to the monad (such as a state effect to count the files in each directory and display a count at the end) requires far fewer changes to the code, because the monad transformers and <code>MonadLift</code> instances provided in the library work well together.
Finally, using a set of type classes included in the standard library, polymorphic code can be written in such a way that it can work with a variety of monads without having to care about details like the order in which the monad transformers were applied.
Just as some functions work in any monad, others can work in any monad that provides a certain type of state, or a certain type of exceptions, without having to specifically describe the <em>way</em> in which a particular concrete monad provides the state or exceptions.</p>
<h2 id="exercises-14"><a class="header" href="#exercises-14">Exercises</a></h2>
<h3 id="controlling-the-display-of-dotfiles"><a class="header" href="#controlling-the-display-of-dotfiles">Controlling the Display of Dotfiles</a></h3>
<p>Files whose names begin with a dot character (<code>'.'</code>) typically represent files that should usually be hidden, such as source-control metadata and configuration files.
Modify <code>doug</code> with an option to show or hide filenames that begin with a dot.
This option should be controlled with a <code>-a</code> command-line option.</p>
<h3 id="starting-directory-as-argument"><a class="header" href="#starting-directory-as-argument">Starting Directory as Argument</a></h3>
<p>Modify <code>doug</code> so that it takes a starting directory as an additional command-line argument.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="a-monad-construction-kit"><a class="header" href="#a-monad-construction-kit">A Monad Construction Kit</a></h1>
<p><code>ReaderT</code> is far from the only useful monad transformer.
This section describes a number of additional transformers.
Each monad transformer consists of the following:</p>
<ol>
<li>A definition or datatype <code>T</code> that takes a monad as an argument.
It should have a type like <code>(Type u → Type v) → Type u → Type v</code>, though it may accept additional arguments prior to the monad.</li>
<li>A <code>Monad</code> instance for <code>T m</code> that relies on an instance of <code>Monad m</code>. This enables the transformed monad to be used as a monad.</li>
<li>A <code>MonadLift</code> instance that translates actions of type <code>m α</code> into actions of type <code>T m α</code>, for arbitrary monads <code>m</code>. This enables actions from the underlying monad to be used in the transformed monad.</li>
</ol>
<p>Furthermore, the <code>Monad</code> instance for the transformer should obey the contract for <code>Monad</code>, at least if the underlying <code>Monad</code> instance does.
In addition, <code>monadLift (pure x)</code> should be equivalent to <code>pure x</code> in the transformed monad, and <code>monadLift</code> should distribute over <code>bind</code> so that <code>monadLift (x &gt;&gt;= f)</code> is the same as <code>monadLift x &gt;&gt;= fun y =&gt; monadLift (f y)</code>.</p>
<p>Many monad transformers additionally define type classes in the style of <code>MonadReader</code> that describe the actual effects available in the monad.
This can provide more flexibility: it allows programs to be written that rely only on an interface, and don't constrain the underlying monad to be implemented by a given transformer.
The type classes are a way for programs to express their requirements, and monad transformers are a convenient way to meet these requirements.</p>
<h2 id="failure-with-optiont"><a class="header" href="#failure-with-optiont">Failure with <code>OptionT</code></a></h2>
<p>Failure, represented by the <code>Option</code> monad, and exceptions, represented by the <code>Except</code> monad, both have corresponding transformers.
In the case of <code>Option</code>, failure can be added to a monad by having it contain values of type <code>Option α</code> where it would otherwise contain values of type <code>α</code>.
For example, <code>IO (Option α)</code> represents <code>IO</code> actions that don't always return a value of type <code>α</code>.
This suggests the definition of the monad transformer <code>OptionT</code>:</p>
<pre><code class="language-lean">def OptionT (m : Type u → Type v) (α : Type u) : Type v :=
  m (Option α)
</code></pre>
<p>As an example of <code>OptionT</code> in action, consider a program that asks the user questions.
The function <code>getSomeInput</code> asks for a line of input and removes whitespace from both ends.
If the resulting trimmed input is non-empty, then it is returned, but the function fails if there are no non-whitespace characters:</p>
<pre><code class="language-lean">def getSomeInput : OptionT IO String := do
  let input ← (← IO.getStdin).getLine
  let trimmed := input.trim
  if trimmed == &quot;&quot; then
    failure
  else pure trimmed
</code></pre>
<p>This particular application tracks users with their name and their favorite species of beetle:</p>
<pre><code class="language-lean">structure UserInfo where
  name : String
  favoriteBeetle : String
</code></pre>
<p>Asking the user for input is no more verbose than a function that uses only <code>IO</code> would be:</p>
<pre><code class="language-lean">def getUserInfo : OptionT IO UserInfo := do
  IO.println &quot;What is your name?&quot;
  let name ← getSomeInput
  IO.println &quot;What is your favorite species of beetle?&quot;
  let beetle ← getSomeInput
  pure ⟨name, beetle⟩
</code></pre>
<p>However, because the function runs in an <code>OptionT IO</code> context rather than just in <code>IO</code>, failure in the first call to <code>getSomeInput</code> causes the whole <code>getUserInfo</code> to fail, with control never reaching the question about beetles.
The main function, <code>interact</code>, invokes <code>getUserInfo</code> in a purely <code>IO</code> context, which allows it to check whether the call succeeded or failed by matching on the inner <code>Option</code>:</p>
<pre><code class="language-lean">def interact : IO Unit := do
  match ← getUserInfo with
  | none =&gt; IO.eprintln &quot;Missing info&quot;
  | some ⟨name, beetle⟩ =&gt; IO.println s!&quot;Hello {name}, whose favorite beetle is {beetle}.&quot;
</code></pre>
<h3 id="the-monad-instance"><a class="header" href="#the-monad-instance">The Monad Instance</a></h3>
<p>Writing the monad instance reveals a difficulty.
Based on the types, <code>pure</code> should use <code>pure</code> from the underlying monad <code>m</code> together with <code>some</code>.
Just as <code>bind</code> for <code>Option</code> branches on the first argument, propagating <code>none</code>, <code>bind</code> for <code>OptionT</code> should run the monadic action that makes up the first argument, branch on the result, and then propagate <code>none</code>.
Following this sketch yields the following definition, which Lean does not accept:</p>
<pre><code class="language-lean">instance [Monad m] : Monad (OptionT m) where
  pure x := pure (some x)
  bind action next := do
    match (← action) with
    | none =&gt; pure none
    | some v =&gt; next v
</code></pre>
<p>The error message shows a cryptic type mismatch:</p>
<pre><code class="language-output error">application type mismatch
  pure (some x)
argument
  some x
has type
  Option α✝ : Type ?u.28
but is expected to have type
  α✝ : Type ?u.28
</code></pre>
<p>The problem here is that Lean is selecting the wrong <code>Monad</code> instance for the surrounding use of <code>pure</code>.
Similar errors occur for the definition of <code>bind</code>.
One solution is to use type annotations to guide Lean to the correct <code>Monad</code> instance:</p>
<pre><code class="language-lean">instance [Monad m] : Monad (OptionT m) where
  pure x := (pure (some x) : m (Option _))
  bind action next := (do
    match (← action) with
    | none =&gt; pure none
    | some v =&gt; next v : m (Option _))
</code></pre>
<p>While this solution works, it is inelegant and the code becomes a bit noisy.</p>
<p>An alternative solution is to define functions whose type signatures guide Lean to the correct instances.
In fact, <code>OptionT</code> could have been defined as a structure:</p>
<pre><code class="language-lean">structure OptionT (m : Type u → Type v) (α : Type u) : Type v where
  run : m (Option α)
</code></pre>
<p>This would solve the problem, because the constructor <code>OptionT.mk</code> and the field accessor <code>OptionT.run</code> would guide type class inference to the correct instances.
The downside to doing this is that structure values would need to be allocated and deallocated repeatedly when running code that uses it, while the direct definition is a compile-time-only feature.
The best of both worlds can be achieved by defining functions that serve the same role as <code>OptionT.mk</code> and <code>OptionT.run</code>, but that work with the direct definition:</p>
<pre><code class="language-lean">def OptionT.mk (x : m (Option α)) : OptionT m α := x

def OptionT.run (x : OptionT m α) : m (Option α) := x
</code></pre>
<p>Both functions return their inputs unchanged, but they indicate the boundary between code that is intended to present the interface of <code>OptionT</code> and code that is intended to present the interface of the underlying monad <code>m</code>.
Using these helpers, the <code>Monad</code> instance becomes more readable:</p>
<pre><code class="language-lean">instance [Monad m] : Monad (OptionT m) where
  pure x := OptionT.mk (pure (some x))
  bind action next := OptionT.mk do
    match ← action with
    | none =&gt; pure none
    | some v =&gt; next v
</code></pre>
<p>Here, the use of <code>OptionT.mk</code> indicates that its arguments should be considered as code that uses the interface of <code>m</code>, which allows Lean to select the correct <code>Monad</code> instances.</p>
<p>After defining the monad instance, it's a good idea to check that the monad contract is satisfied.
The first step is to show that <code>bind (pure v) f</code> is the same as <code>f v</code>.
Here's the steps:</p>
<div class="equational">
<div class="term">
<pre><code class="language-lean hljs">bind (pure v) f</code></pre>
</div>
<div class="explanation">
={ <em>Unfolding the definitions of <code class="hljs">bind</code> and <code class="hljs">pure</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">OptionT.mk do
  match ← pure (some v) with
  | none => pure none
  | some x => f x</code></pre>
</div>
<div class="explanation">
={ <em>Desugaring nested action syntax</em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">OptionT.mk do
  let y ← pure (some v)
  match y with
  | none => pure none
  | some x => f x</code></pre>
</div>
<div class="explanation">
={ <em>Desugaring <code class="hljs">do</code>-notation</em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">OptionT.mk
  (pure (some v) >>= fun y =>
    match y with
    | none => pure none
    | some x => f x)</code></pre>
</div>
<div class="explanation">
={ <em>Using the first monad rule for <code class="hljs">m</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">OptionT.mk
  (match some v with
   | none => pure none
   | some x => f x)</code></pre>
</div>
<div class="explanation">
={ <em>Reduce <code class="hljs">match</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">OptionT.mk (f v)</code></pre>
</div>
<div class="explanation">
={ <em>Definition of <code class="hljs">OptionT.mk</code></em> }=
</div>
<div class="term">
<pre><code class="language-lean hljs">f v</code></pre>
</div>
</div>
<p>The second rule states that <code>bind w pure</code> is the same as <code>w</code>.
To demonstrate this, unfold the definitions of <code>bind</code> and <code>pure</code>, yielding:</p>
<pre><code class="language-lean">OptionT.mk do
    match ← w with
    | none =&gt; pure none
    | some v =&gt; pure (some v)
</code></pre>
<p>In this pattern match, the result of both cases is the same as the pattern being matched, just with <code>pure</code> around it.
In other words, it is equivalent to <code>w &gt;&gt;= fun y =&gt; pure y</code>, which is an instance of <code>m</code>'s second monad rule.</p>
<p>The final rule states that <code>bind (bind v f) g</code>  is the same as <code>bind v (fun x =&gt; bind (f x) g)</code>.
It can be checked in the same way, by expanding the definitions of <code>bind</code> and <code>pure</code> and then delegating to the underlying monad <code>m</code>.</p>
<h3 id="an-alternative-instance"><a class="header" href="#an-alternative-instance">An <code>Alternative</code> Instance</a></h3>
<p>One convenient way to use <code>OptionT</code> is through the <code>Alternative</code> type class.
Successful return is already indicated by <code>pure</code>, and the <code>failure</code> and <code>orElse</code> methods of <code>Alternative</code> provide a way to write a program that returns the first successful result from a number of subprograms:</p>
<pre><code class="language-lean">instance [Monad m] : Alternative (OptionT m) where
  failure := OptionT.mk (pure none)
  orElse x y := OptionT.mk do
    match ← x with
    | some result =&gt; pure (some result)
    | none =&gt; y ()
</code></pre>
<h3 id="lifting"><a class="header" href="#lifting">Lifting</a></h3>
<p>Lifting an action from <code>m</code> to <code>OptionT m</code> only requires wrapping <code>some</code> around the result of the computation:</p>
<pre><code class="language-lean">instance [Monad m] : MonadLift m (OptionT m) where
  monadLift action := OptionT.mk do
    pure (some (← action))
</code></pre>
<h2 id="exceptions"><a class="header" href="#exceptions">Exceptions</a></h2>
<p>The monad transformer version of <code>Except</code> is very similar to the monad transformer version of <code>Option</code>.
Adding exceptions of type <code>ε</code> to some monadic action of type <code>m α</code> can be accomplished by adding exceptions to <code>α</code>, yielding type <code>m (Except ε α)</code>:</p>
<pre><code class="language-lean">def ExceptT (ε : Type u) (m : Type u → Type v) (α : Type u) : Type v :=
  m (Except ε α)
</code></pre>
<p><code>OptionT</code> provides <code>mk</code> and <code>run</code> functions to guide the type checker towards the correct <code>Monad</code> instances.
This trick is also useful for <code>ExceptT</code>:</p>
<pre><code class="language-lean">def ExceptT.mk {ε α : Type u} (x : m (Except ε α)) : ExceptT ε m α := x

def ExceptT.run {ε α : Type u} (x : ExceptT ε m α) : m (Except ε α) := x
</code></pre>
<p>The <code>Monad</code> instance for <code>ExceptT</code> is also very similar to the instance for <code>OptionT</code>.
The only difference is that it propagates a specific error value, rather than <code>none</code>:</p>
<pre><code class="language-lean">instance {ε : Type u} {m : Type u → Type v} [Monad m] : Monad (ExceptT ε m) where
  pure x := ExceptT.mk (pure (Except.ok x))
  bind result next := ExceptT.mk do
    match ← result with
    | .error e =&gt; pure (.error e)
    | .ok x =&gt; next x
</code></pre>
<p>The type signatures of <code>ExceptT.mk</code> and <code>ExceptT.run</code> contain a subtle detail: they annotate the universe levels of <code>α</code> and <code>ε</code> explicitly.
If they are not explicitly annotated, then Lean generates a more general type signature in which they have distinct polymorphic universe variables.
However, the definition of <code>ExceptT</code> expects them to be in the same universe, because they can both be provided as arguments to <code>m</code>.
This can lead to a problem in the <code>Monad</code> instance where the universe level solver fails to find a working solution:</p>
<pre><code class="language-lean">def ExceptT.mk (x : m (Except ε α)) : ExceptT ε m α := x

instance {ε : Type u} {m : Type u → Type v} [Monad m] : Monad (ExceptT ε m) where
  pure x := ExceptT.mk (pure (Except.ok x))
  bind result next := ExceptT.mk do
    match (← result) with
    | .error e =&gt; pure (.error e)
    | .ok x =&gt; next x
</code></pre>
<pre><code class="language-output error">stuck at solving universe constraint
  max ?u.12286 ?u.12287 =?= u
while trying to unify
  ExceptT ε m α✝
with
  (ExceptT ε m α✝) ε m α✝
</code></pre>
<p>This kind of error message is typically caused by underconstrained universe variables.
Diagnosing it can be tricky, but a good first step is to look for reused universe variables in some definitions that are not reused in others.</p>
<p>Unlike <code>Option</code>, the <code>Except</code> datatype is typically not used as a data structure.
It is always used as a control structure with its <code>Monad</code> instance.
This means that it is reasonable to lift <code>Except ε</code> actions into <code>ExceptT ε m</code>, as well as actions from the underlying monad <code>m</code>.
Lifting <code>Except</code> actions into <code>ExceptT</code> actions is done by wrapping them in <code>m</code>'s <code>pure</code>, because an action that only has exception effects cannot have any effects from the monad <code>m</code>:</p>
<pre><code class="language-lean">instance [Monad m] : MonadLift (Except ε) (ExceptT ε m) where
  monadLift action := ExceptT.mk (pure action)
</code></pre>
<p>Because actions from <code>m</code> do not have any exceptions in them, their value should be wrapped in <code>Except.ok</code>.
This can be accomplished using the fact that <code>Functor</code> is a superclass of <code>Monad</code>, so applying a function to the result of any monadic computation can be accomplished using <code>Functor.map</code>:</p>
<pre><code class="language-lean">instance [Monad m] : MonadLift m (ExceptT ε m) where
  monadLift action := ExceptT.mk (.ok &lt;$&gt; action)
</code></pre>
<h3 id="type-classes-for-exceptions"><a class="header" href="#type-classes-for-exceptions">Type Classes for Exceptions</a></h3>
<p>Exception handling fundamentally consists of two operations: the ability to throw exceptions, and the ability to recover from them.
Thus far, this has been accomplished using the constructors of <code>Except</code> and pattern matching, respectively.
However, this ties a program that uses exceptions to one specific encoding of the exception handling effect.
Using a type class to capture these operations allows a program that uses exceptions to be used in <em>any</em> monad that supports throwing and catching.</p>
<p>Throwing an exception should take an exception as an argument, and it should be allowed in any context where a monadic action is requested.
The &quot;any context&quot; part of the specification can be written as a type by writing <code>m α</code>—because there's no way to produce a value of any arbitrary type, the <code>throw</code> operation must be doing something that causes control to leave that part of the program.
Catching an exception should accept any monadic action together with a handler, and the handler should explain how to get back to the action's type from an exception:</p>
<pre><code class="language-lean">class MonadExcept (ε : outParam (Type u)) (m : Type v → Type w) where
  throw : ε → m α
  tryCatch : m α → (ε → m α) → m α
</code></pre>
<p>The universe levels on <code>MonadExcept</code> differ from those of <code>ExceptT</code>.
In <code>ExceptT</code>, both <code>ε</code> and <code>α</code> have the same level, while <code>MonadExcept</code> imposes no such limitation.
This is because <code>MonadExcept</code> never places an exception value inside of <code>m</code>.
The most general universe signature recognizes the fact that <code>ε</code> and <code>α</code> are completely independent in this definition.
Being more general means that the type class can be instantiated for a wider variety of types.</p>
<p>An example program that uses <code>MonadExcept</code> is a simple division service.
The program is divided into two parts: a frontend that supplies a user interface based on strings that handles errors, and a backend that actually does the division.
Both the frontend and the backend can throw exceptions, the former for ill-formed input and the latter for division by zero errors.
The exceptions are an inductive type:</p>
<pre><code class="language-lean">inductive Err where
  | divByZero
  | notANumber : String → Err
</code></pre>
<p>The backend checks for zero, and divides if it can:</p>
<pre><code class="language-lean">def divBackend [Monad m] [MonadExcept Err m] (n k : Int) : m Int :=
  if k == 0 then
    throw .divByZero
  else pure (n / k)
</code></pre>
<p>The frontend's helper <code>asNumber</code> throws an exception if the string it is passed is not a number.
The overall frontend converts its inputs to <code>Int</code>s and calls the backend, handling exceptions by returning a friendly string error:</p>
<pre><code class="language-lean">def asNumber [Monad m] [MonadExcept Err m] (s : String) : m Int :=
  match s.toInt? with
  | none =&gt; throw (.notANumber s)
  | some i =&gt; pure i

def divFrontend [Monad m] [MonadExcept Err m] (n k : String) : m String :=
  tryCatch (do pure (toString (← divBackend (← asNumber n) (← asNumber k))))
    fun
      | .divByZero =&gt; pure &quot;Division by zero!&quot;
      | .notANumber s =&gt; pure s!&quot;Not a number: \&quot;{s}\&quot;&quot;
</code></pre>
<p>Throwing and catching exceptions is common enough that Lean provides a special syntax for using <code>MonadExcept</code>.
Just as <code>+</code> is short for <code>HAdd.hAdd</code>, <code>try</code> and <code>catch</code> can be used as shorthand for the <code>tryCatch</code> method:</p>
<pre><code class="language-lean">def divFrontend [Monad m] [MonadExcept Err m] (n k : String) : m String :=
  try
    pure (toString (← divBackend (← asNumber n) (← asNumber k)))
  catch
    | .divByZero =&gt; pure &quot;Division by zero!&quot;
    | .notANumber s =&gt; pure s!&quot;Not a number: \&quot;{s}\&quot;&quot;
</code></pre>
<p>In addition to <code>Except</code> and <code>ExceptT</code>, there are useful <code>MonadExcept</code> instances for other types that may not seem like exceptions at first glance.
For example, failure due to <code>Option</code> can be seen as throwing an exception that contains no data whatsoever, so there is an instance of <code>MonadExcept Unit Option</code> that allows <code>try ... catch ...</code> syntax to be used with <code>Option</code>.</p>
<h2 id="state"><a class="header" href="#state">State</a></h2>
<p>A simulation of mutable state is added to a monad by having monadic actions accept a starting state as an argument and return a final state together with their result.
The bind operator for a state monad provides the final state of one action as an argument to the next action, threading the state through the program.
This pattern can also be expressed as a monad transformer:</p>
<pre><code class="language-lean">def StateT (σ : Type u) (m : Type u → Type v) (α : Type u) : Type (max u v) :=
  σ → m (α × σ)
</code></pre>
<p>Once again, the monad instance is very similar to that for <code>State</code>.
The only difference is that the input and output states are passed around and returned in the underlying monad, rather than with pure code:</p>
<pre><code class="language-lean">instance [Monad m] : Monad (StateT σ m) where
  pure x := fun s =&gt; pure (x, s)
  bind result next := fun s =&gt; do
    let (v, s') ← result s
    next v s'
</code></pre>
<p>The corresponding type class has <code>get</code> and <code>set</code> methods.
One downside of <code>get</code> and <code>set</code> is that it becomes too easy to <code>set</code> the wrong state when updating it.
This is because retrieving the state, updating it, and saving the updated state is a natural way to write some programs.
For example, the following program counts the number of diacritic-free English vowels and consonants in a string of letters:</p>
<pre><code class="language-lean">structure LetterCounts where
  vowels : Nat
  consonants : Nat
deriving Repr

inductive Err where
  | notALetter : Char → Err
deriving Repr

def vowels :=
  let lowerVowels := &quot;aeiuoy&quot;
  lowerVowels ++ lowerVowels.map (·.toUpper)

def consonants :=
  let lowerConsonants := &quot;bcdfghjklmnpqrstvwxz&quot;
  lowerConsonants ++ lowerConsonants.map (·.toUpper )

def countLetters (str : String) : StateT LetterCounts (Except Err) Unit :=
  let rec loop (chars : List Char) := do
    match chars with
    | [] =&gt; pure ()
    | c :: cs =&gt;
      let st ← get
      let st' ←
        if c.isAlpha then
          if vowels.contains c then
            pure {st with vowels := st.vowels + 1}
          else if consonants.contains c then
            pure {st with consonants := st.consonants + 1}
          else -- modified or non-English letter
            pure st
        else throw (.notALetter c)
      set st'
      loop cs
  loop str.toList
</code></pre>
<p>It would be very easy to write <code>set st</code> instead of <code>set st'</code>.
In a large program, this kind of mistake can lead to difficult-to-diagnose bugs.</p>
<p>While using a nested action for the call to <code>get</code> would solve this problem, it can't solve all such problems.
For example, a function might update a field on a structure based on the values of two other fields.
This would require two separate nested-action calls to <code>get</code>.
Because the Lean compiler contains optimizations that are only effective when there is a single reference to a value, duplicating the references to the state might lead to code that is significantly slower.
Both the potential performance problem and the potential bug can be worked around by using <code>modify</code>, which transforms the state using a function:</p>
<pre><code class="language-lean">def countLetters (str : String) : StateT LetterCounts (Except Err) Unit :=
  let rec loop (chars : List Char) := do
    match chars with
    | [] =&gt; pure ()
    | c :: cs =&gt;
      if c.isAlpha then
        if vowels.contains c then
          modify fun st =&gt; {st with vowels := st.vowels + 1}
        else if consonants.contains c then
          modify fun st =&gt; {st with consonants := st.consonants + 1}
        else -- modified or non-English letter
          pure ()
      else throw (.notALetter c)
      loop cs
  loop str.toList
</code></pre>
<p>The type class contains a function akin to <code>modify</code> called <code>modifyGet</code>, which allows the function to both compute a return value and transform an old state in a single step.
The function returns a pair in which the first element is the return value, and the second element is the new state; <code>modify</code> just adds the constructor of <code>Unit</code> to the pair used in <code>modifyGet</code>:</p>
<pre><code class="language-lean">def modify [MonadState σ m] (f : σ → σ) : m Unit :=
  modifyGet fun s =&gt; ((), f s)
</code></pre>
<p>The definition of <code>MonadState</code> is as follows:</p>
<pre><code class="language-lean">class MonadState (σ : outParam (Type u)) (m : Type u → Type v) : Type (max (u+1) v) where
  get : m σ
  set : σ → m PUnit
  modifyGet : (σ → α × σ) → m α
</code></pre>
<p><code>PUnit</code> is a version of the <code>Unit</code> type that is universe-polymorphic to allow it to be in <code>Type u</code> instead of <code>Type</code>.
While it would be possible to provide a default implementation of <code>modifyGet</code> in terms of <code>get</code> and <code>set</code>, it would not admit the optimizations that make <code>modifyGet</code> useful in the first place, rendering the method useless.</p>
<h2 id="of-classes-and-the-functions"><a class="header" href="#of-classes-and-the-functions"><code>Of</code> Classes and <code>The</code> Functions</a></h2>
<p>Thus far, each monad type class that takes extra information, like the type of exceptions for <code>MonadExcept</code> or the type of the state for <code>MonadState</code>, has this type of extra information as an output parameter.
For simple programs, this is generally convenient, because a monad that combines one use each of <code>StateT</code>, <code>ReaderT</code>, and <code>ExceptT</code> has only a single state type, environment type, and exception type.
As monads grow in complexity, however, they may involve multiple states or errors types.
In this case, the use of an output parameter makes it impossible to target both states in the same <code>do</code>-block.</p>
<p>For these cases, there are additional type classes in which the extra information is not an output parameter.
These versions of the type classes use the word <code>Of</code> in the name.
For example, <code>MonadStateOf</code> is like <code>MonadState</code>, but without an <code>outParam</code> modifier.</p>
<p>Similarly, there are versions of the type class methods that accept the type of the extra information as an <em>explicit</em>, rather than implicit, argument.
For <code>MonadStateOf</code>, there are <code>getThe</code> with type</p>
<pre><code class="language-lean">(σ : Type u) → {m : Type u → Type v} → [MonadStateOf σ m] → m σ
</code></pre>
<p>and <code>modifyThe</code> with type</p>
<pre><code class="language-lean">(σ : Type u) → {m : Type u → Type v} → [MonadStateOf σ m] → (σ → σ) → m PUnit
</code></pre>
<p>There is no <code>setThe</code> because the type of the new state is enough to decide which surrounding state monad transformer to use.</p>
<p>In the Lean standard library, there are instances of the non-<code>Of</code> versions of the classes defined in terms of the instances of the versions with <code>Of</code>.
In other words, implementing the <code>Of</code> version yields implementations of both.
It's generally a good idea to implement the <code>Of</code> version, and then start writing programs using the non-<code>Of</code> versions of the class, transitioning to the <code>Of</code> version if the output parameter becomes inconvenient.</p>
<h2 id="transformers-and-id"><a class="header" href="#transformers-and-id">Transformers and <code>Id</code></a></h2>
<p>The identity monad <code>Id</code> is the monad that has no effects whatsoever, to be used in contexts that expect a monad for some reason but where none is actually necessary.
Another use of <code>Id</code> is to serve as the bottom of a stack of monad transformers.
For instance, <code>StateT σ Id</code> works just like <code>State σ</code>.</p>
<h2 id="exercises-15"><a class="header" href="#exercises-15">Exercises</a></h2>
<h3 id="monad-contract"><a class="header" href="#monad-contract">Monad Contract</a></h3>
<p>Using pencil and paper, check that the rules of the monad transformer contract are satisfied for each monad transformer in this section.</p>
<h3 id="logging-transformer"><a class="header" href="#logging-transformer">Logging Transformer</a></h3>
<p>Define a monad transformer version of <code>WithLog</code>.
Also define the corresponding type class <code>MonadWithLog</code>, and write a program that combines logging and exceptions.</p>
<h3 id="counting-files"><a class="header" href="#counting-files">Counting Files</a></h3>
<p>Modify <code>doug</code>'s monad with <code>StateT</code> such that it counts the number of directories and files seen.
At the end of execution, it should display a report like:</p>
<pre><code>  Viewed 38 files in 5 directories.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ordering-monad-transformers"><a class="header" href="#ordering-monad-transformers">Ordering Monad Transformers</a></h1>
<p>When composing a monad from a stack of monad transformers, it's important to be aware that the order in which the monad transformers are layered matters.
Different orderings of the same set of transformers result in different monads.</p>
<p>This version of <code>countLetters</code> is just like the previous version, except it uses type classes to describe the set of available effects instead of providing a concrete monad:</p>
<pre><code class="language-lean">def countLetters [Monad m] [MonadState LetterCounts m] [MonadExcept Err m] (str : String) : m Unit :=
  let rec loop (chars : List Char) := do
    match chars with
    | [] =&gt; pure ()
    | c :: cs =&gt;
      if c.isAlpha then
        if vowels.contains c then
          modify fun st =&gt; {st with vowels := st.vowels + 1}
        else if consonants.contains c then
          modify fun st =&gt; {st with consonants := st.consonants + 1}
        else -- modified or non-English letter
          pure ()
      else throw (.notALetter c)
      loop cs
  loop str.toList
</code></pre>
<p>The state and exception monad transformers can be combined in two different orders, each resulting in a monad that has instances of both type classes:</p>
<pre><code class="language-lean">abbrev M1 := StateT LetterCounts (ExceptT Err Id)
abbrev M2 := ExceptT Err (StateT LetterCounts Id)
</code></pre>
<p>When run on input for which the program does not throw an exception, both monads yield similar results:</p>
<pre><code class="language-lean">#eval countLetters (m := M1) &quot;hello&quot; ⟨0, 0⟩
</code></pre>
<pre><code class="language-output info">Except.ok ((), { vowels := 2, consonants := 3 })
</code></pre>
<pre><code class="language-lean">#eval countLetters (m := M2) &quot;hello&quot; ⟨0, 0⟩
</code></pre>
<pre><code class="language-output info">(Except.ok (), { vowels := 2, consonants := 3 })
</code></pre>
<p>However, there is a subtle difference between these return values.
In the case of <code>M1</code>, the outermost constructor is <code>Except.ok</code>, and it contains a pair of the unit constructor with the final state.
In the case of <code>M2</code>, the outermost constructor is the pair, which contains <code>Except.ok</code> applied only to the unit constructor.
The final state is outside of <code>Except.ok</code>.
In both cases, the program returns the counts of vowels and consonants.</p>
<p>On the other hand, only one monad yields a count of vowels and consonants when the string causes an exception to be thrown.
Using <code>M1</code>, only an exception value is returned:</p>
<pre><code class="language-lean">#eval countLetters (m := M1) &quot;hello!&quot; ⟨0, 0⟩
</code></pre>
<pre><code class="language-output info">Except.error (StEx.Err.notALetter '!')
</code></pre>
<p>Using <code>M2</code>, the exception value is paired with the state as it was at the time that the exception was thrown:</p>
<pre><code class="language-lean">#eval countLetters (m := M2) &quot;hello!&quot; ⟨0, 0⟩
</code></pre>
<pre><code class="language-output info">(Except.error (StEx.Err.notALetter '!'), { vowels := 2, consonants := 3 })
</code></pre>
<p>It might be tempting to think that <code>M2</code> is superior to <code>M1</code> because it provides more information that might be useful when debugging.
The same program might compute <em>different</em> answers in <code>M1</code> than it does in <code>M2</code>, and there's no principled reason to say that one of these answers is necessarily better than the other.
This can be seen by adding a step to the program that handles exceptions:</p>
<pre><code class="language-lean">def countWithFallback
    [Monad m] [MonadState LetterCounts m] [MonadExcept Err m]
    (str : String) : m Unit :=
  try
    countLetters str
  catch _ =&gt;
    countLetters &quot;Fallback&quot;
</code></pre>
<p>This program always succeeds, but it might succeed with different results.
If no exception is thrown, then the results are the same as <code>countLetters</code>:</p>
<pre><code class="language-lean">#eval countWithFallback (m := M1) &quot;hello&quot; ⟨0, 0⟩
</code></pre>
<pre><code class="language-output info">Except.ok ((), { vowels := 2, consonants := 3 })
</code></pre>
<pre><code class="language-lean">#eval countWithFallback (m := M2) &quot;hello&quot; ⟨0, 0⟩
</code></pre>
<pre><code class="language-output info">(Except.ok (), { vowels := 2, consonants := 3 })
</code></pre>
<p>However, if the exception is thrown and caught, then the final states are very different.
With <code>M1</code>, the final state contains only the letter counts from <code>&quot;Fallback&quot;</code>:</p>
<pre><code class="language-lean">#eval countWithFallback (m := M1) &quot;hello!&quot; ⟨0, 0⟩
</code></pre>
<pre><code class="language-output info">Except.ok ((), { vowels := 2, consonants := 6 })
</code></pre>
<p>With <code>M2</code>, the final state contains letter counts from both <code>&quot;hello&quot;</code> and from <code>&quot;Fallback&quot;</code>, as one would expect in an imperative language:</p>
<pre><code class="language-lean">#eval countWithFallback (m := M2) &quot;hello!&quot; ⟨0, 0⟩
</code></pre>
<pre><code class="language-output info">(Except.ok (), { vowels := 4, consonants := 9 })
</code></pre>
<p>In <code>M1</code>, throwing an exception &quot;rolls back&quot; the state to where the exception was caught.
In <code>M2</code>, modifications to the state persist across the throwing and catching of exceptions.
This difference can be seen by unfolding the definitions of <code>M1</code> and <code>M2</code>.
<code>M1 α</code> unfolds to <code>LetterCounts → Except Err (α × LetterCounts)</code>, and <code>M2 α</code> unfolds to <code>LetterCounts → Except Err α × LetterCounts</code>.
That is to say, <code>M1 α</code> describes functions that take an initial letter count, returning either an error or an <code>α</code> paired with updated counts.
When an exception is thrown in <code>M1</code>, there is no final state.
<code>M2 α</code> describes functions that take an initial letter count and return a new letter count paired with either an error or an <code>α</code>.
When an exception is thrown in <code>M2</code>, it is accompanied by a state.</p>
<h2 id="commuting-monads"><a class="header" href="#commuting-monads">Commuting Monads</a></h2>
<p>In the jargon of functional programming, two monad transformers are said to <em>commute</em> if they can be re-ordered without the meaning of the program changing.
The fact that the result of the program can differ when <code>StateT</code> and <code>ExceptT</code> are reordered means that state and exceptions do not commute.
In general, monad transformers should not be expected to commute.</p>
<p>Even though not all monad transformers commute, some do.
For example, two uses of <code>StateT</code> can be re-ordered.
Expanding the definitions in <code>StateT σ (StateT σ' Id) α</code> yields the type <code>σ → σ' → ((α × σ) × σ')</code>, and <code>StateT σ' (StateT σ Id) α</code> yields <code>σ' → σ → ((α × σ') × σ)</code>.
In other words, the differences between them are that they nest the <code>σ</code> and <code>σ'</code> types in different places in the return type, and they accept their arguments in a different order.
Any client code will still need to provide the same inputs, and it will still receive the same outputs.</p>
<p>Most programming languages that have both mutable state and exceptions work like <code>M2</code>.
In those languages, state that <em>should</em> be rolled back when an exception is thrown is difficult to express, and it usually needs to be simulated in a manner that looks much like the passing of explicit state values in <code>M1</code>.
Monad transformers grant the freedom to choose an interpretation of effect ordering that works for the problem at hand, with both choices being equally easy to program with.
However, they also require care to be taken in the choice of ordering of transformers.
With great expressive power comes the responsibility to check that what's being expressed is what is intended, and the type signature of <code>countWithFallback</code> is probably more polymorphic than it should be.</p>
<h2 id="exercises-16"><a class="header" href="#exercises-16">Exercises</a></h2>
<ul>
<li>Check that <code>ReaderT</code> and <code>StateT</code> commute by expanding their definitions and reasoning about the resulting types.</li>
<li>Do <code>ReaderT</code> and <code>ExceptT</code> commute? Check your answer by expanding their definitions and reasoning about the resulting types.</li>
<li>Construct a monad transformer <code>ManyT</code> based on the definition of <code>Many</code>, with a suitable <code>Alternative</code> instance. Check that it satisfies the <code>Monad</code> contract.</li>
<li>Does <code>ManyT</code> commute with <code>StateT</code>? If so, check your answer by expanding definitions and reasoning about the resulting types. If not, write a program in <code>ManyT (StateT σ Id)</code> and a program in <code>StateT σ (ManyT Id)</code>. Each program should be one that makes more sense for the given ordering of monad transformers.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="more-do-features"><a class="header" href="#more-do-features">More do Features</a></h1>
<p>Lean's <code>do</code>-notation provides a syntax for writing programs with monads that resembles imperative programming languages.
In addition to providing a convenient syntax for programs with monads, <code>do</code>-notation provides syntax for using certain monad transformers.</p>
<h2 id="single-branched-if"><a class="header" href="#single-branched-if">Single-Branched <code>if</code></a></h2>
<p>When working in a monad, a common pattern is to carry out a side effect only if some condition is true.
For instance, <code>countLetters</code> contains a check for vowels or consonants, and letters that are neither have no effect on the state.
This is captured by having the <code>else</code> branch evaluate to <code>pure ()</code>, which has no effects:</p>
<pre><code class="language-lean">def countLetters (str : String) : StateT LetterCounts (Except Err) Unit :=
  let rec loop (chars : List Char) := do
    match chars with
    | [] =&gt; pure ()
    | c :: cs =&gt;
      if c.isAlpha then
        if vowels.contains c then
          modify fun st =&gt; {st with vowels := st.vowels + 1}
        else if consonants.contains c then
          modify fun st =&gt; {st with consonants := st.consonants + 1}
        else -- modified or non-English letter
          pure ()
      else throw (.notALetter c)
      loop cs
  loop str.toList
</code></pre>
<p>When an <code>if</code> is a statement in a <code>do</code>-block, rather than being an expression, then <code>else pure ()</code> can simply be omitted, and Lean inserts it automatically.
The following definition of <code>countLetters</code> is completely equivalent:</p>
<pre><code class="language-lean">def countLetters (str : String) : StateT LetterCounts (Except Err) Unit :=
  let rec loop (chars : List Char) := do
    match chars with
    | [] =&gt; pure ()
    | c :: cs =&gt;
      if c.isAlpha then
        if vowels.contains c then
          modify fun st =&gt; {st with vowels := st.vowels + 1}
        else if consonants.contains c then
          modify fun st =&gt; {st with consonants := st.consonants + 1}
      else throw (.notALetter c)
      loop cs
  loop str.toList
</code></pre>
<p>A program that uses a state monad to count the entries in a list that satisfy some monadic check can be written as follows:</p>
<pre><code class="language-lean">def count [Monad m] [MonadState Nat m] (p : α → m Bool) : List α → m Unit
  | [] =&gt; pure ()
  | x :: xs =&gt; do
    if ← p x then
      modify (· + 1)
    count p xs
</code></pre>
<p>Similarly, <code>if not E1 then STMT...</code> can instead be written <code>unless E1 do STMT...</code>.
The converse of <code>count</code> that counts entries that don't satisfy the monadic check can be written by replacing <code>if</code> with <code>unless</code>:</p>
<pre><code class="language-lean">def countNot [Monad m] [MonadState Nat m] (p : α → m Bool) : List α → m Unit
  | [] =&gt; pure ()
  | x :: xs =&gt; do
    unless ← p x do
      modify (· + 1)
    countNot p xs
</code></pre>
<p>Understanding single-branched <code>if</code> and <code>unless</code> does not require thinking about monad transformers.
They simply replace the missing branch with <code>pure ()</code>.
The remaining extensions in this section, however, require Lean to automatically rewrite the <code>do</code>-block to add a local transformer on top of the monad that the <code>do</code>-block is written in.</p>
<h2 id="early-return"><a class="header" href="#early-return">Early Return</a></h2>
<p>The standard library contains a function <code>List.find?</code> that returns the first entry in a list that satisfies some check.
A simple implementation that doesn't make use of the fact that <code>Option</code> is a monad loops over the list using a recursive function, with an <code>if</code> to stop the loop when the desired entry is found:</p>
<pre><code class="language-lean">def List.find? (p : α → Bool) : List α → Option α
  | [] =&gt; none
  | x :: xs =&gt;
    if p x then
      some x
    else
      find? p xs
</code></pre>
<p>Imperative languages typically sport the <code>return</code> keyword that aborts the execution of a function, immediately returning some value to the caller.
In Lean, this is available in <code>do</code>-notation, and <code>return</code> halts the execution of a <code>do</code>-block, with <code>return</code>'s argument being the value returned from the monad.
In other words, <code>List.find?</code> could have been written like this:</p>
<pre><code class="language-lean">def List.find? (p : α → Bool) : List α → Option α
  | [] =&gt; failure
  | x :: xs =&gt; do
    if p x then return x
    find? p xs
</code></pre>
<p>Early return in imperative languages is a bit like an exception that can only cause the current stack frame to be unwound.
Both early return and exceptions terminate execution of a block of code, effectively replacing the surrounding code with the thrown value.
Behind the scenes, early return in Lean is implemented using a version of <code>ExceptT</code>.
Each <code>do</code>-block that uses early return is wrapped in an exception handler (in the sense of the function <code>tryCatch</code>).
Early returns are translated to throwing the value as an exception, and the handlers catch the thrown value and return it immediately.
In other words, the <code>do</code>-block's original return value type is also used as the exception type.</p>
<p>Making this more concrete, the helper function <code>runCatch</code> strips a layer of <code>ExceptT</code> from the top of a monad transformer stack when the exception type and return type are the same:</p>
<pre><code class="language-lean">def runCatch [Monad m] (action : ExceptT α m α) : m α := do
  match ← action with
  | Except.ok x =&gt; pure x
  | Except.error x =&gt; pure x
</code></pre>
<p>The <code>do</code>-block in <code>List.find?</code> that uses early return is translated to a <code>do</code>-block that does not use early return by wrapping it in a use of <code>runCatch</code>, and replacing early returns with <code>throw</code>:</p>
<pre><code class="language-lean">def List.find? (p : α → Bool) : List α → Option α
  | [] =&gt; failure
  | x :: xs =&gt;
    runCatch do
      if p x then throw x else pure ()
      monadLift (find? p xs)
</code></pre>
<p>Another situation in which early return is useful is command-line applications that terminate early if the arguments or input are incorrect.
Many programs begin with a section that validates arguments and inputs before proceeding to the main body of the program.
The following version of <a href="monad-transformers/../hello-world/running-a-program.html">the greeting program <code>hello-name</code></a> checks that no command-line arguments were provided:</p>
<pre><code class="language-lean">def main (argv : List String) : IO UInt32 := do
  let stdin ← IO.getStdin
  let stdout ← IO.getStdout
  let stderr ← IO.getStderr

  unless argv == [] do
    stderr.putStrLn s!&quot;Expected no arguments, but got {argv.length}&quot;
    return 1

  stdout.putStrLn &quot;How would you like to be addressed?&quot;
  stdout.flush

  let name := (← stdin.getLine).trim
  if name == &quot;&quot; then
    stderr.putStrLn s!&quot;No name provided&quot;
    return 1

  stdout.putStrLn s!&quot;Hello, {name}!&quot;

  return 0
</code></pre>
<p>Running it with no arguments and typing the name <code>David</code> yields the same result as the previous version:</p>
<pre><code>$ lean --run EarlyReturn.lean
How would you like to be addressed?
David
Hello, David!
</code></pre>
<p>Providing the name as a command-line argument instead of an answer causes an error:</p>
<pre><code>$ lean --run EarlyReturn.lean David
Expected no arguments, but got 1
</code></pre>
<p>And providing no name causes the other error:</p>
<pre><code>$ lean --run EarlyReturn.lean
How would you like to be addressed?

No name provided
</code></pre>
<p>The program that uses early return avoids needing to nest the control flow, as is done in this version that does not use early return:</p>
<pre><code class="language-lean">def main (argv : List String) : IO UInt32 := do
  let stdin ← IO.getStdin
  let stdout ← IO.getStdout
  let stderr ← IO.getStderr

  if argv != [] then
    stderr.putStrLn s!&quot;Expected no arguments, but got {argv.length}&quot;
    pure 1
  else
    stdout.putStrLn &quot;How would you like to be addressed?&quot;
    stdout.flush

    let name := (← stdin.getLine).trim
    if name == &quot;&quot; then
      stderr.putStrLn s!&quot;No name provided&quot;
      pure 1
    else
      stdout.putStrLn s!&quot;Hello, {name}!&quot;
      pure 0
</code></pre>
<p>One important difference between early return in Lean and early return in imperative languages is that Lean's early return applies only to the current <code>do</code>-block.
When the entire definition of a function is in the same <code>do</code> block, this difference doesn't matter.
But if <code>do</code> occurs underneath some other structures, then the difference becomes apparent.
For example, given the following definition of <code>greet</code>:</p>
<pre><code class="language-lean">def greet (name : String) : String :=
  &quot;Hello, &quot; ++ Id.run do return name
</code></pre>
<p>the expression <code>greet &quot;David&quot;</code> evaluates to <code>&quot;Hello, David&quot;</code>, not just <code>&quot;David&quot;</code>.</p>
<h2 id="loops"><a class="header" href="#loops">Loops</a></h2>
<p>Just as every program with mutable state can be rewritten to a program that passes the state as arguments, every loop can be rewritten as a recursive function.
From one perspective, <code>List.find?</code> is most clear as a recursive function.
After all, its definition mirrors the structure of the list: if the head passes the check, then it should be returned; otherwise look in the tail.
When no more entries remain, the answer is <code>none</code>.
From another perspective, <code>List.find?</code> is most clear as a loop.
After all, the program consults the entries in order until a satisfactory one is found, at which point it terminates.
If the loop terminates without having returned, the answer is <code>none</code>.</p>
<h3 id="looping-with-form"><a class="header" href="#looping-with-form">Looping with ForM</a></h3>
<p>Lean includes a type class that describes looping over a container type in some monad.
This class is called <code>ForM</code>:</p>
<pre><code class="language-lean">class ForM (m : Type u → Type v) (γ : Type w₁) (α : outParam (Type w₂)) where
  forM [Monad m] : γ → (α → m PUnit) → m PUnit
</code></pre>
<p>This class is quite general.
The parameter <code>m</code> is a monad with some desired effects, <code>γ</code> is the collection to be looped over, and <code>α</code> is the type of elements from the collection.
Typically, <code>m</code> is allowed to be any monad, but it is possible to have a data structure that e.g. only supports looping in <code>IO</code>.
The method <code>forM</code> takes a collection, a monadic action to be run for its effects on each element from the collection, and is then responsible for running the actions.</p>
<p>The instance for <code>List</code> allows <code>m</code> to be any monad, it sets <code>γ</code> to be <code>List α</code>, and sets the class's <code>α</code> to be the same <code>α</code> found in the list:</p>
<pre><code class="language-lean">def List.forM [Monad m] : List α → (α → m PUnit) → m PUnit
  | [], _ =&gt; pure ()
  | x :: xs, action =&gt; do
    action x
    forM xs action

instance : ForM m (List α) α where
  forM := List.forM
</code></pre>
<p>The <a href="monad-transformers/reader-io.html#implementation">function <code>doList</code> from <code>doug</code></a> is <code>forM</code> for lists.
Because <code>forM</code> is intended to be used in <code>do</code>-blocks, it uses <code>Monad</code> rather than <code>Applicative</code>.
<code>forM</code> can be used to make <code>countLetters</code> much shorter:</p>
<pre><code class="language-lean">def countLetters (str : String) : StateT LetterCounts (Except Err) Unit :=
  forM str.toList fun c =&gt; do
    if c.isAlpha then
      if vowels.contains c then
        modify fun st =&gt; {st with vowels := st.vowels + 1}
      else if consonants.contains c then
        modify fun st =&gt; {st with consonants := st.consonants + 1}
    else throw (.notALetter c)
</code></pre>
<p>The instance for <code>Many</code> is very similar:</p>
<pre><code class="language-lean">def Many.forM [Monad m] : Many α → (α → m PUnit) → m PUnit
  | Many.none, _ =&gt; pure ()
  | Many.more first rest, action =&gt; do
    action first
    forM (rest ()) action

instance : ForM m (Many α) α where
  forM := Many.forM
</code></pre>
<p>Because <code>γ</code> can be any type at all, <code>ForM</code> can support non-polymorphic collections.
A very simple collection is one of the natural numbers less than some given number, in reverse order:</p>
<pre><code class="language-lean">structure AllLessThan where
  num : Nat
</code></pre>
<p>Its <code>forM</code> operator applies the provided action to each smaller <code>Nat</code>:</p>
<pre><code class="language-lean">def AllLessThan.forM [Monad m] (coll : AllLessThan) (action : Nat → m Unit) : m Unit :=
  let rec countdown : Nat → m Unit
    | 0 =&gt; pure ()
    | n + 1 =&gt; do
      action n
      countdown n
  countdown coll.num

instance : ForM m AllLessThan Nat where
  forM := AllLessThan.forM
</code></pre>
<p>Running <code>IO.println</code> on each number less than five can be accomplished with <code>forM</code>:</p>
<pre><code class="language-lean">#eval forM { num := 5 : AllLessThan } IO.println
</code></pre>
<pre><code class="language-output info">4
3
2
1
0
</code></pre>
<p>An example <code>ForM</code> instance that works only in a particular monad is one that loops over the lines read from an IO stream, such as standard input:</p>
<pre><code class="language-lean">structure LinesOf where
  stream : IO.FS.Stream

partial def LinesOf.forM (readFrom : LinesOf) (action : String → IO Unit) : IO Unit := do
  let line ← readFrom.stream.getLine
  if line == &quot;&quot; then return ()
  action line
  forM readFrom action

instance : ForM IO LinesOf String where
  forM := LinesOf.forM
</code></pre>
<p>The definition of <code>forM</code> is marked <code>partial</code> because there is no guarantee that the stream is finite.
In this case, <code>IO.FS.Stream.getLine</code> works only in the <code>IO</code> monad, so no other monad can be used for looping.</p>
<p>This example program uses this looping construct to filter out lines that don't contain letters:</p>
<pre><code class="language-lean">def main (argv : List String) : IO UInt32 := do
  if argv != [] then
    IO.eprintln &quot;Unexpected arguments&quot;
    return 1

  forM (LinesOf.mk (← IO.getStdin)) fun line =&gt; do
    if line.any (·.isAlpha) then
      IO.print line

  return 0
</code></pre>
<p>The file <code>test-data</code> contains:</p>
<pre><code>Hello!
!!!!!
12345
abc123

Ok
</code></pre>
<p>Invoking this program, which is stored in <code>ForMIO.lean</code>, yields the following output:</p>
<pre><code>$ lean --run ForMIO.lean &lt; test-data
Hello!
abc123
Ok
</code></pre>
<h3 id="stopping-iteration"><a class="header" href="#stopping-iteration">Stopping Iteration</a></h3>
<p>Terminating a loop early is difficult to do with <code>forM</code>.
Writing a function that iterates over the <code>Nat</code>s in an <code>AllLessThan</code> only until <code>3</code> is reached requires a means of stopping the loop partway through.
One way to achieve this is to use <code>forM</code> with the <code>OptionT</code> monad transformer.
The first step is to define <code>OptionT.exec</code>, which discards information about both the return value and whether or not the transformed computation succeeded:</p>
<pre><code class="language-lean">def OptionT.exec [Applicative m] (action : OptionT m α) : m Unit :=
  action *&gt; pure ()
</code></pre>
<p>Then, failure in the <code>OptionT</code> instance of <code>Alternative</code> can be used to terminate looping early:</p>
<pre><code class="language-lean">def countToThree (n : Nat) : IO Unit :=
  let nums : AllLessThan := ⟨n⟩
  OptionT.exec (forM nums fun i =&gt; do
    if i &lt; 3 then failure else IO.println i)
</code></pre>
<p>A quick test demonstrates that this solution works:</p>
<pre><code class="language-lean">#eval countToThree 7
</code></pre>
<pre><code class="language-output info">6
5
4
3
</code></pre>
<p>However, this code is not so easy to read.
Terminating a loop early is a common task, and Lean provides more syntactic sugar to make this easier.
This same function can also be written as follows:</p>
<pre><code class="language-lean">def countToThree (n : Nat) : IO Unit := do
  let nums : AllLessThan := ⟨n⟩
  for i in nums do
    if i &lt; 3 then break
    IO.println i
</code></pre>
<p>Testing it reveals that it works just like the prior version:</p>
<pre><code class="language-lean">#eval countToThree 7
</code></pre>
<pre><code class="language-output info">6
5
4
3
</code></pre>
<p>At the time of writing, the <code>for ... in ... do ...</code> syntax desugars to the use of a type class called <code>ForIn</code>, which is a somewhat more complicated version of <code>ForM</code> that keeps track of state and early termination.
However, there is a plan to refactor <code>for</code> loops to use the simpler <code>ForM</code>, with monad transformers inserted as necessary.
In the meantime, an adapter is provided that converts a <code>ForM</code> instance into a <code>ForIn</code> instance, called <code>ForM.forIn</code>.
To enable <code>for</code> loops based on a <code>ForM</code> instance, add something like the following, with appropriate replacements for <code>AllLessThan</code> and <code>Nat</code>:</p>
<pre><code class="language-lean">instance : ForIn m AllLessThan Nat where
  forIn := ForM.forIn
</code></pre>
<p>Note, however, that this adapter only works for <code>ForM</code> instances that keep the monad unconstrained, as most of them do.
This is because the adapter uses <code>StateT</code> and <code>ExceptT</code>, rather than the underlying monad.</p>
<p>Early return is supported in <code>for</code> loops.
The translation of <code>do</code> blocks with early return into a use of an exception monad transformer applies equally well underneath <code>forM</code> as the earlier use of <code>OptionT</code> to halt iteration does.
This version of <code>List.find?</code> makes use of both:</p>
<pre><code class="language-lean">def List.find? (p : α → Bool) (xs : List α) : Option α := do
  for x in xs do
    if p x then return x
  failure
</code></pre>
<p>In addition to <code>break</code>, <code>for</code> loops support <code>continue</code> to skip the rest of the loop body in an iteration.
An alternative (but confusing) formulation of <code>List.find?</code> skips elements that don't satisfy the check:</p>
<pre><code class="language-lean">def List.find? (p : α → Bool) (xs : List α) : Option α := do
  for x in xs do
    if not (p x) then continue
    return x
  failure
</code></pre>
<p>A <code>Range</code> is a structure that consists of a starting number, an ending number, and a step.
They represent a sequence of natural numbers, from the starting number to the ending number, increasing by the step each time.
Lean has special syntax to construct ranges, consisting of square brackets, numbers, and colons that comes in four varieties.
The stopping point must always be provided, while the start and the step are optional, defaulting to <code>0</code> and <code>1</code>, respectively:</p>
<table><thead><tr><th>Expression</th><th>Start</th><th>Stop</th><th>Step</th><th>As List</th></tr></thead><tbody>
<tr><td><code>[:10]</code></td><td><code>0</code></td><td><code>10</code></td><td><code>1</code></td><td><code>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</code></td></tr>
<tr><td><code>[2:10]</code></td><td><code>2</code></td><td><code>10</code></td><td><code>1</code></td><td><code>[2, 3, 4, 5, 6, 7, 8, 9]</code></td></tr>
<tr><td><code>[:10:3]</code></td><td><code>0</code></td><td><code>10</code></td><td><code>3</code></td><td><code>[0, 3, 6, 9]</code></td></tr>
<tr><td><code>[2:10:3]</code></td><td><code>2</code></td><td><code>10</code></td><td><code>3</code></td><td><code>[2, 5, 8]</code></td></tr>
</tbody></table>
<p>Note that the starting number <em>is</em> included in the range, while the stopping numbers is not.
All three arguments are <code>Nat</code>s, which means that ranges cannot count down—a range where the starting number is greater than or equal to the stopping number simply contains no numbers.</p>
<p>Ranges can be used with <code>for</code> loops to draw numbers from the range.
This program counts even numbers from four to eight:</p>
<pre><code class="language-lean">def fourToEight : IO Unit := do
  for i in [4:9:2] do
    IO.println i
</code></pre>
<p>Running it yields:</p>
<pre><code class="language-output info">4
6
8
</code></pre>
<p>Finally, <code>for</code> loops support iterating over multiple collections in parallel, by separating the <code>in</code> clauses with commas.
Looping halts when the first collection runs out of elements, so the declaration:</p>
<pre><code class="language-lean">def parallelLoop := do
  for x in [&quot;currant&quot;, &quot;gooseberry&quot;, &quot;rowan&quot;], y in [4:8] do
    IO.println (x, y)
</code></pre>
<p>produces three lines of output:</p>
<pre><code class="language-lean">#eval parallelLoop
</code></pre>
<pre><code class="language-output info">(currant, 4)
(gooseberry, 5)
(rowan, 6)
</code></pre>
<h2 id="mutable-variables"><a class="header" href="#mutable-variables">Mutable Variables</a></h2>
<p>In addition to early <code>return</code>, <code>else</code>-less <code>if</code>, and <code>for</code> loops, Lean supports local mutable variables within a <code>do</code> block.
Behind the scenes, these mutable variables desugar to a use of <code>StateT</code>, rather than being implemented by true mutable variables.
Once again, functional programming is used to simulate imperative programming.</p>
<p>A local mutable variable is introduced with <code>let mut</code> instead of plain <code>let</code>.
The definition <code>two</code>, which uses the identity monad <code>Id</code> to enable <code>do</code>-syntax without introducing any effects, counts to <code>2</code>:</p>
<pre><code class="language-lean">def two : Nat := Id.run do
  let mut x := 0
  x := x + 1
  x := x + 1
  return x
</code></pre>
<p>This code is equivalent to a definition that uses <code>StateT</code> to add <code>1</code> twice:</p>
<pre><code class="language-lean">def two : Nat :=
  let block : StateT Nat Id Nat := do
    modify (· + 1)
    modify (· + 1)
    return (← get)
  let (result, _finalState) := block 0
  result
</code></pre>
<p>Local mutable variables work well with all the other features of <code>do</code>-notation that provide convenient syntax for monad transformers.
The definition <code>three</code> counts the number of entries in a three-entry list:</p>
<pre><code class="language-lean">def three : Nat := Id.run do
  let mut x := 0
  for _ in [1, 2, 3] do
    x := x + 1
  return x
</code></pre>
<p>Similarly, <code>six</code> adds the entries in a list:</p>
<pre><code class="language-lean">def six : Nat := Id.run do
  let mut x := 0
  for y in [1, 2, 3] do
    x := x + y
  return x
</code></pre>
<p><code>List.count</code> counts the number of entries in a list that satisfy some check:</p>
<pre><code class="language-lean">def List.count (p : α → Bool) (xs : List α) : Nat := Id.run do
  let mut found := 0
  for x in xs do
    if p x then found := found + 1
  return found
</code></pre>
<p>Local mutable variables can be more convenient to use and easier to read than an explicit local use of <code>StateT</code>.
However, they don't have the full power of unrestricted mutable variables from imperative languages.
In particular, they can only be modified in the <code>do</code>-block in which they are introduced.
This means, for instance, that <code>for</code>-loops can't be replaced by otherwise-equivalent recursive helper functions.
This version of <code>List.count</code>:</p>
<pre><code class="language-lean">def List.count (p : α → Bool) (xs : List α) : Nat := Id.run do
  let mut found := 0
  let rec go : List α → Id Unit
    | [] =&gt; pure ()
    | y :: ys =&gt; do
      if p y then found := found + 1
      go ys
  return found
</code></pre>
<p>yields the following error on the attempted mutation of <code>found</code>:</p>
<pre><code class="language-output info">`found` cannot be mutated, only variables declared using `let mut` can be mutated. If you did not intent to mutate but define `found`, consider using `let found` instead
</code></pre>
<p>This is because the recursive function is written in the identity monad, and only the monad of the <code>do</code>-block in which the variable is introduced is transformed with <code>StateT</code>.</p>
<h2 id="what-counts-as-a-do-block"><a class="header" href="#what-counts-as-a-do-block">What counts as a <code>do</code> block?</a></h2>
<p>Many features of <code>do</code>-notation apply only to a single <code>do</code>-block.
Early return terminates the current block, and mutable variables can only be mutated in the block that they are defined in.
To use them effectively, it's important to know what counts as &quot;the same block&quot;.</p>
<p>Generally speaking, the indented block following the <code>do</code> keyword counts as a block, and the immediate sequence of statements underneath it are part of that block.
Statements in independent blocks that are nonetheless contained in a block are not considered part of the block.
However, the rules that govern what exactly counts as the same block are slightly subtle, so some examples are in order.
The precise nature of the rules can be tested by setting up a program with a mutable variable and seeing where the mutation is allowed.
This program has a mutation that is clearly in the same block as the mutable variable:</p>
<pre><code class="language-lean">example : Id Unit := do
  let mut x := 0
  x := x + 1
</code></pre>
<p>When a mutation occurs in a <code>do</code>-block that is part of a <code>let</code>-statement that defines a name using <code>:=</code>, then it is not considered to be part of the block:</p>
<pre><code class="language-lean">example : Id Unit := do
  let mut x := 0
  let other := do
    x := x + 1
  other
</code></pre>
<pre><code class="language-output error">`x` cannot be mutated, only variables declared using `let mut` can be mutated. If you did not intent to mutate but define `x`, consider using `let x` instead
</code></pre>
<p>However, a <code>do</code>-block that occurs under a <code>let</code>-statement that defines a name using <code>←</code> is considered part of the surrounding block.
The following program is accepted:</p>
<pre><code class="language-lean">example : Id Unit := do
  let mut x := 0
  let other ← do
    x := x + 1
  pure other
</code></pre>
<p>Similarly, <code>do</code>-blocks that occur as arguments to functions are independent of their surrounding blocks.
The following program is not accepted:</p>
<pre><code class="language-lean">example : Id Unit := do
  let mut x := 0
  let addFour (y : Id Nat) := Id.run y + 4
  addFour do
    x := 5
</code></pre>
<pre><code class="language-output error">`x` cannot be mutated, only variables declared using `let mut` can be mutated. If you did not intent to mutate but define `x`, consider using `let x` instead
</code></pre>
<p>If the <code>do</code> keyword is completely redundant, then it does not introduce a new block.
This program is accepted, and is equivalent to the first one in this section:</p>
<pre><code class="language-lean">example : Id Unit := do
  let mut x := 0
  do x := x + 1
</code></pre>
<p>The contents of branches under a <code>do</code> (such as those introduced by <code>match</code> or <code>if</code>) are considered to be part of the surrounding block, whether or not a redundant <code>do</code> is added.
The following programs are all accepted:</p>
<pre><code class="language-lean">example : Id Unit := do
  let mut x := 0
  if x &gt; 2 then
    x := x + 1

example : Id Unit := do
  let mut x := 0
  if x &gt; 2 then do
    x := x + 1

example : Id Unit := do
  let mut x := 0
  match true with
  | true =&gt; x := x + 1
  | false =&gt; x := 17

example : Id Unit := do
  let mut x := 0
  match true with
  | true =&gt; do
    x := x + 1
  | false =&gt; do
    x := 17
</code></pre>
<p>Similarly, the <code>do</code> that occurs as part of the <code>for</code> and <code>unless</code> syntax is just part of their syntax, and does not introduce a fresh <code>do</code>-block.
These programs are also accepted:</p>
<pre><code class="language-lean">example : Id Unit := do
  let mut x := 0
  for y in [1:5] do
   x := x + y

example : Id Unit := do
  let mut x := 0
  unless 1 &lt; 5 do
    x := x + 1
</code></pre>
<h2 id="imperative-or-functional-programming"><a class="header" href="#imperative-or-functional-programming">Imperative or Functional Programming?</a></h2>
<p>The imperative features provided by Lean's <code>do</code>-notation allow many programs to very closely resemble their counterparts in languages like Rust, Java, or C#.
This resemblance is very convenient when translating an imperative algorithm into Lean, and some tasks are just most naturally thought of imperatively.
The introduction of monads and monad transformers enables imperative programs to be written in purely functional languages, and <code>do</code>-notation as a specialized syntax for monads (potentially locally transformed) allows functional programmers to have the best of both worlds: the strong reasoning principles afforded by immutability and a tight control over available effects through the type system are combined with syntax and libraries that allow programs that use effects to look familiar and be easy to read.
Monads and monad transformers allow functional versus imperative programming to be a matter of perspective.</p>
<h2 id="exercises-17"><a class="header" href="#exercises-17">Exercises</a></h2>
<ul>
<li>Rewrite <code>doug</code> to use <code>for</code> instead of the <code>doList</code> function. Are there other opportunities to use the features introduced in this section to improve the code? If so, use them!</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="additional-conveniences-4"><a class="header" href="#additional-conveniences-4">Additional Conveniences</a></h1>
<h2 id="pipe-operators"><a class="header" href="#pipe-operators">Pipe Operators</a></h2>
<p>Functions are normally written before their arguments.
When reading a program from left to right, this promotes a view in which the function's <em>output</em> is paramount—the function has a goal to achieve (that is, a value to compute), and it receives arguments to support it in this process.
But some programs are easier to understand in terms of an input that is successively refined to produce the output.
For these situations, Lean provides a <em>pipeline</em> operator which is similar to the that provided by F#.
Pipeline operators are useful in the same situations as Clojure's threading macros.</p>
<p>The pipeline <code>E1 |&gt; E2</code> is short for <code>E2 E1</code>.
For example, evaluating:</p>
<pre><code class="language-lean">#eval some 5 |&gt; toString
</code></pre>
<p>results in:</p>
<pre><code class="language-output info">&quot;(some 5)&quot;
</code></pre>
<p>While this change of emphasis can make some programs more convenient to read, pipelines really come into their own when they contain many components.</p>
<p>With the definition:</p>
<pre><code class="language-lean">def times3 (n : Nat) : Nat := n * 3
</code></pre>
<p>the following pipeline:</p>
<pre><code class="language-lean">#eval 5 |&gt; times3 |&gt; toString |&gt; (&quot;It is &quot; ++ ·)
</code></pre>
<p>yields:</p>
<pre><code class="language-output info">&quot;It is 15&quot;
</code></pre>
<p>More generally, a series of pipelines <code>E1 |&gt; E2 |&gt; E3 |&gt; E4</code> is short for nested function applications <code>E4 (E3 (E2 E1))</code>.</p>
<p>Pipelines may also be written in reverse.
In this case, they do not place the subject of data transformation first; however, in cases where many nested parentheses pose a challenge for readers, they can clarify the steps of application.
The prior example could be equivalently written as:</p>
<pre><code class="language-lean">#eval (&quot;It is &quot; ++ ·) &lt;| toString &lt;| times3 &lt;| 5
</code></pre>
<p>which is short for:</p>
<pre><code class="language-lean">#eval (&quot;It is &quot; ++ ·) (toString (times3 5))
</code></pre>
<p>Lean's method dot notation that uses the name of the type before the dot to resolve the namespace of the operator after the dot serves a similar purpose to pipelines.
Even without the pipeline operator, it is possible to write <code>[1, 2, 3].reverse</code> instead of <code>List.reverse [1, 2, 3]</code>.
However, the pipeline operator is also useful for dotted functions when using many of them.
<code>([1, 2, 3].reverse.drop 1).reverse</code> can also be written as <code>[1, 2, 3] |&gt; List.reverse |&gt; List.drop 1 |&gt; List.reverse</code>.
This version avoids having to parenthesize expressions simply because they accept arguments, and it recovers the convenience of a chain of method calls in languages like Kotlin or C#.
However, it still requires the namespace to be provided by hand.
As a final convenience, Lean provides the &quot;pipeline dot&quot; operator, which groups functions like the pipeline but uses the name of the type to resolve namespaces.
With &quot;pipeline dot&quot;, the example can be rewritten to <code>[1, 2, 3] |&gt;.reverse |&gt;.drop 1 |&gt;.reverse</code>.</p>
<h2 id="infinite-loops"><a class="header" href="#infinite-loops">Infinite Loops</a></h2>
<p>Within a <code>do</code>-block, the <code>repeat</code> keyword introduces an infinite loop.
For example, a program that spams the string <code>&quot;Spam!&quot;</code> can use it:</p>
<pre><code class="language-lean">def spam : IO Unit := do
  repeat IO.println &quot;Spam!&quot;
</code></pre>
<p>A <code>repeat</code> loop supports <code>break</code> and <code>continue</code>, just like <code>for</code> loops.</p>
<p>The <code>dump</code> function from the <a href="monad-transformers/../hello-world/cat.html#streams">implementation of <code>feline</code></a> uses a recursive function to run forever:</p>
<pre><code class="language-lean">partial def dump (stream : IO.FS.Stream) : IO Unit := do
  let buf ← stream.read bufsize
  if buf.isEmpty then
    pure ()
  else
    let stdout ← IO.getStdout
    stdout.write buf
    dump stream
</code></pre>
<p>This function can be greatly shortened using <code>repeat</code>:</p>
<pre><code class="language-lean">def dump (stream : IO.FS.Stream) : IO Unit := do
  let stdout ← IO.getStdout
  repeat do
    let buf ← stream.read bufsize
    if buf.isEmpty then break
    stdout.write buf
</code></pre>
<p>Neither <code>spam</code> nor <code>dump</code> need to be declared as <code>partial</code> because they are not themselves infinitely recursive.
Instead, <code>repeat</code> makes use of a type whose <code>ForM</code> instance is <code>partial</code>.
Partiality does not &quot;infect&quot; calling functions.</p>
<h2 id="while-loops"><a class="header" href="#while-loops">While Loops</a></h2>
<p>When programming with local mutability, <code>while</code> loops can be a convenient alternative to <code>repeat</code> with an <code>if</code>-guarded <code>break</code>:</p>
<pre><code class="language-lean">def dump (stream : IO.FS.Stream) : IO Unit := do
  let stdout ← IO.getStdout
  let mut buf ← stream.read bufsize
  while not buf.isEmpty do
    stdout.write buf
    buf ← stream.read bufsize
</code></pre>
<p>Behind the scenes, <code>while</code> is just a simpler notation for <code>repeat</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-5"><a class="header" href="#summary-5">Summary</a></h1>
<h2 id="combining-monads"><a class="header" href="#combining-monads">Combining Monads</a></h2>
<p>When writing a monad from scratch, there are design patterns that tend to describe the ways that each effect is added to the monad.
Reader effects are added by having the monad's type be a function from the reader's environment, state effects are added by including a function from the initial state to the value paired with the final state, failure or exceptions are added by including a sum type in the return type, and logging or other output is added by including a product type in the return type.
Existing monads can be made part of the return type as well, allowing their effects to be included in the new monad.</p>
<p>These design patterns are made into a library of reusable software components by defining <em>monad transformers</em>, which add an effect to some base monad.
Monad transformers take the simpler monad types as arguments, returning the enhanced monad types.
At a minimum, a monad transformer should provide the following instances:</p>
<ol>
<li>A <code>Monad</code> instance that assumes the inner type is already a monad</li>
<li>A <code>MonadLift</code> instance to translate an action from the inner monad to the transformed monad</li>
</ol>
<p>Monad transformers may be implemented as polymorphic structures or inductive datatypes, but they are most often implemented as functions from the underlying monad type to the enhanced monad type.</p>
<h2 id="type-classes-for-effects"><a class="header" href="#type-classes-for-effects">Type Classes for Effects</a></h2>
<p>A common design pattern is to implement a particular effect by defining a monad that has the effect, a monad transformer that adds it to another monad, and a type class that provides a generic interface to the effect.
This allows programs to be written that merely specify which effects they need, so the caller can provide any monad that has the right effects.</p>
<p>Sometimes, auxiliary type information (e.g. the state's type in a monad that provides state, or the exception's type in a monad that provides exceptions) is an output parameter, and sometimes it is not.
The output parameter is most useful for simple programs that use each kind of effect only once, but it risks having the type checker commit to a the wrong type too early when multiple instances of the same effect are used in a given program.
Thus, both versions are typically provided, with the ordinary-parameter version of the type class having a name that ends in <code>-Of</code>.</p>
<h2 id="monad-transformers-dont-commute"><a class="header" href="#monad-transformers-dont-commute">Monad Transformers Don't Commute</a></h2>
<p>It is important to note that changing the order of transformers in a monad can change the meaning of programs that use the monad.
For instance, re-ordering <code>StateT</code> and <code>ExceptT</code> can result either in programs that lose state modifications when exceptions are thrown or programs that keep changes.
While most imperative languages provide only the latter, the increased flexibility provided by monad transformers demands thought and attention to choose the correct variety for the task at hand.</p>
<h2 id="do-notation-for-monad-transformers"><a class="header" href="#do-notation-for-monad-transformers"><code>do</code>-Notation for Monad Transformers</a></h2>
<p>Lean's <code>do</code>-blocks support early return, in which the block is terminated with some value, locally mutable variables, <code>for</code>-loops with <code>break</code> and <code>continue</code>, and single-branched <code>if</code>-statements.
While this may seem to be introducing imperative features that would get in the way of using Lean to write proofs, it is in fact nothing more than a more convenient syntax for certain common uses of monad transformers.
Behind the scenes, whatever monad the <code>do</code>-block is written in is transformed by appropriate uses of <code>ExceptT</code> and <code>StateT</code> to support these additional effects.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="programming-with-dependent-types"><a class="header" href="#programming-with-dependent-types">Programming with Dependent Types</a></h1>
<p>In most statically-typed programming languages, there is a hermetic seal between the world of types and the world of programs.
Types and programs have different grammars and they are used at different times.
Types are typically used at compile time, to check that a program obeys certain invariants.
Programs are used at run time, to actually perform computations.
When the two interact, it is usually in the form of a type-case operator like an &quot;instance-of&quot; check or a casting operator that provides the type checker with information that was otherwise unavailable, to be verified at run time.
In other words, the interaction consists of types being inserted into the world of programs, gaining some limited run-time meaning.</p>
<p>Lean does not impose this strict separation.
In Lean, programs may compute types and types may contain programs.
Placing programs in types allows their full computation power to be used at compile time, and the ability to return types from functions makes types into first-class participants in the programming process.</p>
<p><em>Dependent types</em> are types that contain non-type expressions.
A common source of dependent types is a named argument to a function.
For example, the function <code>natOrStringThree</code> returns either a natural number or a string, depending on which <code>Bool</code> it is passed:</p>
<pre><code class="language-lean">def natOrStringThree (b : Bool) : if b then Nat else String :=
  match b with
  | true =&gt; (3 : Nat)
  | false =&gt; &quot;three&quot;
</code></pre>
<p>Further examples of dependent types include:</p>
<ul>
<li><a href="getting-to-know/polymorphism.html">The introductory section on polymorphism</a> contains <code>posOrNegThree</code>, in which the function's return type depends on the value of the argument.</li>
<li><a href="type-classes/pos.html#literal-numbers">The <code>OfNat</code> type class</a> depends on the specific natural number literal being used.</li>
<li><a href="functor-applicative-monad/applicative.html#validated-input">The <code>CheckedInput</code> structure</a> used in the example of validators depends on the year in which validation occurred.</li>
<li><a href="functor-applicative-monad/applicative.html#subtypes">Subtypes</a> contain propositions that refer to particular values.</li>
<li>Essentially all interesting propositions, including those that determine the validity of <a href="props-proofs-indexing.html">array indexing notation</a>, are types that contain values and are thus dependent types.</li>
</ul>
<p>Dependent types vastly increase the power of a type system.
The flexibility of return types that branch on argument values enables programs to be written that cannot easily be given types in other type systems.
At the same time, dependent types allow a type signature to restrict which values may be returned from a function, enabling strong invariants to be enforced at compile time.</p>
<p>However, programming with dependent types can be quite complex, and it requires a whole set of skills above and beyond functional programming.
Expressive specifications can be complicated to fulfill, and there is a real risk of tying oneself in knots and being unable to complete the program.
On the other hand, this process can lead to new understanding, which can be expressed in a refined type that can be fulfilled.
While this chapter scratches the surface of dependently typed programming, it is a deep topic that deserves an entire book of its own.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="indexed-families"><a class="header" href="#indexed-families">Indexed Families</a></h1>
<p>Polymorphic inductive types take type arguments.
For instance, <code>List</code> takes an argument that determines the type of the entries in the list, and <code>Except</code> takes arguments that determine the types of the exceptions or values.
These type arguments, which are the same in every constructor of the datatype, are referred to as <em>parameters</em>.</p>
<p>Arguments to inductive types need not be the same in every constructor, however.
Inductive types in which the arguments to the type vary based on the choice of constructor are called <em>indexed families</em>, and the arguments that vary are referred to as <em>indices</em>.
The &quot;hello world&quot; of indexed families is a type of lists that contains the length of the list in addition to the type of entries, conventionally referred to as &quot;vectors&quot;:</p>
<pre><code class="language-lean">inductive Vect (α : Type u) : Nat → Type u where
   | nil : Vect α 0
   | cons : α → Vect α n → Vect α (n + 1)
</code></pre>
<p>Function declarations may take some arguments before the colon, indicating that they are available in the entire definition, and some arguments after, indicating a desire to pattern-match on them and define the function case by case.
Inductive datatypes have a similar principle: the argument <code>α</code> is named at the top of the datatype declaration, prior to the colon, which indicates that it is a parameter that must be provided as the first argument in all occurrences of <code>Vect</code> in the definition, while the <code>Nat</code> argument occurs after the colon, indicating that it is an index that may vary.
Indeed, the three occurrences of <code>Vect</code> in the <code>nil</code> and <code>cons</code> constructor declarations consistently provide <code>α</code> as the first argument, while the second argument is different in each case.</p>
<p>The declaration of <code>nil</code> states that it is a constructor of type <code>Vect α 0</code>.
This means that using <code>Vect.nil</code> in a context expecting a <code>Vect String 3</code> is a type error, just as <code>[1, 2, 3]</code> is a type error in a context that expects a <code>List String</code>:</p>
<pre><code class="language-lean">example : Vect String 3 := Vect.nil
</code></pre>
<pre><code class="language-output error">type mismatch
  Vect.nil
has type
  Vect String 0 : Type
but is expected to have type
  Vect String 3 : Type
</code></pre>
<p>The mismatch between <code>0</code> and <code>3</code> in this example plays exactly the same role as any other type mismatch, even though <code>0</code> and <code>3</code> are not themselves types.</p>
<p>Indexed families are called <em>families</em> of types because different index values can make different constructors available for use.
In some sense, an indexed family is not a type; rather, it is a collection of related types, and the choice of index values also chooses a type from the collection.
Choosing the index <code>5</code> for <code>Vect</code> means that only the constructor <code>cons</code> is available, and choosing the index <code>0</code> means that only <code>nil</code> is available.</p>
<p>If the index is not yet known (e.g. because it is a variable), then no constructor can be used until it becomes known.
Using <code>n</code> for the length allows neither <code>Vect.nil</code> nor <code>Vect.cons</code>, because there's no way to know whether the variable <code>n</code> should stand for a <code>Nat</code> that matches <code>0</code> or <code>n + 1</code>:</p>
<pre><code class="language-lean">example : Vect String n := Vect.nil
</code></pre>
<pre><code class="language-output error">type mismatch
  Vect.nil
has type
  Vect String 0 : Type
but is expected to have type
  Vect String n : Type
</code></pre>
<pre><code class="language-lean">example : Vect String n := Vect.cons &quot;Hello&quot; (Vect.cons &quot;world&quot; Vect.nil)
</code></pre>
<pre><code class="language-output error">type mismatch
  Vect.cons &quot;Hello&quot; (Vect.cons &quot;world&quot; Vect.nil)
has type
  Vect String (0 + 1 + 1) : Type
but is expected to have type
  Vect String n : Type
</code></pre>
<p>Having the length of the list as part of its type means that the type becomes more informative.
For example, <code>Vect.replicate</code> is a function that creates a <code>Vect</code> with a number of copies of a given value.
The type that says this precisely is:</p>
<pre><code class="language-lean">def Vect.replicate (n : Nat) (x : α) : Vect α n := _
</code></pre>
<p>The argument <code>n</code> appears as the length of the result.
The message associated with the underscore placeholder describes the task at hand:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n : Nat
x : α
⊢ Vect α n
</code></pre>
<p>When working with indexed families, constructors can only be applied when Lean can see that the constructor's index matches the index in the expected type.
However, neither constructor has an index that matches <code>n</code>—<code>nil</code> matches <code>Nat.zero</code>, and <code>cons</code> matches <code>Nat.succ</code>.
Just as in the example type errors, the variable <code>n</code> could stand for either, depending on which <code>Nat</code> is provided to the function as an argument.
The solution is to use pattern matching to consider both of the possible cases:</p>
<pre><code class="language-lean">def Vect.replicate (n : Nat) (x : α) : Vect α n :=
  match n with
  | 0 =&gt; _
  | k + 1 =&gt; _
</code></pre>
<p>Because <code>n</code> occurs in the expected type, pattern matching on <code>n</code> <em>refines</em> the expected type in the two cases of the match.
In the first underscore, the expected type has become <code>Vect α 0</code>:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n : Nat
x : α
⊢ Vect α 0
</code></pre>
<p>In the second underscore, it has become <code>Vect α (k + 1)</code>:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n : Nat
x : α
k : Nat
⊢ Vect α (k + 1)
</code></pre>
<p>When pattern matching refines the type of a program in addition to discovering the structure of a value, it is called <em>dependent pattern matching</em>.</p>
<p>The refined type makes it possible to apply the constructors.
The first underscore matches <code>Vect.nil</code>, and the second matches <code>Vect.cons</code>: </p>
<pre><code class="language-lean">def Vect.replicate (n : Nat) (x : α) : Vect α n :=
  match n with
  | 0 =&gt; .nil
  | k + 1 =&gt; .cons _ _
</code></pre>
<p>The first underscore under the <code>.cons</code> should have type <code>α</code>.
There is an <code>α</code> available, namely <code>x</code>:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n : Nat
x : α
k : Nat
⊢ α
</code></pre>
<p>The second underscore should be a <code>Vect α k</code>, which can be produced by a recursive call to <code>replicate</code>:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n : Nat
x : α
k : Nat
⊢ Vect α k
</code></pre>
<p>Here is the final definition of <code>replicate</code>:</p>
<pre><code class="language-lean">def Vect.replicate (n : Nat) (x : α) : Vect α n :=
  match n with
  | 0 =&gt; .nil
  | k + 1 =&gt; .cons x (replicate k x)
</code></pre>
<p>In addition to providing assistance while writing the function, the informative type of <code>Vect.replicate</code> also allows client code to rule out a number of unexpected functions without having to read the source code.
A version of <code>replicate</code> for lists could produce a list of the wrong length:</p>
<pre><code class="language-lean">def List.replicate (n : Nat) (x : α) : List α :=
  match n with
  | 0 =&gt; []
  | k + 1 =&gt; x :: x :: replicate k x
</code></pre>
<p>However, making this mistake with <code>Vect.replicate</code> is a type error:</p>
<pre><code class="language-lean">def Vect.replicate (n : Nat) (x : α) : Vect α n :=
  match n with
  | 0 =&gt; .nil
  | k + 1 =&gt; .cons x (.cons x (replicate k x))
</code></pre>
<pre><code class="language-output error">application type mismatch
  cons x (cons x (replicate k x))
argument
  cons x (replicate k x)
has type
  Vect α (k + 1) : Type ?u.2019
but is expected to have type
  Vect α k : Type ?u.2019
</code></pre>
<p>The function <code>List.zip</code> combines two lists by pairing the first entry in the first list with the first entry in the second list, the second entry in the first list with the second entry in the second list, and so forth.
<code>List.zip</code> can be used to pair the three highest peaks in the US state of Oregon with the three highest peaks in Denmark:</p>
<pre><code class="language-lean">[&quot;Mount Hood&quot;,
 &quot;Mount Jefferson&quot;,
 &quot;South Sister&quot;].zip [&quot;Møllehøj&quot;, &quot;Yding Skovhøj&quot;, &quot;Ejer Bavnehøj&quot;]
</code></pre>
<p>The result is a list of three pairs:</p>
<pre><code class="language-lean">[(&quot;Mount Hood&quot;, &quot;Møllehøj&quot;),
 (&quot;Mount Jefferson&quot;, &quot;Yding Skovhøj&quot;),
 (&quot;South Sister&quot;, &quot;Ejer Bavnehøj&quot;)]
</code></pre>
<p>It's somewhat unclear what should happen when the lists have different lengths.
Like many languages, Lean chooses to ignore the extra entries in one of the lists.
For instance, combining the heights of the five highest peaks in Oregon with those of the three highest peaks in Denmark yields three pairs.
In particular,</p>
<pre><code class="language-lean">[3428.8, 3201, 3158.5, 3075, 3064].zip [170.86, 170.77, 170.35]
</code></pre>
<p>evaluates to</p>
<pre><code class="language-lean">[(3428.8, 170.86), (3201, 170.77), (3158.5, 170.35)]
</code></pre>
<p>While this approach is convenient because it always returns an answer, it runs the risk of throwing away data when the lists unintentionally have different lengths.
F# takes a different approach: its version of <code>List.zip</code> throws an exception when the lengths don't match, as can be seen in this <code>fsi</code> session:</p>
<pre><code class="language-fsharp">&gt; List.zip [3428.8; 3201.0; 3158.5; 3075.0; 3064.0] [170.86; 170.77; 170.35];;
</code></pre>
<pre><code class="language-output error">System.ArgumentException: The lists had different lengths.
list2 is 2 elements shorter than list1 (Parameter 'list2')
   at Microsoft.FSharp.Core.DetailedExceptions.invalidArgDifferentListLength[?](String arg1, String arg2, Int32 diff) in /builddir/build/BUILD/dotnet-v3.1.424-SDK/src/fsharp.3ef6f0b514198c0bfa6c2c09fefe41a740b024d5/src/fsharp/FSharp.Core/local.fs:line 24
   at Microsoft.FSharp.Primitives.Basics.List.zipToFreshConsTail[a,b](FSharpList`1 cons, FSharpList`1 xs1, FSharpList`1 xs2) in /builddir/build/BUILD/dotnet-v3.1.424-SDK/src/fsharp.3ef6f0b514198c0bfa6c2c09fefe41a740b024d5/src/fsharp/FSharp.Core/local.fs:line 918
   at Microsoft.FSharp.Primitives.Basics.List.zip[T1,T2](FSharpList`1 xs1, FSharpList`1 xs2) in /builddir/build/BUILD/dotnet-v3.1.424-SDK/src/fsharp.3ef6f0b514198c0bfa6c2c09fefe41a740b024d5/src/fsharp/FSharp.Core/local.fs:line 929
   at Microsoft.FSharp.Collections.ListModule.Zip[T1,T2](FSharpList`1 list1, FSharpList`1 list2) in /builddir/build/BUILD/dotnet-v3.1.424-SDK/src/fsharp.3ef6f0b514198c0bfa6c2c09fefe41a740b024d5/src/fsharp/FSharp.Core/list.fs:line 466
   at &lt;StartupCode$FSI_0006&gt;.$FSI_0006.main@()
Stopped due to error
</code></pre>
<p>This avoids accidentally discarding information, but crashing a program comes with its own difficulties.
The Lean equivalent, which would use the <code>Option</code> or <code>Except</code> monads, would introduce a burden that may not be worth the safety.</p>
<p>Using <code>Vect</code>, however, it is possible to write a version of <code>zip</code> with a type that requires that both arguments have the same length:</p>
<pre><code class="language-lean">def Vect.zip : Vect α n → Vect β n → Vect (α × β) n
  | .nil, .nil =&gt; .nil
  | .cons x xs, .cons y ys =&gt; .cons (x, y) (zip xs ys)
</code></pre>
<p>This definition only has patterns for the cases where either both arguments are <code>Vect.nil</code> or both arguments are <code>Vect.cons</code>, and Lean accepts the definition without a &quot;missing cases&quot; error like the one that results from a similar definition for <code>List</code>:</p>
<pre><code class="language-lean">def List.zip : List α → List β → List (α × β)
  | [], [] =&gt; []
  | x :: xs, y :: ys =&gt; (x, y) :: zip xs ys
</code></pre>
<pre><code class="language-output error">missing cases:
(List.cons _ _), []
[], (List.cons _ _)
</code></pre>
<p>This is because the constructor used in the first pattern, <code>nil</code> or <code>cons</code>, <em>refines</em> the type checker's knowledge about the length <code>n</code>.
When the first pattern is <code>nil</code>, the type checker can additionally determine that the length was <code>0</code>, so the only possible choice for the second pattern is <code>nil</code>.
Similarly, when the first pattern is <code>cons</code>, the type checker can determine that the length was <code>k+1</code> for some <code>Nat</code> <code>k</code>, so the only possible choice for the second pattern is <code>cons</code>.
Indeed, adding a case that uses <code>nil</code> and <code>cons</code> together is a type error, because the lengths don't match:</p>
<pre><code class="language-lean">def Vect.zip : Vect α n → Vect β n → Vect (α × β) n
  | .nil, .nil =&gt; .nil
  | .nil, .cons y ys =&gt; .nil
  | .cons x xs, .cons y ys =&gt; .cons (x, y) (zip xs ys)
</code></pre>
<pre><code class="language-output error">type mismatch
  Vect.cons y ys
has type
  Vect β (?m.4765 + 1) : Type ?u.4577
but is expected to have type
  Vect β 0 : Type ?u.4577
</code></pre>
<p>The refinement of the length can be observed by making <code>n</code> into an explicit argument:</p>
<pre><code class="language-lean">def Vect.zip : (n : Nat) → Vect α n → Vect β n → Vect (α × β) n
  | 0, .nil, .nil =&gt; .nil
  | k + 1, .cons x xs, .cons y ys =&gt; .cons (x, y) (zip k xs ys)
</code></pre>
<h2 id="exercises-18"><a class="header" href="#exercises-18">Exercises</a></h2>
<p>Getting a feel for programming with dependent types requires experience, and the exercises in this section are very important.
For each exercise, try to see which mistakes the type checker can catch, and which ones it can't, by experimenting with the code as you go.
This is also a good way to develop a feel for the error messages.</p>
<ul>
<li>
<p>Double-check that <code>Vect.zip</code> gives the right answer when combining the three highest peaks in Oregon with the three highest peaks in Denmark.
Because <code>Vect</code> doesn't have the syntactic sugar that <code>List</code> has, it can be helpful to begin by defining <code>oregonianPeaks : Vect String 3</code> and <code>danishPeaks : Vect String 3</code>.</p>
</li>
<li>
<p>Define a function <code>Vect.map</code> with type <code>(α → β) → Vect α n → Vect β n</code>.</p>
</li>
<li>
<p>Define a function <code>Vect.zipWith</code> that combines the entries in a <code>Vect</code> one at a time with a function.
It should have the type <code>(α → β → γ) → Vect α n → Vect β n → Vect γ n</code>.</p>
</li>
<li>
<p>Define a function <code>Vect.unzip</code> that splits a <code>Vect</code> of pairs into a pair of <code>Vect</code>s. It should have the type <code>Vect (α × β) n → Vect α n × Vect β n</code>.</p>
</li>
<li>
<p>Define a function <code>Vect.snoc</code> that adds an entry to the <em>end</em> of a <code>Vect</code>. Its type should be <code>Vect α n → α → Vect α (n + 1)</code> and <code>#eval Vect.snoc (.cons &quot;snowy&quot; .nil) &quot;peaks&quot;</code> should yield <code>Vect.cons &quot;snowy&quot; (Vect.cons &quot;peaks&quot; (Vect.nil))</code>. The name <code>snoc</code> is a traditional functional programming pun: it is <code>cons</code> backwards.</p>
</li>
<li>
<p>Define a function <code>Vect.reverse</code> that reverses the order of a <code>Vect</code>.</p>
</li>
<li>
<p>Define a function <code>Vect.drop</code> with the following type: <code>(n : Nat) → Vect α (k + n) → Vect α k</code>.
Verify that it works by checking that <code>#eval danishPeaks.drop 2</code> yields <code>Vect.cons &quot;Ejer Bavnehøj&quot; (Vect.nil)</code>.</p>
</li>
<li>
<p>Define a function <code>Vect.take</code> with type <code>(n : Nat) → Vect α (k + n) → Vect α n</code> that returns the first <code>n</code> entries in the <code>Vect</code>. Check that it works on an example.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-universe-design-pattern"><a class="header" href="#the-universe-design-pattern">The Universe Design Pattern</a></h1>
<p>In Lean, types such as <code>Type</code>, <code>Type 3</code>, and <code>Prop</code> that classify other types are known as universes.
However, the term <em>universe</em> is also used for a design pattern in which a datatype is used to represent a subset of Lean's types, and a function converts the datatype's constructors into actual types.
The values of this datatype are called <em>codes</em> for their types.</p>
<p>Just like Lean's built-in universes, the universes implemented with this pattern are types that describe some collection of available types, even though the mechanism by which it is done is different.
In Lean, there are types such as <code>Type</code>, <code>Type 3</code>, and <code>Prop</code> that directly describe other types.
This arrangement is referred to as <em>universes à la Russell</em>.
The user-defined universes described in this section represent all of their types as <em>data</em>, and include an explicit function to interpret these codes into actual honest-to-goodness types.
This arrangement is referred to as <em>universes à la Tarski</em>.
While languages such as Lean that are based on dependent type theory almost always use Russell-style universes, Tarski-style universes are a useful pattern for defining APIs in these languages.</p>
<p>Defining a custom universe makes it possible to carve out a closed collection of types that can be used with an API.
Because the collection of types is closed, recursion over the codes allows programs to work for <em>any</em> type in the universe.
One example of a custom universe has the codes <code>nat</code>, standing for <code>Nat</code>, and <code>bool</code>, standing for <code>Bool</code>:</p>
<pre><code class="language-lean">inductive NatOrBool where
  | nat | bool

abbrev NatOrBool.asType (code : NatOrBool) : Type :=
  match code with
  | .nat =&gt; Nat
  | .bool =&gt; Bool
</code></pre>
<p>Pattern matching on a code allows the type to be refined, just as pattern matching on the constructors of <code>Vect</code> allows the expected length to be refined.
For instance, a program that deserializes the types in this universe from a string can be written as follows:</p>
<pre><code class="language-lean">def decode (t : NatOrBool) (input : String) : Option t.asType :=
  match t with
  | .nat =&gt; input.toNat?
  | .bool =&gt;
    match input with
    | &quot;true&quot; =&gt; some true
    | &quot;false&quot; =&gt; some false
    | _ =&gt; none
</code></pre>
<p>Dependent pattern matching on <code>t</code> allows the expected result type <code>t.asType</code> to be respectively refined to <code>NatOrBool.nat.asType</code> and <code>NatOrBool.bool.asType</code>, and these compute to the actual types <code>Nat</code> and <code>Bool</code>.</p>
<p>Like any other data, codes may be recursive.
The type <code>NestedPairs</code> codes for any possible nesting of the pair and natural number types:</p>
<pre><code class="language-lean">inductive NestedPairs where
  | nat : NestedPairs
  | pair : NestedPairs → NestedPairs → NestedPairs

abbrev NestedPairs.asType : NestedPairs → Type
  | .nat =&gt; Nat
  | .pair t1 t2 =&gt; asType t1 × asType t2
</code></pre>
<p>In this case, the interpretation function <code>NestedPairs.asType</code> is recursive.
This means that recursion over codes is required in order to implement <code>BEq</code> for the universe:</p>
<pre><code class="language-lean">def NestedPairs.beq (t : NestedPairs) (x y : t.asType) : Bool :=
  match t with
  | .nat =&gt; x == y
  | .pair t1 t2 =&gt; beq t1 x.fst y.fst &amp;&amp; beq t2 x.snd y.snd

instance {t : NestedPairs} : BEq t.asType where
  beq x y := t.beq x y
</code></pre>
<p>Even though every type in the <code>NestedPairs</code> universe already has a <code>BEq</code> instance, type class search does not automatically check every possible case of a datatype in an instance declaration, because there might be infinitely many such cases, as with <code>NestedPairs</code>.
Attempting to appeal directly to the <code>BEq</code> instances rather than explaining to Lean how to find them by recursion on the codes results in an error:</p>
<pre><code class="language-lean">instance {t : NestedPairs} : BEq t.asType where
  beq x y := x == y
</code></pre>
<pre><code class="language-output error">failed to synthesize instance
  BEq (NestedPairs.asType t)
</code></pre>
<p>The <code>t</code> in the error message stands for an unknown value of type <code>NestedPairs</code>.</p>
<h2 id="type-classes-vs-universes"><a class="header" href="#type-classes-vs-universes">Type Classes vs Universes</a></h2>
<p>Type classes allow an open-ended collection of types to be used with an API as long as they have implementations of the necessary interfaces.
In most cases, this is preferable.
It is hard to predict all use cases for an API ahead of time, and type classes are a convenient way to allow library code to be used with more types than the original author expected.</p>
<p>A universe à la Tarski, on the other hand, restricts the API to be usable only with a predetermined collection of types.
This is useful in a few situations:</p>
<ul>
<li>When a function should act very differently depending on which type it is passed—it is impossible to pattern match on types themselves, but pattern matching on codes for types is allowed</li>
<li>When an external system inherently limits the types of data that may be provided, and extra flexibility is not desired</li>
<li>When additional properties of a type are required over and above the implementation of some operations</li>
</ul>
<p>Type classes are useful in many of the same situations as interfaces in Java or C#, while a universe à la Tarski can be useful in cases where a sealed class might be used, but where an ordinary inductive datatype is not usable.</p>
<h2 id="a-universe-of-finite-types"><a class="header" href="#a-universe-of-finite-types">A Universe of Finite Types</a></h2>
<p>Restricting the types that can be used with an API to a predetermined collection can enable operations that would be impossible for an open-ended API.
For example, functions can't normally be compared for equality.
Functions should be considered equal when they map the same inputs to the same outputs.
Checking this could take infinite amounts of time, because comparing two functions with type <code>Nat → Bool</code> would require checking that the functions returned the same <code>Bool</code> for each and every <code>Nat</code>.</p>
<p>In other words, a function from an infinite type is itself infinite.
Functions can be viewed as tables, and a function whose argument type is infinite requires infinitely many rows to represent each case.
But functions from finite types require only finitely many rows in their tables, making them finite.
Two functions whose argument type is finite can be checked for equality by enumerating all possible arguments, calling the functions on each of them, and then comparing the results.
Checking higher-order functions for equality requires generating all possible functions of a given type, which additionally requires that the return type is finite so that each element of the argument type can be mapped to each element of the return type.
This is not a <em>fast</em> method, but it does complete in finite time.</p>
<p>One way to represent finite types is by a universe:</p>
<pre><code class="language-lean">inductive Finite where
  | unit : Finite
  | bool : Finite
  | pair : Finite → Finite → Finite
  | arr : Finite → Finite → Finite

abbrev Finite.asType : Finite → Type
  | .unit =&gt; Unit
  | .bool =&gt; Bool
  | .pair t1 t2 =&gt; asType t1 × asType t2
  | .arr t1 t2 =&gt; asType t1 → asType t2
</code></pre>
<p>In this universe, the constructor <code>arr</code> stands for the function type, which is written with an <code>arr</code>ow.</p>
<p>Comparing two values from this universe for equality is almost the same as in the <code>NestedPairs</code> universe.
The only important difference is the addition of the case for <code>arr</code>, which uses a helper called <code>Finite.enumerate</code> to generate every value from the type coded for by <code>t1</code>, checking that the two functions return equal results for every possible input:</p>
<pre><code class="language-lean">def Finite.beq (t : Finite) (x y : t.asType) : Bool :=
  match t with
  | .unit =&gt; true
  | .bool =&gt; x == y
  | .pair t1 t2 =&gt; beq t1 x.fst y.fst &amp;&amp; beq t2 x.snd y.snd
  | .arr t1 t2 =&gt;
    t1.enumerate.all fun arg =&gt; beq t2 (x arg) (y arg)
</code></pre>
<p>The standard library function <code>List.all</code> checks that the provided function returns <code>true</code> on every entry of a list.
This function can be used to compare functions on the Booleans for equality:</p>
<pre><code class="language-lean">#eval Finite.beq (.arr .bool .bool) (fun _ =&gt; true) (fun b =&gt; b == b)
</code></pre>
<pre><code class="language-output info">true
</code></pre>
<p>It can also be used to compare functions from the standard library:</p>
<pre><code class="language-lean">#eval Finite.beq (.arr .bool .bool) (fun _ =&gt; true) not
</code></pre>
<pre><code class="language-output info">false
</code></pre>
<p>It can even compare functions built using tools such as function composition:</p>
<pre><code class="language-lean">#eval Finite.beq (.arr .bool .bool) id (not ∘ not)
</code></pre>
<pre><code class="language-output info">true
</code></pre>
<p>This is because the <code>Finite</code> universe codes for Lean's <em>actual</em> function type, not a special analogue created by the library.</p>
<p>The implementation of <code>enumerate</code> is also by recursion on the codes from <code>Finite</code>.</p>
<pre><code class="language-lean">  def Finite.enumerate (t : Finite) : List t.asType :=
    match t with
    | .unit =&gt; [()]
    | .bool =&gt; [true, false]
    | .pair t1 t2 =&gt; t1.enumerate.product t2.enumerate
    | .arr t1 t2 =&gt; t1.functions t2.enumerate
</code></pre>
<p>In the case for <code>Unit</code>, there is only a single value.
In the case for <code>Bool</code>, there are two values to return (<code>true</code> and <code>false</code>).
In the case for pairs, the result should be the Cartesian product of the values for the type coded for by <code>t1</code> and the values for the type coded for by <code>t2</code>.
In other words, every value from <code>t1</code> should be paired with every value from <code>t2</code>.
The helper function <code>List.product</code> can certainly be written with an ordinary recursive function, but here it is defined using <code>for</code> in the identity monad:</p>
<pre><code class="language-lean">def List.product (xs : List α) (ys : List β) : List (α × β) := Id.run do
  let mut out : List (α × β) := []
  for x in xs do
    for y in ys do
      out := (x, y) :: out
  pure out.reverse
</code></pre>
<p>Finally, the case of <code>Finite.enumerate</code> for functions delegates to a helper called <code>Finite.functions</code> that takes a list of all of the return values to target as an argument.</p>
<p>Generally speaking, generating all of the functions from some finite type to a collection of result values can be thought of as generating the functions' tables.
Each function assigns an output to each input, which means that a given function has \( k \) rows in its table when there are \( k \) possible arguments.
Because each row of the table could select any of \( n \) possible outputs, there are \( n ^ k \) potential functions to generate.</p>
<p>Once again, generating the functions from a finite type to some list of values is recursive on the code that describes the finite type:</p>
<pre><code class="language-lean">  def Finite.functions (t : Finite) (results : List α) : List (t.asType → α) :=
    match t with
</code></pre>
<p>The table for functions from <code>Unit</code> contains one row, because the function can't pick different results based on which input it is provided.
This means that one function is generated for each potential input.</p>
<pre><code class="language-lean">      | .unit =&gt;
        results.map fun r =&gt;
          fun () =&gt; r
</code></pre>
<p>There are \( n^2 \) functions from <code>Bool</code> when there are \( n \) result values, because each individual function of type <code>Bool → α</code> uses the <code>Bool</code> to select between two particular <code>α</code>s:</p>
<pre><code class="language-lean">      | .bool =&gt;
        (results.product results).map fun (r1, r2) =&gt;
          fun
            | true =&gt; r1
            | false =&gt; r2
</code></pre>
<p>Generating the functions from pairs can be achieved by taking advantage of currying.
A function from a pair can be transformed into a function that takes the first element of the pair and returns a function that's waiting for the second element of the pair.
Doing this allows <code>Finite.functions</code> to be used recursively in this case:</p>
<pre><code class="language-lean">      | .pair t1 t2 =&gt;
        let f1s := t1.functions &lt;| t2.functions results
        f1s.map fun f =&gt;
          fun (x, y) =&gt;
            f x y
</code></pre>
<p>Generating higher-order functions is a bit of a brain bender.
Each higher-order function takes a function as its argument.
This argument function can be distinguished from other functions based on its input/output behavior.
In general, the higher-order function can apply the argument function to every possible argument, and it can then carry out any possible behavior based on the result of applying the argument function.
This suggests a means of constructing the higher-order functions:</p>
<ul>
<li>Begin with a list of all possible arguments to the function that is itself an argument.</li>
<li>For each possible argument, construct all possible behaviors that can result from the observation of applying the argument function to the possible argument. This can be done using <code>Finite.functions</code> and recursion over the rest of the possible arguments, because the result of the recursion represents the functions based on the observations of the rest of the possible arguments. <code>Finite.functions</code> constructs all the ways of achieving these based on the observation for the current argument.</li>
<li>For potential behavior in response to these observations, construct a higher-order function that applies the argument function to the current possible argument. The result of this is then passed to the observation behavior.</li>
<li>The base case of the recursion is a higher-order function that observes nothing for each result value—it ignores the argument function and simply returns the result value.</li>
</ul>
<p>Defining this recursive function directly causes Lean to be unable to prove that the whole function terminates.
However, using a simpler form of recursion called a <em>right fold</em> can be used to make it clear to the termination checker that the function terminates.
A right fold takes three arguments: a step function that combines the head of the list with the result of the recursion over the tail, a default value to return when the list is empty, and the list being processed.
It then analyzes the list, essentially replacing each <code>::</code> in the list with a call to the step function and replacing <code>[]</code> with the default value:</p>
<pre><code class="language-lean">def List.foldr (f : α → β → β) (default : β) : List α → β
  | []     =&gt; default
  | a :: l =&gt; f a (foldr f default l)
</code></pre>
<p>Finding the sum of the <code>Nat</code>s in a list can be done with <code>foldr</code>:</p>
<pre><code class="language-lean">[1, 2, 3, 4, 5].foldr (· + ·) 0
===&gt;
(1 :: 2 :: 3 :: 4 :: 5 :: []).foldr (· + ·) 0
===&gt;
(1 + 2 + 3 + 4 + 5 + 0)
===&gt;
15
</code></pre>
<p>With <code>foldr</code>, the higher-order functions can be created as follows:</p>
<pre><code class="language-lean">      | .arr t1 t2 =&gt;
        let args := t1.enumerate
        let base :=
          results.map fun r =&gt;
            fun _ =&gt; r
        args.foldr
          (fun arg rest =&gt;
            (t2.functions rest).map fun more =&gt;
              fun f =&gt; more (f arg) f)
          base
</code></pre>
<p>The complete definition of <code>Finite.Functions</code> is:</p>
<pre><code class="language-lean">  def Finite.functions (t : Finite) (results : List α) : List (t.asType → α) :=
    match t with
      | .unit =&gt;
        results.map fun r =&gt;
          fun () =&gt; r
      | .bool =&gt;
        (results.product results).map fun (r1, r2) =&gt;
          fun
            | true =&gt; r1
            | false =&gt; r2
      | .pair t1 t2 =&gt;
        let f1s := t1.functions &lt;| t2.functions results
        f1s.map fun f =&gt;
          fun (x, y) =&gt;
            f x y
      | .arr t1 t2 =&gt;
        let args := t1.enumerate
        let base :=
          results.map fun r =&gt;
            fun _ =&gt; r
        args.foldr
          (fun arg rest =&gt;
            (t2.functions rest).map fun more =&gt;
              fun f =&gt; more (f arg) f)
          base
</code></pre>
<p>Because <code>Finite.enumerate</code> and <code>Finite.functions</code> call each other, they must be defined in a <code>mutual</code> block.
In other words, right before the definition of <code>Finite.enumerate</code> is the <code>mutual</code> keyword:</p>
<pre><code class="language-lean">mutual
  def Finite.enumerate (t : Finite) : List t.asType :=
    match t with
</code></pre>
<p>and right after the definition of <code>Finite.functions</code> is the <code>end</code> keyword:</p>
<pre><code class="language-lean">      | .arr t1 t2 =&gt;
        let args := t1.enumerate
        let base :=
          results.map fun r =&gt;
            fun _ =&gt; r
        args.foldr
          (fun arg rest =&gt;
            (t2.functions rest).map fun more =&gt;
              fun f =&gt; more (f arg) f)
          base
end
</code></pre>
<p>This algorithm for comparing functions is not particularly practical.
The number of cases to check grows exponentially; even a simple type like <code>((Bool × Bool) → Bool) → Bool</code> describes 65536 distinct functions.
Why are there so many?
Based on the reasoning above, and using \( \left| T \right| \) to represent the number of values described by the type \( T \), we should expect that
\[ \left| \left( \left( \mathtt{Bool} \times \mathtt{Bool} \right) \rightarrow \mathtt{Bool} \right) \rightarrow \mathtt{Bool} \right| \]
is 
\[ \left|\mathrm{Bool}\right|^{\left| \left( \mathtt{Bool} \times \mathtt{Bool} \right) \rightarrow \mathtt{Bool} \right| }, \]
which is
\[ 2^{2^{\left| \mathtt{Bool} \times \mathtt{Bool} \right| }}, \]
which is
\[ 2^{2^4} \]
or 65536.
Nested exponentials grow quickly, and there are many higher-order functions.</p>
<h2 id="exercises-19"><a class="header" href="#exercises-19">Exercises</a></h2>
<ul>
<li>Write a function that converts any value from a type coded for by <code>Finite</code> into a string. Functions should be represented as their tables.</li>
<li>Add the empty type <code>Empty</code> to <code>Finite</code> and <code>Finite.beq</code>.</li>
<li>Add <code>Option</code> to <code>Finite</code> and <code>Finite.beq</code>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="worked-example-typed-queries"><a class="header" href="#worked-example-typed-queries">Worked Example: Typed Queries</a></h1>
<p>Indexed families are very useful when building an API that is supposed to resemble some other language.
They can be used to write a library of HTML constructors that don't permit generating invalid HTML, to encode the specific rules of a configuration file format, or to model complicated business constraints.
This section describes an encoding of a subset of relational algebra in Lean using indexed families, as a simpler demonstration of techniques that can be used to build a more powerful database query language.</p>
<p>This subset uses the type system to enforce requirements such as disjointness of field names, and it uses type-level computation to reflect the schema into the types of values that are returned from a query.
It is not a realistic system, however—databases are represented as linked lists of linked lists, the type system is much simpler than that of SQL, and the operators of relational algebra don't really match those of SQL.
However, it is large enough to demonstrate useful principles and techniques.</p>
<h2 id="a-universe-of-data"><a class="header" href="#a-universe-of-data">A Universe of Data</a></h2>
<p>In this relational algebra, the base data that can be held in columns can have types <code>Int</code>, <code>String</code>, and <code>Bool</code> and are described by the universe <code>DBType</code>:</p>
<pre><code class="language-lean">inductive DBType where
  | int | string | bool

abbrev DBType.asType : DBType → Type
  | .int =&gt; Int
  | .string =&gt; String
  | .bool =&gt; Bool
</code></pre>
<p>Using <code>asType</code> allows these codes to be used for types.
For example:</p>
<pre><code class="language-lean">#eval (&quot;Mount Hood&quot; : DBType.string.asType)
</code></pre>
<pre><code class="language-output info">&quot;Mount Hood&quot;
</code></pre>
<p>It is possible to compare the values described by any of the three database types for equality.
Explaining this to Lean, however, requires a bit of work.
Simply using <code>BEq</code> directly fails:</p>
<pre><code class="language-lean">def DBType.beq (t : DBType) (x y : t.asType) : Bool :=
  x == y
</code></pre>
<pre><code class="language-output info">failed to synthesize instance
  BEq (asType t)
</code></pre>
<p>Just as in the nested pairs universe, type class search doesn't automatically check each possibility for <code>t</code>'s value
The solution is to use pattern matching to refine the types of <code>x</code> and <code>y</code>:</p>
<pre><code class="language-lean">def DBType.beq (t : DBType) (x y : t.asType) : Bool :=
  match t with
  | .int =&gt; x == y
  | .string =&gt; x == y
  | .bool =&gt; x == y
</code></pre>
<p>In this version of the function, <code>x</code> and <code>y</code> have types <code>Int</code>, <code>String</code>, and <code>Bool</code> in the three respective cases, and these types all have <code>BEq</code> instances.
The definition of <code>dbEq</code> can be used to define a <code>BEq</code> instance for the types that are coded for by <code>DBType</code>:</p>
<pre><code class="language-lean">instance {t : DBType} : BEq t.asType where
  beq := t.beq
</code></pre>
<p>This is not the same as an instance for the codes themselves:</p>
<pre><code class="language-lean">instance : BEq DBType where
  beq
    | .int, .int =&gt; true
    | .string, .string =&gt; true
    | .bool, .bool =&gt; true
    | _, _ =&gt; false
</code></pre>
<p>The former instance allows comparison of values drawn from the types described by the codes, while the latter allows comparison of the codes themselves.</p>
<p>A <code>Repr</code> instance can be written using the same technique.
The method of the <code>Repr</code> class is called <code>reprPrec</code> because it is designed to take things like operator precedence into account when displaying values.
Refining the type through dependent pattern matching allows the <code>reprPrec</code> methods from the <code>Repr</code> instances for <code>Int</code>, <code>String</code>, and <code>Bool</code> to be used:</p>
<pre><code class="language-lean">instance {t : DBType} : Repr t.asType where
  reprPrec :=
    match t with
    | .int =&gt; reprPrec
    | .string =&gt; reprPrec
    | .bool =&gt; reprPrec
</code></pre>
<h2 id="schemas-and-tables"><a class="header" href="#schemas-and-tables">Schemas and Tables</a></h2>
<p>A schema describes the name and type of each column in a database:</p>
<pre><code class="language-lean">structure Column where
  name : String
  contains : DBType

abbrev Schema := List Column
</code></pre>
<p>In fact, a schema can be seen as a universe that describes rows in a table.
The empty schema describes the unit type, a schema with a single column describes that value on its own, and a schema with at least two columns is represented by a tuple:</p>
<pre><code class="language-lean">abbrev Row : Schema → Type
  | [] =&gt; Unit
  | [col] =&gt; col.contains.asType
  | col1 :: col2 :: cols =&gt; col1.contains.asType × Row (col2::cols)
</code></pre>
<p>As described in <a href="dependent-types/../getting-to-know/polymorphism.html#Prod">the initial section on product types</a>, Lean's product type and tuples are right-associative.
This means that nested pairs are equivalent to ordinary flat tuples.</p>
<p>A table is a list of rows that share a schema:</p>
<pre><code class="language-lean">abbrev Table (s : Schema) := List (Row s)
</code></pre>
<p>For example, a diary of visits to mountain peaks can be represented with the schema <code>peak</code>:</p>
<pre><code class="language-lean">abbrev peak : Schema := [
  ⟨&quot;name&quot;, DBType.string⟩,
  ⟨&quot;location&quot;, DBType.string⟩,
  ⟨&quot;elevation&quot;, DBType.int⟩,
  ⟨&quot;lastVisited&quot;, .int⟩
]
</code></pre>
<p>A selection of peaks visited by the author of this book appears as an ordinary list of tuples:</p>
<pre><code class="language-lean">def mountainDiary : Table peak := [
  (&quot;Mount Nebo&quot;,       &quot;USA&quot;,     3637, 2013),
  (&quot;Moscow Mountain&quot;,  &quot;USA&quot;,     1519, 2015),
  (&quot;Himmelbjerget&quot;,    &quot;Denmark&quot;,  147, 2004),
  (&quot;Mount St. Helens&quot;, &quot;USA&quot;,     2549, 2010)
]
</code></pre>
<p>Another example consists of waterfalls and a diary of visits to them:</p>
<pre><code class="language-lean">abbrev waterfall : Schema := [
  ⟨&quot;name&quot;, .string⟩,
  ⟨&quot;location&quot;, .string⟩,
  ⟨&quot;lastVisited&quot;, .int⟩
]

def waterfallDiary : Table waterfall := [
  (&quot;Multnomah Falls&quot;, &quot;USA&quot;, 2018),
  (&quot;Shoshone Falls&quot;,  &quot;USA&quot;, 2014)
]
</code></pre>
<h3 id="recursion-and-universes-revisited"><a class="header" href="#recursion-and-universes-revisited">Recursion and Universes, Revisited</a></h3>
<p>The convenient structuring of rows as tuples comes at a cost: the fact that <code>Row</code> treats its two base cases separately means that functions that use <code>Row</code> in their types and are defined recursively over the codes (that, is the schema) need to make the same distinctions.
One example of a case where this matters is an equality check that uses recursion over the schema to define a function that checks rows for equality.
This example does not pass Lean's type checker:</p>
<pre><code class="language-lean">def Row.bEq (r1 r2 : Row s) : Bool :=
  match s with
  | [] =&gt; true
  | col::cols =&gt;
    match r1, r2 with
    | (v1, r1'), (v2, r2') =&gt;
      v1 == v2 &amp;&amp; bEq r1' r2'
</code></pre>
<pre><code class="language-output error">type mismatch
  (v1, r1')
has type
  ?m.6674 × ?m.6677 : Type (max ?u.6686 ?u.6685)
but is expected to have type
  Row (col :: cols) : Type
</code></pre>
<p>The problem is that the pattern <code>col :: cols</code> does not sufficiently refine the type of the rows.
This is because Lean cannot yet tell whether the singleton pattern <code>[col]</code> or the <code>col1 :: col2 :: cols</code> pattern in the definition of <code>Row</code> was matched, so the call to <code>Row</code> does not compute down to a pair type.
The solution is to mirror the structure of <code>Row</code> in the definition of <code>Row.bEq</code>:</p>
<pre><code class="language-lean">def Row.bEq (r1 r2 : Row s) : Bool :=
  match s with
  | [] =&gt; true
  | [_] =&gt; r1 == r2
  | _::_::_ =&gt;
    match r1, r2 with
    | (v1, r1'), (v2, r2') =&gt;
      v1 == v2 &amp;&amp; bEq r1' r2'

instance : BEq (Row s) where
  beq := Row.bEq
</code></pre>
<p>Unlike in other contexts, functions that occur in types cannot be considered only in terms of their input/output behavior.
Programs that use these types will find themselves forced to mirror the algorithm used in the type-level function so that their structure matches the pattern-matching and recursive behavior of the type.
A big part of the skill of programming with dependent types is the selection of appropriate type-level functions with the right computational behavior.</p>
<h3 id="column-pointers"><a class="header" href="#column-pointers">Column Pointers</a></h3>
<p>Some queries only make sense if a schema contains a particular column.
For example, a query that returns mountains with an elevation greater than 1000 meters only makes sense in the context of a schema with a <code>&quot;elevation&quot;</code> column that contains integers.
One way to indicate that a column is contained in a schema is to provide a pointer directly to it, and defining the pointer as an indexed family makes it possible to rule out invalid pointers.</p>
<p>There are two ways that a column can be present in a schema: either it is at the beginning of the schema, or it is somewhere later in the schema.
Eventually, if a column is later in a schema, then it will be the beginning of some tail of the schema.</p>
<p>The indexed family <code>HasCol</code> is a translation of the specification into Lean code:</p>
<pre><code class="language-lean">inductive HasCol : Schema → String → DBType → Type where
  | here : HasCol (⟨name, t⟩ :: _) name t
  | there : HasCol s name t → HasCol (_ :: s) name t
</code></pre>
<p>The family's three arguments are the schema, the column name, and its type.
All three are indices, but re-ordering the arguments to place the schema after the column name and type would allow the name and type to be parameters.
The constructor <code>here</code> can be used when the schema begins with the column <code>⟨name, t⟩</code>; it is thus a pointer to the first column in the schema that can only be used when the first column has the desired name and type.
The constructor <code>there</code> transforms a pointer into a smaller schema into a pointer into a schema with one more column on it.</p>
<p>Because <code>&quot;elevation&quot;</code> is the third column in <code>peak</code>, it can be found by looking past the first two columns with <code>there</code>, after which it is the first column.
In other words, to satisfy the type <code>HasCol peak &quot;elevation&quot; .int</code>, use the expression <code>.there (.there .here)</code>.
One way to think about <code>HasCol</code> is as a kind of decorated <code>Nat</code>—<code>zero</code> corresponds to <code>here</code>, and <code>succ</code> corresponds to <code>there</code>.
The extra type information makes it impossible to have off-by-one errors.</p>
<p>A pointer to a particular column in a schema can be used to extract that column's value from a row:</p>
<pre><code class="language-lean">def Row.get (row : Row s) (col : HasCol s n t) : t.asType :=
  match s, col, row with
  | [_], .here, v =&gt; v
  | _::_::_, .here, (v, _) =&gt; v
  | _::_::_, .there next, (_, r) =&gt; get r next
</code></pre>
<p>The first step is to pattern match on the schema, because this determines whether the row is a tuple or a single value.
No case is needed for the empty schema because there is a <code>HasCol</code> available, and both constructors of <code>HasCol</code> specify non-empty schemas.
If the schema has just a single column, then the pointer must point to it, so only the <code>here</code> constructor of <code>HasCol</code> need be matched.
If the schema has two or more columns, then there must be a case for <code>here</code>, in which case the value is the first one in the row, and one for <code>there</code>, in which case a recursive call is used.
Because the <code>HasCol</code> type guarantees that the column exists in the row, <code>Row.get</code> does not need to return an <code>Option</code>.</p>
<p><code>HasCol</code> plays two roles:</p>
<ol>
<li>
<p>It serves as <em>evidence</em> that a column with a particular name and type exists in a schema.</p>
</li>
<li>
<p>It serves as <em>data</em> that can be used to find the value associated with the column in a row.</p>
</li>
</ol>
<p>The first role, that of evidence, is similar to way that propositions are used.
The definition of the indexed family <code>HasCol</code> can be read as a specification of what counts as evidence that a given column exists.
Unlike propositions, however, it matters which constructor of <code>HasCol</code> was used.
In the second role, the constructors are used like <code>Nat</code>s to find data in a collection.
Programming with indexed families often requires the ability to switch fluently between both perspectives.</p>
<h3 id="subschemas"><a class="header" href="#subschemas">Subschemas</a></h3>
<p>One important operation in relational algebra is to <em>project</em> a table or row into a smaller schema.
Every column not present in the smaller schema is forgotten.
In order for projection to make sense, the smaller schema must be a subschema of the larger schema, which means that every column in the smaller schema must be present in the larger schema.
Just as <code>HasCol</code> makes it possible to write a single-column lookup in a row that cannot fail, a representation of the subschema relationship as an indexed family makes it possible to write a projection function that cannot fail.</p>
<p>The ways in which one schema can be a subschema of another can be defined as an indexed family.
The basic idea is that a smaller schema is a subschema of a bigger schema if every column in the smaller schema occurs in the bigger schema.
If the smaller schema is empty, then it's certainly a subschema of the bigger schema, represented by the constructor <code>nil</code>.
If the smaller schema has a column, then that column must be in the bigger schema, and all the rest of the columns in the subschema must also be a subschema of the bigger schema.
This is represented by the constructor <code>cons</code>.</p>
<pre><code class="language-lean">inductive Subschema : Schema → Schema → Type where
  | nil : Subschema [] bigger
  | cons :
      HasCol bigger n t →
      Subschema smaller bigger →
      Subschema (⟨n, t⟩ :: smaller) bigger
</code></pre>
<p>In other words, <code>Subschema</code> assigns each column of the smaller schema a <code>HasCol</code> that points to its location in the larger schema.</p>
<p>The schema <code>travelDiary</code> represents the fields that are common to both <code>peak</code> and <code>waterfall</code>.
It is certainly a subschema of <code>peak</code>, as shown by this example:</p>
<pre><code class="language-lean">example : Subschema travelDiary peak :=
  .cons .here
    (.cons (.there .here)
      (.cons (.there (.there (.there .here))) .nil))
</code></pre>
<p>However, code like this is difficult to read and difficult to maintain.
One way to improve it is to instruct Lean to write the <code>Subschema</code> and <code>HasCol</code> constructors automatically.
This can be done using the tactic feature that was introduced in <a href="dependent-types/../props-proofs-indexing.html">the Interlude on propositions and proofs</a>.
That interlude uses <code>by simp</code> to provide evidence of various propositions.</p>
<p>In this context, two tactics are useful:</p>
<ul>
<li>The <code>constructor</code> tactic instructs Lean to solve the problem using the constructor of a datatype.</li>
<li>The <code>repeat</code> tactic instructs Lean to repeat a tactic over and over until it either fails or the proof is finished.</li>
</ul>
<p>In the next example, <code>by constructor</code> has the same effect as just writing <code>.nil</code> would have:</p>
<pre><code class="language-leantac">example : Subschema [] peak := by constructor
</code></pre>
<p>However, attempting that same tactic with a slightly more complicated type fails:</p>
<pre><code class="language-leantac">example : Subschema [⟨&quot;location&quot;, .string⟩] peak := by constructor
</code></pre>
<pre><code class="language-output error">unsolved goals
case a
⊢ HasCol peak &quot;location&quot; DBType.string

case a
⊢ Subschema [] peak
</code></pre>
<p>Errors that begin with <code>unsolved goals</code> describe tactics that failed to completely build the expressions that they were supposed to.
In Lean's tactic language, a <em>goal</em> is a type that a tactic is to fulfill by constructing an appropriate expression behind the scenes.
In this case, <code>constructor</code> caused <code>Subschema.cons</code> to be applied, and the two goals represent the two arguments expected by <code>cons</code>.
Adding another instance of <code>constructor</code> causes the first goal (<code>HasCol peak \&quot;location\&quot; DBType.string</code>) to be addressed with <code>HasCol.there</code>, because <code>peak</code>'s first column is not <code>&quot;location&quot;</code>:</p>
<pre><code class="language-leantac">example : Subschema [⟨&quot;location&quot;, .string⟩] peak := by
  constructor
  constructor
</code></pre>
<pre><code class="language-output error">unsolved goals
case a.a
⊢ HasCol
    [{ name := &quot;location&quot;, contains := DBType.string }, { name := &quot;elevation&quot;, contains := DBType.int },
      { name := &quot;lastVisited&quot;, contains := DBType.int }]
    &quot;location&quot; DBType.string

case a
⊢ Subschema [] peak
</code></pre>
<p>However, adding a third <code>constructor</code> results in the first goal being solved, because <code>HasCol.here</code> is applicable:</p>
<pre><code class="language-leantac">example : Subschema [⟨&quot;location&quot;, .string⟩] peak := by
  constructor
  constructor
  constructor
</code></pre>
<pre><code class="language-output error">unsolved goals
case a
⊢ Subschema [] peak
</code></pre>
<p>A fourth instance of <code>constructor</code> solves the <code>Subschema peak []</code> goal:</p>
<pre><code class="language-leantac">example : Subschema [⟨&quot;location&quot;, .string⟩] peak := by
  constructor
  constructor
  constructor
  constructor
</code></pre>
<p>Indeed, a version written without the use of tactics has four constructors:</p>
<pre><code class="language-lean">example : Subschema [⟨&quot;location&quot;, .string⟩] peak :=
  .cons (.there .here) .nil
</code></pre>
<p>Instead of experimenting to find the right number of times to write <code>constructor</code>, the <code>repeat</code> tactic can be used to ask Lean to just keep trying <code>constructor</code> as long as it keeps making progress:</p>
<pre><code class="language-leantac">example : Subschema [⟨&quot;location&quot;, .string⟩] peak := by repeat constructor
</code></pre>
<p>This more flexible version also works for more interesting <code>Subschema</code> problems:</p>
<pre><code class="language-leantac">example : Subschema travelDiary peak := by repeat constructor

example : Subschema travelDiary waterfall := by repeat constructor
</code></pre>
<p>The approach of blindly trying constructors until something works is not very useful for types like <code>Nat</code> or <code>List Bool</code>.
Just because an expression has type <code>Nat</code> doesn't mean that it's the <em>correct</em> <code>Nat</code>, after all.
But types like <code>HasCol</code> and <code>Subschema</code> are sufficiently constrained by their indices that only one constructor will ever be applicable, which means that the contents of the program itself are less interesting, and a computer can pick the correct one.</p>
<p>If one schema is a subschema of another, then it is also a subschema of the larger schema extended with an additional column.
This fact can be captured as a function definition.
<code>Subschema.addColumn</code> takes evidence that <code>smaller</code> is a subschema of <code>bigger</code>, and then returns evidence that <code>smaller</code> is a subschema of <code>c :: bigger</code>, that is, <code>bigger</code> with one additional column:</p>
<pre><code class="language-lean">def Subschema.addColumn (sub : Subschema smaller bigger) : Subschema smaller (c :: bigger) :=
  match sub with
  | .nil  =&gt; .nil
  | .cons col sub' =&gt; .cons (.there col) sub'.addColumn
</code></pre>
<p>A subschema describes where to find each column from the smaller schema in the larger schema.
<code>Subschema.addColumn</code> must translate these descriptions from the original larger schema into the extended larger schema.
In the <code>nil</code> case, the smaller schema is <code>[]</code>, and <code>nil</code> is also evidence that <code>[]</code> is a subschema of <code>c :: bigger</code>.
In the <code>cons</code> case, which describes how to place one column from <code>smaller</code> into <code>larger</code>, the placement of the column needs to be adjusted with <code>there</code> to account for the new column <code>c</code>, and a recursive call adjusts the rest of the columns.</p>
<p>Another way to think about <code>Subschema</code> is that it defines a <em>relation</em> between two schemas—the existence of an expression  with type <code>Subschema bigger smaller</code> means that <code>(bigger, smaller)</code> is in the relation.
This relation is reflexive, meaning that every schema is a subschema of itself:</p>
<pre><code class="language-lean">def Subschema.reflexive : (s : Schema) → Subschema s s
  | [] =&gt; .nil
  | _ :: cs =&gt; .cons .here (reflexive cs).addColumn
</code></pre>
<h3 id="projecting-rows"><a class="header" href="#projecting-rows">Projecting Rows</a></h3>
<p>Given evidence that <code>s'</code> is a subschema of <code>s</code>, a row in <code>s</code> can be projected into a row in <code>s'</code>.
This is done using the evidence that <code>s'</code> is a subschema of <code>s</code>, which explains where each column of <code>s'</code> is found in <code>s</code>.
The new row in <code>s'</code> is built up one column at a time by retrieving the value from the appropriate place in the old row.</p>
<p>The function that performs this projection, <code>Row.project</code>, has three cases, one for each case of <code>Row</code> itself.
It uses <code>Row.get</code> together with each <code>HasCol</code> in the <code>Subschema</code> argument to construct the projected row:</p>
<pre><code class="language-lean">def Row.project (row : Row s) : (s' : Schema) → Subschema s' s → Row s'
  | [], .nil =&gt; ()
  | [_], .cons c .nil =&gt; row.get c
  | _::_::_, .cons c cs =&gt; (row.get c, row.project _ cs)
</code></pre>
<h2 id="conditions-and-selection"><a class="header" href="#conditions-and-selection">Conditions and Selection</a></h2>
<p>Projection removes unwanted columns from a table, but queries must also be able to remove unwanted rows.
This operation is called <em>selection</em>.
Selection relies on having a means of expressing which rows are desired.</p>
<p>The example query language contains expressions, which are analogous to what can be written in a <code>WHERE</code> clause in SQL.
Expressions are represented by the indexed family <code>DBExpr</code>.
Because expressions can refer to columns from the database, but different sub-expressions all have the same schema, <code>DBExpr</code> takes the database schema as a parameter.
Additionally, each expression has a type, and these vary, making it an index:</p>
<pre><code class="language-lean">inductive DBExpr (s : Schema) : DBType → Type where
  | col (n : String) (loc : HasCol s n t) : DBExpr s t
  | eq (e1 e2 : DBExpr s t) : DBExpr s .bool
  | lt (e1 e2 : DBExpr s .int) : DBExpr s .bool
  | and (e1 e2 : DBExpr s .bool) : DBExpr s .bool
  | const : t.asType → DBExpr s t
</code></pre>
<p>The <code>col</code> constructor represents a reference to a column in the database.
The <code>eq</code> constructor compares two expressions for equality, <code>lt</code> checks whether one is less than the other, <code>and</code> is Boolean conjunction, and <code>const</code> is a constant value of some type.</p>
<p>For example, an expression in <code>peak</code> that checks whether the <code>elevation</code> column is greater than 1000 and the location is <code>&quot;Denmark&quot;</code> can be written:</p>
<pre><code class="language-leantac">def tallInDenmark : DBExpr peak .bool :=
  .and (.lt (.const 1000) (.col &quot;elevation&quot; (by repeat constructor)))
       (.eq (.col &quot;location&quot; (by repeat constructor)) (.const &quot;Denmark&quot;))
</code></pre>
<p>This is somewhat noisy.
In particular, references to columns contain boilerplate calls to <code>by repeat constructor</code>.
A Lean feature called <em>macros</em> can help make expressions easier to read by eliminating this boilerplate:</p>
<pre><code class="language-leantac">macro &quot;c!&quot; n:term : term =&gt; `(DBExpr.col $n (by repeat constructor))
</code></pre>
<p>This declaration adds the <code>c!</code> keyword to Lean, and instructs Lean to replace any instance of <code>c!</code> followed by an expression with the corresponding <code>DBExpr.col</code> construction.
Here, <code>term</code> stands for Lean expressions, rather than commands, tactics, or some other part of the language.
Lean macros are a bit like C preprocessor macros, except they are better integrated into the language and they automatically avoid some of the pitfalls of CPP.
In fact, they are very closely related to macros in Scheme and Racket.</p>
<p>With this macro, the expression can be much easier to read:</p>
<pre><code class="language-lean">def tallInDenmark : DBExpr peak .bool :=
  .and (.lt (.const 1000) (c! &quot;elevation&quot;))
       (.eq (c! &quot;location&quot;) (.const &quot;Denmark&quot;))
</code></pre>
<p>Finding the value of an expression with respect to a given row uses <code>Row.get</code> to extract column references, and it delegates to Lean's operations on values for every other expression:</p>
<pre><code class="language-lean">def DBExpr.evaluate (row : Row s) : DBExpr s t → t.asType
  | .col _ loc =&gt; row.get loc
  | .eq e1 e2  =&gt; evaluate row e1 == evaluate row e2
  | .lt e1 e2  =&gt; evaluate row e1 &lt; evaluate row e2
  | .and e1 e2 =&gt; evaluate row e1 &amp;&amp; evaluate row e2
  | .const v =&gt; v
</code></pre>
<p>Evaluating the expression for Valby Bakke, the tallest hill in the Copenhagen area, yields <code>false</code> because Valby Bakke is much less than 1 km over sea level:</p>
<pre><code class="language-lean">#eval tallInDenmark.evaluate (&quot;Valby Bakke&quot;, &quot;Denmark&quot;, 31, 2023)
</code></pre>
<pre><code class="language-output info">false
</code></pre>
<p>Evaluating it for a fictional mountain of 1230m elevation yields <code>true</code>:</p>
<pre><code class="language-lean">#eval tallInDenmark.evaluate (&quot;Fictional mountain&quot;, &quot;Denmark&quot;, 1230, 2023)
</code></pre>
<pre><code class="language-output info">true
</code></pre>
<p>Evaluating it for the highest peak in the US state of Idaho yields <code>false</code>, as Idaho is not part of Denmark:</p>
<pre><code class="language-lean">#eval tallInDenmark.evaluate (&quot;Mount Borah&quot;, &quot;USA&quot;, 3859, 1996)
</code></pre>
<pre><code class="language-output info">false
</code></pre>
<h2 id="queries"><a class="header" href="#queries">Queries</a></h2>
<p>The query language is based on relational algebra.
In addition to tables, it includes the following operators:</p>
<ol>
<li>The union of two expressions that have the same schema combines the rows that result from two queries</li>
<li>The difference of two expressions that have the same schema removes rows found in the second result from the rows in the first result</li>
<li>Selection by some criterion filters the result of a query according to an expression</li>
<li>Projection into a subschema, removing columns from the result of a query</li>
<li>Cartesian product, combining every row from one query with every row from another</li>
<li>Renaming a column in the result of a query, which modifies its schema</li>
<li>Prefixing all columns in a query with a name</li>
</ol>
<p>The last operator is not strictly necessary, but it makes the language more convenient to use.</p>
<p>Once again, queries are represented by an indexed family:</p>
<pre><code class="language-lean">inductive Query : Schema → Type where
  | table : Table s → Query s
  | union : Query s → Query s → Query s
  | diff : Query s → Query s → Query s
  | select : Query s → DBExpr s .bool → Query s
  | project : Query s → (s' : Schema) → Subschema s' s → Query s'
  | product :
      Query s1 → Query s2 →
      disjoint (s1.map Column.name) (s2.map Column.name) →
      Query (s1 ++ s2)
  | renameColumn :
      Query s → (c : HasCol s n t) → (n' : String) → !((s.map Column.name).contains n') →
      Query (s.renameColumn c n')
  | prefixWith :
      (n : String) → Query s →
      Query (s.map fun c =&gt; {c with name := n ++ &quot;.&quot; ++ c.name})
</code></pre>
<p>The <code>select</code> constructor requires that the expression used for selection return a Boolean.
The <code>product</code> constructor's type contains a call to <code>disjoint</code>, which ensures that the two schemas don't share any names:</p>
<pre><code class="language-lean">def disjoint [BEq α] (xs ys : List α) : Bool :=
  not (xs.any ys.contains || ys.any xs.contains)
</code></pre>
<p>The use of an expression of type <code>Bool</code> where a type is expected triggers a coercion from <code>Bool</code> to <code>Prop</code>.
Just as decidable propositions can be considered to be Booleans, where evidence for the proposition is coerced to <code>true</code> and refutations of the proposition are coerced to <code>false</code>, Booleans are coerced into the proposition that states that the expression is equal to <code>true</code>.
Because all uses of the library are expected to occur in contexts where the schemas are known ahead of time, this proposition can be proved with <code>by simp</code>.
Similarly, the <code>renameColumn</code> constructor checks that the new name does not already exist in the schema.
It uses the helper <code>Schema.renameColumn</code> to change the name of the column pointed to by <code>HasCol</code>:</p>
<pre><code class="language-lean">def Schema.renameColumn : (s : Schema) → HasCol s n t → String → Schema
  | c :: cs, .here, n' =&gt; {c with name := n'} :: cs
  | c :: cs, .there next, n' =&gt; c :: renameColumn cs next n'
</code></pre>
<h2 id="executing-queries"><a class="header" href="#executing-queries">Executing Queries</a></h2>
<p>Executing queries requires a number of helper functions.
The result of a query is a table; this means that each operation in the query language requires a corresponding implementation that works with tables.</p>
<h3 id="cartesian-product"><a class="header" href="#cartesian-product">Cartesian Product</a></h3>
<p>Taking the Cartesian product of two tables is done by appending each row from the first table to each row from the second.
First off, due to the structure of <code>Row</code>, adding a single column to a row requires pattern matching on its schema in order to determine whether the result will be a bare value or a tuple.
Because this is a common operation, factoring the pattern matching out into a helper is convenient:</p>
<pre><code class="language-lean">def addVal (v : c.contains.asType) (row : Row s) : Row (c :: s) :=
  match s, row with
  | [], () =&gt; v
  | c' :: cs, v' =&gt; (v, v')
</code></pre>
<p>Appending two rows is recursive on the structure of both the first schema and the first row, because the structure of the row proceeds in lock-step with the structure of the schema.
When the first row is empty, appending returns the second row.
When the first row is a singleton, the value is added to the second row.
When the first row contains multiple columns, the first column's value is added to the result of recursion on the remainder of the row.</p>
<pre><code class="language-lean">def Row.append (r1 : Row s1) (r2 : Row s2) : Row (s1 ++ s2) :=
  match s1, r1 with
  | [], () =&gt; r2
  | [_], v =&gt; addVal v r2
  | _::_::_, (v, r') =&gt; (v, r'.append r2)
</code></pre>
<p><code>List.flatMap</code> applies a function that itself returns a list to every entry in an input list, returning the result of appending the resulting lists in order:</p>
<pre><code class="language-lean">def List.flatMap (f : α → List β) : (xs : List α) → List β
  | [] =&gt; []
  | x :: xs =&gt; f x ++ xs.flatMap f
</code></pre>
<p>The type signature suggests that <code>List.flatMap</code> could be used to implement a <code>Monad List</code> instance.
Indeed, together with <code>pure x := [x]</code>, <code>List.flatMap</code> does implement a monad.
However, it's not a very useful <code>Monad</code> instance.
The <code>List</code> monad is basically a version of <code>Many</code> that explores <em>every</em> possible path through the search space in advance, before users have the chance to request some number of values.
Because of this performance trap, it's usually not a good idea to define a <code>Monad</code> instance for <code>List</code>.
Here, however, the query language has no operator for restricting the number of results to be returned, so combining all possibilities is exactly what is desired:</p>
<pre><code class="language-lean">def Table.cartesianProduct (table1 : Table s1) (table2 : Table s2) : Table (s1 ++ s2) :=
  table1.flatMap fun r1 =&gt; table2.map r1.append
</code></pre>
<p>Just as with <code>List.product</code>, a loop with mutation in the identity monad can be used as an alternative implementation technique:</p>
<pre><code class="language-lean">def Table.cartesianProduct (table1 : Table s1) (table2 : Table s2) : Table (s1 ++ s2) := Id.run do
  let mut out : Table (s1 ++ s2) := []
  for r1 in table1 do
    for r2 in table2 do
      out := (r1.append r2) :: out
  pure out.reverse
</code></pre>
<h3 id="difference"><a class="header" href="#difference">Difference</a></h3>
<p>Removing undesired rows from a table can be done using <code>List.filter</code>, which takes a list and a function that returns a <code>Bool</code>.
A new list is returned that contains only the entries for which the function returns <code>true</code>.
For instance,</p>
<pre><code class="language-lean">[&quot;Willamette&quot;, &quot;Columbia&quot;, &quot;Sandy&quot;, &quot;Deschutes&quot;].filter (·.length &gt; 8)
</code></pre>
<p>evaluates to</p>
<pre><code class="language-lean">[&quot;Willamette&quot;, &quot;Deschutes&quot;]
</code></pre>
<p>because <code>&quot;Columbia&quot;</code> and <code>&quot;Sandy&quot;</code> have lengths less than or equal to <code>8</code>.
Removing the entries of a table can be done using the helper <code>List.without</code>:</p>
<pre><code class="language-lean">def List.without [BEq α] (source banned : List α) : List α :=
  source.filter fun r =&gt; !(banned.contains r)
</code></pre>
<p>This will be used with the <code>BEq</code> instance for <code>Row</code> when interpreting queries.</p>
<h3 id="renaming-columns"><a class="header" href="#renaming-columns">Renaming Columns</a></h3>
<p>Renaming a column in a row is done with a recursive function that traverses the row until the column in question is found, at which point the column with the new name gets the same value as the column with the old name:</p>
<pre><code class="language-lean">def Row.rename (c : HasCol s n t) (row : Row s) : Row (s.renameColumn c n') :=
  match s, row, c with
  | [_], v, .here =&gt; v
  | _::_::_, (v, r), .here =&gt; (v, r)
  | _::_::_, (v, r), .there next =&gt; addVal v (r.rename next)
</code></pre>
<p>While this function changes the <em>type</em> of its argument, the actual return value contains precisely the same data as the original argument.
From a run-time perspective, <code>renameRow</code> is nothing but a slow identity function.
One difficulty in programming with indexed families is that when performance matters, this kind of operation can get in the way.
It takes a very careful, often brittle, design to eliminate these kinds of &quot;re-indexing&quot; functions.</p>
<h3 id="prefixing-column-names"><a class="header" href="#prefixing-column-names">Prefixing Column Names</a></h3>
<p>Adding a prefix to column names is very similar to renaming a column.
Instead of proceeding to a desired column and then returning, <code>prefixRow</code> must process all columns:</p>
<pre><code class="language-lean">def prefixRow (row : Row s) : Row (s.map fun c =&gt; {c with name := n ++ &quot;.&quot; ++ c.name}) :=
  match s, row with
  | [], _ =&gt; ()
  | [_], v =&gt; v
  | _::_::_, (v, r) =&gt; (v, prefixRow r)
</code></pre>
<p>This can be used with <code>List.map</code> in order to add a prefix to all rows in a table.
Once again, this function only exists to change the type of a value.</p>
<h3 id="putting-the-pieces-together"><a class="header" href="#putting-the-pieces-together">Putting the Pieces Together</a></h3>
<p>With all of these helpers defined, executing a query requires only a short recursive function:</p>
<pre><code class="language-lean">def Query.exec : Query s → Table s
  | .table t =&gt; t
  | .union q1 q2 =&gt; exec q1 ++ exec q2
  | .diff q1 q2 =&gt; exec q1 |&gt;.without (exec q2)
  | .select q e =&gt; exec q |&gt;.filter e.evaluate
  | .project q _ sub =&gt; exec q |&gt;.map (·.project _ sub)
  | .product q1 q2 _ =&gt; exec q1 |&gt;.cartesianProduct (exec q2)
  | .renameColumn q c _ _ =&gt; exec q |&gt;.map (·.rename c)
  | .prefixWith _ q =&gt; exec q |&gt;.map prefixRow
</code></pre>
<p>Some arguments to the constructors are not used during execution.
In particular, both the constructor <code>project</code> and the function <code>Row.project</code> take the smaller schema as explicit arguments, but the type of the <em>evidence</em> that this schema is a subschema of the larger schema contains enough information for Lean to fill out the argument automatically.
Similarly, the fact that the two tables have disjoint column names that is required by the <code>product</code> constructor is not needed by <code>Table.cartesianProduct</code>.
Generally speaking, dependent types provide many opportunities to have Lean fill out arguments on behalf of the programmer.</p>
<p>Dot notation is used with the results of queries to call functions defined both in the <code>Table</code> and <code>List</code> namespaces, such <code>List.map</code>, <code>List.filter</code>, and <code>Table.cartesianProduct</code>.
This works because <code>Table</code> is defined using <code>abbrev</code>.
Just like type class search, dot notation can see through definitions created with <code>abbrev</code>. </p>
<p>The implementation of <code>select</code> is also quite concise.
After executing the query <code>q</code>, <code>List.filter</code> is used to remove the rows that do not satisfy the expression.
Filter expects a function from <code>Row s</code> to <code>Bool</code>, but <code>DBExpr.evaluate</code> has type <code>Row s → DBExpr s t → t.asType</code>.
Because the type of the <code>select</code> constructor requires that the expression have type <code>DBExpr s .bool</code>, <code>t.asType</code> is actually <code>Bool</code> in this context.</p>
<p>A query that finds the heights of all mountain peaks with an elevation greater than 500 meters can be written:</p>
<pre><code class="language-leantac">open Query in
def example1 :=
  table mountainDiary |&gt;.select
  (.lt (.const 500) (c! &quot;elevation&quot;)) |&gt;.project
  [⟨&quot;elevation&quot;, .int⟩] (by repeat constructor)
</code></pre>
<p>Executing it returns the expected list of integers:</p>
<pre><code class="language-lean">#eval example1.exec
</code></pre>
<pre><code class="language-output info">[3637, 1519, 2549]
</code></pre>
<p>To plan a sightseeing tour, it may be relevant to match all pairs mountains and waterfalls in the same location.
This can be done by taking the Cartesian product of both tables, selecting only the rows in which they are equal, and then projecting out the names:</p>
<pre><code class="language-leantac">open Query in
def example2 :=
  let mountain := table mountainDiary |&gt;.prefixWith &quot;mountain&quot;
  let waterfall := table waterfallDiary |&gt;.prefixWith &quot;waterfall&quot;
  mountain.product waterfall (by simp)
    |&gt;.select (.eq (c! &quot;mountain.location&quot;) (c! &quot;waterfall.location&quot;))
    |&gt;.project [⟨&quot;mountain.name&quot;, .string⟩, ⟨&quot;waterfall.name&quot;, .string⟩] (by repeat constructor)
</code></pre>
<p>Because the example data includes only waterfalls in the USA, executing the query returns pairs of mountains and waterfalls in the US:</p>
<pre><code class="language-lean">#eval example2.exec
</code></pre>
<pre><code class="language-output info">[(&quot;Mount Nebo&quot;, &quot;Multnomah Falls&quot;),
 (&quot;Mount Nebo&quot;, &quot;Shoshone Falls&quot;),
 (&quot;Moscow Mountain&quot;, &quot;Multnomah Falls&quot;),
 (&quot;Moscow Mountain&quot;, &quot;Shoshone Falls&quot;),
 (&quot;Mount St. Helens&quot;, &quot;Multnomah Falls&quot;),
 (&quot;Mount St. Helens&quot;, &quot;Shoshone Falls&quot;)]
</code></pre>
<h3 id="errors-you-may-meet"><a class="header" href="#errors-you-may-meet">Errors You May Meet</a></h3>
<p>Many potential errors are ruled out by the definition of <code>Query</code>.
For instance, forgetting the added qualifier in <code>&quot;mountain.location&quot;</code> yields a compile-time error that highlights the column reference <code>c! &quot;location&quot;</code>:</p>
<pre><code class="language-leantac">open Query in
def example2 :=
  let mountains := table mountainDiary |&gt;.prefixWith &quot;mountain&quot;
  let waterfalls := table waterfallDiary |&gt;.prefixWith &quot;waterfall&quot;
  mountains.product waterfalls (by simp)
    |&gt;.select (.eq (c! &quot;location&quot;) (c! &quot;waterfall.location&quot;))
    |&gt;.project [⟨&quot;mountain.name&quot;, .string⟩, ⟨&quot;waterfall.name&quot;, .string⟩] (by repeat constructor)
</code></pre>
<p>This is excellent feedback!
On the other hand, the text of the error message is quite difficult to act on:</p>
<pre><code class="language-output error">unsolved goals
case a.a.a.a.a.a.a
mountains : Query (List.map (fun c =&gt; { name := &quot;mountain&quot; ++ &quot;.&quot; ++ c.name, contains := c.contains }) peak) :=
  prefixWith &quot;mountain&quot; (table mountainDiary)
waterfalls : Query (List.map (fun c =&gt; { name := &quot;waterfall&quot; ++ &quot;.&quot; ++ c.name, contains := c.contains }) waterfall) :=
  prefixWith &quot;waterfall&quot; (table waterfallDiary)
⊢ HasCol (List.map (fun c =&gt; { name := &quot;waterfall&quot; ++ &quot;.&quot; ++ c.name, contains := c.contains }) []) &quot;location&quot; ?m.110696
</code></pre>
<p>Similarly, forgetting to add prefixes to the names of the two tables results in an error on <code>by simp</code>, which should provide evidence that the schemas are in fact disjoint;</p>
<pre><code class="language-leantac">open Query in
def example2 :=
  let mountains := table mountainDiary
  let waterfalls := table waterfallDiary
  mountains.product waterfalls (by simp)
    |&gt;.select (.eq (c! &quot;mountain.location&quot;) (c! &quot;waterfall.location&quot;))
    |&gt;.project [⟨&quot;mountain.name&quot;, .string⟩, ⟨&quot;waterfall.name&quot;, .string⟩] (by repeat constructor)
</code></pre>
<p>However, the error message is similarly unhelpful:</p>
<pre><code class="language-output error">unsolved goals
mountains : Query peak := table mountainDiary
waterfalls : Query waterfall := table waterfallDiary
⊢ False
</code></pre>
<p>Lean's macro system contains everything needed not only to provide a convenient syntax for queries, but also to arrange for the error messages to be helpful.
Unfortunately, it is beyond the scope of this book to provide a description of implementing languages with Lean macros.
An indexed family such as <code>Query</code> is probably best as the core of a typed database interaction library, rather than its user interface.</p>
<h2 id="exercises-20"><a class="header" href="#exercises-20">Exercises</a></h2>
<h3 id="dates"><a class="header" href="#dates">Dates</a></h3>
<p>Define a structure to represent dates. Add it to the <code>DBType</code> universe and update the rest of the code accordingly. Provide the extra <code>DBExpr</code> constructors that seem to be necessary.</p>
<h3 id="nullable-types"><a class="header" href="#nullable-types">Nullable Types</a></h3>
<p>Add support for nullable columns to the query language by representing database types with the following structure:</p>
<pre><code class="language-lean">structure NDBType where
  underlying : DBType
  nullable : Bool

abbrev NDBType.asType (t : NDBType) : Type :=
  if t.nullable then
    Option t.underlying.asType
  else
    t.underlying.asType
</code></pre>
<p>Use this type in place of <code>DBType</code> in <code>Column</code> and <code>DBExpr</code>, and look up SQL's rules for <code>NULL</code> and comparison operators to determine the types of <code>DBExpr</code>'s constructors.</p>
<h3 id="experimenting-with-tactics"><a class="header" href="#experimenting-with-tactics">Experimenting with Tactics</a></h3>
<p>What is the result of asking Lean to find values of the following types using <code>by repeat constructor</code>? Explain why each gives the result that it does.</p>
<ul>
<li><code>Nat</code></li>
<li><code>List Nat</code></li>
<li><code>Vect Nat 4</code></li>
<li><code>Row []</code></li>
<li><code>Row [⟨&quot;price&quot;, .int⟩]</code></li>
<li><code>Row peak</code></li>
<li><code>HasCol [⟨&quot;price&quot;, .int⟩, ⟨&quot;price&quot;, .int⟩] &quot;price&quot; .int</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="indices-parameters-and-universe-levels"><a class="header" href="#indices-parameters-and-universe-levels">Indices, Parameters, and Universe Levels</a></h1>
<p>The distinction between indices and parameters of an inductive type is more than just a way to describe arguments to the type that either vary or do not between the constructors.
Whether an argument to an inductive type is a parameter or an index also matters when it comes time to determine the relationships between their universe levels.
In particular, an inductive type may have the same universe level as a parameter, but it must be in a larger universe than its indices.
This restriction is necessary to ensure that Lean can be used as a theorem prover as well as a programming language—without it, Lean's logic would be inconsistent.
Experimenting with error messages is a good way to illustrate these rules, as well as the precise rules that determine whether an argument to a type is a parameter or an index.</p>
<p>Generally speaking, the definition of an inductive type takes its parameters before a colon and its indices after the colon.
Parameters are given names like function arguments, whereas indices only have their types described.
This can be seen in the definition of <code>Vect</code>:</p>
<pre><code class="language-lean">inductive Vect (α : Type u) : Nat → Type u where
   | nil : Vect α 0
   | cons : α → Vect α n → Vect α (n + 1)
</code></pre>
<p>In this definition, <code>α</code> is a parameter and the <code>Nat</code> is an index.
Parameters may be referred to throughout the definition (for example, <code>Vect.cons</code> uses <code>α</code> for the type of its first argument), but they must always be used consistently.
Because indices are expected to change, they are assigned individual values at each constructor, rather than being provided as arguments at the top of the datatype definition.</p>
<p>A very simple datatype with a parameter is <code>WithParameter</code>:</p>
<pre><code class="language-lean">inductive WithParameter (α : Type u) : Type u where
  | test : α → WithParameter α
</code></pre>
<p>The universe level <code>u</code> can be used for both the parameter and for the inductive type itself, illustrating that parameters do not increase the universe level of a datatype.
Similarly, when there are multiple parameters, the inductive type receives whichever universe level is greater:</p>
<pre><code class="language-lean">inductive WithTwoParameters (α : Type u) (β : Type v) : Type (max u v) where
  | test : α → β → WithTwoParameters α β
</code></pre>
<p>Because parameters do not increase the universe level of a datatype, they can be more convenient to work with.
Lean attempts to identify arguments that are described like indices (after the colon), but used like parameters, and turn them into parameters:
Both of the following inductive datatypes have their parameter written after the colon:</p>
<pre><code class="language-lean">inductive WithParameterAfterColon : Type u → Type u where
  | test : α → WithParameterAfterColon α

inductive WithParameterAfterColon2 : Type u → Type u where
  | test1 : α → WithParameterAfterColon2 α
  | test2 : WithParameterAfterColon2 α
</code></pre>
<p>When a parameter is not named in the initial datatype declaration, different names may be used for it in each constructor, so long as they are used consistently.
The following declaration is accepted:</p>
<pre><code class="language-lean">inductive WithParameterAfterColonDifferentNames : Type u → Type u where
  | test1 : α → WithParameterAfterColonDifferentNames α
  | test2 : β → WithParameterAfterColonDifferentNames β
</code></pre>
<p>However, this flexibility does not extend to datatypes that explicitly declare the names of their parameters:</p>
<pre><code class="language-lean">inductive WithParameterBeforeColonDifferentNames (α : Type u) : Type u where
  | test1 : α → WithParameterBeforeColonDifferentNames α
  | test2 : β → WithParameterBeforeColonDifferentNames β
</code></pre>
<pre><code class="language-output error">inductive datatype parameter mismatch
  β
expected
  α
</code></pre>
<p>Similarly, attempting to name an index results in an error:</p>
<pre><code class="language-lean">inductive WithNamedIndex (α : Type u) : Type (u + 1) where
  | test1 : WithNamedIndex α
  | test2 : WithNamedIndex α → WithNamedIndex α → WithNamedIndex (α × α)
</code></pre>
<pre><code class="language-output error">inductive datatype parameter mismatch
  α × α
expected
  α
</code></pre>
<p>Using an appropriate universe level and placing the index after the colon results in a declaration that is acceptable:</p>
<pre><code class="language-lean">inductive WithIndex : Type u → Type (u + 1) where
  | test1 : WithIndex α
  | test2 : WithIndex α → WithIndex α → WithIndex (α × α)
</code></pre>
<p>Even though Lean can sometimes determine that an argument after the colon in an inductive type declaration is a parameter when it is used consistently in all constructors, all parameters are still required to come before all indices.
Attempting to place a parameter after an index results in the argument being considered an index itself, which would require the universe level of the datatype to increase:</p>
<pre><code class="language-lean">inductive ParamAfterIndex : Nat → Type u → Type u where
  | test1 : ParamAfterIndex 0 γ
  | test2 : ParamAfterIndex n γ → ParamAfterIndex k γ → ParamAfterIndex (n + k) γ
</code></pre>
<pre><code class="language-output error">invalid universe level in constructor 'ParamAfterIndex.test1', parameter 'γ' has type
  Type u
at universe level
  u+2
it must be smaller than or equal to the inductive datatype universe level
  u+1
</code></pre>
<p>Parameters need not be types.
This example shows that ordinary datatypes such as <code>Nat</code> may be used as parameters:</p>
<pre><code class="language-lean">inductive NatParam (n : Nat) : Nat → Type u where
  | five : NatParam 4 5
</code></pre>
<pre><code class="language-output error">inductive datatype parameter mismatch
  4
expected
  n
</code></pre>
<p>Using the <code>n</code> as suggested causes the declaration to be accepted:</p>
<pre><code class="language-lean">inductive NatParam (n : Nat) : Nat → Type u where
  | five : NatParam n 5
</code></pre>
<p>What can be concluded from these experiments?
The rules of parameters and indices are as follows:</p>
<ol>
<li>Parameters must be used identically in each constructor's type.</li>
<li>All parameters must come before all indices.</li>
<li>The universe level of the datatype being defined must be at least as large as the largest parameter, and strictly larger than the largest index.</li>
<li>Named arguments written before the colon are always parameters, while arguments after the colon are typically indices. Lean may determine that the usage of arguments after the colon makes them into parameters if they are used consistently in all constructors and don't come after any indices.</li>
</ol>
<p>When in doubt, the Lean command <code>#print</code> can be used to check how many of a datatype's arguments are parameters.
For example, for <code>Vect</code>, it points out that the number of parameters is 1:</p>
<pre><code class="language-lean">#print Vect
</code></pre>
<pre><code class="language-output info">inductive Vect.{u} : Type u → Nat → Type u
number of parameters: 1
constructors:
Vect.nil : {α : Type u} → Vect α 0
Vect.cons : {α : Type u} → {n : Nat} → α → Vect α n → Vect α (n + 1)
</code></pre>
<p>It is worth thinking about which arguments should be parameters and which should be indices when choosing the order of arguments to a datatype.
Having as many arguments as possible be parameters helps keep universe levels under control, which can make a complicated program easier to type check.
One way to make this possible is to ensure that all parameters come before all indices in the argument list.</p>
<p>Additionally, even though Lean is capable of determining that arguments after the colon are nonetheless parameters by their usage, it's a good idea to write parameters with explicit names.
This makes the intention clear to readers, and it causes Lean to report an error if the argument is mistakenly used inconsistently across the constructors.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pitfalls-of-programming-with-dependent-types"><a class="header" href="#pitfalls-of-programming-with-dependent-types">Pitfalls of Programming with Dependent Types</a></h1>
<p>The flexibility of dependent types allows more useful programs to be accepted by a type checker, because the language of types is expressive enough to describe variations that less-expressive type systems cannot.
At the same time, the ability of dependent types to express very fine-grained specifications allows more buggy programs to be rejected by a type checker.
This power comes at a cost.</p>
<p>The close coupling between the internals of type-returning functions such as <code>Row</code> and the types that they produce is an instance of a bigger difficulty: the distinction between the interface and the implementation of functions begins to break down when functions are used in types.
Normally, all refactorings are valid as long as they don't change the type signature or input-output behavior of a function.
Functions can be rewritten to use more efficient algorithms and data structures, bugs can be fixed, and code clarity can be improved without breaking client code.
When the function is used in a type, however, the internals of the function's implementation become part of the type, and thus part of the <em>interface</em> to another program.</p>
<p>As an example, take the following two implementations of addition on <code>Nat</code>.
<code>Nat.plusL</code> is recursive on its first argument:</p>
<pre><code class="language-lean">def Nat.plusL : Nat → Nat → Nat
  | 0, k =&gt; k
  | n + 1, k =&gt; plusL n k + 1
</code></pre>
<p><code>Nat.plusR</code>, on the other hand, is recursive on its second argument:</p>
<pre><code class="language-lean">def Nat.plusR : Nat → Nat → Nat
  | n, 0 =&gt; n
  | n, k + 1 =&gt; plusR n k + 1
</code></pre>
<p>Both implementations of addition are faithful to the underlying mathematical concept, and they thus return the same result when given the same arguments.</p>
<p>However, these two implementations present quite different interfaces when they are used in types.
As an example, take a function that appends two <code>Vect</code>s.
This function should return a <code>Vect</code> whose length is the sum of the length of the arguments.
Because <code>Vect</code> is essentially a <code>List</code> with a more informative type, it makes sense to write the function just as one would for <code>List.append</code>, with pattern matching and recursion on the first argument.
Starting with a type signature and initial pattern match pointing at placeholders yields two messages:</p>
<pre><code class="language-lean">def appendL : Vect α n → Vect α k → Vect α (n.plusL k)
  | .nil, ys =&gt; _
  | .cons x xs, ys =&gt; _
</code></pre>
<p>The first message, in the <code>nil</code> case, states that the placeholder should be replaced by a <code>Vect</code> with length <code>plusL 0 k</code>:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n k : Nat
ys : Vect α k
⊢ Vect α (Nat.plusL 0 k)
</code></pre>
<p>The second message, in the <code>cons</code> case, states that the placeholder should be replaced by a <code>Vect</code> with length <code>plusL (n✝ + 1) k</code>:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n k n✝ : Nat
x : α
xs : Vect α n✝
ys : Vect α k
⊢ Vect α (Nat.plusL (n✝ + 1) k)
</code></pre>
<p>The symbol after <code>n</code>, called a <em>dagger</em>, is used to indicate names that Lean has internally invented.
Behind the scenes, pattern matching on the first <code>Vect</code> implicitly caused the value of the first <code>Nat</code> to be refined as well, because the index on the constructor <code>cons</code> is <code>n + 1</code>, with the tail of the <code>Vect</code> having length <code>n</code>.
Here, <code>n✝</code> represents the <code>Nat</code> that is one less than the argument <code>n</code>.</p>
<h2 id="definitional-equality"><a class="header" href="#definitional-equality">Definitional Equality</a></h2>
<p>In the definition of <code>plusL</code>, there is a pattern case <code>0, k =&gt; k</code>.
This applies in the length used in the first placeholder, so another way to write the underscore's type <code>Vect α (Nat.plusL 0 k)</code> is <code>Vect α k</code>.
Similarly, <code>plusL</code> contains a pattern case <code>n + 1, k =&gt; plusN n k + 1</code>.
This means that the type of the second underscore can be equivalently written <code>Vect α (plusL n✝ k + 1)</code>.</p>
<p>To expose what is going on behind the scenes, the first step is to write the <code>Nat</code> arguments explicitly, which also results in daggerless error messages because the names are now written explicitly in the program:</p>
<pre><code class="language-lean">def appendL : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusL k)
  | 0, k, .nil, ys =&gt; _
  | n + 1, k, .cons x xs, ys =&gt; _
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
k : Nat
ys : Vect α k
⊢ Vect α (Nat.plusL 0 k)
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n k : Nat
x : α
xs : Vect α n
ys : Vect α k
⊢ Vect α (Nat.plusL (n + 1) k)
</code></pre>
<p>Annotating the underscores with the simplified versions of the types does not introduce a type error, which means that the types as written in the program are equivalent to the ones that Lean found on its own:</p>
<pre><code class="language-lean">def appendL : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusL k)
  | 0, k, .nil, ys =&gt; (_ : Vect α k)
  | n + 1, k, .cons x xs, ys =&gt; (_ : Vect α (n.plusL k + 1))
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
k : Nat
ys : Vect α k
⊢ Vect α k
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n k : Nat
x : α
xs : Vect α n
ys : Vect α k
⊢ Vect α (Nat.plusL n k + 1)
</code></pre>
<p>The first case demands a <code>Vect α k</code>, and <code>ys</code> has that type.
This is parallel to the way that appending the empty list to any other list returns that other list.
Refining the definition with <code>ys</code> instead of the first underscore yields a program with only one remaining underscore to be filled out:</p>
<pre><code class="language-lean">def appendL : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusL k)
  | 0, k, .nil, ys =&gt; ys
  | n + 1, k, .cons x xs, ys =&gt; (_ : Vect α (n.plusL k + 1))
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n k : Nat
x : α
xs : Vect α n
ys : Vect α k
⊢ Vect α (Nat.plusL n k + 1)
</code></pre>
<p>Something very important has happened here.
In a context where Lean expected a <code>Vect α (Nat.plusL 0 k)</code>, it received a <code>Vect α k</code>.
However, <code>Nat.plusL</code> is not an <code>abbrev</code>, so it may seem like it shouldn't be running during type checking.
Something else is happening.</p>
<p>The key to understanding what's going on is that Lean doesn't just expand <code>abbrev</code>s while type checking.
It can also perform computation while checking whether two types are equivalent to one another, such that any expression of one type can be used in a context that expects the other type.
This property is called <em>definitional equality</em>, and it is subtle.</p>
<p>Certainly, two types that are written identically are considered to be definitionally equal—<code>Nat</code> and <code>Nat</code> or <code>List String</code> and <code>List String</code> should be considered equal.
Any two concrete types built from different datatypes are not equal, so <code>List Nat</code> is not equal to <code>Int</code>.
Additionally, types that differ only by renaming internal names are equal, so <code>(n : Nat) → Vect String n</code> is the same as <code>(k : Nat) → Vect String k</code>.
Because types can contain ordinary data, definitional equality must also describe when data are equal.
Uses of the same constructors are equal, so <code>0</code> equals <code>0</code> and <code>[5, 3, 1]</code> equals <code>[5, 3, 1]</code>.</p>
<p>Types contain more than just function arrows, datatypes, and constructors, however.
They also contain <em>variables</em> and <em>functions</em>.
Definitional equality of variables is relatively simple: each variable is equal only to itself, so <code>(n k : Nat) → Vect Int n</code> is not definitionally equal to <code>(n k : Nat) → Vect Int k</code>.
Functions, on the other hand, are more complicated.
While mathematics considers two functions to be equal if they have identical input-output behavior, there is no efficient algorithm to check that, and the whole point of definitional equality is for Lean to check whether two types are interchangeable.
Instead, Lean considers functions to be definitionally equal either when they are both <code>fun</code>-expressions with definitionally equal bodies.
In other words, two functions must use <em>the same algorithm</em> that calls <em>the same helpers</em> to be considered definitionally equal.
This is not typically very helpful, so definitional equality of functions is mostly used when the exact same defined function occurs in two types.</p>
<p>When functions are <em>called</em> in a type, checking definitional equality may involve reducing the function call.
The type <code>Vect String (1 + 4)</code> is definitionally equal to the type <code>Vect String (3 + 2)</code> because <code>1 + 4</code> is definitionally equal to <code>3 + 2</code>.
To check their equality, both are reduced to <code>5</code>, and then the constructor rule can be used five times.
Definitional equality of functions applied to data can be checked first by seeing if they're already the same—there's no need to reduce <code>[&quot;a&quot;, &quot;b&quot;] ++ [&quot;c&quot;]</code> to check that it's equal to <code>[&quot;a&quot;, &quot;b&quot;] ++ [&quot;c&quot;]</code>, after all.
If not, the function is called and replaced with its value, and the value can then be checked.</p>
<p>Not all function arguments are concrete data.
For example, types may contain <code>Nat</code>s that are not built from the <code>zero</code> and <code>succ</code> constructors.
In the type <code>(n : Nat) → Vect String n</code>, the variable <code>n</code> is a <code>Nat</code>, but it is impossible to know <em>which</em> <code>Nat</code> it is before the function is called.
Indeed, the function may be called first with <code>0</code>, and then later with <code>17</code>, and then again with <code>33</code>.
As seen in the definition of <code>appendL</code>, variables with type <code>Nat</code> may also be passed to functions such as <code>plusL</code>.
Indeed, the type <code>(n : Nat) → Vect String n</code> is definitionally equal to the type <code>(n : Nat) → Vect String (Nat.plusL 0 n)</code>.</p>
<p>The reason that <code>n</code> and <code>Nat.plusL 0 n</code> are definitionally equal is that <code>plusL</code>'s pattern match examines its <em>first</em> argument.
This is problematic: <code>(n : Nat) → Vect String n</code> is <em>not</em> definitionally equal to <code>(n : Nat) → Vect String (Nat.plusL n 0)</code>, even though zero should be both a left and a right identity of addition.
This happens because pattern matching gets stuck when it encounters variables.
Until the actual value of <code>n</code> becomes known, there is no way to know which case of <code>Nat.plusL n 0</code> should be selected.</p>
<p>The same issue appears with the <code>Row</code> function in the query example.
The type <code>Row (c :: cs)</code> does not reduce to any datatype because the definition of <code>Row</code> has separate cases for singleton lists and lists with at least two entries.
In other words, it gets stuck when trying to match the variable <code>cs</code> against concrete <code>List</code> constructors.
This is why almost every function that takes apart or constructs a <code>Row</code> needs to match the same three cases as <code>Row</code> itself: getting it unstuck reveals concrete types that can be used for either pattern matching or constructors.</p>
<p>The missing case in <code>appendL</code> requires a <code>Vect α (Nat.plusL n k + 1)</code>.
The <code>+ 1</code> in the index suggests that the next step is to use <code>Vect.cons</code>:</p>
<pre><code class="language-lean">def appendL : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusL k)
  | 0, k, .nil, ys =&gt; ys
  | n + 1, k, .cons x xs, ys =&gt; .cons x (_ : Vect α (n.plusL k))
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n k : Nat
x : α
xs : Vect α n
ys : Vect α k
⊢ Vect α (Nat.plusL n k)
</code></pre>
<p>A recursive call to <code>appendL</code> can construct a <code>Vect</code> with the desired length:</p>
<pre><code class="language-lean">def appendL : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusL k)
  | 0, k, .nil, ys =&gt; ys
  | n + 1, k, .cons x xs, ys =&gt; .cons x (appendL n k xs ys)
</code></pre>
<p>Now that the program is finished, removing the explicit matching on <code>n</code> and <code>k</code> makes it easier to read and easier to call the function:</p>
<pre><code class="language-lean">def appendL : Vect α n → Vect α k → Vect α (n.plusL k)
  | .nil, ys =&gt; ys
  | .cons x xs, ys =&gt; .cons x (appendL xs ys)
</code></pre>
<p>Comparing types using definitional equality means that everything involved in definitional equality, including the internals of function definitions, becomes part of the <em>interface</em> of programs that use dependent types and indexed families.
Exposing the internals of a function in a type means that refactoring the exposed program may cause programs that use it to no longer type check.
In particular, the fact that <code>plusL</code> is used in the type of <code>appendL</code> means that the definition of <code>plusL</code> cannot be replaced by the otherwise-equivalent <code>plusR</code>.</p>
<h2 id="getting-stuck-on-addition"><a class="header" href="#getting-stuck-on-addition">Getting Stuck on Addition</a></h2>
<p>What happens if append is defined with <code>plusR</code> instead?
Beginning in the same way, with explicit lengths and placeholder underscores in each case, reveals the following useful error messages:</p>
<pre><code class="language-lean">def appendR : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusR k)
  | 0, k, .nil, ys =&gt; _
  | n + 1, k, .cons x xs, ys =&gt; _
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
k : Nat
ys : Vect α k
⊢ Vect α (Nat.plusR 0 k)
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n k : Nat
x : α
xs : Vect α n
ys : Vect α k
⊢ Vect α (Nat.plusR (n + 1) k)
</code></pre>
<p>However, attempting to place a <code>Vect α k</code> type annotation around the first placeholder results in an type mismatch error:</p>
<pre><code class="language-lean">def appendR : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusR k)
  | 0, k, .nil, ys =&gt; (_ : Vect α k)
  | n + 1, k, .cons x xs, ys =&gt; _
</code></pre>
<pre><code class="language-output error">type mismatch
  ?m.3079
has type
  Vect α k : Type ?u.3016
but is expected to have type
  Vect α (Nat.plusR 0 k) : Type ?u.3016
</code></pre>
<p>This error is pointing out that <code>plusR 0 k</code> and <code>k</code> are <em>not</em> definitionally equal.</p>
<p>This is because <code>plusR</code> has the following definition:</p>
<pre><code class="language-lean">def Nat.plusR : Nat → Nat → Nat
  | n, 0 =&gt; n
  | n, k + 1 =&gt; plusR n k + 1
</code></pre>
<p>Its pattern matching occurs on the <em>second</em> argument, not the first argument, which means that the presence of the variable <code>k</code> in that position prevents it from reducing.
<code>Nat.add</code> in Lean's standard library is equivalent to <code>plusR</code>, not <code>plusL</code>, so attempting to use it in this definition results in precisely the same difficulties:</p>
<pre><code class="language-lean">def appendR : (n k : Nat) → Vect α n → Vect α k → Vect α (n + k)
  | 0, k, .nil, ys =&gt; (_ : Vect α k)
  | n + 1, k, .cons x xs, ys =&gt; _
</code></pre>
<pre><code class="language-output error">type mismatch
  ?m.3111
has type
  Vect α k : Type ?u.3016
but is expected to have type
  Vect α (0 + k) : Type ?u.3016
</code></pre>
<p>Addition is getting <em>stuck</em> on the variables.
Getting it unstuck requires <a href="dependent-types/../type-classes/standard-classes.html#equality-and-ordering">propositional equality</a>.</p>
<h2 id="propositional-equality"><a class="header" href="#propositional-equality">Propositional Equality</a></h2>
<p>Propositional equality is the mathematical statement that two expressions are equal.
While definitional equality is a kind of ambient fact that Lean automatically checks when required, statements of propositional equality require explicit proofs.
Once an equality proposition has been proved, it can be used in a program to modify a type, replacing one side of the equality with the other, which can unstick the type checker.</p>
<p>The reason why definitional equality is so limited is to enable it to be checked by an algorithm.
Propositional equality is much richer, but the computer cannot in general check whether two expressions are propositionally equal, though it can verify that a purported proof is in fact a proof.
The split between definitional and propositional equality represents a division of labor between humans and machines: the most boring equalities are checked automatically as part of definitional equality, freeing the human mind to work on the interesting problems available in propositional equality.
Similarly, definitional equality is invoked automatically by the type checker, while propositional equality must be specifically appealed to.</p>
<p>In <a href="dependent-types/../props-proofs-indexing.html">Propositions, Proofs, and Indexing</a>, some equality statements are proved using <code>simp</code>.
All of these equality statements are ones in which the propositional equality is in fact already a definitional equality.
Typically, statements of propositional equality are proved by first getting them into a form where they are either definitional or close enough to existing proved equalities, and then using tools like <code>simp</code> to take care of the simplified cases.
The <code>simp</code> tactic is quite powerful: behind the scenes, it uses a number of fast, automated tools to construct a proof.
A simpler tactic called <code>rfl</code> specifically uses definitional equality to prove propositional equality.
The name <code>rfl</code> is short for <em>reflexivity</em>, which is the property of equality that states that everything equals itself.</p>
<p>Unsticking <code>appendR</code> requires a proof that <code>k = Nat.plusR 0 k</code>, which is not a definitional equality because <code>plusR</code> is stuck on the variable in its second argument.
To get it to compute, the <code>k</code> must become a concrete constructor.
This is a job for pattern matching.</p>
<p>In particular, because <code>k</code> could be <em>any</em> <code>Nat</code>, this task requires a function that can return evidence that <code>k = Nat.plusR 0 k</code> for <em>any</em> <code>k</code> whatsoever.
This should be a function that returns a proof of equality, with type <code>(k : Nat) → k = Nat.plusR 0 k</code>.
Getting it started with initial patterns and placeholders yields the following messages:</p>
<pre><code class="language-lean">def plusR_zero_left : (k : Nat) → k = Nat.plusR 0 k
  | 0 =&gt; _
  | k + 1 =&gt; _
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
⊢ 0 = Nat.plusR 0 0
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
k : Nat
⊢ k + 1 = Nat.plusR 0 (k + 1)
</code></pre>
<p>Having refined <code>k</code> to <code>0</code> via pattern matching, the first placeholder stands for evidence of a statement that does hold definitionally.
The <code>rfl</code> tactic takes care of it, leaving only the second placeholder:</p>
<pre><code class="language-lean">def plusR_zero_left : (k : Nat) → k = Nat.plusR 0 k
  | 0 =&gt; by rfl
  | k + 1 =&gt; _
</code></pre>
<p>The second placeholder is a bit trickier.
The expression <code>Nat.plusR 0 k + 1</code> is definitionally equal to <code>Nat.plusR 0 (k + 1)</code>.
This means that the goal could also be written <code>k + 1 = Nat.plusR 0 k + 1</code>:</p>
<pre><code class="language-lean">def plusR_zero_left : (k : Nat) → k = Nat.plusR 0 k
  | 0 =&gt; by rfl
  | k + 1 =&gt; (_ : k + 1 = Nat.plusR 0 k + 1)
</code></pre>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
k : Nat
⊢ k + 1 = Nat.plusR 0 k + 1
</code></pre>
<p>Underneath the <code>+ 1</code> on each side of the equality statement is another instance of what the function itself returns.
In other words, a recursive call on <code>k</code> would return evidence that <code>k = Nat.plusR 0 k</code>.
Equality wouldn't be equality if it didn't apply to function arguments. 
In other words, if <code>x = y</code>, then <code>f x = f y</code>.
The standard library contains a function <code>congrArg</code> that takes a function and an equality proof and returns a new proof where the function has been applied to both sides of the equality.
In this case, the function is <code>(· + 1)</code>:</p>
<pre><code class="language-lean">def plusR_zero_left : (k : Nat) → k = Nat.plusR 0 k
  | 0 =&gt; by rfl
  | k + 1 =&gt;
    congrArg (· + 1) (plusR_zero_left k)
</code></pre>
<p>Propositional equalities can be deployed in a program using the rightward triangle operator <code>▸</code>.
Given an equality proof as its first argument and some other expression as its second, this operator replaces instances of the left side of the equality with the right side of the equality in the second argument's type.
In other words, the following definition contains no type errors:</p>
<pre><code class="language-lean">def appendR : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusR k)
  | 0, k, .nil, ys =&gt; plusR_zero_left k ▸ (_ : Vect α k)
  | n + 1, k, .cons x xs, ys =&gt; _
</code></pre>
<p>The first placeholder has the expected type:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
k : Nat
ys : Vect α k
⊢ Vect α k
</code></pre>
<p>It can now be filled in with <code>ys</code>:</p>
<pre><code class="language-lean">def appendR : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusR k)
  | 0, k, .nil, ys =&gt; plusR_zero_left k ▸ ys
  | n + 1, k, .cons x xs, ys =&gt; _
</code></pre>
<p>Filling in the remaining placeholder requires unsticking another instance of addition:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
α : Type u_1
n k : Nat
x : α
xs : Vect α n
ys : Vect α k
⊢ Vect α (Nat.plusR (n + 1) k)
</code></pre>
<p>Here, the statement to be proved is that <code>Nat.plusR (n + 1) k = Nat.plusR n k + 1</code>, which can be used with <code>▸</code> to draw the <code>+ 1</code> out to the top of the expression so that it matches the index of <code>cons</code>.</p>
<p>The proof is a recursive function that pattern matches on the second argument to <code>plusR</code>, namely <code>k</code>.
This is because <code>plusR</code> itself pattern matches on its second argument, so the proof can &quot;unstick&quot; it through pattern matching, exposing the computational behavior.
The skeleton of the proof is very similar to that of <code>plusR_zero_left</code>:</p>
<pre><code class="language-lean">def plusR_succ_left (n : Nat) : (k : Nat) → Nat.plusR (n + 1) k = Nat.plusR n k + 1
  | 0 =&gt; by rfl
  | k + 1 =&gt; _
</code></pre>
<p>The remaining case's type is definitionally equal to <code>Nat.plusR (n + 1) k + 1 = Nat.plusR n (k + 1) + 1</code>, so it can be solved with <code>congrArg</code>, just as in <code>plusR_zero_left</code>:</p>
<pre><code class="language-output error">don't know how to synthesize placeholder
context:
n k : Nat
⊢ Nat.plusR (n + 1) (k + 1) = Nat.plusR n (k + 1) + 1
</code></pre>
<p>This results in a finished proof:</p>
<pre><code class="language-lean">def plusR_succ_left (n : Nat) : (k : Nat) → Nat.plusR (n + 1) k = Nat.plusR n k + 1
  | 0 =&gt; by rfl
  | k + 1 =&gt; congrArg (· + 1) (plusR_succ_left n k)
</code></pre>
<p>The finished proof can be used to unstick the second case in <code>appendR</code>:</p>
<pre><code class="language-lean">def appendR : (n k : Nat) → Vect α n → Vect α k → Vect α (n.plusR k)
  | 0, k, .nil, ys =&gt; plusR_zero_left k ▸ ys
  | n + 1, k, .cons x xs, ys =&gt; plusR_succ_left n k ▸ .cons x (appendR n k xs ys)
</code></pre>
<p>When making the length arguments to <code>appendR</code> implicit again, they are no longer explicitly named to be appealed to in the proofs.
However, Lean's type checker has enough information to fill them in automatically behind the scenes, because no other values would allow the types to match:</p>
<pre><code class="language-lean">def appendR : Vect α n → Vect α k → Vect α (n.plusR k)
  | .nil, ys =&gt; plusR_zero_left _ ▸ ys
  | .cons x xs, ys =&gt; plusR_succ_left _ _ ▸ .cons x (appendR xs ys)
</code></pre>
<h2 id="pros-and-cons"><a class="header" href="#pros-and-cons">Pros and Cons</a></h2>
<p>Indexed families have an important property: pattern matching on them affects definitional equality.
For example, in the <code>nil</code> case in a <code>match</code> expression on a <code>Vect</code>, the length simply <em>becomes</em> <code>0</code>.
Definitional equality can be very convenient, because it is always active and does not need to be invoked explicitly.</p>
<p>However, the use of definitional equality with dependent types and pattern matching has serious software engineering drawbacks.
First off, functions must be written especially to be used in types, and functions that are convenient to use in types may not use the most efficient algorithms.
Once a function has been exposed through using it in a type, its implementation has become part of the interface, leading to difficulties in future refactoring.
Secondly, definitional equality can be slow.
When asked to check whether two expressions are definitionally equal, Lean may need to run large amounts of code if the functions in question are complicated and have many layers of abstraction.
Third, error messages that result from failures of definitional equality are not always very easy to understand, because they may be phrased in terms of the internals of functions.
It is not always easy to understand the provenance of the expressions in the error messages.
Finally, encoding non-trivial invariants in a collection of indexed families and dependently-typed functions can often be brittle.
It is often necessary to change early definitions in a system when the exposed reduction behavior of functions proves to not provide convenient definitional equalities.
The alternative is to litter the program with appeals to equality proofs, but these can become quite unwieldy.</p>
<p>In idiomatic Lean code, indexed datatypes are not used very often.
Instead, subtypes and explicit propositions are typically used to enforce important invariants.
This approach involves many explicit proofs, and very few appeals to definitional equality.
As befits an interactive theorem prover, Lean has been designed to make explicit proofs convenient.
Generally speaking, this approach should be preferred in most cases.</p>
<p>However, understanding indexed families of datatypes is important.
Recursive functions such as <code>plusR_zero_left</code> and <code>plusR_succ_left</code> are in fact <em>proofs by mathematical induction</em>.
The base case of the recursion corresponds to the base case in induction, and the recursive call represents an appeal to the induction hypothesis.
More generally, new propositions in Lean are often defined as inductive types of evidence, and these inductive types usually have indices.
The process of proving theorems is in fact constructing expressions with these types behind the scenes, in a process not unlike the proofs in this section.
Also, indexed datatypes are sometimes exactly the right tool for the job.
Fluency in their use is an important part of knowing when to use them.</p>
<h2 id="exercises-21"><a class="header" href="#exercises-21">Exercises</a></h2>
<ul>
<li>Using a recursive function in the style of <code>plusR_succ_left</code>, prove that for all <code>Nat</code>s <code>n</code> and <code>k</code>, <code>n.plusR k = n + k</code>.</li>
<li>Write a function on <code>Vect</code> for which <code>plusR</code> is more natural than <code>plusL</code>, where <code>plusL</code> would require proofs to be used in the definition.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-6"><a class="header" href="#summary-6">Summary</a></h1>
<h2 id="dependent-types"><a class="header" href="#dependent-types">Dependent Types</a></h2>
<p>Dependent types, where types contain non-type code such as function calls and ordinary data constructors, lead to a massive increase in the expressive power of a type system.
The ability to <em>compute</em> a type from the <em>value</em> of an argument means that the return type of a function can vary based on which argument is provided.
This can be used, for example, to have the result type of a database query depend on the database's schema and the specific query issued, without needing any potentially-failing cast operations on the result of the query.
When the query changes, so does the type that results from running it, enabling immediate compile-time feedback.</p>
<p>When a function's return type depends on a value, analyzing the value with pattern matching can result in the type being <em>refined</em>, as a variable that stands for a value is replaced by the constructors in the pattern.
The type signature of a function documents the way that the return type depends on the argument value, and pattern matching then explains how the return type can be fulfilled for each potential argument.</p>
<p>Ordinary code that occurs in types is run during type checking, though <code>partial</code> functions that might loop infinitely are not called.
Mostly, this computation follows the rules of ordinary evaluation that were introduced in <a href="dependent-types/../getting-to-know/evaluating.html">the very beginning of this book</a>, with expressions being progressively replaced by their values until a final value is found.
Computation during type checking has an important difference from run-time computation: some values in types may be <em>variables</em> whose values are not yet known.
In these cases, pattern-matching gets &quot;stuck&quot; and does not proceed until or unless a particular constructor is selected, e.g. by pattern matching.
Type-level computation can be seen as a kind of partial evaluation, where only the parts of the program that are sufficiently known need to be evaluated and other parts are left alone.</p>
<h2 id="the-universe-pattern"><a class="header" href="#the-universe-pattern">The Universe Pattern</a></h2>
<p>A common pattern when working with dependent types is to section off some subset of the type system.
For example, a database query library might be able to return varying-length strings, fixed-length strings, or numbers in certain ranges, but it will never return a function, a user-defined datatype, or an <code>IO</code> action.
A domain-specific subset of the type system can be defined by first defining a datatype with constructors that match the structure of the desired types, and then defining a function that interprets values from this datatype into honest-to-goodness types.
The constructors are referred to as <em>codes</em> for the types in question, and the entire pattern is sometimes referred to as a <em>universe à la Tarski</em>, or just as a <em>universe</em> when context makes it clear that universes such as <code>Type 3</code> or <code>Prop</code> are not what's meant.</p>
<p>Custom universes are an alternative to defining a type class with instances for each type of interest.
Type classes are extensible, but extensibility is not always desired.
Defining a custom universe has a number of advantages over using the types directly:</p>
<ul>
<li>Generic operations that work for <em>any</em> type in the universe, such as equality testing and serialization, can be implemented by recursion on codes.</li>
<li>The types accepted by external systems can be represented precisely, and the definition of the code datatype serves to document what can be expected.</li>
<li>Lean's pattern matching completeness checker ensures that no codes are forgotten, while solutions based on type classes defer missing instance errors to client code.</li>
</ul>
<h2 id="indexed-families-1"><a class="header" href="#indexed-families-1">Indexed Families</a></h2>
<p>Datatypes can take two separate kinds of arguments: <em>parameters</em> are identical in each constructor of the datatype, while <em>indices</em> may vary between constructors.
For a given choice of index, only some constructors of the datatype are available.
As an example, <code>Vect.nil</code> is available only when the length index is <code>0</code>, and <code>Vect.cons</code> is available only when the length index is <code>n+1</code> for some <code>n</code>.
While parameters are typically written as named arguments before the colon in a datatype declaration, and indices as arguments in a function type after the colon, Lean can infer when an argument after the colon is used as a parameter.</p>
<p>Indexed families allow the expression of complicated relationships between data, all checked by the compiler.
The datatype's invariants can be encoded directly, and there is no way to violate them, not even temporarily.
Informing the compiler about the datatype's invariants brings a major benefit: the compiler can now inform the programmer about what must be done to satisfy them.
The strategic use of compile-time errors, especially those resulting from underscores, can make it possible to offload some of the programming thought process to Lean, freeing up the programmer's mind to worry about other things.</p>
<p>Encoding invariants using indexed families can lead to difficulties.
First off, each invariant requires its own datatype, which then requires its own support libraries.
<code>List.append</code> and <code>Vect.append</code> are not interchangeable, after all.
This can lead to code duplication.
Secondly, convenient use of indexed families requires that the recursive structure of functions used in types match the recursive structure of the programs being type checked.
Programming with indexed families is the art of arranging for the right coincidences to occur.
While it's possible to work around missing coincidences with appeals to equality proofs, it is difficult, and it leads to programs littered with cryptic justifications.
Thirdly, running complicated code on large values during type checking can lead to compile-time slowdowns.
Avoiding these slowdowns for complicated programs can require specialized techniques.</p>
<h2 id="definitional-and-propositional-equality"><a class="header" href="#definitional-and-propositional-equality">Definitional and Propositional Equality</a></h2>
<p>Lean's type checker must, from time to time, check whether two types should be considered interchangable.
Because types can contain arbitrary programs, it must therefore be able to check arbitrary programs for equality.
However, there is no efficient algorithm to check arbitrary programs for fully-general mathematical equality.
To work around this, Lean contains two notions of equality:</p>
<ul>
<li>
<p><em>Definitional equality</em> is an underapproximation of equality that essentially checks for equality of syntactic representation modulo computation and renaming of bound variables. Lean automatically checks for definitional equality in situations where it is required.</p>
</li>
<li>
<p><em>Propositional equality</em> must be explicitly proved and explicitly invoked by the programmer. In return, Lean automatically checks that the proofs are valid and that the invocations accomplish the right goal.</p>
</li>
</ul>
<p>The two notions of equality represent a division of labor between programmers and Lean itself.
Definitional equality is simple, but automatic, while propositional equality is manual, but expressive.
Propositional equality can be used to unstick otherwise-stuck programs in types.</p>
<p>However, the frequent use of propositional equality to unstick type-level computation is typically a code smell.
It typically means that coincidences were not well-engineered, and it's usually a better idea to either redesign the types and indices or to use a different technique to enforce the needed invariants.
When propositional equality is instead used to prove that a program meets a specification, or as part of a subtype, there is less reason to be suspicious.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="interlude-tactics-induction-and-proofs"><a class="header" href="#interlude-tactics-induction-and-proofs">Interlude: Tactics, Induction, and Proofs</a></h1>
<h2 id="a-note-on-proofs-and-user-interfaces"><a class="header" href="#a-note-on-proofs-and-user-interfaces">A Note on Proofs and User Interfaces</a></h2>
<p>This book presents the process of writing proofs as if they are written in one go and submitted to Lean, which then replies with error messages that describe what remains to be done.
The actual process of interacting with Lean is much more pleasant.
Lean provides information about the proof as the cursor is moved through it and there are a number of interactive features that make proving easier.
Please consult the documentation of your Lean development environment for more information.</p>
<p>The approach in this book that focuses on incrementally building a proof and showing the messages that result demonstrates the kinds of interactive feedback that Lean provides while writing a proof, even though it is much slower than the process used by experts.
At the same time, seeing incomplete proofs evolve towards completeness is a useful perspective on proving.
As your skill in writing proofs increases, Lean's feedback will come to feel less like errors and more like support for your own thought processes.
Learning the interactive approach is very important.</p>
<h2 id="recursion-and-induction"><a class="header" href="#recursion-and-induction">Recursion and Induction</a></h2>
<p>The functions <code>plusR_succ_left</code> and <code>plusR_zero_left</code> from the preceding chapter can be seen from two perspectives.
On the one hand, they are recursive functions that build up evidence for a proposition, just as other recursive functions might construct a list, a string, or any other data structure.
On the other, they also correspond to proofs by <em>mathematical induction</em>.</p>
<p>Mathematical induction is a proof technique where a statement is proven for <em>all</em> natural numbers in two steps:</p>
<ol>
<li>The statement is shown to hold for \( 0 \). This is called the <em>base case</em>.</li>
<li>Under the assumption that the statement holds for some arbitrarily chosen number \( n \), it is shown to hold for \( n + 1 \). This is called the <em>induction step</em>. The assumption that the statement holds for \( n \) is called the <em>induction hypothesis</em>.</li>
</ol>
<p>Because it's impossible to check the statement for <em>every</em> natural number, induction provides a means of writing a proof that could, in principle, be expanded to any particular natural number.
For example, if a concrete proof were desired for the number 3, then it could be constructed by using first the base case and then the induction step three times, to show the statement for 0, 1, 2, and finally 3.
Thus, it proves the statement for all natural numbers.</p>
<h2 id="the-induction-tactic"><a class="header" href="#the-induction-tactic">The Induction Tactic</a></h2>
<p>Writing proofs by induction as recursive functions that use helpers such as <code>congrArg</code> does not always do a good job of expressing the intentions behind the proof.
While recursive functions indeed have the structure of induction, they should probably be viewed as an <em>encoding</em> of a proof.
Furthermore, Lean's tactic system provides a number of opportunities to automate the construction of a proof that are not available when writing the recursive function explicitly.
Lean provides an induction <em>tactic</em> that can carry out an entire proof by induction in a single tactic block.
Behind the scenes, Lean constructs the recursive function that corresponds the use of induction.</p>
<p>To prove <code>plusR_zero_left</code> with the induction tactic, begin by writing its signature (using <code>theorem</code>, because this really is a proof).
Then, use <code>by induction k</code> as the body of the definition:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k
</code></pre>
<p>The resulting message states that there are two goals:</p>
<pre><code class="language-output error">unsolved goals
case zero
⊢ Nat.zero = Nat.plusR 0 Nat.zero

case succ
n✝ : Nat
n_ih✝ : n✝ = Nat.plusR 0 n✝
⊢ Nat.succ n✝ = Nat.plusR 0 (Nat.succ n✝)
</code></pre>
<p>A tactic block is a program that is run while the Lean type checker processes a file, somewhat like a much more powerful C preprocessor macro.
The tactics generate the actual program.</p>
<p>In the tactic language, there can be a number of goals.
Each goal consists of a type together with some assumptions.
These are analogous to using underscores as placeholders—the type in the goal represents what is to be proved, and the assumptions represent what is in-scope and can be used.
In the case of the goal <code>case zero</code>, there are no assumptions and the type is <code>Nat.zero = Nat.plusR 0 Nat.zero</code>—this is the theorem statement with <code>0</code> instead of <code>k</code>.
In the goal <code>case succ</code>, there are two assumptions, named <code>n✝</code> and <code>n_ih✝</code>.
Behind the scenes, the <code>induction</code> tactic creates a dependent pattern match that refines the overall type, and <code>n✝</code> represents the argument to <code>Nat.succ</code> in the pattern.
The assumption <code>n_ih✝</code> represents the result of calling the generated function recursively on <code>n✝</code>.
Its type is the overall type of the theorem, just with <code>n✝</code> instead of <code>k</code>.
The type to be fulfilled as part of the goal <code>case succ</code> is the overall theorem statement, with <code>Nat.succ n✝</code> instead of <code>k</code>.</p>
<p>The two goals that result from the use of the <code>induction</code> tactic correspond to the base case and the induction step in the description of mathematical induction.
The base case is <code>case zero</code>.
In <code>case succ</code>, <code>n_ih✝</code> corresponds to the induction hypothesis, while the whole of <code>case succ</code> is the induction step.</p>
<p>The next step in writing the proof is to focus on each of the two goals in turn.
Just as <code>pure ()</code> can be used in a <code>do</code> block to indicate &quot;do nothing&quot;, the tactic language has a statement <code>skip</code> that also does nothing.
This can be used when Lean's syntax requires a tactic, but it's not yet clear which one should be used.
Adding <code>with</code> to the end of the <code>induction</code> statement provides a syntax that is similar to pattern matching:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; skip
  | succ n ih =&gt; skip
</code></pre>
<p>Each of the two <code>skip</code> statements has a message associated with it.
The first shows the base case:</p>
<pre><code class="language-output error">unsolved goals
case zero
⊢ Nat.zero = Nat.plusR 0 Nat.zero
</code></pre>
<p>The second shows the induction step:</p>
<pre><code class="language-output error">unsolved goals
case succ
n : Nat
ih : n = Nat.plusR 0 n
⊢ Nat.succ n = Nat.plusR 0 (Nat.succ n)
</code></pre>
<p>In the induction step, the inaccessible names with daggers have been replaced with the names provided after <code>succ</code>, namely <code>n</code> and <code>ih</code>.</p>
<p>The cases after <code>induction ... with</code> are not patterns: they consist of the name of a goal followed by zero or more names.
The names are used for assumptions introduced in the goal; it is an error to provide more names than the goal introduces:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; skip
  | succ n ih lots of names =&gt; skip
</code></pre>
<pre><code class="language-output error">too many variable names provided at alternative 'succ', #5 provided, but #2 expected
</code></pre>
<p>Focusing on the base case, the <code>rfl</code> tactic works just as well inside of the <code>induction</code> tactic as it does in a recursive function:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; rfl
  | succ n ih =&gt; skip
</code></pre>
<p>In the recursive function version of the proof, a type annotation made the expected type something that was easier to understand.
In the tactic language, there are a number of specific ways to transform a goal to make it easier to solve.
The <code>unfold</code> tactic replaces a defined name with its definition:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; rfl
  | succ n ih =&gt;
    unfold Nat.plusR
</code></pre>
<p>Now, the right-hand side of the equality in the goal has become <code>Nat.plusR 0 n + 1</code> instead of <code>Nat.plusR 0 (Nat.succ n)</code>:</p>
<pre><code class="language-output error">unsolved goals
case succ
n : Nat
ih : n = Nat.plusR 0 n
⊢ Nat.succ n = Nat.plusR 0 n + 1
</code></pre>
<p>Instead of appealing to functions like <code>congrArg</code> and operators like <code>▸</code>, there are tactics that allow equality proofs to be used to transform proof goals.
One of the most important is <code>rw</code>, which takes a list of equality proofs and replaces the left side with the right side in the goal.
This almost does the right thing in <code>plusR_zero_left</code>:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; rfl
  | succ n ih =&gt;
    unfold Nat.plusR
    rw [ih]
</code></pre>
<p>However, the direction of the rewrite was incorrect.
Replacing <code>n</code> with <code>Nat.plusR 0 n</code> made the goal more complicated rather than less complicated:</p>
<pre><code class="language-output error">unsolved goals
case succ
n : Nat
ih : n = Nat.plusR 0 n
⊢ Nat.succ (Nat.plusR 0 n) = Nat.plusR 0 (Nat.plusR 0 n) + 1
</code></pre>
<p>This can be remedied by placing a left arrow before <code>ih</code> in the call to <code>rewrite</code>, which instructs it to replace the right-hand side of the equality with the left-hand side:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; rfl
  | succ n ih =&gt;
    unfold Nat.plusR
    rw [←ih]
</code></pre>
<p>This rewrite makes both sides of the equation identical, and Lean takes care of the <code>rfl</code> on its own.
The proof is complete.</p>
<h2 id="tactic-golf"><a class="header" href="#tactic-golf">Tactic Golf</a></h2>
<p>So far, the tactic language has not shown its true value.
The above proof is no shorter than the recursive function; it's merely written in a domain-specific language instead of the full Lean language.
But proofs with tactics can be shorter, easier, and more maintainable.
Just as a lower score is better in the game of golf, a shorter proof is better in the game of tactic golf.</p>
<p>The induction step of <code>plusR_zero_left</code> can be proved using the simplification tactic <code>simp</code>.
Using <code>simp</code> on its own does not help, and the goal is left unmodified:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; rfl
  | succ n ih =&gt;
    simp
</code></pre>
<pre><code class="language-output error">unsolved goals
case succ
n : Nat
ih : n = Nat.plusR 0 n
⊢ Nat.succ n = Nat.plusR 0 (Nat.succ n)
</code></pre>
<p>However, <code>simp</code> can be configured to make use of a set of definitions.
Just like <code>rw</code>, these arguments are provided in a list.
Asking <code>simp</code> to take the definition of <code>Nat.plusR</code> into account leads to a simpler goal:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; rfl
  | succ n ih =&gt;
    simp [Nat.plusR]
</code></pre>
<pre><code class="language-output error">unsolved goals
case succ
n : Nat
ih : n = Nat.plusR 0 n
⊢ n = Nat.plusR 0 n
</code></pre>
<p>In particular, the goal is now identical to the induction hypothesis.
In addition to automatically proving simple equality statements, the simplifier automatically replaces goals like <code>Nat.succ A = Nat.succ B</code> with <code>A = B</code>.
Because the induction hypothesis <code>ih</code> has exactly the right type, the <code>exact</code> tactic can indicate that it should be used:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; rfl
  | succ n ih =&gt;
    simp [Nat.plusR]
    exact ih
</code></pre>
<p>However, the use of <code>exact</code> is somewhat fragile.
Renaming the induction hypothesis, which may happen while &quot;golfing&quot; the proof, would cause this proof to stop working.
The <code>assumption</code> tactic solves the current goal if <em>any</em> of the assumptions match it:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k with
  | zero =&gt; rfl
  | succ n ih =&gt;
    simp [Nat.plusR]
    assumption
</code></pre>
<p>This proof is no shorter than the prior proof that used unfolding and explicit rewriting.
However, a series of transformations can make it much shorter, taking advantage of the fact that <code>simp</code> can solve many kinds of goals.
The first step is to drop the <code>with</code> at the end of <code>induction</code>.
For structured, readable proofs, the <code>with</code> syntax is convenient.
It complains if any cases are missing, and it shows the structure of the induction clearly.
But shortening proofs can often require a more liberal approach.</p>
<p>Using <code>induction</code> without <code>with</code> simply results in a proof state with two goals.
The <code>case</code> tactic can be used to select one of them, just as in the branches of the <code>induction ... with</code> tactic.
In other words, the following proof is equivalent to the prior proof:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k
  case zero =&gt; rfl
  case succ n ih =&gt;
    simp [Nat.plusR]
    assumption
</code></pre>
<p>In a context with a single goal (namely, <code>k = Nat.plusR 0 k</code>), the <code>induction k</code> tactic yields two goals.
In general, a tactic will either fail with an error or take a goal and transform it into zero or more new goals.
Each new goal represents what remains to be proved.
If the result is zero goals, then the tactic was a success, and that part of the proof is done.</p>
<p>The <code>&lt;;&gt;</code> operator takes two tactics as arguments, resulting in a new tactic.
<code>T1 &lt;;&gt; T2</code> applies <code>T1</code> to the current goal, and then applies <code>T2</code> in <em>all</em> goals created by <code>T1</code>.
In other words, <code>&lt;;&gt;</code> enables a general tactic that can solve many kinds of goals to be used on multiple new goals all at once.
One such general tactic is <code>simp</code>.</p>
<p>Because <code>simp</code> can both complete the proof of the base case and make progress on the proof of the induction step, using it with <code>induction</code> and <code>&lt;;&gt;</code> shortens the proof:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k &lt;;&gt; simp [Nat.plusR]
</code></pre>
<p>This results in only a single goal, the transformed induction step:</p>
<pre><code class="language-output error">unsolved goals
case succ
n✝ : Nat
n_ih✝ : n✝ = Nat.plusR 0 n✝
⊢ n✝ = Nat.plusR 0 n✝
</code></pre>
<p>Running <code>assumption</code> in this goal completes the proof:</p>
<pre><code class="language-leantac">theorem plusR_zero_left (k : Nat) : k = Nat.plusR 0 k := by
  induction k &lt;;&gt; simp [Nat.plusR] &lt;;&gt; assumption
</code></pre>
<p>Here, <code>exact</code> would not have been possible, because <code>ih</code> was never explicitly named.</p>
<p>For beginners, this proof is not easier to read.
However, a common pattern for expert users is to take care of a number of simple cases with powerful tactics like <code>simp</code>, allowing them to focus the text of the proof on the interesting cases.
Additionally, these proofs tend to be more robust in the face of small changes to the functions and datatypes involved in the proof.
The game of tactic golf is a useful part of developing good taste and style when writing proofs.</p>
<h2 id="induction-on-other-datatypes"><a class="header" href="#induction-on-other-datatypes">Induction on Other Datatypes</a></h2>
<p>Mathematical induction proves a statement for natural numbers by providing a base case for <code>Nat.zero</code> and an induction step for <code>Nat.succ</code>.
The principle of induction is also valid for other datatypes.
Constructors without recursive arguments form the base cases, while constructors with recursive arguments form the induction steps.
The ability to carry out proofs by induction is the very reason why they are called <em>inductive</em> datatypes.</p>
<p>One example of this is induction on binary trees.
Induction on binary trees is a proof technique where a statement is proven for <em>all</em> binary trees in two steps:</p>
<ol>
<li>The statement is shown to hold for <code>BinTree.leaf</code>. This is called the base case.</li>
<li>Under the assumption that the statement holds for some arbitrarily chosen trees <code>l</code> and <code>r</code>, it is shown to hold for <code>BinTree.branch l x r</code>, where <code>x</code> is an arbitrarily-chosen new data point. This is called the <em>induction step</em>. The assumptions that the statement holds for <code>l</code> and <code>r</code> are called the <em>induction hypotheses</em>.</li>
</ol>
<p><code>BinTree.count</code> counts the number of branches in a tree:</p>
<pre><code class="language-lean">def BinTree.count : BinTree α → Nat
  | .leaf =&gt; 0
  | .branch l _ r =&gt;
    1 + l.count + r.count
</code></pre>
<p><a href="monads/conveniences.html#leading-dot-notation">Mirroring a tree</a> does not change the number of branches in it.
This can be proven using induction on trees.
The first step is to state the theorem and invoke <code>induction</code>:</p>
<pre><code class="language-leantac">theorem BinTree.mirror_count (t : BinTree α) : t.mirror.count = t.count := by
  induction t with
  | leaf =&gt; skip
  | branch l x r ihl ihr =&gt; skip
</code></pre>
<p>The base case states that counting the mirror of a leaf is the same as counting the leaf:</p>
<pre><code class="language-output error">unsolved goals
case leaf
α : Type
⊢ count (mirror leaf) = count leaf
</code></pre>
<p>The induction step allows the assumption that mirroring the left and right subtrees won't affect their branch counts, and requests a proof that mirroring a branch with these subtrees also preserves the overall branch count:</p>
<pre><code class="language-output error">unsolved goals
case branch
α : Type
l : BinTree α
x : α
r : BinTree α
ihl : count (mirror l) = count l
ihr : count (mirror r) = count r
⊢ count (mirror (branch l x r)) = count (branch l x r)
</code></pre>
<p>The base case is true because mirroring <code>leaf</code> results in <code>leaf</code>, so the left and right sides are definitionally equal.
This can be expressed by using <code>simp</code> with instructions to unfold <code>BinTree.mirror</code>:</p>
<pre><code class="language-leantac">theorem BinTree.mirror_count (t : BinTree α) : t.mirror.count = t.count := by
  induction t with
  | leaf =&gt; simp [BinTree.mirror]
  | branch l x r ihl ihr =&gt; skip
</code></pre>
<p>In the induction step, nothing in the goal immediately matches the induction hypotheses.
Simplifying using the definitions of <code>BinTree.count</code> and <code>BinTree.mirror</code> reveals the relationship:</p>
<pre><code class="language-leantac">theorem BinTree.mirror_count (t : BinTree α) : t.mirror.count = t.count := by
  induction t with
  | leaf =&gt; simp [BinTree.mirror]
  | branch l x r ihl ihr =&gt;
    simp [BinTree.mirror, BinTree.count]
</code></pre>
<pre><code class="language-output error">unsolved goals
case branch
α : Type
l : BinTree α
x : α
r : BinTree α
ihl : count (mirror l) = count l
ihr : count (mirror r) = count r
⊢ 1 + count (mirror r) + count (mirror l) = 1 + count l + count r
</code></pre>
<p>Both induction hypotheses can be used to rewrite the left-hand side of the goal into something almost like the right-hand side:</p>
<pre><code class="language-leantac">theorem BinTree.mirror_count (t : BinTree α) : t.mirror.count = t.count := by
  induction t with
  | leaf =&gt; simp [BinTree.mirror]
  | branch l x r ihl ihr =&gt;
    simp [BinTree.mirror, BinTree.count]
    rw [ihl, ihr]
</code></pre>
<pre><code class="language-output error">unsolved goals
case branch
α : Type
l : BinTree α
x : α
r : BinTree α
ihl : count (mirror l) = count l
ihr : count (mirror r) = count r
⊢ 1 + count r + count l = 1 + count l + count r
</code></pre>
<p>The <code>simp_arith</code> tactic, a version of <code>simp</code> that can use additional arithmetic identities, is enough to prove this goal, yielding:</p>
<pre><code class="language-leantac">theorem BinTree.mirror_count (t : BinTree α) : t.mirror.count = t.count := by
  induction t with
  | leaf =&gt; simp [BinTree.mirror]
  | branch l x r ihl ihr =&gt;
    simp [BinTree.mirror, BinTree.count]
    rw [ihl, ihr]
    simp_arith
</code></pre>
<p>In addition to definitions to be unfolded, the simplifier can also be passed names of equality proofs to use as rewrites while it simplifies proof goals.
<code>BinTree.mirror_count</code> can also be written:</p>
<pre><code class="language-leantac">theorem BinTree.mirror_count (t : BinTree α) : t.mirror.count = t.count := by
  induction t with
  | leaf =&gt; simp [BinTree.mirror]
  | branch l x r ihl ihr =&gt;
    simp_arith [BinTree.mirror, BinTree.count, ihl, ihr]
</code></pre>
<p>As proofs grow more complicated, listing assumptions by hand can become tedious.
Furthermore, manually writing assumption names can make it more difficult to re-use proof steps for multiple subgoals.
The argument <code>*</code> to <code>simp</code> or <code>simp_arith</code> instructs them to use <em>all</em> assumptions while simplifying or solving the goal.
In other words, the proof could also be written:</p>
<pre><code class="language-leantac">theorem BinTree.mirror_count (t : BinTree α) : t.mirror.count = t.count := by
  induction t with
  | leaf =&gt; simp [BinTree.mirror]
  | branch l x r ihl ihr =&gt;
    simp_arith [BinTree.mirror, BinTree.count, *]
</code></pre>
<p>Because both branches are using the simplifier, the proof can be reduced to:</p>
<pre><code class="language-leantac">theorem BinTree.mirror_count (t : BinTree α) : t.mirror.count = t.count := by
  induction t &lt;;&gt; simp_arith [BinTree.mirror, BinTree.count, *]
</code></pre>
<h2 id="exercises-22"><a class="header" href="#exercises-22">Exercises</a></h2>
<ul>
<li>Prove <code>plusR_succ_left</code> using the <code>induction ... with</code> tactic.</li>
<li>Rewrite the proof of <code>plus_succ_left</code> to use <code>&lt;;&gt;</code> in a single line.</li>
<li>Prove that appending lists is associative using induction on lists: <code>theorem List.append_assoc (xs ys zs : List α) : xs ++ (ys ++ zs) = (xs ++ ys) ++ zs</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="programming-proving-and-performance"><a class="header" href="#programming-proving-and-performance">Programming, Proving, and Performance</a></h1>
<p>This chapter is about programming.
Programs need to compute the correct result, but they also need to do so efficiently.
To write efficient functional programs, it's important to know both how to use data structures appropriately and how to think about the time and space needed to run a program.</p>
<p>This chapter is also about proofs.
One of the most important data structures for efficient programming in Lean is the array, but safe use of arrays requires proving that array indices are in bounds.
Furthermore, most interesting algorithms on arrays do not follow the pattern of structural recursion—instead, they iterate over the array.
While these algorithms terminate, Lean will not necessarily be able to automatically check this.
Proofs can be used to demonstrate why a program terminates.</p>
<p>Rewriting programs to make them faster often results in code that is more difficult to understand.
Proofs can also show that two programs always compute the same answers, even if they do so with different algorithms or implementation techniques.
In this way, the slow, straightforward program can serve as a specification for the fast, complicated version.</p>
<p>Combining proofs and programming allows programs to be both safe and efficient.
Proofs allow elision of run-time bounds checks, they render many tests unnecessary, and they provide an extremely high level of confidence in a program without introducing any runtime performance overhead.
However, proving theorems about programs can be time consuming and expensive, so other tools are often more economical.</p>
<p>Interactive theorem proving is a deep topic.
This chapter provides only a taste, oriented towards the proofs that come up in practice while programming in Lean.
Most interesting theorems are not closely related to programming.
Please refer to <a href="next-steps.html">Next Steps</a> for a list of resources for learning more.
Just as when learning programming, however, there's no substitute for hands-on experience when learning to write proofs—it's time to get started!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tail-recursion"><a class="header" href="#tail-recursion">Tail Recursion</a></h1>
<p>While Lean's <code>do</code>-notation makes it possible to use traditional loop syntax such as <code>for</code> and <code>while</code>, these constructs are translated behind the scenes to invocations of recursive functions.
In most programming languages, recursive functions have a key disadvantage with respect to loops: loops consume no space on the stack, while recursive functions consume stack space proportional to the number of recursive calls.
Stack space is typically limited, and it is often necessary to take algorithms that are naturally expressed as recursive functions and rewrite them as loops paired with an explicit mutable heap-allocated stack.</p>
<p>In functional programming, the opposite is typically true.
Programs that are naturally expressed as mutable loops may consume stack space, while rewriting them to recursive functions can cause them to run quickly.
This is due to a key aspect of functional programming languages: <em>tail-call elimination</em>.
A tail call is a call from one function to another that can be compiled to an ordinary jump, replacing the current stack frame rather than pushing a new one, and tail-call elimination is the process of implementing this transformation.</p>
<p>Tail-call elimination is not just merely an optional optimization.
Its presence is a fundamental part of being able to write efficient functional code.
For it to be useful, it must be reliable.
Programmers must be able to reliably identify tail calls, and they must be able to trust that the compiler will eliminate them.</p>
<p>The function <code>NonTail.sum</code> adds the contents of a list of <code>Nat</code>s:</p>
<pre><code class="language-lean">def NonTail.sum : List Nat → Nat
  | [] =&gt; 0
  | x :: xs =&gt; x + sum xs
</code></pre>
<p>Applying this function to the list <code>[1, 2, 3]</code> results in the following sequence of evaluation steps:</p>
<pre><code class="language-lean">NonTail.sum [1, 2, 3]
===&gt;
1 + (NonTail.sum [2, 3])
===&gt;
1 + (2 + (NonTail.sum [3]))
===&gt;
1 + (2 + (3 + (NonTail.sum [])))
===&gt;
1 + (2 + (3 + 0))
===&gt;
1 + (2 + 3)
===&gt;
1 + 5
===&gt;
6
</code></pre>
<p>In the evaluation steps, parentheses indicate recursive calls to <code>NonTail.sum</code>.
In other words, to add the three numbers, the program must first check that the list is non-empty.
To add the head of the list (<code>1</code>) to the sum of the tail of the list, it is first necessary to compute the sum of the tail of the list:</p>
<pre><code class="language-lean">1 + (NonTail.sum [2, 3])
</code></pre>
<p>But to compute the sum of the tail of the list, the program must check whether it is empty.
It is not - the tail is itself a list with <code>2</code> at its head.
The resulting step is waiting for the return of <code>NonTail.sum [3]</code>:</p>
<pre><code class="language-lean">1 + (2 + (NonTail.sum [3]))
</code></pre>
<p>The whole point of the run-time call stack is to keep track of the values <code>1</code>, <code>2</code>, and <code>3</code> along with the instruction to add them to the result of the recursive call.
As recursive calls are completed, control returns to the stack frame that made the call, so each step of addition is performed.
Storing the heads of the list and the instructions to add them is not free; it takes space proportional to the length of the list.</p>
<p>The function <code>Tail.sum</code> also adds the contents of a list of <code>Nat</code>s:</p>
<pre><code class="language-lean">def Tail.sumHelper (soFar : Nat) : List Nat → Nat
  | [] =&gt; soFar
  | x :: xs =&gt; sumHelper (x + soFar) xs

def Tail.sum (xs : List Nat) : Nat :=
  Tail.sumHelper 0 xs
</code></pre>
<p>Applying it to the list <code>[1, 2, 3]</code> results in the following sequence of evaluation steps:</p>
<pre><code class="language-lean">Tail.sum [1, 2, 3]
===&gt;
Tail.sumHelper 0 [1, 2, 3]
===&gt;
Tail.sumHelper (0 + 1) [2, 3]
===&gt;
Tail.sumHelper 1 [2, 3]
===&gt;
Tail.sumHelper (1 + 2) [3]
===&gt;
Tail.sumHelper 3 [3]
===&gt;
Tail.sumHelper (3 + 3) []
===&gt;
Tail.sumHelper 6 []
===&gt;
6
</code></pre>
<p>The internal helper function calls itself recursively, but it does so in a way where nothing needs to be remembered in order to compute the final result.
When <code>Tail.sumHelper</code> reaches its base case, control can be returned directly to <code>Tail.sum</code>, because the intermediate invocations of <code>Tail.sumHelper</code> simply return the results of their recursive calls unmodified.
In other words, a single stack frame can be re-used for each recursive invocation of <code>Tail.sumHelper</code>.
Tail-call elimination is exactly this re-use of the stack frame, and <code>Tail.sumHelper</code> is referred to as a <em>tail-recursive function</em>.</p>
<p>The first argument to <code>Tail.sumHelper</code> contains all of the information that would otherwise need to be tracked in the call stack—namely, the sum of the numbers encountered so far.
In each recursive call, this argument is updated with new information, rather than adding new information to the call stack.
Arguments like <code>soFar</code> that replace the information from the call stack are called <em>accumulators</em>.</p>
<p>At the time of writing and on the author's computer, <code>NonTail.sum</code> crashes with a stack overflow when passed a list with 216,856 or more entries.
<code>Tail.sum</code>, on the other hand, can sum a list of 100,000,000 elements without a stack overflow.
Because no new stack frames need to be pushed while running <code>Tail.sum</code>, it is completely equivalent to a <code>while</code> loop with a mutable variable that holds the current list.
At each recursive call, the function argument on the stack is simply replaced with the next node of the list.</p>
<h2 id="tail-and-non-tail-positions"><a class="header" href="#tail-and-non-tail-positions">Tail and Non-Tail Positions</a></h2>
<p>The reason why <code>Tail.sumHelper</code> is tail recursive is that the recursive call is in <em>tail position</em>.
Informally speaking, a function call is in tail position when the caller does not need to modify the returned value in any way, but will just return it directly.
More formally, tail position can be defined explicitly for expressions.</p>
<p>If a <code>match</code>-expression is in tail position, then each of its branches is also in tail position.
Once a <code>match</code> has selected a branch, control proceeds immediately to it.
Similarly, both branches of an <code>if</code>-expression are in tail position if the <code>if</code>-expression itself is in tail position.
Finally, if a <code>let</code>-expression is in tail position, then its body is as well.</p>
<p>All other positions are not in tail position.
The arguments to a function or a constructor are not in tail position because evaluation must track the function or constructor that will be applied to the argument's value.
The body of an inner function is not in tail position because control may not even pass to it: function bodies are not evaluated until the function is called.
Similarly, the body of a function type is not in tail position.
To evaluate <code>E</code> in <code>(x : α) → E</code>, it is necessary to track that the resulting type must have <code>(x : α) → ...</code> wrapped around it.</p>
<p>In <code>NonTail.sum</code>, the recursive call is not in tail position because it is an argument to <code>+</code>.
In <code>Tail.sumHelper</code>, the recursive call is in tail position because it is immediately underneath a pattern match, which itself is the body of the function.</p>
<p>At the time of writing, Lean only eliminates direct tail calls in recursive functions.
This means that tail calls to <code>f</code> in <code>f</code>'s definition will be eliminated, but not tail calls to some other function <code>g</code>.
While it is certainly possible to eliminate a tall call to some other function, saving a stack frame, this is not yet implemented in Lean.</p>
<h2 id="reversing-lists"><a class="header" href="#reversing-lists">Reversing Lists</a></h2>
<p>The function <code>NonTail.reverse</code> reverses lists by appending the head of each sub-list to the end of the result:</p>
<pre><code class="language-lean">def NonTail.reverse : List α → List α
  | [] =&gt; []
  | x :: xs =&gt; reverse xs ++ [x]
</code></pre>
<p>Using it to reverse <code>[1, 2, 3]</code> yields the following sequence of steps:</p>
<pre><code class="language-lean">NonTail.reverse [1, 2, 3]
===&gt;
(NonTail.reverse [2, 3]) ++ [1]
===&gt;
((NonTail.reverse [3]) ++ [2]) ++ [1]
===&gt;
(((NonTail.reverse []) ++ [3]) ++ [2]) ++ [1]
===&gt;
(([] ++ [3]) ++ [2]) ++ [1]
===&gt;
([3] ++ [2]) ++ [1]
===&gt;
[3, 2] ++ [1]
===&gt;
[3, 2, 1]
</code></pre>
<p>The tail-recursive version uses <code>x :: ·</code> instead of <code>· ++ [x]</code> on the accumulator at each step:</p>
<pre><code class="language-lean">def Tail.reverseHelper (soFar : List α) : List α → List α
  | [] =&gt; soFar
  | x :: xs =&gt; reverseHelper (x :: soFar) xs

def Tail.reverse (xs : List α) : List α :=
  Tail.reverseHelper [] xs
</code></pre>
<p>This is because the context saved in each stack frame while computing with <code>NonTail.reverse</code> is applied beginning at the base case.
Each &quot;remembered&quot; piece of context is executed in last-in, first-out order.
On the other hand, the accumulator-passing version modifies the accumulator beginning from the first entry in the list, rather than the original base case, as can be seen in the series of reduction steps:</p>
<pre><code class="language-lean">Tail.reverse [1, 2, 3]
===&gt;
Tail.reverseHelper [] [1, 2, 3]
===&gt;
Tail.reverseHelper [1] [2, 3]
===&gt;
Tail.reverseHelper [2, 1] [3]
===&gt;
Tail.reverseHelper [3, 2, 1] []
===&gt;
[3, 2, 1]
</code></pre>
<p>In other words, the non-tail-recursive version starts at the base case, modifying the result of recursion from right to left through the list.
The entries in the list affect the accumulator in a first-in, first-out order.
The tail-recursive version with the accumulator starts at the head of the list, modifying an initial accumulator value from left to right through the list.</p>
<p>Because addition is commutative, nothing needed to be done to account for this in <code>Tail.sum</code>.
Appending lists is not commutative, so care must be taken to find an operation that has the same effect when run in the opposite direction.
Appending <code>[x]</code> after the result of the recursion in <code>NonTail.reverse</code> is analogous to adding <code>x</code> to the beginning of the list when the result is built in the opposite order.</p>
<h2 id="multiple-recursive-calls"><a class="header" href="#multiple-recursive-calls">Multiple Recursive Calls</a></h2>
<p>In the definition of <code>BinTree.mirror</code>, there are two recursive calls:</p>
<pre><code class="language-lean">def BinTree.mirror : BinTree α → BinTree α
  | .leaf =&gt; .leaf
  | .branch l x r =&gt; .branch (mirror r) x (mirror l)
</code></pre>
<p>Just as imperative languages would typically use a while loop for functions like <code>reverse</code> and <code>sum</code>, they would typically use recursive functions for this kind of traversal.
This function cannot be straightforwardly rewritten to be tail recursive using accumulator-passing style.</p>
<p>Typically, if more than one recursive call is required for each recursive step, then it will be difficult to use accumulator-passing style.
This difficulty is similar to the difficulty of rewriting a recursive function to use a loop and an explicit data structure, with the added complication of convincing Lean that the function terminates.
However, as in <code>BinTree.mirror</code>, multiple recursive calls often indicate a data structure that has a constructor with multiple recursive occurrences of itself.
In these cases, the depth of the structure is often logarithmic with respect to its overall size, which makes the tradeoff between stack and heap less stark.
There are systematic techniques for making these functions tail-recursive, such as using <em>continuation-passing style</em>, but they are outside the scope of this chapter.</p>
<h2 id="exercises-23"><a class="header" href="#exercises-23">Exercises</a></h2>
<p>Translate each of the following non-tail-recursive functions into accumulator-passing tail-recursive functions:</p>
<pre><code class="language-lean">def NonTail.length : List α → Nat
  | [] =&gt; 0
  | _ :: xs =&gt; NonTail.length xs + 1 
</code></pre>
<pre><code class="language-lean">def NonTail.factorial : Nat → Nat
  | 0 =&gt; 1
  | n + 1 =&gt; factorial n * (n + 1)
</code></pre>
<p>The translation of <code>NonTail.filter</code> should result in a program that takes constant stack space through tail recursion, and time linear in the length of the input list.
A constant factor overhead is acceptable relative to the original:</p>
<pre><code class="language-lean">def NonTail.filter (p : α → Bool) : List α → List α
  | [] =&gt; []
  | x :: xs =&gt;
    if p x then
      x :: filter p xs
    else
      filter p xs
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="proving-equivalence"><a class="header" href="#proving-equivalence">Proving Equivalence</a></h1>
<p>Programs that have been rewritten to use tail recursion and an accumulator can look quite different from the original program.
The original recursive function is often much easier to understand, but it runs the risk of exhausting the stack at run time.
After testing both versions of the program on examples to rule out simple bugs, proofs can be used to show once and for all that the programs are equivalent.</p>
<h2 id="proving-sum-equal"><a class="header" href="#proving-sum-equal">Proving <code>sum</code> Equal</a></h2>
<p>To prove that both versions of <code>sum</code> are equal, begin by writing the theorem statement with a stub proof:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  skip
</code></pre>
<p>As expected, Lean describes an unsolved goal:</p>
<pre><code class="language-output error">unsolved goals
⊢ NonTail.sum = Tail.sum
</code></pre>
<p>The <code>rfl</code> tactic cannot be applied here, because <code>NonTail.sum</code> and <code>Tail.sum</code> are not definitionally equal.
Functions can be equal in more ways than just definitional equality, however.
It is also possible to prove that two functions are equal by proving that they produce equal outputs for the same input.
In other words, \( f = g \) can be proved by proving that \( f(x) = g(x) \) for all possible inputs \( x \).
This principle is called <em>function extensionality</em>.
Function extensionality is exactly the reason why <code>NonTail.sum</code> equals <code>Tail.sum</code>: they both sum lists of numbers.</p>
<p>In Lean's tactic language, function extensionality is invoked using <code>funext</code>, followed by a name to be used for the arbitrary argument.
The arbitrary argument is added as an assumption to the context, and the goal changes to require a proof that the functions applied to this argument are equal:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
</code></pre>
<pre><code class="language-output error">unsolved goals
case h
xs : List Nat
⊢ NonTail.sum xs = Tail.sum xs
</code></pre>
<p>This goal can be proved by induction on the argument <code>xs</code>.
Both <code>sum</code> functions return <code>0</code> when applied to the empty list, which serves as a base case.
Adding a number to the beginning of the input list causes both functions to add that number to the result, which serves as an induction step.
Invoking the <code>induction</code> tactic results in two goals:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
  induction xs with
  | nil =&gt; skip
  | cons y ys ih =&gt; skip
</code></pre>
<pre><code class="language-output error">unsolved goals
case h.nil
⊢ NonTail.sum [] = Tail.sum []
</code></pre>
<pre><code class="language-output error">unsolved goals
case h.cons
y : Nat
ys : List Nat
ih : NonTail.sum ys = Tail.sum ys
⊢ NonTail.sum (y :: ys) = Tail.sum (y :: ys)
</code></pre>
<p>The base case for <code>nil</code> can be solved using <code>rfl</code>, because both functions return <code>0</code> when passed the empty list:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
  induction xs with
  | nil =&gt; rfl
  | cons y ys ih =&gt; skip
</code></pre>
<p>The first step in solving the induction step is to simplify the goal, asking <code>simp</code> to unfold <code>NonTail.sum</code> and <code>Tail.sum</code>:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
  induction xs with
  | nil =&gt; rfl
  | cons y ys ih =&gt;
    simp [NonTail.sum, Tail.sum]
</code></pre>
<pre><code class="language-output error">unsolved goals
case h.cons
y : Nat
ys : List Nat
ih : NonTail.sum ys = Tail.sum ys
⊢ y + NonTail.sum ys = Tail.sumHelper 0 (y :: ys)
</code></pre>
<p>Unfolding <code>Tail.sum</code> revealed that it immediately delegates to <code>Tail.sumHelper</code>, which should also be simplified:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
  induction xs with
  | nil =&gt; rfl
  | cons y ys ih =&gt;
    simp [NonTail.sum, Tail.sum, Tail.sumHelper]
</code></pre>
<p>In the resulting goal, <code>sumHelper</code> has taken a step of computation and added <code>y</code> to the accumulator:</p>
<pre><code class="language-output error">unsolved goals
case h.cons
y : Nat
ys : List Nat
ih : NonTail.sum ys = Tail.sum ys
⊢ y + NonTail.sum ys = Tail.sumHelper y ys
</code></pre>
<p>Rewriting with the induction hypothesis removes all mentions of <code>NonTail.sum</code> from the goal:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
  induction xs with
  | nil =&gt; rfl
  | cons y ys ih =&gt;
    simp [NonTail.sum, Tail.sum, Tail.sumHelper]
    rw [ih]
</code></pre>
<pre><code class="language-output error">unsolved goals
case h.cons
y : Nat
ys : List Nat
ih : NonTail.sum ys = Tail.sum ys
⊢ y + Tail.sum ys = Tail.sumHelper y ys
</code></pre>
<p>This new goal states that adding some number to the sum of a list is the same as using that number as the initial accumulator in <code>sumHelper</code>.
For the sake of clarity, this new goal can be proved as a separate theorem:</p>
<pre><code class="language-leantac">theorem helper_add_sum_accum (xs : List Nat) (n : Nat) :
    n + Tail.sum xs = Tail.sumHelper n xs := by
  skip
</code></pre>
<pre><code class="language-output error">unsolved goals
xs : List Nat
n : Nat
⊢ n + Tail.sum xs = Tail.sumHelper n xs
</code></pre>
<p>Once again, this is a proof by induction where the base case uses <code>rfl</code>:</p>
<pre><code class="language-leantac">theorem helper_add_sum_accum (xs : List Nat) (n : Nat) :
    n + Tail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt; rfl
  | cons y ys ih =&gt; skip
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons
n y : Nat
ys : List Nat
ih : n + Tail.sum ys = Tail.sumHelper n ys
⊢ n + Tail.sum (y :: ys) = Tail.sumHelper n (y :: ys)
</code></pre>
<p>Because this is an inductive step, the goal should be simplified until it matches the induction hypothesis <code>ih</code>.
Simplifying, using the definitions of <code>Tail.sum</code> and <code>Tail.sumHelper</code>, results in the following:</p>
<pre><code class="language-leantac">theorem helper_add_sum_accum (xs : List Nat) (n : Nat) :
    n + Tail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt; rfl
  | cons y ys ih =&gt;
    simp [Tail.sum, Tail.sumHelper]
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons
n y : Nat
ys : List Nat
ih : n + Tail.sum ys = Tail.sumHelper n ys
⊢ n + Tail.sumHelper y ys = Tail.sumHelper (y + n) ys
</code></pre>
<p>Ideally, the induction hypothesis could be used to replace <code>Tail.sumHelper (y + n) ys</code>, but they don't match.
The induction hypothesis can be used for <code>Tail.sumHelper n ys</code>, not <code>Tail.sumHelper (y + n) ys</code>.
In other words, this proof is stuck.</p>
<h2 id="a-second-attempt"><a class="header" href="#a-second-attempt">A Second Attempt</a></h2>
<p>Rather than attempting to muddle through the proof, it's time to take a step back and think.
Why is it that the tail-recursive version of the function is equal to the non-tail-recursive version?
Fundamentally speaking, at each entry in the list, the accumulator grows by the same amount as would be added to the result of the recursion.
This insight can be used to write an elegant proof.
Crucially, the proof by induction must be set up such that the induction hypothesis can be applied to <em>any</em> accumulator value.</p>
<p>Discarding the prior attempt, the insight can be encoded as the following statement:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  skip
</code></pre>
<p>In this statement, it's very important that <code>n</code> is part of the type that's after the colon.
The resulting goal begins with <code>∀ (n : Nat)</code>, which is short for &quot;For all <code>n</code>&quot;:</p>
<pre><code class="language-output error">unsolved goals
xs : List Nat
⊢ ∀ (n : Nat), n + NonTail.sum xs = Tail.sumHelper n xs
</code></pre>
<p>Using the induction tactic results in goals that include this &quot;for all&quot; statement:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt; skip
  | cons y ys ih =&gt; skip
</code></pre>
<p>In the <code>nil</code> case, the goal is:</p>
<pre><code class="language-output error">unsolved goals
case nil
⊢ ∀ (n : Nat), n + NonTail.sum [] = Tail.sumHelper n []
</code></pre>
<p>For the induction step for <code>cons</code>, both the induction hypothesis and the specific goal contain the &quot;for all <code>n</code>&quot;:</p>
<pre><code class="language-output error">unsolved goals
case cons
y : Nat
ys : List Nat
ih : ∀ (n : Nat), n + NonTail.sum ys = Tail.sumHelper n ys
⊢ ∀ (n : Nat), n + NonTail.sum (y :: ys) = Tail.sumHelper n (y :: ys)
</code></pre>
<p>In other words, the goal has become more challenging to prove, but the induction hypothesis is correspondingly more useful.</p>
<p>A mathematical proof for a statement that beings with &quot;for all \( x \)&quot; should assume some arbitrary \( x \), and prove the statement.
&quot;Arbitrary&quot; means that no additional properties of \( x \) are assumed, so the resulting statement will work for <em>any</em> \( x \).
In Lean, a &quot;for all&quot; statement is a dependent function: no matter which specific value it is applied to, it will return evidence of the proposition.
Similarly, the process of picking an arbitrary \( x \) is the same as using <code>fun x =&gt; ...</code>.
In the tactic language, this process of selecting an arbitrary \( x \) is performed using the <code>intro</code> tactic, which produces the function behind the scenes when the tactic script has completed.
The <code>intro</code> tactic should be provided with the name to be used for this arbitrary value.</p>
<p>Using the <code>intro</code> tactic in the <code>nil</code> case removes the <code>∀ (n : Nat),</code> from the goal, and adds an assumption <code>n : Nat</code>:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt; intro n
  | cons y ys ih =&gt; skip
</code></pre>
<pre><code class="language-output error">unsolved goals
case nil
n : Nat
⊢ n + NonTail.sum [] = Tail.sumHelper n []
</code></pre>
<p>Both sides of this propositional equality are definitionally equal to <code>n</code>, so <code>rfl</code> suffices:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt;
    intro n
    rfl
  | cons y ys ih =&gt; skip
</code></pre>
<p>The <code>cons</code> goal also contains a &quot;for all&quot;:</p>
<pre><code class="language-output error">unsolved goals
case cons
y : Nat
ys : List Nat
ih : ∀ (n : Nat), n + NonTail.sum ys = Tail.sumHelper n ys
⊢ ∀ (n : Nat), n + NonTail.sum (y :: ys) = Tail.sumHelper n (y :: ys)
</code></pre>
<p>This suggests the use of <code>intro</code>.</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt;
    intro n
    rfl
  | cons y ys ih =&gt;
    intro n
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons
y : Nat
ys : List Nat
ih : ∀ (n : Nat), n + NonTail.sum ys = Tail.sumHelper n ys
n : Nat
⊢ n + NonTail.sum (y :: ys) = Tail.sumHelper n (y :: ys)
</code></pre>
<p>The proof goal now contains both <code>NonTail.sum</code> and <code>Tail.sumHelper</code> applied to <code>y :: ys</code>.
The simplifier can make the next step more clear:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt;
    intro n
    rfl
  | cons y ys ih =&gt;
    intro n
    simp [NonTail.sum, Tail.sumHelper]
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons
y : Nat
ys : List Nat
ih : ∀ (n : Nat), n + NonTail.sum ys = Tail.sumHelper n ys
n : Nat
⊢ n + (y + NonTail.sum ys) = Tail.sumHelper (y + n) ys
</code></pre>
<p>This goal is very close to matching the induction hypothesis.
There are two ways in which it does not match:</p>
<ul>
<li>The left-hand side of the equation is <code>n + (y + NonTail.sum ys)</code>, but the induction hypothesis needs the left-hand side to be a number added to <code>NonTail.sum ys</code>.
In other words, this goal should be rewritten to <code>(n + y) + NonTail.sum ys</code>, which is valid because addition of natural numbers is associative.</li>
<li>When the left side has been rewritten to <code>(y + n) + NonTail.sum ys</code>, the accumulator argument on the right side should be <code>n + y</code> rather than <code>y + n</code> in order to match.
This rewrite is valid because addition is also commutative.</li>
</ul>
<p>The associativity and commutativity of addition have already been proved in Lean's standard library.
The proof of associativity is named <code>Nat.add_assoc</code>, and its type is <code>(n m k : Nat) → (n + m) + k = n + (m + k)</code>, while the proof of commutativity is called <code>Nat.add_comm</code> and has type <code>(n m : Nat) → n + m = m + n</code>.
Normally, the <code>rw</code> tactic is provided with an expression whose type is an equality.
However, if the argument is instead a dependent function whose return type is an equality, it attempts to find arguments to the function that would allow the equality to match something in the goal.
There is only one opportunity to apply associativity, though the direction of the rewrite must be reversed because the right side of the equality in <code>Nat.add_assoc</code> is the one that matches the proof goal:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt;
    intro n
    rfl
  | cons y ys ih =&gt;
    intro n
    simp [NonTail.sum, Tail.sumHelper]
    rw [←Nat.add_assoc]
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons
y : Nat
ys : List Nat
ih : ∀ (n : Nat), n + NonTail.sum ys = Tail.sumHelper n ys
n : Nat
⊢ n + y + NonTail.sum ys = Tail.sumHelper (y + n) ys
</code></pre>
<p>Rewriting directly with <code>Nat.add_comm</code>, however, leads to the wrong result.
The <code>rw</code> tactic guesses the wrong location for the rewrite, leading to an unintended goal:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt;
    intro n
    rfl
  | cons y ys ih =&gt;
    intro n
    simp [NonTail.sum, Tail.sumHelper]
    rw [←Nat.add_assoc]
    rw [Nat.add_comm]
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons
y : Nat
ys : List Nat
ih : ∀ (n : Nat), n + NonTail.sum ys = Tail.sumHelper n ys
n : Nat
⊢ NonTail.sum ys + (n + y) = Tail.sumHelper (y + n) ys
</code></pre>
<p>This can be fixed by explicitly providing <code>y</code> and <code>n</code> as arguments to <code>Nat.add_comm</code>:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt;
    intro n
    rfl
  | cons y ys ih =&gt;
    intro n
    simp [NonTail.sum, Tail.sumHelper]
    rw [←Nat.add_assoc]
    rw [Nat.add_comm y n]
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons
y : Nat
ys : List Nat
ih : ∀ (n : Nat), n + NonTail.sum ys = Tail.sumHelper n ys
n : Nat
⊢ n + y + NonTail.sum ys = Tail.sumHelper (n + y) ys
</code></pre>
<p>The goal now matches the induction hypothesis.
In particular, the induction hypothesis's type is a dependent function type.
Applying <code>ih</code> to <code>n + y</code> results in exactly the desired type.
The <code>exact</code> tactic completes a proof goal if its argument has exactly the desired type:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_helper_accum (xs : List Nat) :
    (n : Nat) → n + NonTail.sum xs = Tail.sumHelper n xs := by
  induction xs with
  | nil =&gt; intro n; rfl
  | cons y ys ih =&gt;
    intro n
    simp [NonTail.sum, Tail.sumHelper]
    rw [←Nat.add_assoc]
    rw [Nat.add_comm y n]
    exact ih (n + y)
</code></pre>
<p>The actual proof requires only a little additional work to get the goal to match the helper's type.
The first step is still to invoke function extensionality:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
</code></pre>
<pre><code class="language-output error">unsolved goals
case h
xs : List Nat
⊢ NonTail.sum xs = Tail.sum xs
</code></pre>
<p>The next step is unfold <code>Tail.sum</code>, exposing <code>Tail.sumHelper</code>:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
  simp [Tail.sum]
</code></pre>
<pre><code class="language-output error">unsolved goals
case h
xs : List Nat
⊢ NonTail.sum xs = Tail.sumHelper 0 xs
</code></pre>
<p>Having done this, the types almost match.
However, the helper has an additional addend on the left side.
In other words, the proof goal is <code>NonTail.sum xs = Tail.sumHelper 0 xs</code>, but applying <code>non_tail_sum_eq_helper_accum</code> to <code>xs</code> and <code>0</code> yields the type <code>0 + NonTail.sum xs = Tail.sumHelper 0 xs</code>.
Another standard library proof, <code>Nat.zero_add</code>, has type <code>(n : Nat) → 0 + n = n</code>.
Applying this function to <code>NonTail.sum xs</code> results in an expression with type <code>0 + NonTail.sum xs = NonTail.sum xs</code>, so rewriting from right to left results in the desired goal:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
  simp [Tail.sum]
  rw [←Nat.zero_add (NonTail.sum xs)]
</code></pre>
<pre><code class="language-output error">unsolved goals
case h
xs : List Nat
⊢ 0 + NonTail.sum xs = Tail.sumHelper 0 xs
</code></pre>
<p>Finally, the helper can be used to complete the proof:</p>
<pre><code class="language-leantac">theorem non_tail_sum_eq_tail_sum : NonTail.sum = Tail.sum := by
  funext xs
  simp [Tail.sum]
  rw [←Nat.zero_add (NonTail.sum xs)]
  exact non_tail_sum_eq_helper_accum xs 0
</code></pre>
<p>This proof demonstrates a general pattern that can be used when proving that an accumulator-passing tail-recursive function is equal to the non-tail-recursive version.
The first step is to discover the relationship between the starting accumulator argument and the final result.
For instance, beginning <code>Tail.sumHelper</code> with an accumulator of <code>n</code> results in the final sum being added to <code>n</code>, and beginning <code>Tail.reverseHelper</code> with an accumulator of <code>ys</code> results in the final reversed list being prepended to <code>ys</code>.
The second step is to write down this relationship as a theorem statement and prove it by induction.
While the accumulator is always initialized with some neutral value in practice, such as <code>0</code> or <code>[]</code>, this more general statement that allows the starting accumulator to be any value is what's needed to get a strong enough induction hypothesis.
Finally, using this helper theorem with the actual initial accumulator value results in the desired proof.
For example, in <code>non_tail_sum_eq_tail_sum</code>, the accumulator is specified to be <code>0</code>.
This may require rewriting the goal to make the neutral initial accumulator values occur in the right place.</p>
<h2 id="exercise-2"><a class="header" href="#exercise-2">Exercise</a></h2>
<h3 id="warming-up"><a class="header" href="#warming-up">Warming Up</a></h3>
<p>Write your own proofs for <code>Nat.zero_add</code>, <code>Nat.add_assoc</code>, and <code>Nat.add_comm</code> using the <code>induction</code> tactic.</p>
<h3 id="more-accumulator-proofs"><a class="header" href="#more-accumulator-proofs">More Accumulator Proofs</a></h3>
<h4 id="reversing-lists-1"><a class="header" href="#reversing-lists-1">Reversing Lists</a></h4>
<p>Adapt the proof for <code>sum</code> into a proof for <code>NonTail.reverse</code> and <code>Tail.reverse</code>.
The first step is to think about the relationship between the accumulator value being passed to <code>Tail.reverseHelper</code> and the non-tail-recursive reverse.
Just as adding a number to the accumulator in <code>Tail.sumHelper</code> is the same as adding it to the overall sum, using <code>List.cons</code> to add a new entry to the accumulator in <code>Tail.reverseHelper</code> is equivalent to some change to the overall result.
Try three or four different accumulator values with pencil and paper until the relationship becomes clear.
Use this relationship to prove a suitable helper theorem.
Then, write down the overall theorem.
Because <code>NonTail.reverse</code> and <code>Tail.reverse</code> are polymorphic, stating their equality requires the use of <code>@</code> to stop Lean from trying to figure out which type to use for <code>α</code>.
Once <code>α</code> is treated as an ordinary argument, <code>funext</code> should be invoked with both <code>α</code> and <code>xs</code>:</p>
<pre><code class="language-leantac">theorem non_tail_reverse_eq_tail_reverse : @NonTail.reverse = @Tail.reverse := by
  funext α xs
</code></pre>
<p>This results in a suitable goal:</p>
<pre><code class="language-output error">unsolved goals
case h.h
α : Type u_1
xs : List α
⊢ NonTail.reverse xs = Tail.reverse xs
</code></pre>
<h4 id="factorial"><a class="header" href="#factorial">Factorial</a></h4>
<p>Prove that <code>NonTail.factorial</code> from the exercises in the previous section is equal to your tail-recursive solution by finding the relationship between the accumulator and the result and proving a suitable helper theorem.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="arrays-and-termination"><a class="header" href="#arrays-and-termination">Arrays and Termination</a></h1>
<p>To write efficient code, it is important to select appropriate data structures.
Linked lists have their place: in some applications, the ability to share the tails of lists is very important.
However, most use cases for a variable-length sequential collection of data are better served by arrays, which have both less memory overhead and better locality.</p>
<p>Arrays, however, have two drawbacks relative to lists:</p>
<ol>
<li>Arrays are accessed through indexing, rather than by pattern matching, which imposes <a href="programs-proofs/../props-proofs-indexing.html">proof obligations</a> in order to maintain safety.</li>
<li>A loop that processes an entire array from left to right is a tail-recursive function, but it does not have an argument that decreases on each call.</li>
</ol>
<p>Making effective use of arrays requires knowing how to prove to Lean that an array index is in bounds, and how to prove that an array index that approaches the size of the array also causes the program to terminate.
Both of these are expressed using an inequality proposition, rather than propositional equality.</p>
<h2 id="inequality"><a class="header" href="#inequality">Inequality</a></h2>
<p>Because different types have different notions of ordering, inequality is governed by two type classes, called <code>LE</code> and <code>LT</code>.
The table in the section on <a href="programs-proofs/../type-classes/standard-classes.html#equality-and-ordering">standard type classes</a> describes how these classes relate to the syntax:</p>
<table><thead><tr><th>Expression</th><th>Desugaring</th><th>Class Name</th></tr></thead><tbody>
<tr><td><code>x &lt; y</code></td><td><code>LT.lt x y</code></td><td><code>LT</code></td></tr>
<tr><td><code>x ≤ y</code></td><td><code>LE.le x y</code></td><td><code>LE</code></td></tr>
<tr><td><code>x &gt; y</code></td><td><code>LT.lt y x</code></td><td><code>LT</code></td></tr>
<tr><td><code>x ≥ y</code></td><td><code>LE.le y x</code></td><td><code>LE</code></td></tr>
</tbody></table>
<p>In other words, a type may customize the meaning of the <code>&lt;</code> and <code>≤</code> operators, while <code>&gt;</code> and <code>≥</code> derive their meanings from <code>&lt;</code> and <code>≤</code>.
The classes <code>LT</code> and <code>LE</code> have methods that return propositions rather than <code>Bool</code>s:</p>
<pre><code class="language-lean">class LE (α : Type u) where
  le : α → α → Prop

class LT (α : Type u) where
  lt : α → α → Prop
</code></pre>
<p>The instance of <code>LE</code> for <code>Nat</code> delegates to <code>Nat.le</code>:</p>
<pre><code class="language-lean">instance : LE Nat where
  le := Nat.le
</code></pre>
<p>Defining <code>Nat.le</code> requires a feature of Lean that has not yet been presented: it is an inductively-defined relation.</p>
<h3 id="inductively-defined-propositions-predicates-and-relations"><a class="header" href="#inductively-defined-propositions-predicates-and-relations">Inductively-Defined Propositions, Predicates, and Relations</a></h3>
<p><code>Nat.le</code> is an <em>inductively-defined relation</em>.
Just as <code>inductive</code> can be used to create new datatypes, it can also be used to create new propositions.
When a proposition takes an argument, it is referred to as a <em>predicate</em> that may be true for some, but not all, potential arguments.
Propositions that take multiple arguments are called <em>relations</em>.</p>
<p>Each constructor of an inductively defined proposition is a way to prove it.
In other words, the declaration of the proposition describes the different forms of evidence that it is true.
A proposition with no arguments that has a single constructor can be quite easy to prove:</p>
<pre><code class="language-lean">inductive EasyToProve : Prop where
  | heresTheProof : EasyToProve
</code></pre>
<p>The proof consists of using its constructor:</p>
<pre><code class="language-lean">theorem fairlyEasy : EasyToProve := by
  constructor
</code></pre>
<p>In fact, the proposition <code>True</code>, which should always be easy to prove, is defined just like <code>EasyToProve</code>:</p>
<pre><code class="language-lean">inductive True : Prop where
  | intro : True
</code></pre>
<p>Inductively-defined propositions that don't take arguments are not nearly as interesting as inductively-defined datatypes.
This is because data is interesting in its own right—the natural number <code>3</code> is different from the number <code>35</code>, and someone who has ordered 3 pizzas will be upset if 35 arrive at their door 30 minutes later.
The constructors of a proposition describe ways in which the proposition can be true, but once a proposition has been proved, there is no need to know <em>which</em> underlying constructors were used.
This is why most interesting inductively-defined types in the <code>Prop</code> universe take arguments.</p>
<p>The inductively-defined predicate <code>IsThree</code> states that its argument is three:</p>
<pre><code class="language-lean">inductive IsThree : Nat → Prop where
  | isThree : IsThree 3
</code></pre>
<p>The mechanism used here is just like <a href="programs-proofs/../dependent-types/typed-queries.html#column-pointers">indexed families such as <code>HasCol</code></a>, except the resulting type is a proposition that can be proved rather than data that can be used.</p>
<p>Using this predicate, it is possible to prove that three is indeed three:</p>
<pre><code class="language-lean">theorem three_is_three : IsThree 3 := by
  constructor
</code></pre>
<p>Similarly, <code>IsFive</code> is a predicate that states that its argument is <code>5</code>:</p>
<pre><code class="language-lean">inductive IsFive : Nat → Prop where
  | isFive : IsFive 5
</code></pre>
<p>If a number is three, then the result of adding two to it should be five.
This can be expressed as a theorem statement:</p>
<pre><code class="language-leantac">theorem three_plus_two_five : IsThree n → IsFive (n + 2) := by
  skip
</code></pre>
<p>The resulting goal has a function type:</p>
<pre><code class="language-output error">unsolved goals
n : Nat
⊢ IsThree n → IsFive (n + 2)
</code></pre>
<p>Thus, the <code>intro</code> tactic can be used to convert the argument into an assumption:</p>
<pre><code class="language-leantac">theorem three_plus_two_five : IsThree n → IsFive (n + 2) := by
  intro three
</code></pre>
<pre><code class="language-output error">unsolved goals
n : Nat
three : IsThree n
⊢ IsFive (n + 2)
</code></pre>
<p>Given the assumption that <code>n</code> is three, it should be possible to use the constructor of <code>IsFive</code> to complete the proof:</p>
<pre><code class="language-leantac">theorem three_plus_two_five : IsThree n → IsFive (n + 2) := by
  intro three
  constructor
</code></pre>
<p>However, this results in an error:</p>
<pre><code class="language-output error">tactic 'constructor' failed, no applicable constructor found
n : Nat
three : IsThree n
⊢ IsFive (n + 2)
</code></pre>
<p>This error occurs because <code>n + 2</code> is not definitionally equal to <code>5</code>.
In an ordinary function definition, dependent pattern matching on the assumption <code>three</code> could be used to refine <code>n</code> to <code>3</code>.
The tactic equivalent of dependent pattern matching is <code>cases</code>, which has a syntax similar to that of <code>induction</code>:</p>
<pre><code class="language-leantac">theorem three_plus_two_five : IsThree n → IsFive (n + 2) := by
  intro three
  cases three with
  | isThree =&gt; skip
</code></pre>
<p>In the remaining case, <code>n</code> has been refined to <code>3</code>:</p>
<pre><code class="language-output error">unsolved goals
case isThree
⊢ IsFive (3 + 2)
</code></pre>
<p>Because <code>3 + 2</code> is definitionally equal to <code>5</code>, the constructor is now applicable:</p>
<pre><code class="language-leantac">theorem three_plus_two_five : IsThree n → IsFive (n + 2) := by
  intro three
  cases three with
  | isThree =&gt; constructor
</code></pre>
<p>The standard false proposition <code>False</code> has no constructors, making it impossible to provide direct evidence for.
The only way to provide evidence for <code>False</code> is if an assumption is itself impossible, similarly to how <code>nomatch</code> can be used to mark code that the type system can see is unreachable.
As described in <a href="programs-proofs/../props-proofs-indexing.html#connectives">the initial Interlude on proofs</a>, the negation <code>Not A</code> is short for <code>A → False</code>.
<code>Not A</code> can also be written <code>¬A</code>.</p>
<p>It is not the case that four is three:</p>
<pre><code class="language-leantac">theorem four_is_not_three : ¬ IsThree 4 := by
  skip
</code></pre>
<p>The initial proof goal contains <code>Not</code>:</p>
<pre><code class="language-output error">unsolved goals
⊢ ¬IsThree 4
</code></pre>
<p>The fact that it's actually a function type can be exposed using <code>simp</code>:</p>
<pre><code class="language-leantac">theorem four_is_not_three : ¬ IsThree 4 := by
  simp [Not]
</code></pre>
<pre><code class="language-output error">unsolved goals
⊢ IsThree 4 → False
</code></pre>
<p>Because the goal is a function type, <code>intro</code> can be used to convert the argument into an assumption.
There is no need to keep <code>simp</code>, as <code>intro</code> can unfold the definition of <code>Not</code> itself:</p>
<pre><code class="language-leantac">theorem four_is_not_three : ¬ IsThree 4 := by
  intro h
</code></pre>
<pre><code class="language-output error">unsolved goals
h : IsThree 4
⊢ False
</code></pre>
<p>In this proof, the <code>cases</code> tactic solves the goal immediately:</p>
<pre><code class="language-leantac">theorem four_is_not_three : ¬ IsThree 4 := by
  intro h
  cases h
</code></pre>
<p>Just as a pattern match on a <code>Vect String 2</code> doesn't need to include a case for <code>Vect.nil</code>, a proof by cases over <code>IsThree 4</code> doesn't need to include a case for <code>isThree</code>.</p>
<h3 id="inequality-of-natural-numbers"><a class="header" href="#inequality-of-natural-numbers">Inequality of Natural Numbers</a></h3>
<p>The definition of <code>Nat.le</code> has a parameter and an index:</p>
<pre><code class="language-lean">inductive Nat.le (n : Nat) : Nat → Prop
  | refl : Nat.le n n
  | step : Nat.le n m → Nat.le n (m + 1)
</code></pre>
<p>The parameter <code>n</code> is the number that should be smaller, while the index is the number that should be greater than or equal to <code>n</code>.
The <code>refl</code> constructor is used when both numbers are equal, while the <code>step</code> constructor is used when the index is greater than <code>n</code>.</p>
<p>From the perspective of evidence, a proof that \( n \leq k \) consists of finding some number \( d \) such that \( n + d = m \).
In Lean, the proof then consists of a <code>Nat.le.refl</code> constructor wrapped by \( d \) instances of <code>Nat.le.step</code>.
Each <code>step</code> constructor adds one to its index argument, so \( d \) <code>step</code> constructors adds \( d \) to the larger number.
For example, evidence that four is less than or equal to seven consists of three <code>step</code>s around a <code>refl</code>:</p>
<pre><code class="language-lean">theorem four_le_seven : 4 ≤ 7 :=
  open Nat.le in
  step (step (step refl))
</code></pre>
<p>The strict less-than relation is defined by adding one to the number on the left:</p>
<pre><code class="language-lean">def Nat.lt (n m : Nat) : Prop :=
  Nat.le (n + 1) m

instance : LT Nat where
  lt := Nat.lt
</code></pre>
<p>Evidence that four is strictly less than seven consists of two <code>step</code>'s around a <code>refl</code>:</p>
<pre><code class="language-lean">theorem four_lt_seven : 4 &lt; 7 :=
  open Nat.le in
  step (step refl)
</code></pre>
<p>This is because <code>4 &lt; 7</code> is equivalent to <code>5 ≤ 7</code>.</p>
<h2 id="proving-termination"><a class="header" href="#proving-termination">Proving Termination</a></h2>
<p>The function <code>Array.map</code> transforms an array with a function, returning a new array that contains the result of applying the function to each element of the input array.
Writing it as a tail-recursive function follows the usual pattern of delegating to a function that passes the output array in an accumulator.
The accumulator is initialized with an empty array.
The accumulator-passing helper function also takes an argument that tracks the current index into the array, which starts at <code>0</code>:</p>
<pre><code class="language-lean">def Array.map (f : α → β) (arr : Array α) : Array β :=
  arrayMapHelper f arr Array.empty 0
</code></pre>
<p>The helper should, at each iteration, check whether the index is still in bounds.
If so, it should loop again with the transformed element added to the end of the accumulator and the index incremented by <code>1</code>.
If not, then it should terminate and return the accumulator.
An initial implementation of this code fails because Lean is unable to prove that the array index is valid:</p>
<pre><code class="language-lean">def arrayMapHelper (f : α → β) (arr : Array α) (soFar : Array β) (i : Nat) : Array β :=
  if i &lt; arr.size then
    arrayMapHelper f arr (soFar.push (f arr[i])) (i + 1)
  else soFar
</code></pre>
<pre><code class="language-output error">failed to prove index is valid, possible solutions:
  - Use `have`-expressions to prove the index is valid
  - Use `a[i]!` notation instead, runtime check is perfomed, and 'Panic' error message is produced if index is not valid
  - Use `a[i]?` notation instead, result is an `Option` type
  - Use `a[i]'h` notation instead, where `h` is a proof that index is valid
α : Type ?u.1742
β : Type ?u.1745
f : α → β
arr : Array α
soFar : Array β
i : Nat
⊢ i &lt; Array.size arr
</code></pre>
<p>However, the conditional expression already checks the precise condition that the array index's validity demands (namely, <code>i &lt; arr.size</code>).
Adding a name to the <code>if</code> resolves the issue, because it adds an assumption that the array indexing tactic can use:</p>
<pre><code class="language-lean">def arrayMapHelper (f : α → β) (arr : Array α) (soFar : Array β) (i : Nat) : Array β :=
  if inBounds : i &lt; arr.size then
    arrayMapHelper f arr (soFar.push (f arr[i])) (i + 1)
  else soFar
</code></pre>
<p>Lean does not, however, accept the modified program, because the recursive call is not made on an argument to one of the input constructors.
In fact, both the accumulator and the index grow, rather than shrinking:</p>
<pre><code class="language-output error">fail to show termination for
  arrayMapHelper
with errors
argument #6 was not used for structural recursion
  failed to eliminate recursive application
    arrayMapHelper f✝ arr (Array.push soFar (f✝ arr[i])) (i + 1)

structural recursion cannot be used

failed to prove termination, use `termination_by` to specify a well-founded relation
</code></pre>
<p>Nevertheless, this function terminates, so simply marking it <code>partial</code> would be unfortunate.</p>
<p>Why does <code>arrayMapHelper</code> terminate?
Each iteration checks whether the index <code>i</code> is still in bounds for the array <code>arr</code>.
If so, <code>i</code> is incremented and the loop repeats.
If not, the program terminates.
Because <code>arr.size</code> is a finite number, <code>i</code> can be incremented only a finite number of times.
Even though no argument to the function decreases on each call, <code>arr.size - i</code> decreases toward zero.</p>
<p>Lean can be instructed to use another expression for termination by providing a <code>termination_by</code> clause at the end of a definition.
The <code>termination_by</code> clause has two components: names for the function's arguments and an expression using those names that should decrease on each call.
For <code>arrayMapHelper</code>, the final definition looks like this:</p>
<pre><code class="language-lean">def arrayMapHelper (f : α → β) (arr : Array α) (soFar : Array β) (i : Nat) : Array β :=
  if inBounds : i &lt; arr.size then
    arrayMapHelper f arr (soFar.push (f arr[i])) (i + 1)
  else soFar
termination_by arrayMapHelper _ arr _ i _ =&gt; arr.size - i
</code></pre>
<p>A similar termination proof can be used to write <code>Array.find</code>, a function that finds the first element in an array that satisfies a Boolean function and returns both the element and its index:</p>
<pre><code class="language-lean">def Array.find (arr : Array α) (p : α → Bool) : Option (Nat × α) :=
  findHelper arr p 0
</code></pre>
<p>Once again, the helper function terminates because <code>arr.size - i</code> decreases as <code>i</code> increases:</p>
<pre><code class="language-lean">def findHelper (arr : Array α) (p : α → Bool) (i : Nat) : Option (Nat × α) :=
  if h : i &lt; arr.size then
    let x := arr[i]
    if p x then
      some (i, x)
    else findHelper arr p (i + 1)
  else none
termination_by findHelper arr p i =&gt; arr.size - i
</code></pre>
<p>Not all termination arguments are as quite as simple as this one.
However, the basic structure of identifying some expression based on the function's arguments that will decrease in each call occurs in all termination proofs.
Sometimes, creativity can be required in order to figure out just why a function terminates, and sometimes Lean requires additional proofs in order to accept the termination argument.</p>
<h2 id="exercises-24"><a class="header" href="#exercises-24">Exercises</a></h2>
<ul>
<li>Implement a <code>ForM (Array α)</code> instance on arrays using a tail-recursive accumulator-passing function and a <code>termination_by</code> clause.</li>
<li>Implement a function to reverse arrays using a tail-recursive accumulator-passing function that <em>doesn't</em> need a <code>termination_by</code> clause.</li>
<li>Reimplement <code>Array.map</code>, <code>Array.find</code>, and the <code>ForM</code> instance using <code>for ... in ...</code> loops in the identity monad and compare the resulting code.</li>
<li>Reimplement array reversal using a <code>for ... in ...</code> loop in the identity monad. Compare it to the tail-recursive function.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="more-inequalities"><a class="header" href="#more-inequalities">More Inequalities</a></h1>
<p>Lean's built-in proof automation is sufficient to check that <code>arrayMapHelper</code> and <code>findHelper</code> terminate.
All that was needed was to provide an expression whose value decreases with each recursive call.
However, Lean's built-in automation is not magic, and it often needs some help.</p>
<h2 id="merge-sort"><a class="header" href="#merge-sort">Merge Sort</a></h2>
<p>One example of a function whose termination proof is non-trivial is merge sort on <code>List</code>.
Merge sort consists of two phases: first, a list is split in half.
Each half is sorted using merge sort, and then the results are merged using a function that combines two sorted lists into a larger sorted list.
The base cases are the empty list and the singleton list, both of which are already considered to be sorted.</p>
<p>To merge two sorted lists, there are two basic cases to consider:</p>
<ol>
<li>If one of the input lists is empty, then the result is the other list.</li>
<li>If both lists are non-empty, then their heads should be compared. The result of the function is the smaller of the two heads, followed by the result of merging the remaining entries of both lists.</li>
</ol>
<p>This is not structurally recursive on either list.
The recursion terminates because an entry is removed from one of the two lists in each recursive call, but it could be either list.
The <code>termination_by</code> clause uses the sum of the length of both lists as a decreasing value:</p>
<pre><code class="language-lean">def merge [Ord α] (xs : List α) (ys : List α) : List α :=
  match xs, ys with
  | [], _ =&gt; ys
  | _, [] =&gt; xs
  | x'::xs', y'::ys' =&gt;
    match Ord.compare x' y' with
    | .lt | .eq =&gt; x' :: merge xs' (y' :: ys')
    | .gt =&gt; y' :: merge (x'::xs') ys'
termination_by merge xs ys =&gt; xs.length + ys.length
</code></pre>
<p>In addition to using the lengths of the lists, a pair that contains both lists can also be provided:</p>
<pre><code class="language-lean">def merge [Ord α] (xs : List α) (ys : List α) : List α :=
  match xs, ys with
  | [], _ =&gt; ys
  | _, [] =&gt; xs
  | x'::xs', y'::ys' =&gt;
    match Ord.compare x' y' with
    | .lt | .eq =&gt; x' :: merge xs' (y' :: ys')
    | .gt =&gt; y' :: merge (x'::xs') ys'
termination_by merge xs ys =&gt; (xs, ys)
</code></pre>
<p>This works because Lean has a built-in notion of sizes of data, expressed through a type class called <code>WellFoundedRelation</code>.
The instance for pairs automatically considers them to be smaller if either the first or the second item in the pair shrinks.</p>
<p>A simple way to split a list is to add each entry in the input list to two alternating output lists:</p>
<pre><code class="language-lean">def splitList (lst : List α) : (List α × List α) :=
  match lst with
  | [] =&gt; ([], [])
  | x :: xs =&gt;
    let (a, b) := splitList xs
    (x :: b, a)
</code></pre>
<p>Merge sort checks whether a base case has been reached.
If so, it returns the input list.
If not, it splits the input, and merges the result of sorting each half:</p>
<pre><code class="language-lean">def mergeSort [Ord α] (xs : List α) : List α :=
  if h : xs.length &lt; 2 then
    match xs with
    | [] =&gt; []
    | [x] =&gt; [x]
  else
    let halves := splitList xs
    merge (mergeSort halves.fst) (mergeSort halves.snd)
</code></pre>
<p>Lean's pattern match compiler is able to tell that the assumption <code>h</code> introduced by the <code>if</code> that tests whether <code>xs.length &lt; 2</code> rules out lists longer than one entry, so there is no &quot;missing cases&quot; error.
However, even though this program always terminates, it is not structurally recursive:</p>
<pre><code class="language-output error">fail to show termination for
  mergeSort
with errors
argument #3 was not used for structural recursion
  failed to eliminate recursive application
    mergeSort halves.fst

structural recursion cannot be used

failed to prove termination, use `termination_by` to specify a well-founded relation
</code></pre>
<p>The reason it terminates is that <code>splitList</code> always returns lists that are shorter than its input.
Thus, the length of <code>halves.fst</code> and <code>halves.snd</code> are less than the length of <code>xs</code>.
This can be expressed using a <code>termination_by</code> clause:</p>
<pre><code class="language-lean">def mergeSort [Ord α] (xs : List α) : List α :=
  if h : xs.length &lt; 2 then
    match xs with
    | [] =&gt; []
    | [x] =&gt; [x]
  else
    let halves := splitList xs
    merge (mergeSort halves.fst) (mergeSort halves.snd)
termination_by mergeSort xs =&gt; xs.length
</code></pre>
<p>With this clause, the error message changes.
Instead of complaining that the function isn't structurally recursive, Lean instead points out that it was unable to automatically prove that <code>(splitList xs).fst.length &lt; xs.length</code>:</p>
<pre><code class="language-output error">failed to prove termination, possible solutions:
  - Use `have`-expressions to prove the remaining goals
  - Use `termination_by` to specify a different well-founded relation
  - Use `decreasing_by` to specify your own tactic for discharging this kind of goal
α : Type u_1
xs : List α
h : ¬List.length xs &lt; 2
halves : List α × List α := splitList xs
⊢ List.length (splitList xs).fst &lt; List.length xs
</code></pre>
<h2 id="splitting-a-list-makes-it-shorter"><a class="header" href="#splitting-a-list-makes-it-shorter">Splitting a List Makes it Shorter</a></h2>
<p>It will also be necessary to prove that <code>(splitList xs).snd.length &lt; xs.length</code>.
Because <code>splitList</code> alternates between adding entries to the two lists, it is easiest to prove both statements at once, so the structure of the proof can follow the algorithm used to implement <code>splitList</code>.
In other words, it is easiest to prove that <code>∀(lst : List), (splitList lst).fst.length &lt; lst.length ∧ (splitList lst).snd.length &lt; lst.length</code>.</p>
<p>Unfortunately, the statement is false.
In particular, <code>splitList []</code> is <code>([], [])</code>. Both output lists have length <code>0</code>, which is not less than <code>0</code>, the length of the input list.
Similarly, <code>splitList [&quot;basalt&quot;]</code> evaluates to <code>([&quot;basalt&quot;], [])</code>, and <code>[&quot;basalt&quot;]</code> is not shorter than <code>[&quot;basalt&quot;]</code>.
However, <code>splitList [&quot;basalt&quot;, &quot;granite&quot;]</code> evaluates to <code>([&quot;basalt&quot;], [&quot;granite&quot;])</code>, and both of these output lists are shorter than the input list.</p>
<p>It turns out that the lengths of the output lists are always less than or equal to the length of the input list, but they are only strictly shorter when the input list contains at least two entries.
It turns out to be easiest to prove the former statement, then extend it to the latter statement.
Begin with a theorem statement:</p>
<pre><code class="language-leantac">theorem splitList_shorter_le (lst : List α) :
    (splitList lst).fst.length ≤ lst.length ∧
      (splitList lst).snd.length ≤ lst.length := by
  skip
</code></pre>
<pre><code class="language-output error">unsolved goals
α : Type u_1
lst : List α
⊢ List.length (splitList lst).fst ≤ List.length lst ∧ List.length (splitList lst).snd ≤ List.length lst
</code></pre>
<p>Because <code>splitList</code> is structurally recursive on the list, the proof should use induction.
The structural recursion in <code>splitList</code> fits a proof by induction perfectly: the base case of the induction matches the base case of the recursion, and the inductive step matches the recursive call.
The <code>induction</code> tactic gives two goals:</p>
<pre><code class="language-leantac">theorem splitList_shorter_le (lst : List α) :
    (splitList lst).fst.length ≤ lst.length ∧
      (splitList lst).snd.length ≤ lst.length := by
  induction lst with
  | nil =&gt; skip
  | cons x xs ih =&gt; skip
</code></pre>
<pre><code class="language-output error">unsolved goals
case nil
α : Type u_1
⊢ List.length (splitList []).fst ≤ List.length [] ∧ List.length (splitList []).snd ≤ List.length []
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons
α : Type u_1
x : α
xs : List α
ih : List.length (splitList xs).fst ≤ List.length xs ∧ List.length (splitList xs).snd ≤ List.length xs
⊢ List.length (splitList (x :: xs)).fst ≤ List.length (x :: xs) ∧
    List.length (splitList (x :: xs)).snd ≤ List.length (x :: xs)
</code></pre>
<p>The goal for the <code>nil</code> case can be proved by invoking the simplifier and instructing it to unfold the definition of <code>splitList</code>, because the length of the empty list is less than or equal to the length of the empty list.
Similarly, simplifying with <code>splitList</code> in the <code>cons</code> case places <code>Nat.succ</code> around the lengths in the goal:</p>
<pre><code class="language-leantac">theorem splitList_shorter_le (lst : List α) :
    (splitList lst).fst.length ≤ lst.length ∧
      (splitList lst).snd.length ≤ lst.length := by
  induction lst with
  | nil =&gt; simp [splitList]
  | cons x xs ih =&gt;
    simp [splitList]
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons
α : Type u_1
x : α
xs : List α
ih : List.length (splitList xs).fst ≤ List.length xs ∧ List.length (splitList xs).snd ≤ List.length xs
⊢ Nat.succ (List.length (splitList xs).snd) ≤ Nat.succ (List.length xs) ∧
    List.length (splitList xs).fst ≤ Nat.succ (List.length xs)
</code></pre>
<p>This is because the call to <code>List.length</code> consumes the head of the list <code>x :: xs</code>, converting it to a <code>Nat.succ</code>, in both the length of the input list and the length of the first output list.</p>
<p>Writing <code>A ∧ B</code> in Lean is short for <code>And A B</code>.
<code>And</code> is a structure type in the <code>Prop</code> universe:</p>
<pre><code class="language-lean">structure And (a b : Prop) : Prop where
  intro ::
  left : a
  right : b
</code></pre>
<p>In other words, a proof of <code>A ∧ B</code> consists of the <code>And.intro</code> constructor applied to a proof of <code>A</code> in the <code>left</code> field and a proof of <code>B</code> in the <code>right</code> field.</p>
<p>The <code>cases</code> tactic allows a proof to consider each constructor of a datatype or each potential proof of a proposition in turn.
It corresponds to a <code>match</code> expression without recursion.
Using <code>cases</code> on a structure results in the structure being broken apart, with an assumption added for each field of the structure, just as a pattern match expression extracts the field of a structure for use in a program.
Because structures have only one constructor, using <code>cases</code> on a structure does not result in additional goals.</p>
<p>Because <code>ih</code> is a proof of <code>List.length (splitList xs).fst ≤ List.length xs ∧ List.length (splitList xs).snd ≤ List.length xs</code>, using <code>cases ih</code> results in an assumption that <code>List.length (splitList xs).fst ≤ List.length xs</code> and an assumption that <code>List.length (splitList xs).snd ≤ List.length xs</code>:</p>
<pre><code class="language-leantac">theorem splitList_shorter_le (lst : List α) :
    (splitList lst).fst.length ≤ lst.length ∧
      (splitList lst).snd.length ≤ lst.length := by
  induction lst with
  | nil =&gt; simp [splitList]
  | cons x xs ih =&gt;
    simp [splitList]
    cases ih
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons.intro
α : Type u_1
x : α
xs : List α
left✝ : List.length (splitList xs).fst ≤ List.length xs
right✝ : List.length (splitList xs).snd ≤ List.length xs
⊢ Nat.succ (List.length (splitList xs).snd) ≤ Nat.succ (List.length xs) ∧
    List.length (splitList xs).fst ≤ Nat.succ (List.length xs)
</code></pre>
<p>Because the goal of the proof is also an <code>And</code>, the <code>constructor</code> tactic can be used to apply <code>And.intro</code>, resulting in a goal for each argument:</p>
<pre><code class="language-leantac">theorem splitList_shorter_le (lst : List α) :
    (splitList lst).fst.length ≤ lst.length ∧
      (splitList lst).snd.length ≤ lst.length := by
  induction lst with
  | nil =&gt; simp [splitList]
  | cons x xs ih =&gt;
    simp [splitList]
    cases ih
    constructor
</code></pre>
<pre><code class="language-output error">unsolved goals
case cons.intro.left
α : Type u_1
x : α
xs : List α
left✝ : List.length (splitList xs).fst ≤ List.length xs
right✝ : List.length (splitList xs).snd ≤ List.length xs
⊢ Nat.succ (List.length (splitList xs).snd) ≤ Nat.succ (List.length xs)

case cons.intro.right
α : Type u_1
x : α
xs : List α
left✝ : List.length (splitList xs).fst ≤ List.length xs
right✝ : List.length (splitList xs).snd ≤ List.length xs
⊢ List.length (splitList xs).fst ≤ Nat.succ (List.length xs)
</code></pre>
<p>The <code>left</code> goal is very similar to the <code>left✝</code> assumption, except the goal wraps both sides of the inequality in <code>Nat.succ</code>.
Likewise, the <code>right</code> goal resembles the <code>right✝</code> assumption, except the goal adds a <code>Nat.succ</code> only to the length of the input list.
It's time to prove that these wrappings of <code>Nat.succ</code> preserve the truth of the statement.</p>
<h3 id="adding-one-to-both-sides"><a class="header" href="#adding-one-to-both-sides">Adding One to Both Sides</a></h3>
<p>For the <code>left</code> goal, the statement to prove is <code>Nat.succ_le_succ : n ≤ m → Nat.succ n ≤ Nat.succ m</code>.
In other words, if <code>n ≤ m</code>, then adding one to both sides doesn't change this fact.
Why is this true?
The proof that <code>n ≤ m</code> is a <code>Nat.le.refl</code> constructor with <code>m - n</code> instances of the <code>Nat.le.step</code> constructor wrapped around it.
Adding one to both sides simply means that the <code>refl</code> applies to a number that's one larger than before, with the same number of <code>step</code> constructors.</p>
<p>More formally, the proof is by induction on the evidence that <code>n ≤ m</code>.
If the evidence is <code>refl</code>, then <code>n = m</code>, so <code>Nat.succ n = Nat.succ m</code> and <code>refl</code> can be used again.
If the evidence is <code>step</code>, then the induction hypothesis provides evidence that <code>Nat.succ n ≤ Nat.succ m</code>, and the goal is to show that <code>Nat.succ n ≤ Nat.succ (Nat.succ m)</code>.
This can be done by using <code>step</code> together with the induction hypothesis.</p>
<p>In Lean, the theorem statement is:</p>
<pre><code class="language-leantac">theorem Nat.succ_le_succ : n ≤ m → Nat.succ n ≤ Nat.succ m := by
  skip
</code></pre>
<p>and the error message recapitulates it:</p>
<pre><code class="language-output error">unsolved goals
n m : Nat
⊢ n ≤ m → Nat.succ n ≤ Nat.succ m
</code></pre>
<p>The first step is to use the <code>intro</code> tactic, bringing the hypothesis that <code>n ≤ m</code> into scope and giving it a name:</p>
<pre><code class="language-leantac">theorem Nat.succ_le_succ : n ≤ m → Nat.succ n ≤ Nat.succ m := by
  intro h
</code></pre>
<pre><code class="language-output error">unsolved goals
n m : Nat
h : n ≤ m
⊢ Nat.succ n ≤ Nat.succ m
</code></pre>
<p>Because the proof is by induction on the evidence that <code>n ≤ m</code>, the next tactic is <code>induction h</code>:</p>
<pre><code class="language-leantac">theorem Nat.succ_le_succ : n ≤ m → Nat.succ n ≤ Nat.succ m := by
  intro h
  induction h
</code></pre>
<p>This results in two goals, once for each constructor of <code>Nat.le</code>:</p>
<pre><code class="language-output error">unsolved goals
case refl
n m : Nat
⊢ Nat.succ n ≤ Nat.succ n

case step
n m m✝ : Nat
a✝ : Nat.le n m✝
a_ih✝ : Nat.succ n ≤ Nat.succ m✝
⊢ Nat.succ n ≤ Nat.succ (Nat.succ m✝)
</code></pre>
<p>The goal for <code>refl</code> can itself be solved using <code>refl</code>, which the <code>constructor</code> tactic selects.
The goal for <code>step</code> will also require a use of the <code>step</code> constructor:</p>
<pre><code class="language-leantac">theorem Nat.succ_le_succ : n ≤ m → Nat.succ n ≤ Nat.succ m := by
  intro h
  induction h with
  | refl =&gt; constructor
  | step h' ih =&gt; constructor
</code></pre>
<pre><code class="language-output error">unsolved goals
case step.a
n m m✝ : Nat
h' : Nat.le n m✝
ih : Nat.succ n ≤ Nat.succ m✝
⊢ Nat.le (Nat.succ n) (m✝ + 1)
</code></pre>
<p>The goal is no longer shown using the <code>≤</code> operator, but it is equivalent to the induction hypothesis <code>ih</code>.
The <code>assumption</code> tactic automatically selects an assumption that fulfills the goal, and the proof is complete:</p>
<pre><code class="language-leantac">theorem Nat.succ_le_succ : n ≤ m → Nat.succ n ≤ Nat.succ m := by
  intro h
  induction h with
  | refl =&gt; constructor
  | step h' ih =&gt;
    constructor
    assumption
</code></pre>
<p>Written as a recursive function, the proof is:</p>
<pre><code class="language-lean">theorem Nat.succ_le_succ : n ≤ m → Nat.succ n ≤ Nat.succ m
  | .refl =&gt; .refl
  | .step h' =&gt; .step (Nat.succ_le_succ h')
</code></pre>
<p>It can be instructional to compare the tactic-based proof by induction with this recursive function.
Which proof steps correspond to which parts of the definition?</p>
<h3 id="adding-one-to-the-greater-side"><a class="header" href="#adding-one-to-the-greater-side">Adding One to the Greater Side</a></h3>
<p>The second inequality needed to prove <code>splitList_shorter_le</code> is <code>∀(n m : Nat), n ≤ m → n ≤ Nat.succ m</code>.
This proof is almost identical to <code>Nat.succ_le_succ</code>.
Once again, the incoming assumption that <code>n ≤ m</code> essentially tracks the difference between <code>n</code> and <code>m</code> in the number of <code>Nat.le.step</code> constructors.
Thus, the proof should add an extra <code>Nat.le.step</code> in the base case.
The proof can be written:</p>
<pre><code class="language-leantac">theorem Nat.le_succ_of_le : n ≤ m → n ≤ Nat.succ m := by
  intro h
  induction h with
  | refl =&gt; constructor; constructor
  | step =&gt; constructor; assumption
</code></pre>
<p>To reveal what's going on behind the scenes, the <code>apply</code> and <code>exact</code> tactics can be used to indicate exactly which constructor is being applied.
The <code>apply</code> tactic solves the current goal by applying a function or constructor whose return type matches, creating new goals for each argument that was not provided, while <code>exact</code> fails if any new goals would be needed:</p>
<pre><code class="language-leantac">theorem Nat.le_succ_of_le : n ≤ m → n ≤ Nat.succ m := by
  intro h
  induction h with
  | refl =&gt; apply Nat.le.step; exact Nat.le.refl
  | step _ ih =&gt; apply Nat.le.step; exact ih
</code></pre>
<p>The proof can be golfed:</p>
<pre><code class="language-leantac">theorem Nat.le_succ_of_le (h : n ≤ m) : n ≤ Nat.succ m := by
  induction h &lt;;&gt; repeat (first | constructor | assumption)
</code></pre>
<p>In this short tactic script, both goals introduced by <code>induction</code> are addressed using <code>repeat (first | constructor | assumption)</code>.
The tactic <code>first | T1 | T2 | ... | Tn</code> means to use try <code>T1</code> through <code>Tn</code> in order, using the first tactic that succeeds.
In other words, <code>repeat (first | constructor | assumption)</code> applies constructors as long as it can, and then attempts to solve the goal using an assumption.</p>
<p>Finally, the proof can be written as a recursive function:</p>
<pre><code class="language-lean">theorem Nat.le_succ_of_le : n ≤ m → n ≤ Nat.succ m
  | .refl =&gt; .step .refl
  | .step h =&gt; .step (Nat.le_succ_of_le h)
</code></pre>
<p>Each style of proof can be appropriate to different circumstances.
The detailed proof script is useful in cases where beginners may be reading the code, or where the steps of the proof provide some kind of insight.
The short, highly-automated proof script is typically easier to maintain, because automation is frequently both flexible and robust in the face of small changes to definitions and datatypes.
The recursive function is typically both harder to understand from the perspective of mathematical proofs and harder to maintain, but it can be a useful bridge for programmers who are beginning to work with interactive theorem proving.</p>
<h3 id="finishing-the-proof"><a class="header" href="#finishing-the-proof">Finishing the Proof</a></h3>
<p>Now that both helper theorems have been proved, the rest of <code>splitList_shorter_le</code> will be completed quickly.
The current proof state has two goals, for the left and right sides of the <code>And</code>:</p>
<pre><code class="language-output error">unsolved goals
case cons.intro.left
α : Type u_1
x : α
xs : List α
left✝ : List.length (splitList xs).fst ≤ List.length xs
right✝ : List.length (splitList xs).snd ≤ List.length xs
⊢ Nat.succ (List.length (splitList xs).snd) ≤ Nat.succ (List.length xs)

case cons.intro.right
α : Type u_1
x : α
xs : List α
left✝ : List.length (splitList xs).fst ≤ List.length xs
right✝ : List.length (splitList xs).snd ≤ List.length xs
⊢ List.length (splitList xs).fst ≤ Nat.succ (List.length xs)
</code></pre>
<p>The goals are named for the fields of the <code>And</code> structure. This means that the <code>case</code> tactic (not to be confused with <code>cases</code>) can be used to focus on each of them in turn:</p>
<pre><code class="language-leantac">theorem splitList_shorter_le (lst : List α) :
    (splitList lst).fst.length ≤ lst.length ∧ (splitList lst).snd.length ≤ lst.length := by
  induction lst with
  | nil =&gt; simp [splitList]
  | cons x xs ih =&gt;
    simp [splitList]
    cases ih
    constructor
    case left =&gt; skip
    case right =&gt; skip
</code></pre>
<p>Instead of a single error that lists both unsolved goals, there are now two messages, one on each <code>skip</code>.
For the <code>left</code> goal, <code>Nat.succ_le_succ</code> can be used:</p>
<pre><code class="language-output error">unsolved goals
α : Type u_1
x : α
xs : List α
left✝ : List.length (splitList xs).fst ≤ List.length xs
right✝ : List.length (splitList xs).snd ≤ List.length xs
⊢ Nat.succ (List.length (splitList xs).snd) ≤ Nat.succ (List.length xs)
</code></pre>
<p>In the right goal, <code>Nat.le_suc_of_le</code> fits:</p>
<pre><code class="language-output error">unsolved goals
α : Type u_1
x : α
xs : List α
left✝ : List.length (splitList xs).fst ≤ List.length xs
right✝ : List.length (splitList xs).snd ≤ List.length xs
⊢ List.length (splitList xs).fst ≤ Nat.succ (List.length xs)
</code></pre>
<p>Both theorems include the precondition that <code>n ≤ m</code>.
These can be found as the <code>left✝</code> and <code>right✝</code> assumptions, which means that the <code>assumption</code> tactic takes care of the final goals:</p>
<pre><code class="language-leantac">theorem splitList_shorter_le (lst : List α) :
    (splitList lst).fst.length ≤ lst.length ∧ (splitList lst).snd.length ≤ lst.length := by
  induction lst with
  | nil =&gt; simp [splitList]
  | cons x xs ih =&gt;
    simp [splitList]
    cases ih
    constructor
    case left =&gt; apply Nat.succ_le_succ; assumption
    case right =&gt; apply Nat.le_succ_of_le; assumption
</code></pre>
<p>The next step is to return to the actual theorem that is needed to prove that merge sort terminates: that so long as a list has at least two entries, both results of splitting it are strictly shorter.</p>
<pre><code class="language-leantac">theorem splitList_shorter (lst : List α) (_ : lst.length ≥ 2) :
    (splitList lst).fst.length &lt; lst.length ∧
      (splitList lst).snd.length &lt; lst.length := by
  skip
</code></pre>
<pre><code class="language-output error">unsolved goals
α : Type u_1
lst : List α
x✝ : List.length lst ≥ 2
⊢ List.length (splitList lst).fst &lt; List.length lst ∧ List.length (splitList lst).snd &lt; List.length lst
</code></pre>
<p>Pattern matching works just as well in tactic scripts as it does in programs.
Because <code>lst</code> has at least two entries, they can be exposed with <code>match</code>, which also refines the type through dependent pattern matching:</p>
<pre><code class="language-leantac">theorem splitList_shorter (lst : List α) (_ : lst.length ≥ 2) :
    (splitList lst).fst.length &lt; lst.length ∧
      (splitList lst).snd.length &lt; lst.length := by
  match lst with
  | x :: y :: xs =&gt;
    skip
</code></pre>
<pre><code class="language-output error">unsolved goals
α : Type u_1
lst : List α
x y : α
xs : List α
x✝ : List.length (x :: y :: xs) ≥ 2
⊢ List.length (splitList (x :: y :: xs)).fst &lt; List.length (x :: y :: xs) ∧
    List.length (splitList (x :: y :: xs)).snd &lt; List.length (x :: y :: xs)
</code></pre>
<p>Simplifying using <code>splitList</code> removes <code>x</code> and <code>y</code>, resulting in the computed lengths of lists each gaining a <code>Nat.succ</code>:</p>
<pre><code class="language-leantac">theorem splitList_shorter (lst : List α) (_ : lst.length ≥ 2) :
    (splitList lst).fst.length &lt; lst.length ∧
      (splitList lst).snd.length &lt; lst.length := by
  match lst with
  | x :: y :: xs =&gt;
    simp [splitList]
</code></pre>
<pre><code class="language-output error">unsolved goals
α : Type u_1
lst : List α
x y : α
xs : List α
x✝ : List.length (x :: y :: xs) ≥ 2
⊢ Nat.succ (List.length (splitList xs).fst) &lt; Nat.succ (Nat.succ (List.length xs)) ∧
    Nat.succ (List.length (splitList xs).snd) &lt; Nat.succ (Nat.succ (List.length xs))
</code></pre>
<p>Replacing <code>simp</code> with <code>simp_arith</code> removes these <code>Nat.succ</code> constructors, because <code>simp_arith</code> makes use of the fact that <code>n + 1 &lt; m + 1</code> implies <code>n &lt; m</code>:</p>
<pre><code class="language-leantac">theorem splitList_shorter (lst : List α) (_ : lst.length ≥ 2) :
    (splitList lst).fst.length &lt; lst.length ∧
      (splitList lst).snd.length &lt; lst.length := by
  match lst with
  | x :: y :: xs =&gt;
    simp_arith [splitList]
</code></pre>
<pre><code class="language-output error">unsolved goals
α : Type u_1
lst : List α
x y : α
xs : List α
x✝ : List.length (x :: y :: xs) ≥ 2
⊢ List.length (splitList xs).fst ≤ List.length xs ∧ List.length (splitList xs).snd ≤ List.length xs
</code></pre>
<p>This goal now matches <code>splitList_shorter_le</code>, which can be used to conclude the proof:</p>
<pre><code class="language-leantac">theorem splitList_shorter (lst : List α) (_ : lst.length ≥ 2) :
    (splitList lst).fst.length &lt; lst.length ∧
      (splitList lst).snd.length &lt; lst.length := by
  match lst with
  | x :: y :: xs =&gt;
    simp_arith [splitList]
    apply splitList_shorter_le
</code></pre>
<p>The facts needed to prove that <code>mergeSort</code> terminates can be pulled out of the resulting <code>And</code>:</p>
<pre><code class="language-leantac">theorem splitList_shorter_fst (lst : List α) (h : lst.length ≥ 2) :
    (splitList lst).fst.length &lt; lst.length :=
  splitList_shorter lst h |&gt;.left

theorem splitList_shorter_snd (lst : List α) (h : lst.length ≥ 2) :
    (splitList lst).snd.length &lt; lst.length :=
  splitList_shorter lst h |&gt;.right
</code></pre>
<h2 id="merge-sort-terminates"><a class="header" href="#merge-sort-terminates">Merge Sort Terminates</a></h2>
<p>Merge sort has two recursive calls, one for each sub-list returned by <code>splitList</code>.
Each recursive call will require a proof that the length of the list being passed to it is shorter than the length of the input list.
It's usually convenient to write a termination proof in two steps: first, write down the propositions that will allow Lean to verify termination, and then prove them.
Otherwise, it's possible to put a lot of effort into proving the propositions, only to find out that they aren't quite what's needed to establish that the recursive calls are on smaller inputs.</p>
<p>The <code>sorry</code> tactic can prove any goal, even false ones.
It isn't intended for use in production code or final proofs, but it is a convenient way to &quot;sketch out&quot; a proof or program ahead of time.
Any definitions or theorems that use <code>sorry</code> are annotated with a warning.</p>
<p>The initial sketch of <code>mergeSort</code>'s termination argument that uses <code>sorry</code> can be written by copying the goals that Lean couldn't prove into <code>have</code>-expressions.
In Lean, <code>have</code> is similar to <code>let</code>.
When using <code>have</code>, the name is optional.
Typically, <code>let</code> is used to define names that refer to interesting values, while <code>have</code> is used to locally prove propositions that can be found when Lean is searching for evidence that an array lookup is in-bounds or that a function terminates.</p>
<pre><code class="language-leantac">def mergeSort [Ord α] (xs : List α) : List α :=
  if h : xs.length &lt; 2 then
    match xs with
    | [] =&gt; []
    | [x] =&gt; [x]
  else
    let halves := splitList xs
    have : halves.fst.length &lt; xs.length := by
      sorry
    have : halves.snd.length &lt; xs.length := by
      sorry
    merge (mergeSort halves.fst) (mergeSort halves.snd)
termination_by mergeSort xs =&gt; xs.length
</code></pre>
<p>The warning is located on the name <code>mergeSort</code>:</p>
<pre><code class="language-output warning">declaration uses 'sorry'
</code></pre>
<p>Because there are no errors, the proposed propositions are enough to establish termination.</p>
<p>The proofs begin by applying the helper theorems:</p>
<pre><code class="language-leantac">def mergeSort [Ord α] (xs : List α) : List α :=
  if h : xs.length &lt; 2 then
    match xs with
    | [] =&gt; []
    | [x] =&gt; [x]
  else
    let halves := splitList xs
    have : halves.fst.length &lt; xs.length := by
      apply splitList_shorter_fst
    have : halves.snd.length &lt; xs.length := by
      apply splitList_shorter_snd
    merge (mergeSort halves.fst) (mergeSort halves.snd)
termination_by mergeSort xs =&gt; xs.length
</code></pre>
<p>Both proofs fail, because <code>splitList_shorter_fst</code> and <code>splitList_shorter_snd</code> both require a proof that <code>xs.length ≥ 2</code>:</p>
<pre><code class="language-output error">unsolved goals
case h
α : Type ?u.37632
inst✝ : Ord α
xs : List α
h : ¬List.length xs &lt; 2
halves : List α × List α := splitList xs
⊢ List.length xs ≥ 2
</code></pre>
<p>To check that this will be enough to complete the proof, add it using <code>sorry</code> and check for errors:</p>
<pre><code class="language-leantac">def mergeSort [Ord α] (xs : List α) : List α :=
  if h : xs.length &lt; 2 then
    match xs with
    | [] =&gt; []
    | [x] =&gt; [x]
  else
    let halves := splitList xs
    have : xs.length ≥ 2 := by sorry
    have : halves.fst.length &lt; xs.length := by
      apply splitList_shorter_fst
      assumption
    have : halves.snd.length &lt; xs.length := by
      apply splitList_shorter_snd
      assumption
    merge (mergeSort halves.fst) (mergeSort halves.snd)
termination_by mergeSort xs =&gt; xs.length
</code></pre>
<p>Once again, there is only a warning.</p>
<pre><code class="language-output warning">declaration uses 'sorry'
</code></pre>
<p>There is one promising assumption available: <code>h : ¬List.length xs &lt; 2</code>, which comes from the <code>if</code>.
Clearly, if it is not the case that <code>xs.length &lt; 2</code>, then <code>xs.length ≥ 2</code>.
The Lean library provides this theorem under the name <code>Nat.ge_of_not_lt</code>.
The program is now complete:</p>
<pre><code class="language-leantac">def mergeSort [Ord α] (xs : List α) : List α :=
  if h : xs.length &lt; 2 then
    match xs with
    | [] =&gt; []
    | [x] =&gt; [x]
  else
    let halves := splitList xs
    have : xs.length ≥ 2 := by
      apply Nat.ge_of_not_lt
      assumption
    have : halves.fst.length &lt; xs.length := by
      apply splitList_shorter_fst
      assumption
    have : halves.snd.length &lt; xs.length := by
      apply splitList_shorter_snd
      assumption
    merge (mergeSort halves.fst) (mergeSort halves.snd)
termination_by mergeSort xs =&gt; xs.length
</code></pre>
<p>The function can be tested on examples:</p>
<pre><code class="language-lean">#eval mergeSort [&quot;soapstone&quot;, &quot;geode&quot;, &quot;mica&quot;, &quot;limestone&quot;]
</code></pre>
<pre><code class="language-output info">[&quot;geode&quot;, &quot;limestone&quot;, &quot;mica&quot;, &quot;soapstone&quot;]
</code></pre>
<pre><code class="language-lean">#eval mergeSort [5, 3, 22, 15]
</code></pre>
<pre><code class="language-output info">[3, 5, 15, 22]
</code></pre>
<h2 id="division-as-iterated-subtraction"><a class="header" href="#division-as-iterated-subtraction">Division as Iterated Subtraction</a></h2>
<p>Just as multiplication is iterated addition and exponentiation is iterated multiplication, division can be understood as iterated subtraction.
The <a href="programs-proofs/../getting-to-know/datatypes-and-patterns.html#recursive-functions">very first description of recursive functions in this book</a> presents a version of division that terminates when the divisor is not zero, but that Lean does not accept.
Proving that division terminates requires the use of a fact about inequalities.</p>
<p>The first step is to refine the definition of division so that it requires evidence that the divisor is not zero:</p>
<pre><code class="language-lean">def div (n k : Nat) (ok : k &gt; 0) : Nat :=
  if n &lt; k then
    0
  else
    1 + div (n - k) k ok
</code></pre>
<p>The error message is somewhat longer, due to the additional argument, but it contains essentially the same information:</p>
<pre><code class="language-output error">fail to show termination for
  div
with errors
argument #1 was not used for structural recursion
  failed to eliminate recursive application
    div (n - k) k ok

argument #2 was not used for structural recursion
  failed to eliminate recursive application
    div (n - k) k ok

argument #3 was not used for structural recursion
  application type mismatch
    @Nat.le.brecOn (Nat.succ 0) fun k ok =&gt; Nat → Nat
  argument
    fun k ok =&gt; Nat → Nat
  has type
    (k : Nat) → k &gt; 0 → Type : Type 1
  but is expected to have type
    (a : Nat) → Nat.le (Nat.succ 0) a → Prop : Type

structural recursion cannot be used

failed to prove termination, use `termination_by` to specify a well-founded relation
</code></pre>
<p>This definition of <code>div</code> terminates because the first argument <code>n</code> is smaller on each recursive call.
This can be expressed using a <code>termination_by</code> clause:</p>
<pre><code class="language-lean">def div (n k : Nat) (ok : k &gt; 0) : Nat :=
  if h : n &lt; k then
    0
  else
    1 + div (n - k) k ok
termination_by div n k ok =&gt; n
</code></pre>
<p>Now, the error is confined to the recursive call:</p>
<pre><code class="language-output error">failed to prove termination, possible solutions:
  - Use `have`-expressions to prove the remaining goals
  - Use `termination_by` to specify a different well-founded relation
  - Use `decreasing_by` to specify your own tactic for discharging this kind of goal
n k : Nat
ok : k &gt; 0
h : ¬n &lt; k
⊢ n - k &lt; n
</code></pre>
<p>This can be proved using a theorem from the standard library, <code>Nat.sub_lt</code>.
This theorem states that <code>∀ {n k : Nat}, 0 &lt; n → 0 &lt; k → n - k &lt; n</code> (the curly braces indicate that <code>n</code> and <code>k</code> are implicit arguments).
Using this theorem requires demonstrating that both <code>n</code> and <code>k</code> are greater than zero.
Because <code>k &gt; 0</code> is syntactic sugar for <code>0 &lt; k</code>, the only necessary goal is to show that <code>0 &lt; n</code>.
There are two possibilities: either <code>n</code> is <code>0</code>, or it is <code>n' + 1</code> for some other <code>Nat</code> <code>n'</code>.
But <code>n</code> cannot be <code>0</code>.
The fact that the <code>if</code> selected the second branch means that <code>¬ n &lt; k</code>, but if <code>n = 0</code> and <code>k &gt; 0</code> then <code>n</code> must be less than <code>k</code>, which would be a contradiction.
This, <code>n = Nat.succ n'</code>, and <code>Nat.succ n'</code> is clearly greater than <code>0</code>.</p>
<p>The full definition of <code>div</code>, including the termination proof, is:</p>
<pre><code class="language-leantac">def div (n k : Nat) (ok : k &gt; 0) : Nat :=
  if h : n &lt; k then
    0
  else
    have : 0 &lt; n := by
      cases n with
      | zero =&gt; contradiction
      | succ n' =&gt; simp_arith
    have : n - k &lt; n := by
      apply Nat.sub_lt &lt;;&gt; assumption
    1 + div (n - k) k ok
termination_by div n k ok =&gt; n
</code></pre>
<h2 id="exercises-25"><a class="header" href="#exercises-25">Exercises</a></h2>
<p>Prove the following theorems:</p>
<ul>
<li>For all natural numbers \( n \), \( 0 &lt; n + 1 \).</li>
<li>For all natural numbers \( n \), \( 0 \leq n \).</li>
<li>For all natural numbers \( n \) and \( k \), \( (n + 1) - (k + 1) = n - k \)</li>
<li>For all natural numbers \( n \) and \( k \), if \( k &lt; n \) then \( n \neq 0 \)</li>
<li>For all natural numbers \( n \), \( n - n = 0 \)</li>
<li>For all natural numbers \( n \) and \( k \), if \( n + 1 &lt; k \) then \( n &lt; k \)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="safe-array-indices"><a class="header" href="#safe-array-indices">Safe Array Indices</a></h1>
<p>The <code>GetElem</code> instance for <code>Array</code> and <code>Nat</code> requires a proof that the provided <code>Nat</code> is smaller than the array.
In practice, these proofs often end up being passed to functions along with the indices.
Rather than passing an index and a proof separately, a type called <code>Fin</code> can be used to bundle up the index and the proof into a single value.
This can make code easier to read.
Additionally, many of the built-in operations on arrays take their index arguments as <code>Fin</code> rather than as <code>Nat</code>, so using these built-in operations requires understanding how to use <code>Fin</code>.</p>
<p>The type <code>Fin n</code> represents numbers that are strictly less than <code>n</code>.
In other words, <code>Fin 3</code> describes <code>0</code>, <code>1</code>, and <code>2</code>, while <code>Fin 0</code> has no values at all.
The definition of <code>Fin</code> resembles <code>Subtype</code>, as a <code>Fin n</code> is a structure that contains a <code>Nat</code> and a proof that it is less than <code>n</code>:</p>
<pre><code class="language-lean">structure Fin (n : Nat) where
  val  : Nat
  isLt : LT.lt val n
</code></pre>
<p>Lean includes instances of <code>ToString</code> and <code>OfNat</code> that allow <code>Fin</code> values to be conveniently used as numbers.
In other words, the output of <code>#eval (5 : Fin 8)</code> is <code>5</code>, rather than something like <code>{val := 5, isLt := _}</code>.</p>
<p>Instead of failing when the provided number is larger than the bound, the <code>OfNat</code> instance for <code>Fin</code> returns a value modulo the bound.
This means that <code>#eval (45 : Fin 10)</code> results in <code>5</code> rather than a compile-time error.</p>
<p>In a return type, a <code>Fin</code> returned as a found index makes its connection to the data structure in which it was found more clear.
The <code>Array.find</code> in the <a href="programs-proofs/./arrays-termination.html#proving-termination">previous section</a> returns an index that the caller cannot immediately use to perform lookups into the array, because the information about its validity has been lost.
A more specific type results in a value that can be used without making the program significantly more complicated:</p>
<pre><code class="language-lean">def findHelper (arr : Array α) (p : α → Bool) (i : Nat) : Option (Fin arr.size × α) :=
  if h : i &lt; arr.size then
    let x := arr[i]
    if p x then
      some (⟨i, h⟩, x)
    else findHelper arr p (i + 1)
  else none
termination_by findHelper arr p i =&gt; arr.size - i

def Array.find (arr : Array α) (p : α → Bool) : Option (Fin arr.size × α) :=
  findHelper arr p 0
</code></pre>
<h2 id="exercise-3"><a class="header" href="#exercise-3">Exercise</a></h2>
<p>Write a function <code>Fin.next? : Fin n → Option (Fin n)</code> that returns the next largest <code>Fin</code> when it would be in bounds, or <code>none</code> if not.
Check that</p>
<pre><code class="language-lean">#eval (3 : Fin 8).next?
</code></pre>
<p>outputs</p>
<pre><code class="language-output info">some 4
</code></pre>
<p>and that</p>
<pre><code class="language-lean">#eval (7 : Fin 8).next?
</code></pre>
<p>outputs</p>
<pre><code class="language-output info">none
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="insertion-sort-and-array-mutation"><a class="header" href="#insertion-sort-and-array-mutation">Insertion Sort and Array Mutation</a></h1>
<p>While insertion sort does not have the optimal worst-case time complexity for a sorting algorithm, it still has a number of useful properties:</p>
<ul>
<li>It is simple and straightforward to implement and understand</li>
<li>It is an in-place algorithm, requiring no additional space to run</li>
<li>It is a stable sort</li>
<li>It is fast when the input is already almost sorted</li>
</ul>
<p>In-place algorithms are particularly useful in Lean due to the way it manages memory.
In some cases, operations that would normally copy an array can be optimized into mutation.
This includes swapping elements in an array.</p>
<p>Most languages and run-time systems with automatic memory management, including JavaScript, the JVM, and .NET, use tracing garbage collection.
When memory needs to be reclaimed, the system starts at a number of <em>roots</em> (such as the call stack and global values) and then determines which values can be reached by recursively chasing pointers.
Any values that can't be reached are deallocated, freeing memory.</p>
<p>Reference counting is an alternative to tracing garbage collection that is used by a number of languages, including Python, Swift, and Lean.
In a system with reference counting, each object in memory has a field that tracks how many references there are to it.
When a new reference is established, the counter is incremented.
When a reference ceases to exist, the counter is decremented.
When the counter reaches zero, the object is immediately deallocated.</p>
<p>Reference counting has one major disadvantage compared to a tracing garbage collector: circular references can lead to memory leaks.
If object \( A \) references object \( B \) , and object \( B \) references object \( A \), they will never be deallocated, even if nothing else in the program references either \( A \) or \( B \).
Circular references result either from uncontrolled recursion or from mutable references.
Because Lean supports neither, it is impossible to construct circular references.</p>
<p>Reference counting means that the Lean runtime system's primitives for allocating and deallocating data structures can check whether a reference count is about to fall to zero, and re-use an existing object instead of allocating a new one.
This is particularly important when working with large arrays.</p>
<p>An implementation of insertion sort for Lean arrays should satisfy the following criteria:</p>
<ol>
<li>Lean should accept the function without a <code>partial</code> annotation</li>
<li>If passed an array to which there are no other references, it should modify the array in-place rather than allocating a new one</li>
</ol>
<p>The first criterion is easy to check: if Lean accepts the definition, then it is satisfied.
The second, however, requires a means of testing it.
Lean provides a built-in function called <code>dbgTraceIfShared</code> with the following signature:</p>
<pre><code class="language-lean">#check dbgTraceIfShared
</code></pre>
<pre><code class="language-output info">dbgTraceIfShared.{u} {α : Type u} (s : String) (a : α) : α
</code></pre>
<p>It takes a string and a value as arguments, and prints a message that uses the string to standard error if the value has more than one reference, returning the value.
This is not, strictly speaking, a pure function.
However, it is intended to be used only during development to check that a function is in fact able to re-use memory rather than allocating and copying.</p>
<p>When learning to use <code>dbgTraceIfShared</code>, it's important to know that <code>#eval</code> will report that many more values are shared than in compiled code.
This can be confusing.
It's important to build an executable with <code>lake</code> rather than experimenting in an editor.</p>
<p>Insertion sort consists of two loops.
The outer loop moves a pointer from left to right across the array to be sorted.
After each iteration, the region of the array to the left of the pointer is sorted, while the region to the right may not yet be sorted.
The inner loop takes the element pointed to by the pointer and moves it to the left until the appropriate location has been found and the loop invariant has been restored.
In other words, each iteration inserts the next element of the array into the appropriate location in the sorted region.</p>
<h2 id="the-inner-loop"><a class="header" href="#the-inner-loop">The Inner Loop</a></h2>
<p>The inner loop of insertion sort can be implemented as a tail-recursive function that takes the array and the index of the element being inserted as arguments.
The element being inserted is repeatedly swapped with the element to its left until either the element to the left is smaller or the beginning of the array is reached.
The inner loop is structurally recursive on the <code>Nat</code> that is inside the <code>Fin</code> used to index into the array:</p>
<pre><code class="language-leantac">def insertSorted [Ord α] (arr : Array α) (i : Fin arr.size) : Array α :=
  match i with
  | ⟨0, _⟩ =&gt; arr
  | ⟨i' + 1, _⟩ =&gt;
    have : i' &lt; arr.size := by
      simp [Nat.lt_of_succ_lt, *]
    match Ord.compare arr[i'] arr[i] with
    | .lt | .eq =&gt; arr
    | .gt =&gt;
      insertSorted (arr.swap ⟨i', by assumption⟩ i) ⟨i', by simp [*]⟩
</code></pre>
<p>If the index <code>i</code> is <code>0</code>, then the element being inserted into the sorted region has reached the beginning of the region and is the smallest.
If the index is <code>i' + 1</code>, then the element at <code>i'</code> should be compared to the element at <code>i</code>.
Note that while <code>i</code> is a <code>Fin arr.size</code>, <code>i'</code> is just a <code>Nat</code> because it results from the <code>val</code> field of <code>i</code>.
It is thus necessary to prove that <code>i' &lt; arr.size</code> before <code>i'</code> can be used to index into <code>arr</code>.</p>
<p>Omitting the <code>have</code>-expression with the proof that <code>i' &lt; arr.size</code> reveals the following goal:</p>
<pre><code class="language-output error">unsolved goals
α : Type ?u.7
inst✝ : Ord α
arr : Array α
i : Fin (Array.size arr)
i' : Nat
isLt✝ : i' + 1 &lt; Array.size arr
⊢ i' &lt; Array.size arr
</code></pre>
<p>The hint <code>Nat.lt_of_succ_lt</code> is a theorem from Lean's standard library.
Its signature, found by <code>#check Nat.lt_of_succ_lt</code>, is</p>
<pre><code class="language-output info">Nat.lt_of_succ_lt {n m : Nat} (a✝ : Nat.succ n &lt; m) : n &lt; m
</code></pre>
<p>In other words, it states that if <code>n + 1 &lt; m</code>, then <code>n &lt; m</code>.
The <code>*</code> passed to <code>simp</code> causes it to combine <code>Nat.lt_of_succ_lt</code> with the <code>isLt</code> field from <code>i</code> to get the final proof.</p>
<p>Having established that <code>i'</code> can be used to look up the element to the left of the element being inserted, the two elements are looked up and compared. 
If the element to the left is less than or equal to the element being inserted, then the loop is finished and the invariant has been restored.
If the element to the left is greater than the element being inserted, then the elements are swapped and the inner loop begins again.
<code>Array.swap</code> takes both of its indices as <code>Fin</code>s, and the <code>by assumption</code> that establishes that <code>i' &lt; arr.size</code> makes use of the <code>have</code>.
The index to be examined on the next round through the inner loop is also <code>i'</code>, but <code>by assumption</code> is not sufficient in this case.
This is because the proof was written for the original array <code>arr</code>, not the result of swapping two elements.
The <code>simp</code> tactic's database contains the fact that swapping two elements of an array doesn't change its size, and the <code>[*]</code> argument instructs it to additionally use the assumption introduced by <code>have</code>.</p>
<h2 id="the-outer-loop"><a class="header" href="#the-outer-loop">The Outer Loop</a></h2>
<p>The outer loop of insertion sort moves the pointer from left to right, invoking <code>insertSorted</code> at each iteration to insert the element at the pointer into the correct position in the array.
The basic form of the loop resembles the implementation of <code>Array.map</code>:</p>
<pre><code class="language-lean">def insertionSortLoop [Ord α] (arr : Array α) (i : Nat) : Array α :=
  if h : i &lt; arr.size then
    insertionSortLoop (insertSorted arr ⟨i, h⟩) (i + 1)
  else
    arr
</code></pre>
<p>The resulting error is also the same as the error that occurs without a <code>termination_by</code> clause on <code>Array.map</code>, because there is no argument that decreases at every recursive call:</p>
<pre><code class="language-output error">fail to show termination for
  insertionSortLoop
with errors
argument #4 was not used for structural recursion
  failed to eliminate recursive application
    insertionSortLoop (insertSorted arr { val := i, isLt := h }) (i + 1)

structural recursion cannot be used

failed to prove termination, use `termination_by` to specify a well-founded relation
</code></pre>
<p>Before constructing the termination proof, it can be convenient to test the definition with a <code>partial</code> modifier to make sure that it returns the expected answers:</p>
<pre><code class="language-lean">partial def insertionSortLoop [Ord α] (arr : Array α) (i : Nat) : Array α :=
  if h : i &lt; arr.size then
    insertionSortLoop (insertSorted arr ⟨i, h⟩) (i + 1)
  else
    arr
</code></pre>
<pre><code class="language-lean">#eval insertionSortLoop #[5, 17, 3, 8] 0
</code></pre>
<pre><code class="language-output info">#[3, 5, 8, 17]
</code></pre>
<pre><code class="language-lean">#eval insertionSortLoop #[&quot;metamorphic&quot;, &quot;igneous&quot;, &quot;sedentary&quot;] 0
</code></pre>
<pre><code class="language-output info">#[&quot;igneous&quot;, &quot;metamorphic&quot;, &quot;sedentary&quot;]
</code></pre>
<h3 id="termination"><a class="header" href="#termination">Termination</a></h3>
<p>Once again, the function terminates because the difference between the index and the size of the array being processed decreases on each recursive call.
This time, however, Lean does not accept the <code>termination_by</code>:</p>
<pre><code class="language-lean">def insertionSortLoop [Ord α] (arr : Array α) (i : Nat) : Array α :=
  if h : i &lt; arr.size then
    insertionSortLoop (insertSorted arr ⟨i, h⟩) (i + 1)
  else
    arr
termination_by insertionSortLoop arr i =&gt; arr.size - i
</code></pre>
<pre><code class="language-output error">failed to prove termination, possible solutions:
  - Use `have`-expressions to prove the remaining goals
  - Use `termination_by` to specify a different well-founded relation
  - Use `decreasing_by` to specify your own tactic for discharging this kind of goal
α : Type u_1
inst✝ : Ord α
arr : Array α
i : Nat
h : i &lt; Array.size arr
⊢ Array.size (insertSorted arr { val := i, isLt := h }) - (i + 1) &lt; Array.size arr - i
</code></pre>
<p>The problem is that Lean has no way to know that <code>insertSorted</code> returns an array that's the same size as the one it is passed.
In order to prove that <code>insertionSortLoop</code> terminates, it is necessary to first prove that <code>insertSorted</code> doesn't change the size of the array.
Copying the unproved termination condition from the error message to the function and &quot;proving&quot; it with <code>sorry</code> allows the function to be temporarily accepted:</p>
<pre><code class="language-leantac">def insertionSortLoop [Ord α] (arr : Array α) (i : Nat) : Array α :=
  if h : i &lt; arr.size then
    have : (insertSorted arr ⟨i, h⟩).size - (i + 1) &lt; arr.size - i := by
      sorry
    insertionSortLoop (insertSorted arr ⟨i, h⟩) (i + 1)
  else
    arr
termination_by insertionSortLoop arr i =&gt; arr.size - i
</code></pre>
<pre><code class="language-output warning">declaration uses 'sorry'
</code></pre>
<p>Because <code>insertSorted</code> is structurally recursive on the index of the element being inserted, the proof should be by induction on the index.
In the base case, the array is returned unchanged, so its length certainly does not change.
For the inductive step, the induction hypothesis is that a recursive call on the next smaller index will not change the length of the array.
There are two cases two consider: either the element has been fully inserted into the sorted region and the array is returned unchanged, in which case the length is also unchanged, or the element is swapped with the next one before the recursive call.
However, swapping two elements in an array doesn't change the size of it, and the induction hypothesis states that the recursive call with the next index returns an array that's the same size as its argument.
Thus, the size remains unchanged.</p>
<p>Translating this English-language theorem statement to Lean and proceeding using the techniques from this chapter is enough to prove the base case and make progress in the inductive step:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (arr : Array α) (i : Fin arr.size) :
    (insertSorted arr i).size = arr.size := by
  match i with
  | ⟨j, isLt⟩ =&gt;
    induction j with
    | zero =&gt; simp [insertSorted]
    | succ j' ih =&gt;
      simp [insertSorted]
</code></pre>
<p>The simplification using <code>insertSorted</code> in the inductive step revealed the pattern match in <code>insertSorted</code>:</p>
<pre><code class="language-output error">unsolved goals
case succ
α : Type u_1
inst✝ : Ord α
arr : Array α
i : Fin (Array.size arr)
j' : Nat
ih : ∀ (isLt : j' &lt; Array.size arr), Array.size (insertSorted arr { val := j', isLt := isLt }) = Array.size arr
isLt : Nat.succ j' &lt; Array.size arr
⊢ Array.size
      (match compare arr[j'] arr[{ val := Nat.succ j', isLt := isLt }] with
      | Ordering.lt =&gt; arr
      | Ordering.eq =&gt; arr
      | Ordering.gt =&gt;
        insertSorted
          (Array.swap arr { val := j', isLt := (_ : j' &lt; Array.size arr) } { val := Nat.succ j', isLt := isLt })
          { val := j',
            isLt :=
              (_ :
                j' &lt;
                  Array.size
                    (Array.swap arr { val := j', isLt := (_ : j' &lt; Array.size arr) }
                      { val := Nat.succ j', isLt := isLt })) }) =
    Array.size arr
</code></pre>
<p>When faced with a goal that includes <code>if</code> or <code>match</code>, the <code>split</code> tactic (not to be confused with the <code>split</code> function used in the definition of merge sort) replaces the goal with one new goal for each path of control flow:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (arr : Array α) (i : Fin arr.size) :
    (insertSorted arr i).size = arr.size := by
  match i with
  | ⟨j, isLt⟩ =&gt;
    induction j with
    | zero =&gt; simp [insertSorted]
    | succ j' ih =&gt;
      simp [insertSorted]
      split
</code></pre>
<p>Additionally, each new goal has an assumption that indicates which branch led to that goal, named <code>heq✝</code> in this case:</p>
<pre><code class="language-output error">unsolved goals
case succ.h_1
α : Type u_1
inst✝ : Ord α
arr : Array α
i : Fin (Array.size arr)
j' : Nat
ih : ∀ (isLt : j' &lt; Array.size arr), Array.size (insertSorted arr { val := j', isLt := isLt }) = Array.size arr
isLt : Nat.succ j' &lt; Array.size arr
x✝ : Ordering
heq✝ : compare arr[j'] arr[{ val := Nat.succ j', isLt := isLt }] = Ordering.lt
⊢ Array.size arr = Array.size arr

case succ.h_2
α : Type u_1
inst✝ : Ord α
arr : Array α
i : Fin (Array.size arr)
j' : Nat
ih : ∀ (isLt : j' &lt; Array.size arr), Array.size (insertSorted arr { val := j', isLt := isLt }) = Array.size arr
isLt : Nat.succ j' &lt; Array.size arr
x✝ : Ordering
heq✝ : compare arr[j'] arr[{ val := Nat.succ j', isLt := isLt }] = Ordering.eq
⊢ Array.size arr = Array.size arr

case succ.h_3
α : Type u_1
inst✝ : Ord α
arr : Array α
i : Fin (Array.size arr)
j' : Nat
ih : ∀ (isLt : j' &lt; Array.size arr), Array.size (insertSorted arr { val := j', isLt := isLt }) = Array.size arr
isLt : Nat.succ j' &lt; Array.size arr
x✝ : Ordering
heq✝ : compare arr[j'] arr[{ val := Nat.succ j', isLt := isLt }] = Ordering.gt
⊢ Array.size
      (insertSorted
        (Array.swap arr { val := j', isLt := (_ : j' &lt; Array.size arr) } { val := Nat.succ j', isLt := isLt })
        { val := j',
          isLt :=
            (_ :
              j' &lt;
                Array.size
                  (Array.swap arr { val := j', isLt := (_ : j' &lt; Array.size arr) }
                    { val := Nat.succ j', isLt := isLt })) }) =
    Array.size arr
</code></pre>
<p>Rather than write proofs for both simple cases, adding <code>&lt;;&gt; try rfl</code> after <code>split</code> causes the two straightforward cases to disappear immediately, leaving only a single goal:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (arr : Array α) (i : Fin arr.size) :
    (insertSorted arr i).size = arr.size := by
  match i with
  | ⟨j, isLt⟩ =&gt;
    induction j with
    | zero =&gt; simp [insertSorted]
    | succ j' ih =&gt;
      simp [insertSorted]
      split &lt;;&gt; try rfl
</code></pre>
<pre><code class="language-output error">unsolved goals
case succ.h_3
α : Type u_1
inst✝ : Ord α
arr : Array α
i : Fin (Array.size arr)
j' : Nat
ih : ∀ (isLt : j' &lt; Array.size arr), Array.size (insertSorted arr { val := j', isLt := isLt }) = Array.size arr
isLt : Nat.succ j' &lt; Array.size arr
x✝ : Ordering
heq✝ : compare arr[j'] arr[{ val := Nat.succ j', isLt := isLt }] = Ordering.gt
⊢ Array.size
      (insertSorted
        (Array.swap arr { val := j', isLt := (_ : j' &lt; Array.size arr) } { val := Nat.succ j', isLt := isLt })
        { val := j',
          isLt :=
            (_ :
              j' &lt;
                Array.size
                  (Array.swap arr { val := j', isLt := (_ : j' &lt; Array.size arr) }
                    { val := Nat.succ j', isLt := isLt })) }) =
    Array.size arr
</code></pre>
<p>Unfortunately, the induction hypothesis is not strong enough to prove this goal.
The induction hypothesis states that calling <code>insertSorted</code> on <code>arr</code> leaves the size unchanged, but the proof goal is to show that the result of the recursive call with the result of swapping leaves the size unchanged.
Successfully completing the proof requires an induction hypothesis that works for <em>any</em> array that is passed to <code>insertSorted</code> together with the smaller index as an argument</p>
<p>It is possible to get a strong induction hypothesis by using the <code>generalizing</code> option to the <code>induction</code> tactic.
This option brings additional assumptions from the context into the statement that's used to generate the base case, the induction hypothesis, and the goal to be shown in the inductive step.
Generalizing over <code>arr</code> leads to a stronger hypothesis:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (arr : Array α) (i : Fin arr.size) :
    (insertSorted arr i).size = arr.size := by
  match i with
  | ⟨j, isLt⟩ =&gt;
    induction j generalizing arr with
    | zero =&gt; simp [insertSorted]
    | succ j' ih =&gt;
      simp [insertSorted]
      split &lt;;&gt; try rfl
</code></pre>
<p>In the resulting goal, <code>arr</code> is now part of a &quot;for all&quot; statement in the inductive hypothesis:</p>
<pre><code class="language-output error">unsolved goals
case succ.h_3
α : Type u_1
inst✝ : Ord α
j' : Nat
ih :
  ∀ (arr : Array α),
    Fin (Array.size arr) →
      ∀ (isLt : j' &lt; Array.size arr), Array.size (insertSorted arr { val := j', isLt := isLt }) = Array.size arr
arr : Array α
i : Fin (Array.size arr)
isLt : Nat.succ j' &lt; Array.size arr
x✝ : Ordering
heq✝ : compare arr[j'] arr[{ val := Nat.succ j', isLt := isLt }] = Ordering.gt
⊢ Array.size
      (insertSorted
        (Array.swap arr { val := j', isLt := (_ : j' &lt; Array.size arr) } { val := Nat.succ j', isLt := isLt })
        { val := j',
          isLt :=
            (_ :
              j' &lt;
                Array.size
                  (Array.swap arr { val := j', isLt := (_ : j' &lt; Array.size arr) }
                    { val := Nat.succ j', isLt := isLt })) }) =
    Array.size arr
</code></pre>
<p>However, this whole proof is beginning to get unmanageable.
The next step would be to introduce a variable standing for the length of the result of swapping, show that it is equal to <code>arr.size</code>, and then show that this variable is also equal to the length of the array that results from the recursive call.
These equality statement can then be chained together to prove the goal.
It's much easier, however, to carefully reformulate the theorem statement such that the induction hypothesis is automatically strong enough and the variables are already introduced.
The reformulated statement reads:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → arr.size = len →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  skip
</code></pre>
<p>This version of the theorem statement is easier to prove for a few reasons:</p>
<ol>
<li>Rather than bundling up the index and the proof of its validity in a <code>Fin</code>, the index comes before the array.
This allows the induction hypothesis to naturally generalize over the array and the proof that <code>i</code> is in bounds.</li>
<li>An abstract length <code>len</code> is introduced to stand for <code>array.size</code>.
Proof automation is often better at working with explicit statements of equality.</li>
</ol>
<p>The resulting proof state shows the statement that will be used to generate the induction hypothesis, as well as the base case and the goal of the inductive step:</p>
<pre><code class="language-output error">unsolved goals
α : Type u_1
inst✝ : Ord α
len i : Nat
⊢ ∀ (arr : Array α) (isLt : i &lt; Array.size arr),
    Array.size arr = len → Array.size (insertSorted arr { val := i, isLt := isLt }) = len
</code></pre>
<p>Compare the statement with the goals that result from the <code>induction</code> tactic:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → arr.size = len →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  induction i with
  | zero =&gt; skip
  | succ i' ih =&gt; skip
</code></pre>
<p>In the base case, each occurrence of <code>i</code> has been replaced by <code>0</code>.
Using <code>intro</code> to introduce each assumption and then simplifying using <code>insertSorted</code> will prove the goal, because <code>insertSorted</code> at index <code>zero</code> returns its argument unchanged:</p>
<pre><code class="language-output error">unsolved goals
case zero
α : Type u_1
inst✝ : Ord α
len : Nat
⊢ ∀ (arr : Array α) (isLt : Nat.zero &lt; Array.size arr),
    Array.size arr = len → Array.size (insertSorted arr { val := Nat.zero, isLt := isLt }) = len
</code></pre>
<p>In the inductive step, the induction hypothesis has exactly the right strength.
It will be useful for <em>any</em> array, so long as that array has length <code>len</code>:</p>
<pre><code class="language-output error">unsolved goals
case succ
α : Type u_1
inst✝ : Ord α
len i' : Nat
ih :
  ∀ (arr : Array α) (isLt : i' &lt; Array.size arr),
    Array.size arr = len → Array.size (insertSorted arr { val := i', isLt := isLt }) = len
⊢ ∀ (arr : Array α) (isLt : Nat.succ i' &lt; Array.size arr),
    Array.size arr = len → Array.size (insertSorted arr { val := Nat.succ i', isLt := isLt }) = len
</code></pre>
<p>In the base case, <code>simp</code> reduces the goal to <code>arr.size = len</code>:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → arr.size = len →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  induction i with
  | zero =&gt;
    intro arr isLt hLen
    simp [insertSorted]
  | succ i' ih =&gt; skip
</code></pre>
<pre><code class="language-output error">unsolved goals
case zero
α : Type u_1
inst✝ : Ord α
len : Nat
arr : Array α
isLt : Nat.zero &lt; Array.size arr
hLen : Array.size arr = len
⊢ Array.size arr = len
</code></pre>
<p>This can be proved using the assumption <code>hLen</code>.
Adding the <code>*</code> parameter to <code>simp</code> instructs it to additionally use assumptions, which solves the goal:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → arr.size = len →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  induction i with
  | zero =&gt;
    intro arr isLt hLen
    simp [insertSorted, *]
  | succ i' ih =&gt; skip
</code></pre>
<p>In the inductive step, introducing assumptions and simplifying the goal results once again in a goal that contains a pattern match:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → (arr.size = len) →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  induction i with
  | zero =&gt;
    intro arr isLt hLen
    simp [insertSorted, *]
  | succ i' ih =&gt;
    intro arr isLt hLen
    simp [insertSorted]
</code></pre>
<pre><code class="language-output error">unsolved goals
case succ
α : Type u_1
inst✝ : Ord α
len i' : Nat
ih :
  ∀ (arr : Array α) (isLt : i' &lt; Array.size arr),
    Array.size arr = len → Array.size (insertSorted arr { val := i', isLt := isLt }) = len
arr : Array α
isLt : Nat.succ i' &lt; Array.size arr
hLen : Array.size arr = len
⊢ Array.size
      (match compare arr[i'] arr[{ val := Nat.succ i', isLt := isLt }] with
      | Ordering.lt =&gt; arr
      | Ordering.eq =&gt; arr
      | Ordering.gt =&gt;
        insertSorted
          (Array.swap arr { val := i', isLt := (_ : i' &lt; Array.size arr) } { val := Nat.succ i', isLt := isLt })
          { val := i',
            isLt :=
              (_ :
                i' &lt;
                  Array.size
                    (Array.swap arr { val := i', isLt := (_ : i' &lt; Array.size arr) }
                      { val := Nat.succ i', isLt := isLt })) }) =
    len
</code></pre>
<p>Using the <code>split</code> tactic results in one goal for each pattern.
Once again, the first two goals result from branches without recursive calls, so the induction hypothesis is not necessary:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → (arr.size = len) →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  induction i with
  | zero =&gt;
    intro arr isLt hLen
    simp [insertSorted, *]
  | succ i' ih =&gt;
    intro arr isLt hLen
    simp [insertSorted]
    split
</code></pre>
<pre><code class="language-output error">unsolved goals
case succ.h_1
α : Type u_1
inst✝ : Ord α
len i' : Nat
ih :
  ∀ (arr : Array α) (isLt : i' &lt; Array.size arr),
    Array.size arr = len → Array.size (insertSorted arr { val := i', isLt := isLt }) = len
arr : Array α
isLt : Nat.succ i' &lt; Array.size arr
hLen : Array.size arr = len
x✝ : Ordering
heq✝ : compare arr[i'] arr[{ val := Nat.succ i', isLt := isLt }] = Ordering.lt
⊢ Array.size arr = len

case succ.h_2
α : Type u_1
inst✝ : Ord α
len i' : Nat
ih :
  ∀ (arr : Array α) (isLt : i' &lt; Array.size arr),
    Array.size arr = len → Array.size (insertSorted arr { val := i', isLt := isLt }) = len
arr : Array α
isLt : Nat.succ i' &lt; Array.size arr
hLen : Array.size arr = len
x✝ : Ordering
heq✝ : compare arr[i'] arr[{ val := Nat.succ i', isLt := isLt }] = Ordering.eq
⊢ Array.size arr = len

case succ.h_3
α : Type u_1
inst✝ : Ord α
len i' : Nat
ih :
  ∀ (arr : Array α) (isLt : i' &lt; Array.size arr),
    Array.size arr = len → Array.size (insertSorted arr { val := i', isLt := isLt }) = len
arr : Array α
isLt : Nat.succ i' &lt; Array.size arr
hLen : Array.size arr = len
x✝ : Ordering
heq✝ : compare arr[i'] arr[{ val := Nat.succ i', isLt := isLt }] = Ordering.gt
⊢ Array.size
      (insertSorted
        (Array.swap arr { val := i', isLt := (_ : i' &lt; Array.size arr) } { val := Nat.succ i', isLt := isLt })
        { val := i',
          isLt :=
            (_ :
              i' &lt;
                Array.size
                  (Array.swap arr { val := i', isLt := (_ : i' &lt; Array.size arr) }
                    { val := Nat.succ i', isLt := isLt })) }) =
    len
</code></pre>
<p>Running <code>try assumption</code> in each goal that results from <code>split</code> eliminates both of the non-recursive goals:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → (arr.size = len) →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  induction i with
  | zero =&gt;
    intro arr isLt hLen
    simp [insertSorted, *]
  | succ i' ih =&gt;
    intro arr isLt hLen
    simp [insertSorted]
    split &lt;;&gt; try assumption
</code></pre>
<pre><code class="language-output error">unsolved goals
case succ.h_3
α : Type u_1
inst✝ : Ord α
len i' : Nat
ih :
  ∀ (arr : Array α) (isLt : i' &lt; Array.size arr),
    Array.size arr = len → Array.size (insertSorted arr { val := i', isLt := isLt }) = len
arr : Array α
isLt : Nat.succ i' &lt; Array.size arr
hLen : Array.size arr = len
x✝ : Ordering
heq✝ : compare arr[i'] arr[{ val := Nat.succ i', isLt := isLt }] = Ordering.gt
⊢ Array.size
      (insertSorted
        (Array.swap arr { val := i', isLt := (_ : i' &lt; Array.size arr) } { val := Nat.succ i', isLt := isLt })
        { val := i',
          isLt :=
            (_ :
              i' &lt;
                Array.size
                  (Array.swap arr { val := i', isLt := (_ : i' &lt; Array.size arr) }
                    { val := Nat.succ i', isLt := isLt })) }) =
    len
</code></pre>
<p>The new formulation of the proof goal, in which a constant <code>len</code> is used for the lengths of all the arrays involved in the recursive function, falls nicely within the kinds of problems that <code>simp</code> can solve.
This final proof goal can be solved by <code>simp [*]</code>, because the assumptions that relate the array's length to <code>len</code> are important:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → (arr.size = len) →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  induction i with
  | zero =&gt;
    intro arr isLt hLen
    simp [insertSorted, *]
  | succ i' ih =&gt;
    intro arr isLt hLen
    simp [insertSorted]
    split &lt;;&gt; try assumption
    simp [*]
</code></pre>
<p>Finally, because <code>simp [*]</code> can use assumptions, the <code>try assumption</code> line can be replaced by <code>simp [*]</code>, shortening the proof:</p>
<pre><code class="language-leantac">theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → (arr.size = len) →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  induction i with
  | zero =&gt;
    intro arr isLt hLen
    simp [insertSorted, *]
  | succ i' ih =&gt;
    intro arr isLt hLen
    simp [insertSorted]
    split &lt;;&gt; simp [*]
</code></pre>
<p>This proof can now be used to replace the <code>sorry</code> in <code>insertionSortLoop</code>.
Providing <code>arr.size</code> as the <code>len</code> argument to the theorem causes the final conclusion to be <code>(insertSorted arr ⟨i, isLt⟩).size = arr.size</code>, so the rewrite ends with a very manageable proof goal:</p>
<pre><code class="language-leantacnorfl">  def insertionSortLoop [Ord α] (arr : Array α) (i : Nat) : Array α :=
    if h : i &lt; arr.size then
      have : (insertSorted arr ⟨i, h⟩).size - (i + 1) &lt; arr.size - i := by
        rw [insert_sorted_size_eq arr.size i arr h rfl]
      insertionSortLoop (insertSorted arr ⟨i, h⟩) (i + 1)
    else
      arr
termination_by insertionSortLoop arr i =&gt; arr.size - i
</code></pre>
<pre><code class="language-output error">unsolved goals
α : Type ?u.22342
inst✝ : Ord α
arr : Array α
i : Nat
h : i &lt; Array.size arr
⊢ Array.size arr - (i + 1) &lt; Array.size arr - i
</code></pre>
<p>The proof <code>Nat.sub_succ_lt_self</code> is part of Lean's standard library.
It's type is <code>∀ (a i : Nat), i &lt; a → a - (i + 1) &lt; a - i</code>, which is exactly what's needed:</p>
<pre><code class="language-leantacnorfl">def insertionSortLoop [Ord α] (arr : Array α) (i : Nat) : Array α :=
  if h : i &lt; arr.size then
    have : (insertSorted arr ⟨i, h⟩).size - (i + 1) &lt; arr.size - i := by
      rw [insert_sorted_size_eq arr.size i arr h rfl]
      simp [Nat.sub_succ_lt_self, *]
    insertionSortLoop (insertSorted arr ⟨i, h⟩) (i + 1)
  else
    arr
termination_by insertionSortLoop arr i =&gt; arr.size - i
</code></pre>
<h2 id="the-driver-function"><a class="header" href="#the-driver-function">The Driver Function</a></h2>
<p>Insertion sort itself calls <code>insertionSortLoop</code>, initializing the index that demarcates the sorted region of the array from the unsorted region to <code>0</code>:</p>
<pre><code class="language-lean">def insertionSort [Ord α] (arr : Array α) : Array α :=
   insertionSortLoop arr 0
</code></pre>
<p>A few quick tests show the function is at least not blatantly wrong:</p>
<pre><code class="language-lean">#eval insertionSort #[3, 1, 7, 4]
</code></pre>
<pre><code class="language-output info">#[1, 3, 4, 7]
</code></pre>
<pre><code class="language-lean">#eval insertionSort #[ &quot;quartz&quot;, &quot;marble&quot;, &quot;granite&quot;, &quot;hematite&quot;]
</code></pre>
<pre><code class="language-output info">#[&quot;granite&quot;, &quot;hematite&quot;, &quot;marble&quot;, &quot;quartz&quot;]
</code></pre>
<h2 id="is-this-really-insertion-sort"><a class="header" href="#is-this-really-insertion-sort">Is This Really Insertion Sort?</a></h2>
<p>Insertion sort is <em>defined</em> to be an in-place sorting algorithm.
What makes it useful, despite its quadratic worst-case run time, is that it is a stable sorting algorithm that doesn't allocate extra space and that handles almost-sorted data efficiently.
If each iteration of the inner loop allocated a new array, then the algorithm wouldn't <em>really</em> be insertion sort.</p>
<p>Lean's array operations, such as <code>Array.set</code> and <code>Array.swap</code>, check whether the array in question has a reference count that is greater than one.
If so, then the array is visible to multiple parts of the code, which means that it must be copied.
Otherwise, Lean would no longer be a pure functional language.
However, when the reference count is exactly one, there are no other potential observers of the value.
In these cases, the array primitives mutate the array in place.
What other parts of the program don't know can't hurt them.</p>
<p>Lean's proof logic works at the level of pure functional programs, not the underlying implementation.
This means that the best way to discover whether a program unnecessarily copies data is to test it.
Adding calls to <code>dbgTraceIfShared</code> at each point where mutation is desired causes the provided message to be printed to <code>stderr</code> when the value in question has more than one reference.</p>
<p>Insertion sort has precisely one place that is at risk of copying rather than mutating: the call to <code>Array.swap</code>.
Replacing <code>arr.swap ⟨i', by assumption⟩ i</code> with <code>((dbgTraceIfShared &quot;array to swap&quot; arr).swap ⟨i', by assumption⟩ i)</code> causes the program to emit <code>shared RC array to swap</code> whenever it is unable to mutate the array.
However, this change to the program changes the proofs as well, because now there's a call to an additional function.
Because <code>dbgTraceIfShared</code> returns its second argument directly, adding it to the calls to <code>simp</code> is enough to fix the proofs.</p>
<p>The complete instrumented code for insertion sort is:</p>
<pre><code class="language-leantacnorfl">def insertSorted [Ord α] (arr : Array α) (i : Fin arr.size) : Array α :=
  match i with
  | ⟨0, _⟩ =&gt; arr
  | ⟨i' + 1, _⟩ =&gt;
    have : i' &lt; arr.size := by
      simp [Nat.lt_of_succ_lt, *]
    match Ord.compare arr[i'] arr[i] with
    | .lt | .eq =&gt; arr
    | .gt =&gt;
      insertSorted
        ((dbgTraceIfShared &quot;array to swap&quot; arr).swap ⟨i', by assumption⟩ i)
        ⟨i', by simp [dbgTraceIfShared, *]⟩

theorem insert_sorted_size_eq [Ord α] (len : Nat) (i : Nat) :
    (arr : Array α) → (isLt : i &lt; arr.size) → (arr.size = len) →
    (insertSorted arr ⟨i, isLt⟩).size = len := by
  induction i with
  | zero =&gt;
    intro arr isLt hLen
    simp [insertSorted, *]
  | succ i' ih =&gt;
    intro arr isLt hLen
    simp [insertSorted, dbgTraceIfShared]
    split &lt;;&gt; simp [*]

def insertionSortLoop [Ord α] (arr : Array α) (i : Nat) : Array α :=
  if h : i &lt; arr.size then
    have : (insertSorted arr ⟨i, h⟩).size - (i + 1) &lt; arr.size - i := by
      rw [insert_sorted_size_eq arr.size i arr h rfl]
      simp [Nat.sub_succ_lt_self, *]
    insertionSortLoop (insertSorted arr ⟨i, h⟩) (i + 1)
  else
    arr
termination_by insertionSortLoop arr i =&gt; arr.size - i

def insertionSort [Ord α] (arr : Array α) : Array α :=
  insertionSortLoop arr 0
</code></pre>
<p>A bit of cleverness is required to check whether the instrumentation actually works.
First off, the Lean compiler aggressively optimizes function calls away when all their arguments are known at compile time.
Simply writing a program that applies <code>insertionSort</code> to a large array is not sufficient, because the resulting compiled code may contain only the sorted array as a constant.
The easiest way to ensure that the compiler doesn't optimize away the sorting routine is to read the array from <code>stdin</code>.
Secondly, the compiler performs dead code elimination.
Adding extra <code>let</code>s to the program won't necessarily result in more references in running code if the <code>let</code>-bound variables are never used.
To ensure that the extra reference is not eliminated entirely, it's important to ensure that the extra reference is somehow used.</p>
<p>The first step in testing the instrumentation is to write <code>getLines</code>, which reads an array of lines from standard input:</p>
<pre><code class="language-lean">def getLines : IO (Array String) := do
  let stdin ← IO.getStdin
  let mut lines : Array String := #[]
  let mut currLine ← stdin.getLine
  while !currLine.isEmpty do
     -- Drop trailing newline:
    lines := lines.push (currLine.dropRight 1)
    currLine ← stdin.getLine
  pure lines
</code></pre>
<p><code>IO.FS.Stream.getLine</code> returns a complete line of text, including the trailing newline.
It returns <code>&quot;&quot;</code> when the end-of-file marker has been reached.</p>
<p>Next, two separate <code>main</code> routines are needed.
Both read the array to be sorted from standard input, ensuring that the calls to <code>insertionSort</code> won't be replaced by their return values at compile time.
Both then print to the console, ensuring that the calls to <code>insertionSort</code> won't be optimized away entirely.
One of them prints only the sorted array, while the other prints both the sorted array and the original array.
The second function should trigger a warning that <code>Array.swap</code> had to allocate a new array:</p>
<pre><code class="language-lean">def mainUnique : IO Unit := do
  let lines ← getLines
  for line in insertionSort lines do
    IO.println line

def mainShared : IO Unit := do
  let lines ← getLines
  IO.println &quot;--- Sorted lines: ---&quot;
  for line in insertionSort lines do
    IO.println line

  IO.println &quot;&quot;
  IO.println &quot;--- Original data: ---&quot;
  for line in lines do
    IO.println line
</code></pre>
<p>The actual <code>main</code> simply selects one of the two main actions based on the provided command-line arguments:</p>
<pre><code class="language-lean">def main (args : List String) : IO UInt32 := do
  match args with
  | [&quot;--shared&quot;] =&gt; mainShared; pure 0
  | [&quot;--unique&quot;] =&gt; mainUnique; pure 0
  | _ =&gt;
    IO.println &quot;Expected single argument, either \&quot;--shared\&quot; or \&quot;--unique\&quot;&quot;
    pure 1
</code></pre>
<p>Running it with no arguments produces the expected usage information:</p>
<pre><code>$ sort
Expected single argument, either &quot;--shared&quot; or &quot;--unique&quot;
</code></pre>
<p>The file <code>test-data</code> contains the following rocks:</p>
<pre><code>schist
feldspar
diorite
pumice
obsidian
shale
gneiss
marble
flint
</code></pre>
<p>Using the instrumented insertion sort on these rocks results them being printed in alphabetical order:</p>
<pre><code>$ sort --unique &lt; test-data
diorite
feldspar
flint
gneiss
marble
obsidian
pumice
schist
shale
</code></pre>
<p>However, the version in which a reference is retained to the original array results in a notification on <code>stderr</code> (namely, <code>shared RC array to swap</code>) from the first call to <code>Array.swap</code>:</p>
<pre><code>$ sort --shared &lt; test-data
shared RC array to swap
--- Sorted lines: ---
diorite
feldspar
flint
gneiss
marble
obsidian
pumice
schist
shale

--- Original data: ---
schist
feldspar
diorite
pumice
obsidian
shale
gneiss
marble
flint
</code></pre>
<p>The fact that only a single <code>shared RC</code> notification appears means that the array is copied only once.
This is because the copy that results from the call to <code>Array.swap</code> is itself unique, so no further copies need to be made.
In an imperative language, subtle bugs can result from forgetting to explicitly copy an array before passing it by reference.
When running <code>sort --shared</code>, the array is copied as needed to preserve the pure functional meaning of Lean programs, but no more.</p>
<h2 id="other-opportunities-for-mutation"><a class="header" href="#other-opportunities-for-mutation">Other Opportunities for Mutation</a></h2>
<p>The use of mutation instead of copying when references are unique is not limited to array update operators.
Lean also attempts to &quot;recycle&quot; constructors whose reference counts are about to fall to zero, reusing them instead of allocating new data.
This means, for instance, that <code>List.map</code> will mutate a linked list in place, at least in cases when nobody could possibly notice.
One of the most important steps in optimizing hot loops in Lean code is making sure that the data being modified is not referred to from multiple locations.</p>
<h2 id="exercises-26"><a class="header" href="#exercises-26">Exercises</a></h2>
<ul>
<li>
<p>Write a function that reverses arrays. Test that if the input array has a reference count of one, then your function does not allocate a new array.</p>
</li>
<li>
<p>Implement either merge sort or quicksort for arrays. Prove that your implementation terminates, and test that it doesn't allocate more arrays than expected. This is a challenging exercise!</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="special-types"><a class="header" href="#special-types">Special Types</a></h1>
<p>Understanding the representation of data in memory is very important.
Usually, the representation can be understood from the definition of a datatype.
Each constructor corresponds to an object in memory that has a header that includes a tag and a reference count.
The constructor's arguments are each represented by a pointer to some other object.
In other words, <code>List</code> really is a linked list and extracting a field from a <code>structure</code> really does just chase a pointer.</p>
<p>There are, however, some important exceptions to this rule.
A number of types are treated specially by the compiler.
For example, the type <code>UInt32</code> is defined as <code>Fin (2 ^ 32)</code>, but it is replaced at run-time with an actual native implementation based on machine words.
Similarly, even though the definition of <code>Nat</code> suggests an implementation similar to <code>List Unit</code>, the actual run-time representation uses immediate machine words for sufficiently-small numbers and an efficient arbitrary-precision arithmetic library for larger numbers.
The Lean compiler translates from definitions that use pattern matching into the appropriate operations for this representation, and calls to operations like addition and subtraction are mapped to fast operations from the underlying arithmetic library.
After all, addition should not take time linear in the size of the addends.</p>
<p>The fact that some types have special representations also means that care is needed when working with them.
Most of these types consist of a <code>structure</code> that is treated specially by the compiler.
With these structures, using the constructor or the field accessors directly can trigger an expensive conversion from an efficient representation to a slow one that is convenient for proofs.
For example, <code>String</code> is defined as a structure that contains a list of characters, but the run-time representation of strings uses UTF-8, not linked lists of pointers to characters.
Applying the constructor to a list of characters creates a byte array that encodes them in UTF-8, and accessing the field of the structure takes time linear in the length of the string to decode the UTF-8 representation and allocate a linked list.
Arrays are represented similarly.
From the logical perspective, arrays are structures that contain a list of array elements, but the run-time representation is a dynamically-sized array.
At run time, the constructor translates the list into an array, and the field accessor allocates a linked list from the array.
The various array operations are replaced with efficient versions by the compiler that mutate the array when possible instead of allocating a new one.</p>
<p>Both types themselves and proofs of propositions are completely erased from compiled code.
In other words, they take up no space, and any computations that might have been performed as part of a proof are similarly erased.
This means that proofs can take advantage of the convenient interface to strings and arrays as inductively-defined lists, including using induction to prove things about them, without imposing slow conversion steps while the program is running.
For these built-in types, a convenient logical representation of the data does not imply that the program must be slow.</p>
<p>If a structure type has only a single non-type non-proof field, then the constructor itself disappears at run time, being replaced with its single argument.
In other words, a subtype is represented identically to its underlying type, rather than with an extra layer of indirection.
Similarly, <code>Fin</code> is just <code>Nat</code> in memory, and single-field structures can be created to keep track of different uses of <code>Nat</code>s or <code>String</code>s without paying a performance penalty.
If a constructor has no non-type non-proof arguments, then the constructor also disappears and is replaced with a constant value where the pointer would otherwise be used.
This means that <code>true</code>, <code>false</code>, and <code>none</code> are constant values, rather than pointers to heap-allocated objects.</p>
<p>The following types have special representations:</p>
<table><thead><tr><th>Type</th><th>Logical representation</th><th>Run-time Representation</th></tr></thead><tbody>
<tr><td><code>Nat</code></td><td>Unary, with one pointer from each <code>Nat.succ</code></td><td>Efficient arbitrary-precision integers</td></tr>
<tr><td><code>Int</code></td><td>A sum type with constructors for positive or negative values, each containing a <code>Nat</code></td><td>Efficient arbitrary-precision integers</td></tr>
<tr><td><code>UInt8</code>, <code>UInt16</code>, <code>UInt32</code>, <code>UInt64</code></td><td>A <code>Fin</code> with an appropriate bound</td><td>Fixed-precision machine integers</td></tr>
<tr><td><code>Char</code></td><td>A <code>UInt32</code> paired with a proof that it's a valid code point</td><td>Ordinary characters</td></tr>
<tr><td><code>String</code></td><td>A structure that contains a <code>List Char</code> in a field called <code>data</code></td><td>UTF-8-encoded string</td></tr>
<tr><td><code>Array α</code></td><td>A structure that contains a <code>List α</code> in a field called <code>data</code></td><td>Packed arrays of pointers to <code>α</code> values</td></tr>
<tr><td><code>Sort u</code></td><td>A type</td><td>Erased completely</td></tr>
<tr><td>Proofs of propositions</td><td>Whatever data is suggested by the proposition when considered as a type of evidence</td><td>Erased completely</td></tr>
</tbody></table>
<h2 id="exercise-4"><a class="header" href="#exercise-4">Exercise</a></h2>
<p>The <a href="programs-proofs/../type-classes/pos.html">definition of <code>Pos</code></a> does not take advantage of Lean's compilation of <code>Nat</code> to an efficient type.
At run time, it is essentially a linked list.
Alternatively, a subtype can be defined that allows Lean's fast <code>Nat</code> type to be used internally, as described <a href="programs-proofs/../functor-applicative-monad/applicative.html#subtypes">in the initial section on subtypes</a>.
At run time, the proof will be erased.
Because the resulting structure has only a single data field, it is represented as that field, which means that this new representation of <code>Pos</code> is identical to that of <code>Nat</code>.</p>
<p>After proving the theorem <code>∀ {n k : Nat}, n ≠ 0 → k ≠ 0 → n + k ≠ 0</code>, define instances of <code>ToString</code>, and <code>Add</code> for this new representation of <code>Pos</code>. Then, define an instance of <code>Mul</code>, proving any necessary theorems along the way.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-7"><a class="header" href="#summary-7">Summary</a></h1>
<h2 id="tail-recursion-1"><a class="header" href="#tail-recursion-1">Tail Recursion</a></h2>
<p>Tail recursion is recursion in which the results of recursive calls are returned immediately, rather than being used in some other way.
These recursive calls are called <em>tail calls</em>.
Tail calls are interesting because they can be compiled to a jump instruction rather than a call instruction, and the current stack frame can be re-used instead of pushing a new frame.
In other words, tail-recursive functions are actually loops.</p>
<p>A common way to make a recursive function faster is to rewrite it in accumulator-passing style.
Instead of using the call stack to remember what is to be done with the result of a recursive call, an additional argument called an <em>accumulator</em> is used to collect this information.
For example, an accumulator for a tail-recursive function that reverses a list contains the already-seen list entries, in reverse order.</p>
<p>In Lean, only self-tail-calls are optimized into loops.
In other words, two functions that each end with a tail call to the other will not be optimized.</p>
<h2 id="reference-counting-and-in-place-updates"><a class="header" href="#reference-counting-and-in-place-updates">Reference Counting and In-Place Updates</a></h2>
<p>Rather than using a tracing garbage collector, as is done in Java, C#, and most JavaScript implementations, Lean uses reference counting for memory management.
This means that each value in memory contains a field that tracks how many other values refer to it, and the run-time system maintains these counts as references appear or disappear.
Reference counting is also used in Python, PHP, and Swift.</p>
<p>When asked to allocate a fresh object, Lean's run-time system is able to recycle existing objects whose reference counts are falling to zero.
Additionally, array operations such as <code>Array.set</code> and <code>Array.swap</code> will mutate an array if its reference count is one, rather than allocating a modified copy.
If <code>Array.swap</code> holds the only reference to an array, then no other part of the program can tell that it was mutated rather than copied.</p>
<p>Writing efficient code in Lean requires the use of tail recursion and being careful to ensure that large arrays are used uniquely.
While tail calls can be identified by inspecting the function's definition, understanding whether a value is referred to uniquely may require reading the whole program.
The debugging helper <code>dbgTraceIfShared</code> can be used at key locations in the program to check that a value is not shared.</p>
<h2 id="proving-programs-correct"><a class="header" href="#proving-programs-correct">Proving Programs Correct</a></h2>
<p>Rewriting a program in accumulator-passing style, or making other transformations that make it run faster, can also make it more difficult to understand.
It can be useful to keep the original version of the program that is more clearly correct, and then use it as an executable specification for the optimized version.
While techniques such as unit testing work just as well in Lean as in any other language, Lean also enables the use of mathematical proofs that completely ensure that both versions of the function return the same result for <em>all possible</em> inputs.</p>
<p>Typically, proving that two functions are equal is done using function extensionality (the <code>funext</code> tactic), which is the principle that two functions are equal if they return the same values for every input.
If the functions are recursive, then induction is usually a good way to prove that their outputs are the same.
Usually, the recursive definition of the function will make recursive calls on one particular argument; this argument is a good choice for induction.
In some cases, the induction hypothesis is not strong enough.
Fixing this problem usually requires thought about how to construct a more general version of the theorem statement that provides induction hypotheses that are strong enough.
In particular, to prove that a function is equivalent to an accumulator-passing version, a theorem statement that relates arbitrary initial accumulator values to the final result of the original function is needed.</p>
<h2 id="safe-array-indices-1"><a class="header" href="#safe-array-indices-1">Safe Array Indices</a></h2>
<p>The type <code>Fin n</code> represents natural numbers that are strictly less than <code>n</code>.
<code>Fin</code> is short for &quot;finite&quot;.
As with subtypes, a <code>Fin n</code> is a structure that contains a <code>Nat</code> and a proof that this <code>Nat</code> is less than <code>n</code>.
There are no values of type <code>Fin 0</code>.</p>
<p>If <code>arr</code> is an <code>Array α</code>, then <code>Fin arr.size</code> always contains a number that is a suitable index into <code>arr</code>.
Many of the built-in array operators, such as <code>Array.swap</code>, take <code>Fin</code> values as arguments rather than separated proof objects.</p>
<p>Lean provides instances of most of the useful numeric type classes for <code>Fin</code>.
The <code>OfNat</code> instances for <code>Fin</code> perform modular arithmetic rather than failing at compile time if the number provided is larger than the <code>Fin</code> can accept.</p>
<h2 id="provisional-proofs"><a class="header" href="#provisional-proofs">Provisional Proofs</a></h2>
<p>Sometimes, it can be useful to pretend that a statement is proved without actually doing the work of proving it.
This can be useful when making sure that a proof of a statement would be suitable for some task, such as a rewrite in another proof, determining that an array access is safe, or showing that a recursive call is made on a smaller value than the original argument.
It's very frustrating to spend time proving something, only to discover that some other proof would have been more useful.</p>
<p>The <code>sorry</code> tactic causes Lean to provisionally accept a statement as if it were a real proof.
It can be seen as analogous to a stub method that throws a <code>NotImplementedException</code> in C#.
Any proof that relies on <code>sorry</code> includes a warning in Lean.</p>
<p>Be careful!
The <code>sorry</code> tactic can prove <em>any</em> statement, even false statements.
Proving that <code>3 &lt; 2</code> can cause an out-of-bounds array access to persist to runtime, unexpectedly crashing a program.
Using <code>sorry</code> is convenient during development, but keeping it in the code is dangerous.</p>
<h2 id="proving-termination-1"><a class="header" href="#proving-termination-1">Proving Termination</a></h2>
<p>When a recursive function does not use structural recursion, Lean cannot automatically determine that it terminates.
In these situations, the function could just be marked <code>partial</code>.
However, it is also possible to provide a proof that the function terminates.</p>
<p>Partial functions have a key downside: they can't be unfolded during type checking or in proofs.
This means that Lean's value as an interactive theorem prover can't be applied to them.
Additionally, showing that a function that is expected to terminate actually always does terminate removes one more potential source of bugs.</p>
<p>The <code>termination_by</code> clause that's allowed at the end of a function can be used to specify the reason why a recursive function terminates.
The clause maps the function's arguments to an expression that is expected to be smaller for each recursive call.
Some examples of expressions that might decrease are the difference between a growing index into an array and the array's size, the length of a list that's cut in half at each recursive call, or a pair of lists, exactly one of which shrinks on each recursive call.</p>
<p>Lean contains proof automation that can automatically determine that some expressions shrink with each call, but many interesting programs will require manual proofs.
These proofs can be provided with <code>have</code>, a version of <code>let</code> that's intended for locally providing proofs rather than values.</p>
<p>A good way to write recursive functions is to begin by declaring them <code>partial</code> and debugging them with testing until they return the right answers.
Then, <code>partial</code> can be removed and replaced with a <code>termination_by</code> clause.
Lean will place error highlights on each recursive call for which a proof is needed that contains the statement that needs to be proved.
Each of these statements can be placed in a <code>have</code>, with the proof being <code>sorry</code>.
If Lean accepts the program and it still passes its tests, the final step is to actually prove the theorems that enable Lean to accept it.
This approach can prevent wasting time on proving that a buggy program terminates.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h1>
<p>This book introduces the very basics of functional programming in Lean, including a tiny amount of interactive theorem proving.
Using dependently-typed functional languages like Lean is a deep topic, and much can be said.
Depending on your interests, the following resources might be useful for learning Lean 4.</p>
<h2 id="learning-lean"><a class="header" href="#learning-lean">Learning Lean</a></h2>
<p>Lean 4 itself is described in the following resources:</p>
<ul>
<li><a href="https://leanprover.github.io/theorem_proving_in_lean4/">Theorem Proving in Lean 4</a> is a tutorial on writing proofs using Lean.</li>
<li><a href="https://leanprover.github.io/lean4/doc/">The Lean 4 Manual</a> provides a reference for the language and its features. At the time of writing, it is still incomplete, but it describes many aspects of Lean in greater detail than this book.</li>
<li><a href="https://djvelleman.github.io/HTPIwL/">How To Prove It With Lean</a> is a Lean-based accompaniment to the well-regarded textbook <a href="https://www.cambridge.org/highereducation/books/how-to-prove-it/6D2965D625C6836CD4A785A2C843B3DA#overview"><em>How To Prove It</em></a> that provides an introduction to writing paper-and-pencil mathematical proofs.</li>
<li><a href="https://github.com/arthurpaulino/lean4-metaprogramming-book">Metaprogramming in Lean 4</a> provides an overview of Lean's extension mechanisms, from infix operators and notations to macros, custom tactics, and full-on custom embedded languages.</li>
<li><a href="https://leanprover.github.io/functional_programming_in_lean/">Functional Programming in Lean</a> may be interesting to readers who enjoy jokes about recursion.</li>
</ul>
<p>However, the best way to continue learning Lean is to start reading and writing code, consulting the documentation when you get stuck.
Additionally, the <a href="https://leanprover.zulipchat.com/">Lean Zulip</a> is an excellent place to meet other Lean users, ask for help, and help others.</p>
<h2 id="the-standard-library"><a class="header" href="#the-standard-library">The Standard Library</a></h2>
<p>Out of the box, Lean itself includes a fairly minimal library.
Lean is self-hosted, and the included code is just enough to implement Lean itself.
For many applications, a larger standard library is needed.</p>
<p><a href="https://github.com/leanprover/std4">std4</a> is an in-progress standard library that includes many data structures, tactics, type class instances, and functions that are out of scope for the Lean compiler itself.
To use <code>std4</code>, the first step is to find a commit in its history that's compatible with the version of Lean 4 that you're using (that is, one in which the <code>lean-toolchain</code> file matches the one in your project).
Then, add the following to the top level of your <code>lakefile.lean</code>, where <code>COMMIT_HASH</code> is the appropriate version:</p>
<pre><code class="language-lean">require std from git
  &quot;https://github.com/leanprover/std4/&quot; @ &quot;COMMIT_HASH&quot;
</code></pre>
<h2 id="mathematics-in-lean"><a class="header" href="#mathematics-in-lean">Mathematics in Lean</a></h2>
<p>Most resources for mathematicians are written for Lean 3.
A wide selection are available at <a href="https://leanprover-community.github.io/learn.html">the community site</a>.
To get started doing mathematics in Lean 4, it is probably easiest to participate in the process of porting the mathematics library <code>mathlib</code> from Lean 3 to Lean 4.
Please see the <a href="https://github.com/leanprover-community/mathlib4"><code>mathlib4</code> README</a> for further information.</p>
<h2 id="using-dependent-types-in-computer-science"><a class="header" href="#using-dependent-types-in-computer-science">Using Dependent Types in Computer Science</a></h2>
<p>Coq is a language that has a lot in common with Lean.
For computer scientists, the <a href="https://softwarefoundations.cis.upenn.edu/">Software Foundations</a> series of interactive textbooks provides an excellent introduction to applications of Coq in computer science.
The fundamental ideas of Lean and Coq are very similar, and skills are readily transferable between the systems.</p>
<h2 id="programming-with-dependent-types-1"><a class="header" href="#programming-with-dependent-types-1">Programming with Dependent Types</a></h2>
<p>For programmers who are interested in learning to use indexed families and dependent types to structure programs, Edwin Brady's <a href="https://www.manning.com/books/type-driven-development-with-idris"><em>Type Driven Development with Idris</em></a> provides an excellent introduction.
Like Coq, Idris is a close cousin of Lean, though it lacks tactics.</p>
<h2 id="understanding-dependent-types"><a class="header" href="#understanding-dependent-types">Understanding Dependent Types</a></h2>
<p><a href="https://thelittletyper.com/"><em>The Little Typer</em></a> is a book for programmers who haven't formally studied logic or the theory of programming languages, but who want to build an understanding of the core ideas of dependent type theory.
While all of the above resources aim to be as practical as possible, <em>The Little Typer</em> presents an approach to dependent type theory where the very basics are built up from scratch, using only concepts from programming.
Disclaimer: the author of <em>Functional Programming in Lean</em> is also an author of <em>The Little Typer</em>.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
    </body>
</html>
